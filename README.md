CLASSIFICATION PROJECT
In this project, I presented the results of my analysis using three machine learning models: K-Nearest Neighbor (KNN), Logistic Regression, and Support Vector Machine (SVM). I used several libraries for my analysis, including Pandas to read dataframe, Numpy to create arrays, Scikit-learn for data shuffle, train test split, K-fold, evaluation metrics, classification report, confusion matrix, preprocessing, logistic regression, SVM model, and Matplotlib for scatter plot. I also used Itertools to iterate over all possible combinations of indices of a confusion matrix, creating a loop to annotate each cell of the confusion matrix with its corresponding value.

From the dataset analysis with these 3 models, I came to the conclusiom that all three models perform well on the given dataset, with accuracies ranging from 96% to 97%. The KNN model performs best in terms of precision for class 0, while the logistic regression and SVM models perform similarly in terms of precision for class 0 with the logistic regression model performing slightly better in terms of precision of class 1 than the other 2 models. Overall, the KNN, logistic regression and SVM models have similar performance across all evaluation metrics. However, it is important to note that the choice of model should be based on the specific problem and dataset, as each model has its own strengths and weaknesses.

MULTILAYER PERCEPTRON AND CNN MODEL FOR BALANCED EMNIST
In this report, I utilized the EMNIST dataset to train and test a Multilayer Perceptron and a Convoluted Neural network model. The EMNIST dataset is a set of handwritten character digits derived from the NIST Special Database 19 and converted to a 28x28 pixel image format and dataset structure that directly matches the MNIST dataset. The dataset consists of 6 splits, but I utilized the balanced dataset which addresses the balance issue in 2 of the splits.

Following the analysis, it was evident that the CNN model is computationally expensive to train than the MLP. Also, to deal with overfitting and underfitting, I deployed Early Stopping, which is a useful tool that monitors the validation loss during training and stops training when validation loss stops improving. In general, controlling complexity is very important to training models.

SEMANTIC SEGMENTATION WITH CAMBRIDGE LABELED OBJECTS IN VIDEO 
In this project, I utilised the Cambridge labelled objects in video dataset. This is a dataset of videos that have been annotated with semantic labels for each pixel. It consists of 700 images and 32 classes, including cars, pedestrians, and buildings. The images in this unique dataset were captured from a car driving through the iconic town of Cambridge in the United Kingdom. The dataset is popularly used for training and evaluating semantic segmentation algorithms. I used the mean intersection over union (mIoU) metric to evaluate the performance of the proposed architectures. The mIoU metric is a measure of the accuracy of a semantic segmentation algorithm. The higher the mIoU, the more accurate the algorithm.

I used the following architectures, FCN, UNet and Deeplabv3 and found that they achieve fair results on the Cambridge Labeled Objects in Video dataset. The FCN architecture achieved an mIoU of 64.4%, the DeepLabv3 architecture achieved an mIoU of 69.4%, and the UNet architecture achieved an mIoU of 71.8%. I drew the conclusion that the proposed architectures are effective for semantic segmentation. They also suggest that the proposed architectures could be used for other types of image segmentation, such as natural scene segmentation.
