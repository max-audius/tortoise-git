{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48ec8df",
   "metadata": {
    "id": "b48ec8df"
   },
   "source": [
    "# Set up Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5fe2e60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5fe2e60",
    "outputId": "0982d160-5ab8-4fb3-eb46-f5f3ccb826f4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tempfile\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "print(f' tensorflow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e12445",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyyaml h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356e08e7",
   "metadata": {
    "id": "356e08e7"
   },
   "outputs": [],
   "source": [
    "# Surpress warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c22472",
   "metadata": {
    "id": "23c22472"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca08c1",
   "metadata": {
    "id": "6eca08c1"
   },
   "outputs": [],
   "source": [
    "tmpdir = tempfile.gettempdir() # creating a temporary directory for storage\n",
    "# ds, info = tfds.load('emnist/balanced', split=['train', 'test'], shuffle_files=True, with_info=True, data_dir=tmpdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e09a9f",
   "metadata": {
    "id": "a6e09a9f"
   },
   "source": [
    "# Test-Train Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073f4953",
   "metadata": {
    "id": "073f4953"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_ds, info \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memnist/balanced\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, with_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_dir\u001b[38;5;241m=\u001b[39mtmpdir)\n\u001b[0;32m      2\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memnist/balanced\u001b[39m\u001b[38;5;124m'\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_dir\u001b[38;5;241m=\u001b[39mtmpdir)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds, info = tfds.load('emnist/balanced', split='train', shuffle_files=True, with_info=True, data_dir=tmpdir)\n",
    "test_ds = tfds.load('emnist/balanced', split='test', shuffle_files=True, data_dir=tmpdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2caba1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ea2caba1",
    "outputId": "506175be-3bfc-4827-aca8-bb1589d8c029"
   },
   "outputs": [],
   "source": [
    "# Get a random sample of 9 images from the training dataset\n",
    "sample = train_ds.shuffle(buffer_size=10000).take(9)\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "for img, ax in zip(sample, axes):\n",
    "    image = img['image'].numpy().reshape(28, 28)\n",
    "    label = chr(img['label'].numpy() + 96)\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(label)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995b54cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "995b54cf",
    "outputId": "8265a953-af65-4629-8ea0-f64c53459de1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get number of classes in dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[43minfo\u001b[49m\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_classes\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get number of samples in training and testing sets\u001b[39;00m\n\u001b[0;32m      5\u001b[0m num_train_samples \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39msplits[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnum_examples\n",
      "\u001b[1;31mNameError\u001b[0m: name 'info' is not defined"
     ]
    }
   ],
   "source": [
    "# Get number of classes in dataset\n",
    "num_classes = info.features['label'].num_classes\n",
    "\n",
    "# Get number of samples in training and testing sets\n",
    "num_train_samples = info.splits['train'].num_examples\n",
    "num_test_samples = info.splits['test'].num_examples\n",
    "\n",
    "print('Number of training samples in dataset:', num_train_samples)\n",
    "print('Number of testing samples in dataset:', num_test_samples)\n",
    "print('Number of classes in dataset:', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503f40bd",
   "metadata": {
    "id": "503f40bd"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "def preprocess(features):\n",
    "    # Get the images and labels from the dataset\n",
    "    images = []\n",
    "    labels = []\n",
    "    for example in features:\n",
    "        images.append(example['image'].numpy())\n",
    "        labels.append(example['label'].numpy())\n",
    "\n",
    "    # Convert the lists to numpy arrays\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Preprocess the images\n",
    "    images = images/255.0\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "ds_train_images, ds_train_labels = preprocess(train_ds)\n",
    "\n",
    "ds_test_images, ds_test_labels = preprocess(test_ds)\n",
    "\n",
    "# ds_train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b63965c",
   "metadata": {
    "id": "7b63965c"
   },
   "outputs": [],
   "source": [
    "# Define learning rate schedulers\n",
    "def scheduler1(epoch, lr):\n",
    "    \"\"\"Learning rate scheduler function\"\"\"\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "def scheduler2(epoch, lr, T=20, M=0.5):\n",
    "    \"\"\"Cosine annealing learning rate scheduler function\"\"\"\n",
    "    alpha = lr * M\n",
    "    cos_inner = (math.pi * epoch) / T\n",
    "    cos_out = math.cos(cos_inner) + 1\n",
    "    return alpha/2 * cos_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11796155",
   "metadata": {
    "id": "11796155"
   },
   "source": [
    "## Build an MLP model\n",
    "\n",
    "Build a `tf.keras.Sequential` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db8f8198",
   "metadata": {
    "id": "db8f8198"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters to be considered\n",
    "hyperparams = {                  #creating a dictionary to store hyperparameters\n",
    "    'optimizer': ['adam', 'sgd', 'adagrad'], # explore at least 3 optimizers\n",
    "    'batchNorm': [True, False],              # with or without batch normalization\n",
    "    'dropOut': [True, False],                # with or without dropout\n",
    "    'reg': [None, regularizers.l1(0.001), regularizers.l2(0.001)], # with or without regularization\n",
    "    'activation': ['relu', 'elu', 'leaky_relu'] # exploring at least 3 activation functions\n",
    "}\n",
    "\n",
    "# create a dictionary to map the activation functions to hyperparams \n",
    "# because leaky relu and elu are not built-in functions\n",
    "activation_function = {\n",
    "    'relu': tf.nn.relu,\n",
    "    'elu': tf.nn.elu,\n",
    "    'leaky_relu': tf.nn.leaky_relu\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f323ebd",
   "metadata": {
    "id": "2f323ebd"
   },
   "outputs": [],
   "source": [
    "\n",
    "def mlp_model(optimizer, batchNorm, dropOut, activation, reg):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation_function[activation], kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dense(64, activation_function[activation], kernel_regularizer=reg),\n",
    "        tf.keras.layers.Dense(32, activation_function[activation], kernel_regularizer=reg),\n",
    "    ])\n",
    "    \n",
    "    if batchNorm:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    if dropOut:\n",
    "        model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(info.features['label'].num_classes))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9297cd",
   "metadata": {
    "id": "be9297cd"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69a5879f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "69a5879f",
    "outputId": "d4cb6824-b680-43a0-f778-151cf7dd7d91"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "\n",
    "# define the splits for cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "schedulers = [scheduler1, scheduler2]   # creating a list of learning rate schedulers\n",
    "\n",
    "# initializing the basis for the best combination\n",
    "best_model = None \n",
    "best_acc = 0.0            # best accuracy\n",
    "\n",
    "for params in itertools.product(*hyperparams.values()): # performing a grid search\n",
    "    param_dict = dict(zip(hyperparams.keys(), params))  # producing a combo of all possible hyperparams\n",
    "    accuracies = []\n",
    "    for train_index, val_index in kf.split(ds_train_images):\n",
    "        # Split data into training and validation sets\n",
    "\n",
    "        new_train_ds, new_train_labels = ds_train_images[train_index], ds_train_labels[train_index]\n",
    "        new_val_ds, new_val_labels = ds_train_images[val_index], ds_train_labels[val_index]\n",
    "        model = mlp_model(**param_dict) # double asterix to unpack key-value pairs in dictionary\n",
    "        \n",
    "        for scheduler in schedulers:\n",
    "            # define the learning rate schedulers\n",
    "            lr_scheduler = LearningRateScheduler(scheduler)\n",
    "            # train the model\n",
    "            start_time = datetime.datetime.now()            # start the timer\n",
    "            # history = model.fit(train_ds.batch(128),\n",
    "            history = model.fit(new_train_ds, new_train_labels, batch_size=128,\n",
    "                                     epochs=20,\n",
    "                                     validation_data=(new_val_ds, new_val_labels),\n",
    "                                     callbacks=[lr_scheduler, early_stopping])\n",
    "            accuracies.append(history.history['val_accuracy'][-1])\n",
    "            end_time = datetime.datetime.now()             # end timer\n",
    "            total_time = end_time - start_time\n",
    "            print(f' Hyperparameter combinations for training, {param_dict}')\n",
    "            print(f' Training time for the model is, {total_time}')\n",
    "            \n",
    "            \n",
    "    avg_acc = np.mean(accuracies)\n",
    "    \n",
    "    # To ascertain if current set of hyperparameters are best\n",
    "    if avg_acc > best_acc:\n",
    "        best_acc = avg_acc\n",
    "        best_model = mlp_model(**param_dict)\n",
    "    \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d1b46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
    "best_model.save(\"best_model.h5\")\n",
    "saved_model = keras.models.load_model(\"best_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61ba0826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 1.7465 - accuracy: 0.5951 - val_loss: 0.9993 - val_accuracy: 0.7560\n",
      "Epoch 2/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.9914 - accuracy: 0.7528 - val_loss: 0.7931 - val_accuracy: 0.8043\n",
      "Epoch 3/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.8591 - accuracy: 0.7818 - val_loss: 0.7837 - val_accuracy: 0.7984\n",
      "Epoch 4/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.7999 - accuracy: 0.7944 - val_loss: 0.6805 - val_accuracy: 0.8287\n",
      "Epoch 5/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.7593 - accuracy: 0.8026 - val_loss: 0.6799 - val_accuracy: 0.8247\n",
      "Epoch 6/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.7355 - accuracy: 0.8092 - val_loss: 0.6554 - val_accuracy: 0.8307\n",
      "Epoch 7/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.7143 - accuracy: 0.8143 - val_loss: 0.6154 - val_accuracy: 0.8390\n",
      "Epoch 8/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.7005 - accuracy: 0.8162 - val_loss: 0.6091 - val_accuracy: 0.8451\n",
      "Epoch 9/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6870 - accuracy: 0.8196 - val_loss: 0.6203 - val_accuracy: 0.8346\n",
      "Epoch 10/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6782 - accuracy: 0.8227 - val_loss: 0.6051 - val_accuracy: 0.8415\n",
      "Epoch 11/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6684 - accuracy: 0.8250 - val_loss: 0.5749 - val_accuracy: 0.8513\n",
      "Epoch 12/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6664 - accuracy: 0.8247 - val_loss: 0.5825 - val_accuracy: 0.8478\n",
      "Epoch 13/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6542 - accuracy: 0.8273 - val_loss: 0.5913 - val_accuracy: 0.8433\n",
      "Epoch 14/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6511 - accuracy: 0.8299 - val_loss: 0.5651 - val_accuracy: 0.8527\n",
      "Epoch 15/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6484 - accuracy: 0.8289 - val_loss: 0.5822 - val_accuracy: 0.8482\n",
      "Epoch 16/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6411 - accuracy: 0.8319 - val_loss: 0.5599 - val_accuracy: 0.8545\n",
      "Epoch 17/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6404 - accuracy: 0.8316 - val_loss: 0.5594 - val_accuracy: 0.8533\n",
      "Epoch 18/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6379 - accuracy: 0.8319 - val_loss: 0.5804 - val_accuracy: 0.8438\n",
      "Epoch 19/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6343 - accuracy: 0.8330 - val_loss: 0.5773 - val_accuracy: 0.8457\n",
      "Epoch 20/20\n",
      "882/882 [==============================] - 2s 2ms/step - loss: 0.6324 - accuracy: 0.8343 - val_loss: 0.5544 - val_accuracy: 0.8570\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = best_model.fit(ds_train_images, ds_train_labels, batch_size=128,\n",
    "                             epochs=20,\n",
    "                             validation_data=(new_val_ds, new_val_labels))\n",
    "\n",
    "\n",
    "# plot the loss and accuracy graphs\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss function graph respect to the iteration/epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy graph respect to the iteration/epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac25b8c",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ead4fc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588/588 - 0s - loss: 0.6636 - accuracy: 0.8287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6636008024215698, 0.8287234306335449]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(ds_test_images, ds_test_labels, verbose=2) # evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3a32f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = best_model.predict(ds_test_images)\n",
    "\n",
    "#manual\n",
    "# idx = np.argmax(result, axis = 1)\n",
    "# resultValue = []\n",
    "# for i in range(len(result)):\n",
    "#   resultValue.append(result[i][idx[i]])\n",
    "# resultValue = np.array(resultValue)\n",
    "\n",
    "#same with above\n",
    "resultValue = [max(row) for row in result]\n",
    "resultValue = np.array(resultValue)\n",
    "\n",
    "# Getting indices of N = 6 maximum values\n",
    "six_best = np.argsort(resultValue)[::-1][:6]\n",
    "\n",
    "# Getting N maximum values\n",
    "# resultValue[six_best]\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "for img, label, value, ax in zip(ds_test_images[six_best], ds_test_labels[six_best], resultValue[six_best], axes):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(str(label) + \"\\nscore:\" + str(value))\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbb4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the predictions of the best model on the testing dataset\n",
    "# test_pred = best_model.predict(ds_test_images)\n",
    "\n",
    "# # get the indices of the top six samples with highest prediction scores\n",
    "# top_six_indices = np.argsort(test_pred, axis=0)[-6:][::-1].flatten()\n",
    "\n",
    "# for index in top_six_indices:\n",
    "#     pred = np.argmax(test_pred[index])\n",
    "#     true = ds_test_labels[index]\n",
    "#     print(f'Sample {index}: Prediction: {pred}, True Label: {true}')\n",
    "#     img = ds_test_images[index]\n",
    "\n",
    "#     # plot the image\n",
    "#     plt.imshow(img, cmap='gray')\n",
    "#     plt.title(f'True Label: {true}')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3139cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[319   0   0 ...   0   1   0]\n",
      " [  0 245   1 ...   0   1   1]\n",
      " [  0   0 315 ...   1   0   0]\n",
      " ...\n",
      " [  0   0   0 ... 213   0   1]\n",
      " [  0   1   0 ...   0 342   2]\n",
      " [  0   0   0 ...   0   2 348]]\n",
      "\n",
      "Precision: 0.831\n",
      "Recall: 0.829\n",
      "F1 Score: 0.827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# get the predicted labels\n",
    "y_pred_labels = np.argmax(result, axis=1)\n",
    "\n",
    "# calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(ds_test_labels, y_pred_labels)\n",
    "\n",
    "# calculate the precision, recall, and F1 score\n",
    "precision = precision_score(ds_test_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(ds_test_labels, y_pred_labels, average='weighted')\n",
    "f1 = f1_score(ds_test_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "# print the confusion matrix and the metrics\n",
    "print(f\"Confusion matrix:\\n{conf_mat}\\n\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fd260",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1136b",
   "metadata": {},
   "source": [
    "### building the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6639936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(optimizer, batchNorm, dropOut, activation, reg):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(32, kernel_size=(3, 3), activation=activation_function[activation], input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3, 3), activation=activation_function[activation]))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=activation_function[activation], kernel_regularizer=reg))\n",
    "    \n",
    "    if batchNorm:\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    if dropOut:\n",
    "        model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(info.features['label'].num_classes))\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                 loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaa0ea5",
   "metadata": {},
   "source": [
    "### Training the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1ba970a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8412 - accuracy: 0.7636 - val_loss: 0.4716 - val_accuracy: 0.8439\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4511 - accuracy: 0.8488 - val_loss: 0.4038 - val_accuracy: 0.8582\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3873 - accuracy: 0.8658 - val_loss: 0.3732 - val_accuracy: 0.8703\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3507 - accuracy: 0.8768 - val_loss: 0.3799 - val_accuracy: 0.8666\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3258 - accuracy: 0.8824 - val_loss: 0.3510 - val_accuracy: 0.8777\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3020 - accuracy: 0.8897 - val_loss: 0.3558 - val_accuracy: 0.8727\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2791 - accuracy: 0.8967 - val_loss: 0.3541 - val_accuracy: 0.8778\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2609 - accuracy: 0.9012 - val_loss: 0.3447 - val_accuracy: 0.8798\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2464 - accuracy: 0.9053 - val_loss: 0.3568 - val_accuracy: 0.8770\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2299 - accuracy: 0.9115 - val_loss: 0.3454 - val_accuracy: 0.8808\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2185 - accuracy: 0.9155 - val_loss: 0.3466 - val_accuracy: 0.8825\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2025 - accuracy: 0.9206 - val_loss: 0.3560 - val_accuracy: 0.8790\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1928 - accuracy: 0.9246 - val_loss: 0.3553 - val_accuracy: 0.8813\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1839 - accuracy: 0.9271 - val_loss: 0.3550 - val_accuracy: 0.8779\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:06:30.927219\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1905 - accuracy: 0.9262 - val_loss: 0.3371 - val_accuracy: 0.8855\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1773 - accuracy: 0.9309 - val_loss: 0.3363 - val_accuracy: 0.8863\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1722 - accuracy: 0.9332 - val_loss: 0.3373 - val_accuracy: 0.8851\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1677 - accuracy: 0.9349 - val_loss: 0.3373 - val_accuracy: 0.8852\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1664 - accuracy: 0.9356 - val_loss: 0.3376 - val_accuracy: 0.8855\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:24.072321\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7692 - accuracy: 0.7753 - val_loss: 0.4643 - val_accuracy: 0.8449\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4330 - accuracy: 0.8548 - val_loss: 0.3984 - val_accuracy: 0.8621\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3702 - accuracy: 0.8702 - val_loss: 0.3795 - val_accuracy: 0.8665\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3373 - accuracy: 0.8792 - val_loss: 0.3581 - val_accuracy: 0.8762\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3128 - accuracy: 0.8856 - val_loss: 0.3619 - val_accuracy: 0.8714\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2887 - accuracy: 0.8931 - val_loss: 0.3520 - val_accuracy: 0.8729\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2690 - accuracy: 0.8987 - val_loss: 0.3556 - val_accuracy: 0.8749\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:21.747003\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.2862 - accuracy: 0.8954 - val_loss: 0.3315 - val_accuracy: 0.8822\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2572 - accuracy: 0.9048 - val_loss: 0.3263 - val_accuracy: 0.8826\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2412 - accuracy: 0.9099 - val_loss: 0.3218 - val_accuracy: 0.8814\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2335 - accuracy: 0.9137 - val_loss: 0.3219 - val_accuracy: 0.8836\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.2287 - accuracy: 0.9151 - val_loss: 0.3213 - val_accuracy: 0.8829\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2264 - accuracy: 0.9149 - val_loss: 0.3213 - val_accuracy: 0.8835\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2256 - accuracy: 0.9160 - val_loss: 0.3214 - val_accuracy: 0.8833\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:21.261970\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7726 - accuracy: 0.7732 - val_loss: 0.4775 - val_accuracy: 0.8441\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4395 - accuracy: 0.8514 - val_loss: 0.4170 - val_accuracy: 0.8564\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3787 - accuracy: 0.8677 - val_loss: 0.3837 - val_accuracy: 0.8714\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3423 - accuracy: 0.8771 - val_loss: 0.3847 - val_accuracy: 0.8692\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3202 - accuracy: 0.8831 - val_loss: 0.3686 - val_accuracy: 0.8746\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2912 - accuracy: 0.8910 - val_loss: 0.3800 - val_accuracy: 0.8700\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2696 - accuracy: 0.8982 - val_loss: 0.3574 - val_accuracy: 0.8758\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2494 - accuracy: 0.9051 - val_loss: 0.3724 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2356 - accuracy: 0.9087 - val_loss: 0.3719 - val_accuracy: 0.8743\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2194 - accuracy: 0.9141 - val_loss: 0.3667 - val_accuracy: 0.8757\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:37.067026\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2296 - accuracy: 0.9120 - val_loss: 0.3495 - val_accuracy: 0.8802\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2101 - accuracy: 0.9198 - val_loss: 0.3417 - val_accuracy: 0.8837\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2013 - accuracy: 0.9227 - val_loss: 0.3396 - val_accuracy: 0.8836\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1949 - accuracy: 0.9254 - val_loss: 0.3412 - val_accuracy: 0.8846\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1913 - accuracy: 0.9263 - val_loss: 0.3413 - val_accuracy: 0.8845\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1917 - accuracy: 0.9264 - val_loss: 0.3413 - val_accuracy: 0.8845\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1900 - accuracy: 0.9267 - val_loss: 0.3414 - val_accuracy: 0.8846\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:13.494625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7922 - accuracy: 0.7703 - val_loss: 0.4760 - val_accuracy: 0.8430\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4400 - accuracy: 0.8510 - val_loss: 0.4158 - val_accuracy: 0.8583\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3784 - accuracy: 0.8692 - val_loss: 0.3765 - val_accuracy: 0.8706\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3416 - accuracy: 0.8771 - val_loss: 0.3706 - val_accuracy: 0.8724\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3177 - accuracy: 0.8848 - val_loss: 0.3675 - val_accuracy: 0.8720\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2918 - accuracy: 0.8924 - val_loss: 0.3479 - val_accuracy: 0.8762\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2708 - accuracy: 0.8977 - val_loss: 0.3458 - val_accuracy: 0.8831\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2504 - accuracy: 0.9042 - val_loss: 0.3493 - val_accuracy: 0.8824\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2350 - accuracy: 0.9099 - val_loss: 0.3492 - val_accuracy: 0.8805\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2182 - accuracy: 0.9159 - val_loss: 0.3516 - val_accuracy: 0.8805\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:35.247391\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2308 - accuracy: 0.9120 - val_loss: 0.3282 - val_accuracy: 0.8871\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2109 - accuracy: 0.9194 - val_loss: 0.3265 - val_accuracy: 0.8878\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2014 - accuracy: 0.9227 - val_loss: 0.3247 - val_accuracy: 0.8892\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1960 - accuracy: 0.9249 - val_loss: 0.3248 - val_accuracy: 0.8891\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1927 - accuracy: 0.9272 - val_loss: 0.3247 - val_accuracy: 0.8885\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1922 - accuracy: 0.9264 - val_loss: 0.3249 - val_accuracy: 0.8884\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:42.324776\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7868 - accuracy: 0.7690 - val_loss: 0.4628 - val_accuracy: 0.8430\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4382 - accuracy: 0.8516 - val_loss: 0.4492 - val_accuracy: 0.8451\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3786 - accuracy: 0.8677 - val_loss: 0.3739 - val_accuracy: 0.8667\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3437 - accuracy: 0.8785 - val_loss: 0.3744 - val_accuracy: 0.8697\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3196 - accuracy: 0.8848 - val_loss: 0.3428 - val_accuracy: 0.8786\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2940 - accuracy: 0.8916 - val_loss: 0.3479 - val_accuracy: 0.8769\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2733 - accuracy: 0.8979 - val_loss: 0.3479 - val_accuracy: 0.8773\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2538 - accuracy: 0.9036 - val_loss: 0.3521 - val_accuracy: 0.8765\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:42.279575\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2714 - accuracy: 0.8994 - val_loss: 0.3241 - val_accuracy: 0.8859\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2453 - accuracy: 0.9083 - val_loss: 0.3183 - val_accuracy: 0.8862\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2328 - accuracy: 0.9130 - val_loss: 0.3157 - val_accuracy: 0.8866\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2242 - accuracy: 0.9160 - val_loss: 0.3144 - val_accuracy: 0.8863\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2222 - accuracy: 0.9168 - val_loss: 0.3142 - val_accuracy: 0.8872\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2195 - accuracy: 0.9176 - val_loss: 0.3143 - val_accuracy: 0.8871\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2202 - accuracy: 0.9166 - val_loss: 0.3144 - val_accuracy: 0.8873\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2178 - accuracy: 0.9182 - val_loss: 0.3144 - val_accuracy: 0.8873\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2180 - accuracy: 0.9183 - val_loss: 0.3145 - val_accuracy: 0.8872\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2179 - accuracy: 0.9179 - val_loss: 0.3144 - val_accuracy: 0.8873\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:36.849812\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7819 - accuracy: 0.7639 - val_loss: 0.5601 - val_accuracy: 0.8195\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4945 - accuracy: 0.8363 - val_loss: 0.5142 - val_accuracy: 0.8336\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4371 - accuracy: 0.8516 - val_loss: 0.4934 - val_accuracy: 0.8381\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4012 - accuracy: 0.8627 - val_loss: 0.5548 - val_accuracy: 0.8166\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3725 - accuracy: 0.8686 - val_loss: 0.4163 - val_accuracy: 0.8601\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3438 - accuracy: 0.8767 - val_loss: 0.3943 - val_accuracy: 0.8682\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3214 - accuracy: 0.8829 - val_loss: 0.3982 - val_accuracy: 0.8638\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2994 - accuracy: 0.8905 - val_loss: 0.4145 - val_accuracy: 0.8600\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2807 - accuracy: 0.8963 - val_loss: 0.3869 - val_accuracy: 0.8743\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2653 - accuracy: 0.9006 - val_loss: 0.3940 - val_accuracy: 0.8681\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2500 - accuracy: 0.9052 - val_loss: 0.3944 - val_accuracy: 0.8690\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2357 - accuracy: 0.9097 - val_loss: 0.3969 - val_accuracy: 0.8680\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:37.707260\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2454 - accuracy: 0.9077 - val_loss: 0.3668 - val_accuracy: 0.8787\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2301 - accuracy: 0.9132 - val_loss: 0.3664 - val_accuracy: 0.8792\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2221 - accuracy: 0.9167 - val_loss: 0.3663 - val_accuracy: 0.8805\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2174 - accuracy: 0.9175 - val_loss: 0.3657 - val_accuracy: 0.8801\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2159 - accuracy: 0.9190 - val_loss: 0.3660 - val_accuracy: 0.8801\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2130 - accuracy: 0.9196 - val_loss: 0.3661 - val_accuracy: 0.8798\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:48.780710\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7812 - accuracy: 0.7636 - val_loss: 0.5629 - val_accuracy: 0.8200\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4903 - accuracy: 0.8378 - val_loss: 0.4810 - val_accuracy: 0.8412\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4363 - accuracy: 0.8520 - val_loss: 0.4774 - val_accuracy: 0.8413\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3998 - accuracy: 0.8633 - val_loss: 0.4779 - val_accuracy: 0.8402\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3749 - accuracy: 0.8688 - val_loss: 0.4945 - val_accuracy: 0.8317\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3469 - accuracy: 0.8762 - val_loss: 0.4729 - val_accuracy: 0.8473\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3207 - accuracy: 0.8845 - val_loss: 0.3930 - val_accuracy: 0.8657\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3004 - accuracy: 0.8910 - val_loss: 0.3813 - val_accuracy: 0.8691\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2825 - accuracy: 0.8950 - val_loss: 0.3879 - val_accuracy: 0.8694\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2669 - accuracy: 0.8998 - val_loss: 0.3796 - val_accuracy: 0.8687\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2492 - accuracy: 0.9059 - val_loss: 0.3969 - val_accuracy: 0.8681\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2368 - accuracy: 0.9091 - val_loss: 0.3847 - val_accuracy: 0.8738\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2250 - accuracy: 0.9134 - val_loss: 0.3936 - val_accuracy: 0.8677\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2130 - accuracy: 0.9166 - val_loss: 0.3901 - val_accuracy: 0.8688\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2046 - accuracy: 0.9202 - val_loss: 0.3898 - val_accuracy: 0.8692\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:06:55.448491\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2112 - accuracy: 0.9192 - val_loss: 0.3693 - val_accuracy: 0.8787\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1980 - accuracy: 0.9241 - val_loss: 0.3694 - val_accuracy: 0.8796\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1931 - accuracy: 0.9255 - val_loss: 0.3695 - val_accuracy: 0.8792\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1892 - accuracy: 0.9265 - val_loss: 0.3682 - val_accuracy: 0.8782\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1884 - accuracy: 0.9277 - val_loss: 0.3691 - val_accuracy: 0.8786\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:18.526518\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7911 - accuracy: 0.7626 - val_loss: 0.5130 - val_accuracy: 0.8320\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4944 - accuracy: 0.8362 - val_loss: 0.4704 - val_accuracy: 0.8465\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4363 - accuracy: 0.8524 - val_loss: 0.4461 - val_accuracy: 0.8532\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3991 - accuracy: 0.8617 - val_loss: 0.4431 - val_accuracy: 0.8509\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3724 - accuracy: 0.8686 - val_loss: 0.4528 - val_accuracy: 0.8539\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3458 - accuracy: 0.8768 - val_loss: 0.4990 - val_accuracy: 0.8395\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3200 - accuracy: 0.8843 - val_loss: 0.4119 - val_accuracy: 0.8601\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2999 - accuracy: 0.8902 - val_loss: 0.3968 - val_accuracy: 0.8672\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2833 - accuracy: 0.8935 - val_loss: 0.4166 - val_accuracy: 0.8644\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2669 - accuracy: 0.9001 - val_loss: 0.3968 - val_accuracy: 0.8694\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2508 - accuracy: 0.9046 - val_loss: 0.3859 - val_accuracy: 0.8723\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2380 - accuracy: 0.9082 - val_loss: 0.4054 - val_accuracy: 0.8708\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2271 - accuracy: 0.9120 - val_loss: 0.3939 - val_accuracy: 0.8707\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2162 - accuracy: 0.9157 - val_loss: 0.4030 - val_accuracy: 0.8682\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:06:25.947651\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2224 - accuracy: 0.9147 - val_loss: 0.3760 - val_accuracy: 0.8756\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2076 - accuracy: 0.9212 - val_loss: 0.3750 - val_accuracy: 0.8754\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2015 - accuracy: 0.9223 - val_loss: 0.3745 - val_accuracy: 0.8758\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1999 - accuracy: 0.9236 - val_loss: 0.3753 - val_accuracy: 0.8762\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1968 - accuracy: 0.9246 - val_loss: 0.3744 - val_accuracy: 0.8758\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1953 - accuracy: 0.9250 - val_loss: 0.3748 - val_accuracy: 0.8759\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1963 - accuracy: 0.9241 - val_loss: 0.3749 - val_accuracy: 0.8758\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:13.090768\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7939 - accuracy: 0.7611 - val_loss: 0.8976 - val_accuracy: 0.7109\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4992 - accuracy: 0.8362 - val_loss: 0.5039 - val_accuracy: 0.8369\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4440 - accuracy: 0.8507 - val_loss: 0.4429 - val_accuracy: 0.8529\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4064 - accuracy: 0.8617 - val_loss: 0.4771 - val_accuracy: 0.8382\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3789 - accuracy: 0.8686 - val_loss: 0.3962 - val_accuracy: 0.8633\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3537 - accuracy: 0.8748 - val_loss: 0.4072 - val_accuracy: 0.8624\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3298 - accuracy: 0.8825 - val_loss: 0.3984 - val_accuracy: 0.8600\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3076 - accuracy: 0.8885 - val_loss: 0.3865 - val_accuracy: 0.8643\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2896 - accuracy: 0.8940 - val_loss: 0.4309 - val_accuracy: 0.8518\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2723 - accuracy: 0.8993 - val_loss: 0.4013 - val_accuracy: 0.8645\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2570 - accuracy: 0.9038 - val_loss: 0.3797 - val_accuracy: 0.8715\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2431 - accuracy: 0.9081 - val_loss: 0.3942 - val_accuracy: 0.8676\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2336 - accuracy: 0.9110 - val_loss: 0.3823 - val_accuracy: 0.8686\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2201 - accuracy: 0.9157 - val_loss: 0.3784 - val_accuracy: 0.8733\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2111 - accuracy: 0.9184 - val_loss: 0.4049 - val_accuracy: 0.8686\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2030 - accuracy: 0.9212 - val_loss: 0.3863 - val_accuracy: 0.8731\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1957 - accuracy: 0.9243 - val_loss: 0.3855 - val_accuracy: 0.8741\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1863 - accuracy: 0.9273 - val_loss: 0.3963 - val_accuracy: 0.8691\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1805 - accuracy: 0.9294 - val_loss: 0.3954 - val_accuracy: 0.8691\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1761 - accuracy: 0.9315 - val_loss: 0.3976 - val_accuracy: 0.8687\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:11.537263\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1769 - accuracy: 0.9317 - val_loss: 0.3827 - val_accuracy: 0.8745\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1701 - accuracy: 0.9337 - val_loss: 0.3826 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1685 - accuracy: 0.9347 - val_loss: 0.3833 - val_accuracy: 0.8746\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1653 - accuracy: 0.9359 - val_loss: 0.3823 - val_accuracy: 0.8746\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1640 - accuracy: 0.9366 - val_loss: 0.3821 - val_accuracy: 0.8748\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:15.267724\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8013 - accuracy: 0.7600 - val_loss: 0.5235 - val_accuracy: 0.8291\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5028 - accuracy: 0.8351 - val_loss: 0.5115 - val_accuracy: 0.8284\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4462 - accuracy: 0.8509 - val_loss: 0.4710 - val_accuracy: 0.8401\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4116 - accuracy: 0.8595 - val_loss: 0.4870 - val_accuracy: 0.8399\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3817 - accuracy: 0.8672 - val_loss: 0.4402 - val_accuracy: 0.8536\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3561 - accuracy: 0.8754 - val_loss: 0.4249 - val_accuracy: 0.8546\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3301 - accuracy: 0.8823 - val_loss: 0.3997 - val_accuracy: 0.8631\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3091 - accuracy: 0.8888 - val_loss: 0.3900 - val_accuracy: 0.8677\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2936 - accuracy: 0.8916 - val_loss: 0.3955 - val_accuracy: 0.8662\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2739 - accuracy: 0.8977 - val_loss: 0.4004 - val_accuracy: 0.8643\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2583 - accuracy: 0.9026 - val_loss: 0.3964 - val_accuracy: 0.8673\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:56.033269\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2685 - accuracy: 0.9020 - val_loss: 0.3632 - val_accuracy: 0.8752\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2504 - accuracy: 0.9081 - val_loss: 0.3566 - val_accuracy: 0.8775\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2405 - accuracy: 0.9113 - val_loss: 0.3548 - val_accuracy: 0.8794\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2348 - accuracy: 0.9127 - val_loss: 0.3549 - val_accuracy: 0.8789\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2320 - accuracy: 0.9140 - val_loss: 0.3540 - val_accuracy: 0.8785\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2326 - accuracy: 0.9140 - val_loss: 0.3543 - val_accuracy: 0.8791\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:40.989894\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7434 - accuracy: 0.7745 - val_loss: 0.4751 - val_accuracy: 0.8408\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4468 - accuracy: 0.8507 - val_loss: 0.4426 - val_accuracy: 0.8483\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3921 - accuracy: 0.8646 - val_loss: 0.3775 - val_accuracy: 0.8678\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3593 - accuracy: 0.8729 - val_loss: 0.3773 - val_accuracy: 0.8697\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3321 - accuracy: 0.8805 - val_loss: 0.4139 - val_accuracy: 0.8571\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3039 - accuracy: 0.8888 - val_loss: 0.3750 - val_accuracy: 0.8719\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2859 - accuracy: 0.8945 - val_loss: 0.3515 - val_accuracy: 0.8788\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2663 - accuracy: 0.9008 - val_loss: 0.3603 - val_accuracy: 0.8745\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2493 - accuracy: 0.9047 - val_loss: 0.3674 - val_accuracy: 0.8755\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2324 - accuracy: 0.9114 - val_loss: 0.3530 - val_accuracy: 0.8806\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2189 - accuracy: 0.9152 - val_loss: 0.3711 - val_accuracy: 0.8775\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2053 - accuracy: 0.9207 - val_loss: 0.3595 - val_accuracy: 0.8804\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1962 - accuracy: 0.9232 - val_loss: 0.3705 - val_accuracy: 0.8781\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:58.298316\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2020 - accuracy: 0.9223 - val_loss: 0.3443 - val_accuracy: 0.8822\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1867 - accuracy: 0.9283 - val_loss: 0.3443 - val_accuracy: 0.8843\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1785 - accuracy: 0.9313 - val_loss: 0.3448 - val_accuracy: 0.8837\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1754 - accuracy: 0.9327 - val_loss: 0.3443 - val_accuracy: 0.8839\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1735 - accuracy: 0.9337 - val_loss: 0.3452 - val_accuracy: 0.8837\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:18.048288\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.7446 - accuracy: 0.7758 - val_loss: 0.4861 - val_accuracy: 0.8409\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4493 - accuracy: 0.8494 - val_loss: 0.4323 - val_accuracy: 0.8547\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.3922 - accuracy: 0.8638 - val_loss: 0.4861 - val_accuracy: 0.8414\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3609 - accuracy: 0.8726 - val_loss: 0.3871 - val_accuracy: 0.8691\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3359 - accuracy: 0.8790 - val_loss: 0.3755 - val_accuracy: 0.8707\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.3096 - accuracy: 0.8876 - val_loss: 0.3656 - val_accuracy: 0.8743\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2880 - accuracy: 0.8926 - val_loss: 0.3720 - val_accuracy: 0.8702\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2680 - accuracy: 0.8990 - val_loss: 0.3606 - val_accuracy: 0.8771\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2536 - accuracy: 0.9026 - val_loss: 0.3815 - val_accuracy: 0.8723\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2371 - accuracy: 0.9088 - val_loss: 0.3646 - val_accuracy: 0.8752\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2233 - accuracy: 0.9132 - val_loss: 0.3678 - val_accuracy: 0.8757\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:32.112019\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2315 - accuracy: 0.9118 - val_loss: 0.3426 - val_accuracy: 0.8839\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2121 - accuracy: 0.9194 - val_loss: 0.3415 - val_accuracy: 0.8831\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2035 - accuracy: 0.9223 - val_loss: 0.3401 - val_accuracy: 0.8821\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.1991 - accuracy: 0.9240 - val_loss: 0.3399 - val_accuracy: 0.8855\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.1963 - accuracy: 0.9251 - val_loss: 0.3397 - val_accuracy: 0.8848\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.1955 - accuracy: 0.9254 - val_loss: 0.3398 - val_accuracy: 0.8852\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.1951 - accuracy: 0.9256 - val_loss: 0.3396 - val_accuracy: 0.8852\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:30.748418\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.7527 - accuracy: 0.7742 - val_loss: 0.5207 - val_accuracy: 0.8284\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4493 - accuracy: 0.8495 - val_loss: 0.5264 - val_accuracy: 0.8277\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3925 - accuracy: 0.8642 - val_loss: 0.4773 - val_accuracy: 0.8352\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3603 - accuracy: 0.8729 - val_loss: 0.4013 - val_accuracy: 0.8621\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3329 - accuracy: 0.8817 - val_loss: 0.3974 - val_accuracy: 0.8656\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3113 - accuracy: 0.8870 - val_loss: 0.3905 - val_accuracy: 0.8667\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2890 - accuracy: 0.8942 - val_loss: 0.3943 - val_accuracy: 0.8638\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2710 - accuracy: 0.8989 - val_loss: 0.3906 - val_accuracy: 0.8684\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2518 - accuracy: 0.9061 - val_loss: 0.3977 - val_accuracy: 0.8673\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2369 - accuracy: 0.9101 - val_loss: 0.3888 - val_accuracy: 0.8713\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2244 - accuracy: 0.9139 - val_loss: 0.3981 - val_accuracy: 0.8682\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2103 - accuracy: 0.9179 - val_loss: 0.3930 - val_accuracy: 0.8728\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2005 - accuracy: 0.9216 - val_loss: 0.4014 - val_accuracy: 0.8676\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.1912 - accuracy: 0.9252 - val_loss: 0.3993 - val_accuracy: 0.8705\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.1806 - accuracy: 0.9292 - val_loss: 0.4080 - val_accuracy: 0.8691\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:26.711459\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.1854 - accuracy: 0.9282 - val_loss: 0.3855 - val_accuracy: 0.8754\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.1745 - accuracy: 0.9325 - val_loss: 0.3841 - val_accuracy: 0.8751\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.1681 - accuracy: 0.9347 - val_loss: 0.3855 - val_accuracy: 0.8751\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.1648 - accuracy: 0.9369 - val_loss: 0.3844 - val_accuracy: 0.8750\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:01:59.222412\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.7391 - accuracy: 0.7759 - val_loss: 0.4917 - val_accuracy: 0.8355\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4481 - accuracy: 0.8499 - val_loss: 0.4185 - val_accuracy: 0.8593\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3926 - accuracy: 0.8633 - val_loss: 0.3979 - val_accuracy: 0.8650\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3583 - accuracy: 0.8735 - val_loss: 0.3722 - val_accuracy: 0.8712\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3360 - accuracy: 0.8795 - val_loss: 0.3858 - val_accuracy: 0.8693\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3090 - accuracy: 0.8879 - val_loss: 0.3566 - val_accuracy: 0.8752\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2851 - accuracy: 0.8938 - val_loss: 0.3572 - val_accuracy: 0.8777\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2698 - accuracy: 0.8999 - val_loss: 0.3519 - val_accuracy: 0.8768\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2504 - accuracy: 0.9060 - val_loss: 0.3562 - val_accuracy: 0.8762\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2347 - accuracy: 0.9096 - val_loss: 0.3606 - val_accuracy: 0.8781\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 126s 178ms/step - loss: 0.2204 - accuracy: 0.9143 - val_loss: 0.3598 - val_accuracy: 0.8761\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2084 - accuracy: 0.9185 - val_loss: 0.3688 - val_accuracy: 0.8756\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.1967 - accuracy: 0.9227 - val_loss: 0.3602 - val_accuracy: 0.8781\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:08:00.255967\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2038 - accuracy: 0.9220 - val_loss: 0.3453 - val_accuracy: 0.8819\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.1882 - accuracy: 0.9273 - val_loss: 0.3389 - val_accuracy: 0.8838\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.1813 - accuracy: 0.9300 - val_loss: 0.3392 - val_accuracy: 0.8841\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1775 - accuracy: 0.9317 - val_loss: 0.3401 - val_accuracy: 0.8843\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1767 - accuracy: 0.9318 - val_loss: 0.3400 - val_accuracy: 0.8850\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.1751 - accuracy: 0.9329 - val_loss: 0.3401 - val_accuracy: 0.8849\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.1739 - accuracy: 0.9334 - val_loss: 0.3403 - val_accuracy: 0.8844\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1733 - accuracy: 0.9337 - val_loss: 0.3404 - val_accuracy: 0.8848\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:54.736191\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7421 - accuracy: 0.7755 - val_loss: 0.4769 - val_accuracy: 0.8437\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4528 - accuracy: 0.8470 - val_loss: 0.4051 - val_accuracy: 0.8598\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3933 - accuracy: 0.8638 - val_loss: 0.4334 - val_accuracy: 0.8558\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3551 - accuracy: 0.8743 - val_loss: 0.3995 - val_accuracy: 0.8652\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3320 - accuracy: 0.8800 - val_loss: 0.3575 - val_accuracy: 0.8782\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3068 - accuracy: 0.8869 - val_loss: 0.3624 - val_accuracy: 0.8737\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2858 - accuracy: 0.8938 - val_loss: 0.3563 - val_accuracy: 0.8781\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2668 - accuracy: 0.8991 - val_loss: 0.3599 - val_accuracy: 0.8755\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:51.516493\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2811 - accuracy: 0.8972 - val_loss: 0.3441 - val_accuracy: 0.8816\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2554 - accuracy: 0.9052 - val_loss: 0.3249 - val_accuracy: 0.8880\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2399 - accuracy: 0.9109 - val_loss: 0.3254 - val_accuracy: 0.8885\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2331 - accuracy: 0.9124 - val_loss: 0.3226 - val_accuracy: 0.8878\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2297 - accuracy: 0.9141 - val_loss: 0.3226 - val_accuracy: 0.8879\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2282 - accuracy: 0.9139 - val_loss: 0.3226 - val_accuracy: 0.8883\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:53.409944\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9312 - accuracy: 0.7528 - val_loss: 1.0098 - val_accuracy: 0.8092\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8909 - accuracy: 0.8224 - val_loss: 0.8779 - val_accuracy: 0.8235\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8246 - accuracy: 0.8342 - val_loss: 0.8040 - val_accuracy: 0.8349\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7913 - accuracy: 0.8392 - val_loss: 0.7835 - val_accuracy: 0.8479\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7723 - accuracy: 0.8435 - val_loss: 0.7622 - val_accuracy: 0.8497\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7451 - accuracy: 0.8460 - val_loss: 0.7713 - val_accuracy: 0.8419\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7162 - accuracy: 0.8513 - val_loss: 0.7128 - val_accuracy: 0.8530\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6869 - accuracy: 0.8547 - val_loss: 0.6834 - val_accuracy: 0.8605\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6633 - accuracy: 0.8562 - val_loss: 0.6606 - val_accuracy: 0.8610\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6437 - accuracy: 0.8585 - val_loss: 0.6486 - val_accuracy: 0.8595\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6222 - accuracy: 0.8616 - val_loss: 0.6236 - val_accuracy: 0.8598\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6049 - accuracy: 0.8633 - val_loss: 0.6133 - val_accuracy: 0.8628\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5851 - accuracy: 0.8641 - val_loss: 0.5958 - val_accuracy: 0.8656\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5718 - accuracy: 0.8686 - val_loss: 0.5967 - val_accuracy: 0.8632\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5574 - accuracy: 0.8688 - val_loss: 0.5712 - val_accuracy: 0.8656\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5441 - accuracy: 0.8705 - val_loss: 0.5507 - val_accuracy: 0.8719\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5304 - accuracy: 0.8724 - val_loss: 0.5558 - val_accuracy: 0.8629\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5161 - accuracy: 0.8734 - val_loss: 0.5304 - val_accuracy: 0.8738\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5053 - accuracy: 0.8756 - val_loss: 0.5199 - val_accuracy: 0.8749\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 1072s 2s/step - loss: 0.4950 - accuracy: 0.8768 - val_loss: 0.5107 - val_accuracy: 0.8750\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:26:30.374282\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4530 - accuracy: 0.8823 - val_loss: 0.4635 - val_accuracy: 0.8783\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4219 - accuracy: 0.8867 - val_loss: 0.4401 - val_accuracy: 0.8813\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4053 - accuracy: 0.8884 - val_loss: 0.4297 - val_accuracy: 0.8829\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3969 - accuracy: 0.8895 - val_loss: 0.4227 - val_accuracy: 0.8830\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3908 - accuracy: 0.8909 - val_loss: 0.4196 - val_accuracy: 0.8834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3890 - accuracy: 0.8910 - val_loss: 0.4186 - val_accuracy: 0.8839\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3868 - accuracy: 0.8917 - val_loss: 0.4181 - val_accuracy: 0.8836\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3877 - accuracy: 0.8914 - val_loss: 0.4180 - val_accuracy: 0.8840\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3872 - accuracy: 0.8916 - val_loss: 0.4179 - val_accuracy: 0.8835\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3862 - accuracy: 0.8918 - val_loss: 0.4179 - val_accuracy: 0.8836\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3858 - accuracy: 0.8921 - val_loss: 0.4179 - val_accuracy: 0.8833\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:03.167057\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9185 - accuracy: 0.7539 - val_loss: 1.1093 - val_accuracy: 0.7702\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8952 - accuracy: 0.8221 - val_loss: 0.8709 - val_accuracy: 0.8203\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8238 - accuracy: 0.8324 - val_loss: 0.8526 - val_accuracy: 0.8240\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7902 - accuracy: 0.8392 - val_loss: 0.8172 - val_accuracy: 0.8321\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7721 - accuracy: 0.8419 - val_loss: 0.7570 - val_accuracy: 0.8488\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7390 - accuracy: 0.8464 - val_loss: 0.7462 - val_accuracy: 0.8450\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7087 - accuracy: 0.8495 - val_loss: 0.6949 - val_accuracy: 0.8562\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6829 - accuracy: 0.8521 - val_loss: 0.7240 - val_accuracy: 0.8441\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6613 - accuracy: 0.8558 - val_loss: 0.6716 - val_accuracy: 0.8574\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6376 - accuracy: 0.8581 - val_loss: 0.6288 - val_accuracy: 0.8655\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6171 - accuracy: 0.8618 - val_loss: 0.6241 - val_accuracy: 0.8629\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6006 - accuracy: 0.8628 - val_loss: 0.5975 - val_accuracy: 0.8654\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5844 - accuracy: 0.8635 - val_loss: 0.5836 - val_accuracy: 0.8672\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5655 - accuracy: 0.8667 - val_loss: 0.6010 - val_accuracy: 0.8607\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5508 - accuracy: 0.8687 - val_loss: 0.5756 - val_accuracy: 0.8661\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5389 - accuracy: 0.8700 - val_loss: 0.5463 - val_accuracy: 0.8730\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5274 - accuracy: 0.8712 - val_loss: 0.5323 - val_accuracy: 0.8740\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5148 - accuracy: 0.8730 - val_loss: 0.5326 - val_accuracy: 0.8727\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5026 - accuracy: 0.8739 - val_loss: 0.5305 - val_accuracy: 0.8695\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4900 - accuracy: 0.8765 - val_loss: 0.5089 - val_accuracy: 0.8759\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:03.625666\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4503 - accuracy: 0.8825 - val_loss: 0.4644 - val_accuracy: 0.8792\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4221 - accuracy: 0.8863 - val_loss: 0.4416 - val_accuracy: 0.8825\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4055 - accuracy: 0.8886 - val_loss: 0.4296 - val_accuracy: 0.8834\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3962 - accuracy: 0.8887 - val_loss: 0.4232 - val_accuracy: 0.8834\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3924 - accuracy: 0.8901 - val_loss: 0.4207 - val_accuracy: 0.8839\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3911 - accuracy: 0.8908 - val_loss: 0.4196 - val_accuracy: 0.8842\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3900 - accuracy: 0.8908 - val_loss: 0.4192 - val_accuracy: 0.8841\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3873 - accuracy: 0.8910 - val_loss: 0.4191 - val_accuracy: 0.8844\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3894 - accuracy: 0.8906 - val_loss: 0.4189 - val_accuracy: 0.8845\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3878 - accuracy: 0.8905 - val_loss: 0.4190 - val_accuracy: 0.8843\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3877 - accuracy: 0.8911 - val_loss: 0.4190 - val_accuracy: 0.8846\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3890 - accuracy: 0.8899 - val_loss: 0.4191 - val_accuracy: 0.8844\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3885 - accuracy: 0.8916 - val_loss: 0.4190 - val_accuracy: 0.8842\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3889 - accuracy: 0.8901 - val_loss: 0.4190 - val_accuracy: 0.8842\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:06:20.586871\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9054 - accuracy: 0.7548 - val_loss: 0.9758 - val_accuracy: 0.8176\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8875 - accuracy: 0.8230 - val_loss: 0.8676 - val_accuracy: 0.8216\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8150 - accuracy: 0.8334 - val_loss: 0.7715 - val_accuracy: 0.8394\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7819 - accuracy: 0.8396 - val_loss: 0.7882 - val_accuracy: 0.8407\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7638 - accuracy: 0.8441 - val_loss: 0.8131 - val_accuracy: 0.8286\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7398 - accuracy: 0.8477 - val_loss: 0.7651 - val_accuracy: 0.8426\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7109 - accuracy: 0.8513 - val_loss: 0.7565 - val_accuracy: 0.8418\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6825 - accuracy: 0.8546 - val_loss: 0.6895 - val_accuracy: 0.8546\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6649 - accuracy: 0.8554 - val_loss: 0.6900 - val_accuracy: 0.8497\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6410 - accuracy: 0.8594 - val_loss: 0.6681 - val_accuracy: 0.8534\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6256 - accuracy: 0.8604 - val_loss: 0.6329 - val_accuracy: 0.8539\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:58.432302\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5627 - accuracy: 0.8684 - val_loss: 0.5472 - val_accuracy: 0.8684\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5001 - accuracy: 0.8745 - val_loss: 0.4960 - val_accuracy: 0.8760\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4655 - accuracy: 0.8792 - val_loss: 0.4644 - val_accuracy: 0.8775\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4454 - accuracy: 0.8810 - val_loss: 0.4492 - val_accuracy: 0.8790\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4357 - accuracy: 0.8821 - val_loss: 0.4419 - val_accuracy: 0.8793\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4306 - accuracy: 0.8812 - val_loss: 0.4390 - val_accuracy: 0.8798\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4286 - accuracy: 0.8832 - val_loss: 0.4379 - val_accuracy: 0.8800\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4261 - accuracy: 0.8834 - val_loss: 0.4374 - val_accuracy: 0.8797\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4262 - accuracy: 0.8829 - val_loss: 0.4372 - val_accuracy: 0.8800\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4281 - accuracy: 0.8828 - val_loss: 0.4372 - val_accuracy: 0.8798\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:28.291487\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.9337 - accuracy: 0.7534 - val_loss: 0.9720 - val_accuracy: 0.8218\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8980 - accuracy: 0.8219 - val_loss: 0.8609 - val_accuracy: 0.8279\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8277 - accuracy: 0.8349 - val_loss: 0.7791 - val_accuracy: 0.8452\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7932 - accuracy: 0.8406 - val_loss: 0.7728 - val_accuracy: 0.8440\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7720 - accuracy: 0.8427 - val_loss: 0.7776 - val_accuracy: 0.8374\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7350 - accuracy: 0.8471 - val_loss: 0.7147 - val_accuracy: 0.8528\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7050 - accuracy: 0.8510 - val_loss: 0.6719 - val_accuracy: 0.8586\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6829 - accuracy: 0.8552 - val_loss: 0.6772 - val_accuracy: 0.8555\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6584 - accuracy: 0.8573 - val_loss: 0.6452 - val_accuracy: 0.8596\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6342 - accuracy: 0.8597 - val_loss: 0.6185 - val_accuracy: 0.8655\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6151 - accuracy: 0.8627 - val_loss: 0.6132 - val_accuracy: 0.8608\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5971 - accuracy: 0.8635 - val_loss: 0.5917 - val_accuracy: 0.8628\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5805 - accuracy: 0.8667 - val_loss: 0.5908 - val_accuracy: 0.8692\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5665 - accuracy: 0.8677 - val_loss: 0.5611 - val_accuracy: 0.8713\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5506 - accuracy: 0.8695 - val_loss: 0.5454 - val_accuracy: 0.8707\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5368 - accuracy: 0.8714 - val_loss: 0.5591 - val_accuracy: 0.8651\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5255 - accuracy: 0.8732 - val_loss: 0.5217 - val_accuracy: 0.8747\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5125 - accuracy: 0.8740 - val_loss: 0.5169 - val_accuracy: 0.8741\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4999 - accuracy: 0.8765 - val_loss: 0.4967 - val_accuracy: 0.8770\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4887 - accuracy: 0.8766 - val_loss: 0.4941 - val_accuracy: 0.8773\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:51.647195\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4504 - accuracy: 0.8829 - val_loss: 0.4463 - val_accuracy: 0.8798\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4192 - accuracy: 0.8878 - val_loss: 0.4245 - val_accuracy: 0.8847\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4047 - accuracy: 0.8901 - val_loss: 0.4149 - val_accuracy: 0.8833\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3945 - accuracy: 0.8913 - val_loss: 0.4101 - val_accuracy: 0.8838\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3911 - accuracy: 0.8908 - val_loss: 0.4067 - val_accuracy: 0.8849\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3879 - accuracy: 0.8918 - val_loss: 0.4056 - val_accuracy: 0.8848\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3872 - accuracy: 0.8912 - val_loss: 0.4051 - val_accuracy: 0.8846\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3865 - accuracy: 0.8920 - val_loss: 0.4049 - val_accuracy: 0.8848\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:42.031819\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8885 - accuracy: 0.7559 - val_loss: 1.0201 - val_accuracy: 0.7931\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8911 - accuracy: 0.8244 - val_loss: 0.8728 - val_accuracy: 0.8230\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8266 - accuracy: 0.8344 - val_loss: 0.8338 - val_accuracy: 0.8230\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7908 - accuracy: 0.8401 - val_loss: 0.7733 - val_accuracy: 0.8412\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7755 - accuracy: 0.8421 - val_loss: 0.7713 - val_accuracy: 0.8401\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7361 - accuracy: 0.8479 - val_loss: 0.7495 - val_accuracy: 0.8437\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7127 - accuracy: 0.8507 - val_loss: 0.7128 - val_accuracy: 0.8484\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6819 - accuracy: 0.8550 - val_loss: 0.6868 - val_accuracy: 0.8511\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6621 - accuracy: 0.8556 - val_loss: 0.6860 - val_accuracy: 0.8484\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 3090s 4s/step - loss: 0.6394 - accuracy: 0.8594 - val_loss: 0.6318 - val_accuracy: 0.8622\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.6198 - accuracy: 0.8607 - val_loss: 0.6258 - val_accuracy: 0.8603\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.6001 - accuracy: 0.8640 - val_loss: 0.6120 - val_accuracy: 0.8588\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.5849 - accuracy: 0.8646 - val_loss: 0.6031 - val_accuracy: 0.8597\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:56:53.943641\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 25s 36ms/step - loss: 0.5318 - accuracy: 0.8731 - val_loss: 0.5233 - val_accuracy: 0.8700\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4803 - accuracy: 0.8788 - val_loss: 0.4828 - val_accuracy: 0.8737\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.4520 - accuracy: 0.8806 - val_loss: 0.4591 - val_accuracy: 0.8759\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4354 - accuracy: 0.8823 - val_loss: 0.4484 - val_accuracy: 0.8768\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4279 - accuracy: 0.8832 - val_loss: 0.4426 - val_accuracy: 0.8775\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4245 - accuracy: 0.8845 - val_loss: 0.4398 - val_accuracy: 0.8780\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4220 - accuracy: 0.8841 - val_loss: 0.4389 - val_accuracy: 0.8777\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4216 - accuracy: 0.8837 - val_loss: 0.4386 - val_accuracy: 0.8774\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4207 - accuracy: 0.8839 - val_loss: 0.4385 - val_accuracy: 0.8777\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:46.841837\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.1700 - accuracy: 0.7407 - val_loss: 1.1830 - val_accuracy: 0.7715\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 1.0321 - accuracy: 0.8014 - val_loss: 1.0426 - val_accuracy: 0.7873\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.9724 - accuracy: 0.8113 - val_loss: 1.0628 - val_accuracy: 0.7792\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.9200 - accuracy: 0.8189 - val_loss: 1.2012 - val_accuracy: 0.7309\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.8932 - accuracy: 0.8213 - val_loss: 1.1513 - val_accuracy: 0.7375\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:09.647769\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8467 - accuracy: 0.8262 - val_loss: 0.8849 - val_accuracy: 0.8103\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7173 - accuracy: 0.8358 - val_loss: 0.6969 - val_accuracy: 0.8388\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6397 - accuracy: 0.8453 - val_loss: 0.6272 - val_accuracy: 0.8447\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5931 - accuracy: 0.8507 - val_loss: 0.5825 - val_accuracy: 0.8513\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5674 - accuracy: 0.8530 - val_loss: 0.5532 - val_accuracy: 0.8561\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5535 - accuracy: 0.8543 - val_loss: 0.5451 - val_accuracy: 0.8578\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 169s 240ms/step - loss: 0.5485 - accuracy: 0.8550 - val_loss: 0.5415 - val_accuracy: 0.8578\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5454 - accuracy: 0.8556 - val_loss: 0.5400 - val_accuracy: 0.8570\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5446 - accuracy: 0.8556 - val_loss: 0.5395 - val_accuracy: 0.8573\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5439 - accuracy: 0.8556 - val_loss: 0.5394 - val_accuracy: 0.8574\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:06:44.224933\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.1859 - accuracy: 0.7394 - val_loss: 1.1414 - val_accuracy: 0.7824\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0379 - accuracy: 0.8024 - val_loss: 1.0470 - val_accuracy: 0.7922\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9607 - accuracy: 0.8122 - val_loss: 1.1331 - val_accuracy: 0.7605\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9258 - accuracy: 0.8190 - val_loss: 2.0549 - val_accuracy: 0.5459\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9001 - accuracy: 0.8215 - val_loss: 1.3719 - val_accuracy: 0.6761\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:20.733211\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8461 - accuracy: 0.8248 - val_loss: 0.9276 - val_accuracy: 0.7983\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7181 - accuracy: 0.8367 - val_loss: 0.6962 - val_accuracy: 0.8372\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6394 - accuracy: 0.8449 - val_loss: 0.6082 - val_accuracy: 0.8513\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5923 - accuracy: 0.8504 - val_loss: 0.5692 - val_accuracy: 0.8566\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5677 - accuracy: 0.8525 - val_loss: 0.5470 - val_accuracy: 0.8596\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5541 - accuracy: 0.8559 - val_loss: 0.5380 - val_accuracy: 0.8602\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5478 - accuracy: 0.8556 - val_loss: 0.5340 - val_accuracy: 0.8606\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5448 - accuracy: 0.8556 - val_loss: 0.5327 - val_accuracy: 0.8605\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5441 - accuracy: 0.8562 - val_loss: 0.5324 - val_accuracy: 0.8608\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5443 - accuracy: 0.8556 - val_loss: 0.5322 - val_accuracy: 0.8607\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5445 - accuracy: 0.8554 - val_loss: 0.5320 - val_accuracy: 0.8609\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5438 - accuracy: 0.8561 - val_loss: 0.5321 - val_accuracy: 0.8609\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 2890s 4s/step - loss: 0.5445 - accuracy: 0.8564 - val_loss: 0.5321 - val_accuracy: 0.8610\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.5454 - accuracy: 0.8548 - val_loss: 0.5322 - val_accuracy: 0.8611\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5440 - accuracy: 0.8566 - val_loss: 0.5321 - val_accuracy: 0.8609\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5446 - accuracy: 0.8562 - val_loss: 0.5321 - val_accuracy: 0.8609\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5452 - accuracy: 0.8562 - val_loss: 0.5324 - val_accuracy: 0.8610\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:55:44.575030\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.2224 - accuracy: 0.7379 - val_loss: 1.1445 - val_accuracy: 0.7910\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0314 - accuracy: 0.8019 - val_loss: 1.0991 - val_accuracy: 0.7704\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9579 - accuracy: 0.8137 - val_loss: 1.0782 - val_accuracy: 0.7689\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9058 - accuracy: 0.8198 - val_loss: 1.1539 - val_accuracy: 0.7450\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:54.541794\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9341 - accuracy: 0.8138 - val_loss: 0.8921 - val_accuracy: 0.8121\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7519 - accuracy: 0.8304 - val_loss: 0.7166 - val_accuracy: 0.8362\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6664 - accuracy: 0.8400 - val_loss: 0.6334 - val_accuracy: 0.8479\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6174 - accuracy: 0.8462 - val_loss: 0.5884 - val_accuracy: 0.8526\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5899 - accuracy: 0.8492 - val_loss: 0.5676 - val_accuracy: 0.8544\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5738 - accuracy: 0.8514 - val_loss: 0.5570 - val_accuracy: 0.8551\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5677 - accuracy: 0.8520 - val_loss: 0.5524 - val_accuracy: 0.8556\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5655 - accuracy: 0.8524 - val_loss: 0.5510 - val_accuracy: 0.8553\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5652 - accuracy: 0.8522 - val_loss: 0.5503 - val_accuracy: 0.8557\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5618 - accuracy: 0.8526 - val_loss: 0.5503 - val_accuracy: 0.8557\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5640 - accuracy: 0.8517 - val_loss: 0.5503 - val_accuracy: 0.8552\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5630 - accuracy: 0.8532 - val_loss: 0.5502 - val_accuracy: 0.8551\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:41.495162\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.1738 - accuracy: 0.7380 - val_loss: 1.1482 - val_accuracy: 0.7778\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0087 - accuracy: 0.8045 - val_loss: 1.1128 - val_accuracy: 0.7789\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9532 - accuracy: 0.8124 - val_loss: 1.0742 - val_accuracy: 0.7742\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9052 - accuracy: 0.8190 - val_loss: 1.0143 - val_accuracy: 0.7873\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9005 - accuracy: 0.8220 - val_loss: 1.2003 - val_accuracy: 0.7317\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8433 - accuracy: 0.8283 - val_loss: 1.5820 - val_accuracy: 0.6360\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8166 - accuracy: 0.8311 - val_loss: 1.8741 - val_accuracy: 0.5720\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:17.670455\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7406 - accuracy: 0.8388 - val_loss: 0.7735 - val_accuracy: 0.8262\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6466 - accuracy: 0.8456 - val_loss: 0.6580 - val_accuracy: 0.8423\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5877 - accuracy: 0.8525 - val_loss: 0.6015 - val_accuracy: 0.8474\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5542 - accuracy: 0.8561 - val_loss: 0.5586 - val_accuracy: 0.8543\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5355 - accuracy: 0.8576 - val_loss: 0.5432 - val_accuracy: 0.8555\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5284 - accuracy: 0.8589 - val_loss: 0.5379 - val_accuracy: 0.8567\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5230 - accuracy: 0.8601 - val_loss: 0.5352 - val_accuracy: 0.8572\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5211 - accuracy: 0.8599 - val_loss: 0.5342 - val_accuracy: 0.8572\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5206 - accuracy: 0.8605 - val_loss: 0.5337 - val_accuracy: 0.8574\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5217 - accuracy: 0.8586 - val_loss: 0.5335 - val_accuracy: 0.8573\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5202 - accuracy: 0.8589 - val_loss: 0.5335 - val_accuracy: 0.8574\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5203 - accuracy: 0.8600 - val_loss: 0.5337 - val_accuracy: 0.8574\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5217 - accuracy: 0.8590 - val_loss: 0.5336 - val_accuracy: 0.8577\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5207 - accuracy: 0.8587 - val_loss: 0.5336 - val_accuracy: 0.8571\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5201 - accuracy: 0.8600 - val_loss: 0.5336 - val_accuracy: 0.8571\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5194 - accuracy: 0.8604 - val_loss: 0.5335 - val_accuracy: 0.8573\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:07:32.360534\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.2045 - accuracy: 0.7378 - val_loss: 1.1762 - val_accuracy: 0.7770\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0350 - accuracy: 0.8017 - val_loss: 1.0359 - val_accuracy: 0.7936\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9692 - accuracy: 0.8093 - val_loss: 1.0720 - val_accuracy: 0.7793\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9373 - accuracy: 0.8163 - val_loss: 1.1413 - val_accuracy: 0.7559\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9027 - accuracy: 0.8215 - val_loss: 1.3184 - val_accuracy: 0.7043\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:21.330607\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8486 - accuracy: 0.8240 - val_loss: 0.8918 - val_accuracy: 0.8088\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7213 - accuracy: 0.8370 - val_loss: 0.6854 - val_accuracy: 0.8417\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6439 - accuracy: 0.8440 - val_loss: 0.6280 - val_accuracy: 0.8473\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5963 - accuracy: 0.8487 - val_loss: 0.5640 - val_accuracy: 0.8574\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5711 - accuracy: 0.8532 - val_loss: 0.5443 - val_accuracy: 0.8580\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5580 - accuracy: 0.8533 - val_loss: 0.5360 - val_accuracy: 0.8577\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5510 - accuracy: 0.8540 - val_loss: 0.5314 - val_accuracy: 0.8585\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5500 - accuracy: 0.8534 - val_loss: 0.5300 - val_accuracy: 0.8588\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5482 - accuracy: 0.8544 - val_loss: 0.5295 - val_accuracy: 0.8587\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5484 - accuracy: 0.8533 - val_loss: 0.5293 - val_accuracy: 0.8586\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5475 - accuracy: 0.8547 - val_loss: 0.5293 - val_accuracy: 0.8585\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:09.726426\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.0082 - accuracy: 0.7519 - val_loss: 1.0882 - val_accuracy: 0.7871\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9404 - accuracy: 0.8186 - val_loss: 0.9178 - val_accuracy: 0.8178\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8784 - accuracy: 0.8281 - val_loss: 0.9057 - val_accuracy: 0.8129\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8513 - accuracy: 0.8348 - val_loss: 0.8523 - val_accuracy: 0.8305\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8351 - accuracy: 0.8379 - val_loss: 0.8447 - val_accuracy: 0.8336\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8020 - accuracy: 0.8427 - val_loss: 0.7904 - val_accuracy: 0.8492\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.7684 - accuracy: 0.8466 - val_loss: 0.7874 - val_accuracy: 0.8360\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7435 - accuracy: 0.8489 - val_loss: 0.7512 - val_accuracy: 0.8497\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7225 - accuracy: 0.8527 - val_loss: 0.7034 - val_accuracy: 0.8534\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6884 - accuracy: 0.8546 - val_loss: 0.6943 - val_accuracy: 0.8545\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6690 - accuracy: 0.8566 - val_loss: 0.6861 - val_accuracy: 0.8509\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6468 - accuracy: 0.8592 - val_loss: 0.6376 - val_accuracy: 0.8643\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6324 - accuracy: 0.8602 - val_loss: 0.6384 - val_accuracy: 0.8568\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6112 - accuracy: 0.8632 - val_loss: 0.6152 - val_accuracy: 0.8608\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5956 - accuracy: 0.8634 - val_loss: 0.5861 - val_accuracy: 0.8672\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5802 - accuracy: 0.8646 - val_loss: 0.5811 - val_accuracy: 0.8634\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5651 - accuracy: 0.8660 - val_loss: 0.5557 - val_accuracy: 0.8709\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5497 - accuracy: 0.8687 - val_loss: 0.5533 - val_accuracy: 0.8669\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5361 - accuracy: 0.8692 - val_loss: 0.5413 - val_accuracy: 0.8709\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5227 - accuracy: 0.8708 - val_loss: 0.5198 - val_accuracy: 0.8741\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:43.395987\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4748 - accuracy: 0.8770 - val_loss: 0.4717 - val_accuracy: 0.8757\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4425 - accuracy: 0.8815 - val_loss: 0.4458 - val_accuracy: 0.8804\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4261 - accuracy: 0.8833 - val_loss: 0.4304 - val_accuracy: 0.8821\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4143 - accuracy: 0.8841 - val_loss: 0.4233 - val_accuracy: 0.8829\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4110 - accuracy: 0.8847 - val_loss: 0.4203 - val_accuracy: 0.8831\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4077 - accuracy: 0.8854 - val_loss: 0.4188 - val_accuracy: 0.8830\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4065 - accuracy: 0.8851 - val_loss: 0.4183 - val_accuracy: 0.8828\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4055 - accuracy: 0.8858 - val_loss: 0.4181 - val_accuracy: 0.8830\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:52.929494\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.9922 - accuracy: 0.7561 - val_loss: 1.0476 - val_accuracy: 0.7992\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9334 - accuracy: 0.8187 - val_loss: 0.9024 - val_accuracy: 0.8165\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8618 - accuracy: 0.8302 - val_loss: 0.8565 - val_accuracy: 0.8235\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8396 - accuracy: 0.8346 - val_loss: 0.8271 - val_accuracy: 0.8358\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8239 - accuracy: 0.8389 - val_loss: 0.8086 - val_accuracy: 0.8409\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7855 - accuracy: 0.8424 - val_loss: 0.8689 - val_accuracy: 0.8232\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7629 - accuracy: 0.8462 - val_loss: 0.7662 - val_accuracy: 0.8411\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7364 - accuracy: 0.8488 - val_loss: 0.7370 - val_accuracy: 0.8506\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7063 - accuracy: 0.8526 - val_loss: 0.7112 - val_accuracy: 0.8515\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6847 - accuracy: 0.8534 - val_loss: 0.6837 - val_accuracy: 0.8536\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6589 - accuracy: 0.8578 - val_loss: 0.6714 - val_accuracy: 0.8533\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6441 - accuracy: 0.8584 - val_loss: 0.6713 - val_accuracy: 0.8496\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6233 - accuracy: 0.8610 - val_loss: 0.6488 - val_accuracy: 0.8527\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:14.253230\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5610 - accuracy: 0.8686 - val_loss: 0.5538 - val_accuracy: 0.8647\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5039 - accuracy: 0.8736 - val_loss: 0.4970 - val_accuracy: 0.8725\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4732 - accuracy: 0.8754 - val_loss: 0.4725 - val_accuracy: 0.8739\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4589 - accuracy: 0.8764 - val_loss: 0.4583 - val_accuracy: 0.8756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4487 - accuracy: 0.8777 - val_loss: 0.4523 - val_accuracy: 0.8769\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4434 - accuracy: 0.8795 - val_loss: 0.4498 - val_accuracy: 0.8767\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4417 - accuracy: 0.8797 - val_loss: 0.4487 - val_accuracy: 0.8769\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4422 - accuracy: 0.8786 - val_loss: 0.4483 - val_accuracy: 0.8772\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4402 - accuracy: 0.8796 - val_loss: 0.4482 - val_accuracy: 0.8768\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4410 - accuracy: 0.8786 - val_loss: 0.4480 - val_accuracy: 0.8771\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4405 - accuracy: 0.8793 - val_loss: 0.4480 - val_accuracy: 0.8771\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:15.529396\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.0494 - accuracy: 0.7507 - val_loss: 1.0791 - val_accuracy: 0.7996\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9745 - accuracy: 0.8139 - val_loss: 0.9190 - val_accuracy: 0.8280\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 0.9042 - accuracy: 0.8257 - val_loss: 0.8691 - val_accuracy: 0.8355\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8594 - accuracy: 0.8318 - val_loss: 0.8785 - val_accuracy: 0.8303\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8535 - accuracy: 0.8357 - val_loss: 0.8625 - val_accuracy: 0.8410\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8174 - accuracy: 0.8409 - val_loss: 0.8555 - val_accuracy: 0.8326\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7836 - accuracy: 0.8455 - val_loss: 0.7682 - val_accuracy: 0.8538\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7560 - accuracy: 0.8503 - val_loss: 0.7645 - val_accuracy: 0.8454\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7295 - accuracy: 0.8508 - val_loss: 0.7351 - val_accuracy: 0.8562\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7013 - accuracy: 0.8540 - val_loss: 0.7017 - val_accuracy: 0.8577\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6809 - accuracy: 0.8563 - val_loss: 0.6943 - val_accuracy: 0.8584\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.6655 - accuracy: 0.8595 - val_loss: 0.6620 - val_accuracy: 0.8552\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6343 - accuracy: 0.8620 - val_loss: 0.6415 - val_accuracy: 0.8616\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6188 - accuracy: 0.8637 - val_loss: 0.6225 - val_accuracy: 0.8660\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6006 - accuracy: 0.8642 - val_loss: 0.6103 - val_accuracy: 0.8675\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5864 - accuracy: 0.8666 - val_loss: 0.5875 - val_accuracy: 0.8667\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.5668 - accuracy: 0.8676 - val_loss: 0.5759 - val_accuracy: 0.8685\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5609 - accuracy: 0.8670 - val_loss: 0.5570 - val_accuracy: 0.8707\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5427 - accuracy: 0.8707 - val_loss: 0.5407 - val_accuracy: 0.8742\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5305 - accuracy: 0.8715 - val_loss: 0.5374 - val_accuracy: 0.8714\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:38.050395\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4771 - accuracy: 0.8785 - val_loss: 0.4889 - val_accuracy: 0.8767\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4431 - accuracy: 0.8826 - val_loss: 0.4532 - val_accuracy: 0.8800\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4229 - accuracy: 0.8856 - val_loss: 0.4402 - val_accuracy: 0.8804\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4123 - accuracy: 0.8855 - val_loss: 0.4327 - val_accuracy: 0.8821\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4065 - accuracy: 0.8875 - val_loss: 0.4292 - val_accuracy: 0.8820\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4043 - accuracy: 0.8881 - val_loss: 0.4274 - val_accuracy: 0.8817\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4018 - accuracy: 0.8876 - val_loss: 0.4269 - val_accuracy: 0.8821\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4011 - accuracy: 0.8875 - val_loss: 0.4265 - val_accuracy: 0.8816\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4013 - accuracy: 0.8887 - val_loss: 0.4264 - val_accuracy: 0.8819\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4018 - accuracy: 0.8878 - val_loss: 0.4265 - val_accuracy: 0.8817\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:45.970615\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0423 - accuracy: 0.7506 - val_loss: 1.2335 - val_accuracy: 0.7416\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9591 - accuracy: 0.8126 - val_loss: 0.8960 - val_accuracy: 0.8215\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8851 - accuracy: 0.8262 - val_loss: 0.8472 - val_accuracy: 0.8312\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8537 - accuracy: 0.8325 - val_loss: 0.8491 - val_accuracy: 0.8325\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8413 - accuracy: 0.8357 - val_loss: 0.8319 - val_accuracy: 0.8371\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8015 - accuracy: 0.8408 - val_loss: 0.7755 - val_accuracy: 0.8494\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7682 - accuracy: 0.8463 - val_loss: 0.7349 - val_accuracy: 0.8518\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7437 - accuracy: 0.8479 - val_loss: 0.7389 - val_accuracy: 0.8504\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7170 - accuracy: 0.8506 - val_loss: 0.7379 - val_accuracy: 0.8460\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6989 - accuracy: 0.8523 - val_loss: 0.7091 - val_accuracy: 0.8486\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:45.063321\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.6181 - accuracy: 0.8612 - val_loss: 0.5924 - val_accuracy: 0.8621\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5446 - accuracy: 0.8666 - val_loss: 0.5199 - val_accuracy: 0.8695\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5051 - accuracy: 0.8709 - val_loss: 0.4886 - val_accuracy: 0.8726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4821 - accuracy: 0.8725 - val_loss: 0.4698 - val_accuracy: 0.8729\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4716 - accuracy: 0.8741 - val_loss: 0.4609 - val_accuracy: 0.8735\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4636 - accuracy: 0.8760 - val_loss: 0.4570 - val_accuracy: 0.8736\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4605 - accuracy: 0.8761 - val_loss: 0.4555 - val_accuracy: 0.8733\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4596 - accuracy: 0.8762 - val_loss: 0.4549 - val_accuracy: 0.8733\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4599 - accuracy: 0.8741 - val_loss: 0.4546 - val_accuracy: 0.8731\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:17.414282\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0148 - accuracy: 0.7509 - val_loss: 1.0740 - val_accuracy: 0.7859\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9400 - accuracy: 0.8151 - val_loss: 0.9175 - val_accuracy: 0.8178\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8769 - accuracy: 0.8292 - val_loss: 0.8972 - val_accuracy: 0.8252\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8597 - accuracy: 0.8334 - val_loss: 0.8600 - val_accuracy: 0.8338\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8399 - accuracy: 0.8373 - val_loss: 0.8393 - val_accuracy: 0.8354\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8018 - accuracy: 0.8432 - val_loss: 0.8199 - val_accuracy: 0.8435\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7737 - accuracy: 0.8471 - val_loss: 0.7828 - val_accuracy: 0.8428\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7459 - accuracy: 0.8495 - val_loss: 0.7525 - val_accuracy: 0.8536\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7210 - accuracy: 0.8518 - val_loss: 0.7535 - val_accuracy: 0.8470\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6988 - accuracy: 0.8556 - val_loss: 0.7006 - val_accuracy: 0.8529\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6705 - accuracy: 0.8584 - val_loss: 0.6863 - val_accuracy: 0.8546\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6487 - accuracy: 0.8599 - val_loss: 0.6691 - val_accuracy: 0.8547\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6336 - accuracy: 0.8612 - val_loss: 0.6483 - val_accuracy: 0.8601\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6124 - accuracy: 0.8635 - val_loss: 0.6105 - val_accuracy: 0.8641\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5962 - accuracy: 0.8639 - val_loss: 0.6115 - val_accuracy: 0.8616\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5833 - accuracy: 0.8671 - val_loss: 0.5761 - val_accuracy: 0.8688\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5653 - accuracy: 0.8681 - val_loss: 0.5591 - val_accuracy: 0.8706\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5500 - accuracy: 0.8689 - val_loss: 0.5634 - val_accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5356 - accuracy: 0.8705 - val_loss: 0.5419 - val_accuracy: 0.8703\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5260 - accuracy: 0.8712 - val_loss: 0.5227 - val_accuracy: 0.8723\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:20.233825\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4740 - accuracy: 0.8786 - val_loss: 0.4752 - val_accuracy: 0.8778\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4421 - accuracy: 0.8828 - val_loss: 0.4496 - val_accuracy: 0.8806\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4227 - accuracy: 0.8843 - val_loss: 0.4361 - val_accuracy: 0.8811\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4131 - accuracy: 0.8853 - val_loss: 0.4293 - val_accuracy: 0.8830\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4080 - accuracy: 0.8863 - val_loss: 0.4257 - val_accuracy: 0.8831\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4043 - accuracy: 0.8866 - val_loss: 0.4246 - val_accuracy: 0.8831\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4051 - accuracy: 0.8860 - val_loss: 0.4241 - val_accuracy: 0.8827\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4039 - accuracy: 0.8867 - val_loss: 0.4238 - val_accuracy: 0.8828\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:49.468073\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9520 - accuracy: 0.7699 - val_loss: 0.6022 - val_accuracy: 0.8407\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5505 - accuracy: 0.8496 - val_loss: 0.5110 - val_accuracy: 0.8555\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4822 - accuracy: 0.8636 - val_loss: 0.5015 - val_accuracy: 0.8555\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4542 - accuracy: 0.8708 - val_loss: 0.4803 - val_accuracy: 0.8611\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4388 - accuracy: 0.8743 - val_loss: 0.4743 - val_accuracy: 0.8618\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4183 - accuracy: 0.8789 - val_loss: 0.4548 - val_accuracy: 0.8673\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3986 - accuracy: 0.8842 - val_loss: 0.4531 - val_accuracy: 0.8683\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3813 - accuracy: 0.8876 - val_loss: 0.4286 - val_accuracy: 0.8746\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3632 - accuracy: 0.8932 - val_loss: 0.4185 - val_accuracy: 0.8763\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3473 - accuracy: 0.8975 - val_loss: 0.4316 - val_accuracy: 0.8702\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3319 - accuracy: 0.9012 - val_loss: 0.4209 - val_accuracy: 0.8764\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3183 - accuracy: 0.9046 - val_loss: 0.4370 - val_accuracy: 0.8720\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3020 - accuracy: 0.9091 - val_loss: 0.4209 - val_accuracy: 0.8784\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2910 - accuracy: 0.9115 - val_loss: 0.4145 - val_accuracy: 0.8806\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2750 - accuracy: 0.9166 - val_loss: 0.4197 - val_accuracy: 0.8771\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2652 - accuracy: 0.9205 - val_loss: 0.4207 - val_accuracy: 0.8766\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2513 - accuracy: 0.9230 - val_loss: 0.4215 - val_accuracy: 0.8762\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:49.065467\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2498 - accuracy: 0.9263 - val_loss: 0.3949 - val_accuracy: 0.8819\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2282 - accuracy: 0.9336 - val_loss: 0.3915 - val_accuracy: 0.8835\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2172 - accuracy: 0.9380 - val_loss: 0.3908 - val_accuracy: 0.8835\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2126 - accuracy: 0.9398 - val_loss: 0.3915 - val_accuracy: 0.8828\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2088 - accuracy: 0.9410 - val_loss: 0.3909 - val_accuracy: 0.8826\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:16.883361\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9630 - accuracy: 0.7668 - val_loss: 0.6324 - val_accuracy: 0.8301\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5544 - accuracy: 0.8479 - val_loss: 0.5190 - val_accuracy: 0.8527\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4884 - accuracy: 0.8622 - val_loss: 0.5137 - val_accuracy: 0.8551\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4623 - accuracy: 0.8665 - val_loss: 0.4406 - val_accuracy: 0.8733\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4436 - accuracy: 0.8710 - val_loss: 0.4732 - val_accuracy: 0.8653\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4257 - accuracy: 0.8761 - val_loss: 0.4409 - val_accuracy: 0.8709\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4029 - accuracy: 0.8818 - val_loss: 0.4326 - val_accuracy: 0.8767\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3869 - accuracy: 0.8861 - val_loss: 0.4203 - val_accuracy: 0.8758\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3689 - accuracy: 0.8900 - val_loss: 0.4214 - val_accuracy: 0.8786\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3550 - accuracy: 0.8939 - val_loss: 0.4205 - val_accuracy: 0.8762\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3388 - accuracy: 0.8979 - val_loss: 0.4097 - val_accuracy: 0.8799\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3247 - accuracy: 0.9014 - val_loss: 0.4086 - val_accuracy: 0.8817\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3102 - accuracy: 0.9060 - val_loss: 0.4069 - val_accuracy: 0.8807\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2948 - accuracy: 0.9091 - val_loss: 0.4010 - val_accuracy: 0.8823\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2825 - accuracy: 0.9146 - val_loss: 0.3956 - val_accuracy: 0.8840\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2701 - accuracy: 0.9172 - val_loss: 0.4045 - val_accuracy: 0.8832\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2586 - accuracy: 0.9208 - val_loss: 0.3942 - val_accuracy: 0.8828\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2465 - accuracy: 0.9237 - val_loss: 0.3988 - val_accuracy: 0.8843\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2384 - accuracy: 0.9268 - val_loss: 0.4030 - val_accuracy: 0.8807\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2270 - accuracy: 0.9308 - val_loss: 0.3981 - val_accuracy: 0.8840\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.938283\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2071 - accuracy: 0.9376 - val_loss: 0.3895 - val_accuracy: 0.8855\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1915 - accuracy: 0.9441 - val_loss: 0.3842 - val_accuracy: 0.8885\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1852 - accuracy: 0.9472 - val_loss: 0.3857 - val_accuracy: 0.8881\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1806 - accuracy: 0.9491 - val_loss: 0.3865 - val_accuracy: 0.8881\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1800 - accuracy: 0.9492 - val_loss: 0.3861 - val_accuracy: 0.8883\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:17.103257\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9410 - accuracy: 0.7724 - val_loss: 0.6018 - val_accuracy: 0.8418\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5451 - accuracy: 0.8504 - val_loss: 0.5136 - val_accuracy: 0.8593\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4814 - accuracy: 0.8638 - val_loss: 0.5045 - val_accuracy: 0.8530\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4569 - accuracy: 0.8692 - val_loss: 0.4613 - val_accuracy: 0.8666\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4415 - accuracy: 0.8730 - val_loss: 0.4670 - val_accuracy: 0.8665\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4211 - accuracy: 0.8781 - val_loss: 0.4625 - val_accuracy: 0.8687\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4023 - accuracy: 0.8828 - val_loss: 0.4550 - val_accuracy: 0.8688\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3836 - accuracy: 0.8876 - val_loss: 0.4326 - val_accuracy: 0.8742\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3670 - accuracy: 0.8916 - val_loss: 0.4476 - val_accuracy: 0.8727\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3525 - accuracy: 0.8953 - val_loss: 0.4276 - val_accuracy: 0.8713\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3386 - accuracy: 0.8979 - val_loss: 0.4183 - val_accuracy: 0.8798\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3207 - accuracy: 0.9037 - val_loss: 0.4205 - val_accuracy: 0.8752\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3076 - accuracy: 0.9065 - val_loss: 0.4200 - val_accuracy: 0.8766\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2929 - accuracy: 0.9109 - val_loss: 0.4121 - val_accuracy: 0.8799\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2801 - accuracy: 0.9148 - val_loss: 0.4195 - val_accuracy: 0.8764\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2680 - accuracy: 0.9184 - val_loss: 0.4122 - val_accuracy: 0.8799\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2545 - accuracy: 0.9229 - val_loss: 0.4205 - val_accuracy: 0.8781\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:44.991540\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2540 - accuracy: 0.9248 - val_loss: 0.3961 - val_accuracy: 0.8826\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2326 - accuracy: 0.9316 - val_loss: 0.3920 - val_accuracy: 0.8855\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2225 - accuracy: 0.9357 - val_loss: 0.3906 - val_accuracy: 0.8858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2157 - accuracy: 0.9381 - val_loss: 0.3895 - val_accuracy: 0.8858\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2123 - accuracy: 0.9394 - val_loss: 0.3892 - val_accuracy: 0.8857\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2123 - accuracy: 0.9395 - val_loss: 0.3892 - val_accuracy: 0.8857\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:43.226749\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9461 - accuracy: 0.7704 - val_loss: 0.6124 - val_accuracy: 0.8378\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5461 - accuracy: 0.8490 - val_loss: 0.5262 - val_accuracy: 0.8537\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4819 - accuracy: 0.8621 - val_loss: 0.4765 - val_accuracy: 0.8657\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4517 - accuracy: 0.8695 - val_loss: 0.4742 - val_accuracy: 0.8633\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4385 - accuracy: 0.8732 - val_loss: 0.4585 - val_accuracy: 0.8683\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4199 - accuracy: 0.8789 - val_loss: 0.4849 - val_accuracy: 0.8614\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3992 - accuracy: 0.8838 - val_loss: 0.4530 - val_accuracy: 0.8692\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3783 - accuracy: 0.8893 - val_loss: 0.4372 - val_accuracy: 0.8716\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3636 - accuracy: 0.8923 - val_loss: 0.4335 - val_accuracy: 0.8752\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3485 - accuracy: 0.8967 - val_loss: 0.4294 - val_accuracy: 0.8757\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3345 - accuracy: 0.9004 - val_loss: 0.4292 - val_accuracy: 0.8761\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3175 - accuracy: 0.9050 - val_loss: 0.4252 - val_accuracy: 0.8773\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3025 - accuracy: 0.9083 - val_loss: 0.4255 - val_accuracy: 0.8758\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2887 - accuracy: 0.9126 - val_loss: 0.4275 - val_accuracy: 0.8754\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2740 - accuracy: 0.9173 - val_loss: 0.4370 - val_accuracy: 0.8724\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:06:41.472198\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2707 - accuracy: 0.9206 - val_loss: 0.4008 - val_accuracy: 0.8818\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2455 - accuracy: 0.9287 - val_loss: 0.3932 - val_accuracy: 0.8842\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2333 - accuracy: 0.9320 - val_loss: 0.3915 - val_accuracy: 0.8849\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2261 - accuracy: 0.9345 - val_loss: 0.3913 - val_accuracy: 0.8832\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2224 - accuracy: 0.9361 - val_loss: 0.3907 - val_accuracy: 0.8843\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2208 - accuracy: 0.9364 - val_loss: 0.3907 - val_accuracy: 0.8842\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:41.707471\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9546 - accuracy: 0.7683 - val_loss: 0.7112 - val_accuracy: 0.8117\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5621 - accuracy: 0.8466 - val_loss: 0.5595 - val_accuracy: 0.8464\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4916 - accuracy: 0.8609 - val_loss: 0.4797 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4611 - accuracy: 0.8682 - val_loss: 0.4789 - val_accuracy: 0.8682\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4428 - accuracy: 0.8739 - val_loss: 0.4715 - val_accuracy: 0.8682\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4240 - accuracy: 0.8771 - val_loss: 0.4438 - val_accuracy: 0.8716\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4029 - accuracy: 0.8822 - val_loss: 0.4578 - val_accuracy: 0.8706\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3844 - accuracy: 0.8867 - val_loss: 0.4273 - val_accuracy: 0.8816\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3694 - accuracy: 0.8911 - val_loss: 0.4242 - val_accuracy: 0.8807\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3537 - accuracy: 0.8950 - val_loss: 0.4370 - val_accuracy: 0.8762\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3358 - accuracy: 0.9011 - val_loss: 0.4228 - val_accuracy: 0.8775\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:53.341842\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3257 - accuracy: 0.9060 - val_loss: 0.3910 - val_accuracy: 0.8883\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2879 - accuracy: 0.9152 - val_loss: 0.3809 - val_accuracy: 0.8886\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2678 - accuracy: 0.9211 - val_loss: 0.3779 - val_accuracy: 0.8883\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2571 - accuracy: 0.9244 - val_loss: 0.3746 - val_accuracy: 0.8902\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2523 - accuracy: 0.9260 - val_loss: 0.3729 - val_accuracy: 0.8905\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2492 - accuracy: 0.9269 - val_loss: 0.3726 - val_accuracy: 0.8907\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2474 - accuracy: 0.9272 - val_loss: 0.3724 - val_accuracy: 0.8904\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2478 - accuracy: 0.9275 - val_loss: 0.3724 - val_accuracy: 0.8906\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2474 - accuracy: 0.9277 - val_loss: 0.3725 - val_accuracy: 0.8906\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:03.684189\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9804 - accuracy: 0.7640 - val_loss: 0.6791 - val_accuracy: 0.8242\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6377 - accuracy: 0.8308 - val_loss: 0.6339 - val_accuracy: 0.8212\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5747 - accuracy: 0.8418 - val_loss: 0.6822 - val_accuracy: 0.8086\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5498 - accuracy: 0.8466 - val_loss: 0.5772 - val_accuracy: 0.8367\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5315 - accuracy: 0.8520 - val_loss: 0.6019 - val_accuracy: 0.8335\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5085 - accuracy: 0.8576 - val_loss: 0.6006 - val_accuracy: 0.8251\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4917 - accuracy: 0.8603 - val_loss: 0.5851 - val_accuracy: 0.8356\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:13.261421\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4710 - accuracy: 0.8665 - val_loss: 0.5024 - val_accuracy: 0.8554\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4140 - accuracy: 0.8807 - val_loss: 0.4588 - val_accuracy: 0.8660\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3787 - accuracy: 0.8898 - val_loss: 0.4354 - val_accuracy: 0.8724\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3580 - accuracy: 0.8945 - val_loss: 0.4301 - val_accuracy: 0.8738\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3457 - accuracy: 0.8984 - val_loss: 0.4260 - val_accuracy: 0.8744\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3400 - accuracy: 0.8997 - val_loss: 0.4254 - val_accuracy: 0.8749\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3375 - accuracy: 0.9008 - val_loss: 0.4251 - val_accuracy: 0.8748\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3379 - accuracy: 0.9017 - val_loss: 0.4249 - val_accuracy: 0.8748\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3369 - accuracy: 0.9013 - val_loss: 0.4250 - val_accuracy: 0.8747\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:11.039694\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9804 - accuracy: 0.7634 - val_loss: 0.7450 - val_accuracy: 0.8077\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6379 - accuracy: 0.8281 - val_loss: 0.7241 - val_accuracy: 0.8010\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5725 - accuracy: 0.8405 - val_loss: 0.6534 - val_accuracy: 0.8221\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5469 - accuracy: 0.8451 - val_loss: 0.7000 - val_accuracy: 0.8091\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5301 - accuracy: 0.8506 - val_loss: 0.6105 - val_accuracy: 0.8347\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5081 - accuracy: 0.8564 - val_loss: 0.7119 - val_accuracy: 0.8055\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4900 - accuracy: 0.8611 - val_loss: 0.5980 - val_accuracy: 0.8345\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4707 - accuracy: 0.8651 - val_loss: 0.6243 - val_accuracy: 0.8341\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:39.042923\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4516 - accuracy: 0.8718 - val_loss: 0.4921 - val_accuracy: 0.8604\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4006 - accuracy: 0.8839 - val_loss: 0.4841 - val_accuracy: 0.8600\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3672 - accuracy: 0.8926 - val_loss: 0.4547 - val_accuracy: 0.8693\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3478 - accuracy: 0.8979 - val_loss: 0.4486 - val_accuracy: 0.8714\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3389 - accuracy: 0.9001 - val_loss: 0.4478 - val_accuracy: 0.8719\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.3341 - accuracy: 0.9014 - val_loss: 0.4471 - val_accuracy: 0.8723\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3315 - accuracy: 0.9024 - val_loss: 0.4468 - val_accuracy: 0.8723\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3308 - accuracy: 0.9021 - val_loss: 0.4468 - val_accuracy: 0.8726\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3314 - accuracy: 0.9028 - val_loss: 0.4468 - val_accuracy: 0.8720\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3305 - accuracy: 0.9033 - val_loss: 0.4468 - val_accuracy: 0.8723\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3310 - accuracy: 0.9030 - val_loss: 0.4468 - val_accuracy: 0.8721\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:10.309910\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0068 - accuracy: 0.7570 - val_loss: 0.7650 - val_accuracy: 0.8003\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6422 - accuracy: 0.8293 - val_loss: 0.6335 - val_accuracy: 0.8201\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5779 - accuracy: 0.8396 - val_loss: 0.7030 - val_accuracy: 0.8022\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5513 - accuracy: 0.8454 - val_loss: 0.6272 - val_accuracy: 0.8244\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5338 - accuracy: 0.8499 - val_loss: 0.7101 - val_accuracy: 0.8037\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5068 - accuracy: 0.8574 - val_loss: 0.7120 - val_accuracy: 0.7978\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4930 - accuracy: 0.8605 - val_loss: 0.5919 - val_accuracy: 0.8331\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4727 - accuracy: 0.8660 - val_loss: 0.5367 - val_accuracy: 0.8481\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4529 - accuracy: 0.8708 - val_loss: 0.5754 - val_accuracy: 0.8374\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4362 - accuracy: 0.8748 - val_loss: 0.4976 - val_accuracy: 0.8548\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4215 - accuracy: 0.8774 - val_loss: 0.4913 - val_accuracy: 0.8619\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4040 - accuracy: 0.8829 - val_loss: 0.5027 - val_accuracy: 0.8540\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3898 - accuracy: 0.8851 - val_loss: 0.4921 - val_accuracy: 0.8598\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3734 - accuracy: 0.8896 - val_loss: 0.4775 - val_accuracy: 0.8614\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:06:30.368203\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 0.3605 - accuracy: 0.8971 - val_loss: 0.4423 - val_accuracy: 0.8710\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3289 - accuracy: 0.9043 - val_loss: 0.4268 - val_accuracy: 0.8752\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3102 - accuracy: 0.9101 - val_loss: 0.4240 - val_accuracy: 0.8762\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2992 - accuracy: 0.9138 - val_loss: 0.4194 - val_accuracy: 0.8767\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2938 - accuracy: 0.9152 - val_loss: 0.4189 - val_accuracy: 0.8778\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2914 - accuracy: 0.9155 - val_loss: 0.4186 - val_accuracy: 0.8779\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2905 - accuracy: 0.9155 - val_loss: 0.4185 - val_accuracy: 0.8782\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2895 - accuracy: 0.9163 - val_loss: 0.4188 - val_accuracy: 0.8779\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2878 - accuracy: 0.9175 - val_loss: 0.4186 - val_accuracy: 0.8779\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2899 - accuracy: 0.9164 - val_loss: 0.4185 - val_accuracy: 0.8781\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:40.713102\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9859 - accuracy: 0.7631 - val_loss: 0.6844 - val_accuracy: 0.8223\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6388 - accuracy: 0.8298 - val_loss: 0.8656 - val_accuracy: 0.7529\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5776 - accuracy: 0.8390 - val_loss: 0.8204 - val_accuracy: 0.7777\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5527 - accuracy: 0.8459 - val_loss: 0.7184 - val_accuracy: 0.7934\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:49.980803\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6121 - accuracy: 0.8385 - val_loss: 0.5742 - val_accuracy: 0.8424\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.5170 - accuracy: 0.8582 - val_loss: 0.5000 - val_accuracy: 0.8635\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4635 - accuracy: 0.8705 - val_loss: 0.4907 - val_accuracy: 0.8596\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4316 - accuracy: 0.8786 - val_loss: 0.4620 - val_accuracy: 0.8681\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4157 - accuracy: 0.8837 - val_loss: 0.4539 - val_accuracy: 0.8712\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4080 - accuracy: 0.8859 - val_loss: 0.4528 - val_accuracy: 0.8726\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4031 - accuracy: 0.8873 - val_loss: 0.4518 - val_accuracy: 0.8726\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4036 - accuracy: 0.8865 - val_loss: 0.4516 - val_accuracy: 0.8728\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4031 - accuracy: 0.8877 - val_loss: 0.4514 - val_accuracy: 0.8728\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4029 - accuracy: 0.8884 - val_loss: 0.4515 - val_accuracy: 0.8730\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4035 - accuracy: 0.8868 - val_loss: 0.4514 - val_accuracy: 0.8726\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4016 - accuracy: 0.8872 - val_loss: 0.4514 - val_accuracy: 0.8728\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4037 - accuracy: 0.8869 - val_loss: 0.4514 - val_accuracy: 0.8727\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:06:02.873749\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9883 - accuracy: 0.7625 - val_loss: 0.6743 - val_accuracy: 0.8268\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6389 - accuracy: 0.8301 - val_loss: 0.7700 - val_accuracy: 0.7834\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5742 - accuracy: 0.8400 - val_loss: 0.6165 - val_accuracy: 0.8299\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5492 - accuracy: 0.8461 - val_loss: 0.6682 - val_accuracy: 0.8026\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5355 - accuracy: 0.8495 - val_loss: 0.6269 - val_accuracy: 0.8232\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5114 - accuracy: 0.8572 - val_loss: 0.5623 - val_accuracy: 0.8435\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4905 - accuracy: 0.8621 - val_loss: 0.5290 - val_accuracy: 0.8499\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4713 - accuracy: 0.8674 - val_loss: 0.5248 - val_accuracy: 0.8511\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4548 - accuracy: 0.8706 - val_loss: 0.5780 - val_accuracy: 0.8326\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4342 - accuracy: 0.8760 - val_loss: 0.5094 - val_accuracy: 0.8535\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4195 - accuracy: 0.8782 - val_loss: 0.5201 - val_accuracy: 0.8512\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4073 - accuracy: 0.8820 - val_loss: 0.5008 - val_accuracy: 0.8590\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3908 - accuracy: 0.8862 - val_loss: 0.4701 - val_accuracy: 0.8655\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3789 - accuracy: 0.8887 - val_loss: 0.4807 - val_accuracy: 0.8617\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3627 - accuracy: 0.8939 - val_loss: 0.4827 - val_accuracy: 0.8582\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3511 - accuracy: 0.8949 - val_loss: 0.4594 - val_accuracy: 0.8686\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3377 - accuracy: 0.8991 - val_loss: 0.4784 - val_accuracy: 0.8620\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3228 - accuracy: 0.9033 - val_loss: 0.4622 - val_accuracy: 0.8638\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3106 - accuracy: 0.9069 - val_loss: 0.4664 - val_accuracy: 0.8641\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:36.960375\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3063 - accuracy: 0.9110 - val_loss: 0.4346 - val_accuracy: 0.8706\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2843 - accuracy: 0.9174 - val_loss: 0.4336 - val_accuracy: 0.8733\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2714 - accuracy: 0.9217 - val_loss: 0.4312 - val_accuracy: 0.8731\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2660 - accuracy: 0.9237 - val_loss: 0.4312 - val_accuracy: 0.8724\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2635 - accuracy: 0.9241 - val_loss: 0.4309 - val_accuracy: 0.8719\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:25.140127\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9360 - accuracy: 0.7753 - val_loss: 0.6469 - val_accuracy: 0.8325\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.5792 - accuracy: 0.8449 - val_loss: 0.5511 - val_accuracy: 0.8449\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.5096 - accuracy: 0.8583 - val_loss: 0.4966 - val_accuracy: 0.8620\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4825 - accuracy: 0.8640 - val_loss: 0.4940 - val_accuracy: 0.8643\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4686 - accuracy: 0.8674 - val_loss: 0.4947 - val_accuracy: 0.8637\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4454 - accuracy: 0.8740 - val_loss: 0.4849 - val_accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4279 - accuracy: 0.8768 - val_loss: 0.4669 - val_accuracy: 0.8704\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 0.4108 - accuracy: 0.8816 - val_loss: 0.4653 - val_accuracy: 0.8655\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.3920 - accuracy: 0.8868 - val_loss: 0.4540 - val_accuracy: 0.8714\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.3759 - accuracy: 0.8905 - val_loss: 0.4381 - val_accuracy: 0.8754\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3597 - accuracy: 0.8937 - val_loss: 0.4404 - val_accuracy: 0.8766\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3448 - accuracy: 0.8982 - val_loss: 0.4317 - val_accuracy: 0.8747\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3310 - accuracy: 0.9022 - val_loss: 0.4243 - val_accuracy: 0.8777\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3158 - accuracy: 0.9062 - val_loss: 0.4263 - val_accuracy: 0.8751\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3026 - accuracy: 0.9097 - val_loss: 0.4261 - val_accuracy: 0.8771\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2871 - accuracy: 0.9145 - val_loss: 0.4227 - val_accuracy: 0.8773\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:56.675314\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2815 - accuracy: 0.9177 - val_loss: 0.4031 - val_accuracy: 0.8836\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2551 - accuracy: 0.9265 - val_loss: 0.3949 - val_accuracy: 0.8836\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2407 - accuracy: 0.9309 - val_loss: 0.3935 - val_accuracy: 0.8851\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2330 - accuracy: 0.9336 - val_loss: 0.3919 - val_accuracy: 0.8844\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2296 - accuracy: 0.9342 - val_loss: 0.3914 - val_accuracy: 0.8850\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2282 - accuracy: 0.9353 - val_loss: 0.3913 - val_accuracy: 0.8848\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:57.187013\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9311 - accuracy: 0.7778 - val_loss: 0.6794 - val_accuracy: 0.8172\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.5729 - accuracy: 0.8474 - val_loss: 0.5385 - val_accuracy: 0.8533\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.5097 - accuracy: 0.8583 - val_loss: 0.5657 - val_accuracy: 0.8402\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4808 - accuracy: 0.8660 - val_loss: 0.5207 - val_accuracy: 0.8536\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4662 - accuracy: 0.8696 - val_loss: 0.4723 - val_accuracy: 0.8668\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4435 - accuracy: 0.8745 - val_loss: 0.4827 - val_accuracy: 0.8623\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4243 - accuracy: 0.8788 - val_loss: 0.4652 - val_accuracy: 0.8661\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4069 - accuracy: 0.8827 - val_loss: 0.4787 - val_accuracy: 0.8612\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:55.912966\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3870 - accuracy: 0.8897 - val_loss: 0.4206 - val_accuracy: 0.8770\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3367 - accuracy: 0.9023 - val_loss: 0.3929 - val_accuracy: 0.8827\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3069 - accuracy: 0.9108 - val_loss: 0.3822 - val_accuracy: 0.8849\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2903 - accuracy: 0.9151 - val_loss: 0.3775 - val_accuracy: 0.8852\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2806 - accuracy: 0.9177 - val_loss: 0.3769 - val_accuracy: 0.8857\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2768 - accuracy: 0.9186 - val_loss: 0.3763 - val_accuracy: 0.8855\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2751 - accuracy: 0.9198 - val_loss: 0.3759 - val_accuracy: 0.8855\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2736 - accuracy: 0.9202 - val_loss: 0.3759 - val_accuracy: 0.8855\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:56.752959\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9472 - accuracy: 0.7713 - val_loss: 0.7070 - val_accuracy: 0.8194\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5864 - accuracy: 0.8422 - val_loss: 0.5682 - val_accuracy: 0.8434\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5117 - accuracy: 0.8565 - val_loss: 0.5212 - val_accuracy: 0.8517\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4850 - accuracy: 0.8626 - val_loss: 0.5018 - val_accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4668 - accuracy: 0.8676 - val_loss: 0.4961 - val_accuracy: 0.8645\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4486 - accuracy: 0.8722 - val_loss: 0.5044 - val_accuracy: 0.8625\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4250 - accuracy: 0.8773 - val_loss: 0.4682 - val_accuracy: 0.8706\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4087 - accuracy: 0.8821 - val_loss: 0.4707 - val_accuracy: 0.8676\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3920 - accuracy: 0.8857 - val_loss: 0.4514 - val_accuracy: 0.8723\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3745 - accuracy: 0.8893 - val_loss: 0.4474 - val_accuracy: 0.8745\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3614 - accuracy: 0.8922 - val_loss: 0.4395 - val_accuracy: 0.8780\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3452 - accuracy: 0.8976 - val_loss: 0.4418 - val_accuracy: 0.8766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3289 - accuracy: 0.9019 - val_loss: 0.4351 - val_accuracy: 0.8763\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3144 - accuracy: 0.9051 - val_loss: 0.4244 - val_accuracy: 0.8801\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3009 - accuracy: 0.9099 - val_loss: 0.4299 - val_accuracy: 0.8767\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2894 - accuracy: 0.9125 - val_loss: 0.4187 - val_accuracy: 0.8808\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.2741 - accuracy: 0.9176 - val_loss: 0.4211 - val_accuracy: 0.8791\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2646 - accuracy: 0.9195 - val_loss: 0.4232 - val_accuracy: 0.8798\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2531 - accuracy: 0.9238 - val_loss: 0.4232 - val_accuracy: 0.8797\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:18.593398\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 0.2507 - accuracy: 0.9262 - val_loss: 0.4005 - val_accuracy: 0.8865\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.2299 - accuracy: 0.9336 - val_loss: 0.3995 - val_accuracy: 0.8865\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2192 - accuracy: 0.9378 - val_loss: 0.3997 - val_accuracy: 0.8859\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2137 - accuracy: 0.9397 - val_loss: 0.3984 - val_accuracy: 0.8858\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:02.048244\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.9494 - accuracy: 0.7723 - val_loss: 0.6732 - val_accuracy: 0.8271\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.5869 - accuracy: 0.8444 - val_loss: 0.5433 - val_accuracy: 0.8503\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.5185 - accuracy: 0.8565 - val_loss: 0.5078 - val_accuracy: 0.8583\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4887 - accuracy: 0.8629 - val_loss: 0.5067 - val_accuracy: 0.8574\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4712 - accuracy: 0.8677 - val_loss: 0.4982 - val_accuracy: 0.8607\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.4509 - accuracy: 0.8715 - val_loss: 0.4735 - val_accuracy: 0.8663\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 0.4315 - accuracy: 0.8779 - val_loss: 0.4665 - val_accuracy: 0.8694\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.4121 - accuracy: 0.8821 - val_loss: 0.4593 - val_accuracy: 0.8698\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.3947 - accuracy: 0.8860 - val_loss: 0.4513 - val_accuracy: 0.8708\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.3801 - accuracy: 0.8906 - val_loss: 0.4373 - val_accuracy: 0.8738\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3623 - accuracy: 0.8946 - val_loss: 0.4425 - val_accuracy: 0.8711\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.3484 - accuracy: 0.8970 - val_loss: 0.4360 - val_accuracy: 0.8725\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.3327 - accuracy: 0.9012 - val_loss: 0.4366 - val_accuracy: 0.8724\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:36.081562\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.3204 - accuracy: 0.9087 - val_loss: 0.3958 - val_accuracy: 0.8840\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 0.2861 - accuracy: 0.9166 - val_loss: 0.3888 - val_accuracy: 0.8839\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2663 - accuracy: 0.9232 - val_loss: 0.3818 - val_accuracy: 0.8859\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2566 - accuracy: 0.9259 - val_loss: 0.3814 - val_accuracy: 0.8860\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2520 - accuracy: 0.9282 - val_loss: 0.3809 - val_accuracy: 0.8863\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2494 - accuracy: 0.9287 - val_loss: 0.3807 - val_accuracy: 0.8862\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2475 - accuracy: 0.9296 - val_loss: 0.3806 - val_accuracy: 0.8862\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2479 - accuracy: 0.9287 - val_loss: 0.3806 - val_accuracy: 0.8863\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:02.823443\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.9393 - accuracy: 0.7751 - val_loss: 0.6599 - val_accuracy: 0.8345\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5815 - accuracy: 0.8450 - val_loss: 0.5430 - val_accuracy: 0.8515\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5139 - accuracy: 0.8569 - val_loss: 0.4854 - val_accuracy: 0.8641\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4854 - accuracy: 0.8626 - val_loss: 0.4652 - val_accuracy: 0.8699\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4704 - accuracy: 0.8677 - val_loss: 0.4709 - val_accuracy: 0.8711\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 827s 1s/step - loss: 0.4482 - accuracy: 0.8731 - val_loss: 0.4599 - val_accuracy: 0.8708\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4289 - accuracy: 0.8771 - val_loss: 0.4619 - val_accuracy: 0.8698\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4102 - accuracy: 0.8826 - val_loss: 0.4433 - val_accuracy: 0.8764\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3919 - accuracy: 0.8869 - val_loss: 0.4308 - val_accuracy: 0.8794\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3757 - accuracy: 0.8904 - val_loss: 0.4335 - val_accuracy: 0.8756\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3617 - accuracy: 0.8933 - val_loss: 0.4172 - val_accuracy: 0.8817\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3457 - accuracy: 0.8981 - val_loss: 0.4163 - val_accuracy: 0.8808\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3295 - accuracy: 0.9021 - val_loss: 0.4095 - val_accuracy: 0.8808\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3154 - accuracy: 0.9063 - val_loss: 0.4103 - val_accuracy: 0.8814\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:19:56.578097\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3075 - accuracy: 0.9118 - val_loss: 0.3908 - val_accuracy: 0.8885\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2736 - accuracy: 0.9210 - val_loss: 0.3785 - val_accuracy: 0.8886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2566 - accuracy: 0.9260 - val_loss: 0.3751 - val_accuracy: 0.8905\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2478 - accuracy: 0.9294 - val_loss: 0.3741 - val_accuracy: 0.8903\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2430 - accuracy: 0.9309 - val_loss: 0.3735 - val_accuracy: 0.8910\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2406 - accuracy: 0.9318 - val_loss: 0.3733 - val_accuracy: 0.8913\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2392 - accuracy: 0.9320 - val_loss: 0.3732 - val_accuracy: 0.8914\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2387 - accuracy: 0.9318 - val_loss: 0.3730 - val_accuracy: 0.8911\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2392 - accuracy: 0.9324 - val_loss: 0.3731 - val_accuracy: 0.8912\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2385 - accuracy: 0.9327 - val_loss: 0.3731 - val_accuracy: 0.8911\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:43.772812\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.7084 - accuracy: 0.7970 - val_loss: 0.5173 - val_accuracy: 0.8280\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3925 - accuracy: 0.8653 - val_loss: 0.4161 - val_accuracy: 0.8605\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3394 - accuracy: 0.8795 - val_loss: 0.4400 - val_accuracy: 0.8538\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3057 - accuracy: 0.8882 - val_loss: 0.4026 - val_accuracy: 0.8660\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2770 - accuracy: 0.8975 - val_loss: 0.4062 - val_accuracy: 0.8594\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2495 - accuracy: 0.9055 - val_loss: 0.3781 - val_accuracy: 0.8711\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2242 - accuracy: 0.9138 - val_loss: 0.3815 - val_accuracy: 0.8730\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2033 - accuracy: 0.9206 - val_loss: 0.3728 - val_accuracy: 0.8776\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1830 - accuracy: 0.9281 - val_loss: 0.3988 - val_accuracy: 0.8695\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1641 - accuracy: 0.9353 - val_loss: 0.4017 - val_accuracy: 0.8746\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1478 - accuracy: 0.9415 - val_loss: 0.4193 - val_accuracy: 0.8707\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:47.263498\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1629 - accuracy: 0.9373 - val_loss: 0.3714 - val_accuracy: 0.8783\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.1447 - accuracy: 0.9451 - val_loss: 0.3666 - val_accuracy: 0.8795\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1358 - accuracy: 0.9491 - val_loss: 0.3685 - val_accuracy: 0.8820\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1315 - accuracy: 0.9513 - val_loss: 0.3695 - val_accuracy: 0.8814\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1288 - accuracy: 0.9525 - val_loss: 0.3698 - val_accuracy: 0.8810\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1282 - accuracy: 0.9528 - val_loss: 0.3705 - val_accuracy: 0.8811\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:39.398078\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6937 - accuracy: 0.7968 - val_loss: 0.4888 - val_accuracy: 0.8426\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3874 - accuracy: 0.8662 - val_loss: 0.4104 - val_accuracy: 0.8593\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3350 - accuracy: 0.8812 - val_loss: 0.3947 - val_accuracy: 0.8631\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3015 - accuracy: 0.8904 - val_loss: 0.3740 - val_accuracy: 0.8708\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2743 - accuracy: 0.8984 - val_loss: 0.3858 - val_accuracy: 0.8672\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2471 - accuracy: 0.9056 - val_loss: 0.3840 - val_accuracy: 0.8699\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2231 - accuracy: 0.9148 - val_loss: 0.3800 - val_accuracy: 0.8732\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2006 - accuracy: 0.9217 - val_loss: 0.3860 - val_accuracy: 0.8723\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1810 - accuracy: 0.9284 - val_loss: 0.4121 - val_accuracy: 0.8676\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1629 - accuracy: 0.9356 - val_loss: 0.4079 - val_accuracy: 0.8684\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:22.047817\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1796 - accuracy: 0.9300 - val_loss: 0.3596 - val_accuracy: 0.8788\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1586 - accuracy: 0.9389 - val_loss: 0.3537 - val_accuracy: 0.8812\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1478 - accuracy: 0.9434 - val_loss: 0.3570 - val_accuracy: 0.8816\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1427 - accuracy: 0.9464 - val_loss: 0.3584 - val_accuracy: 0.8813\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1400 - accuracy: 0.9475 - val_loss: 0.3584 - val_accuracy: 0.8820\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1387 - accuracy: 0.9480 - val_loss: 0.3592 - val_accuracy: 0.8822\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1380 - accuracy: 0.9485 - val_loss: 0.3596 - val_accuracy: 0.8817\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1376 - accuracy: 0.9492 - val_loss: 0.3596 - val_accuracy: 0.8820\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1380 - accuracy: 0.9487 - val_loss: 0.3597 - val_accuracy: 0.8817\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:55.845979\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.7128 - accuracy: 0.7942 - val_loss: 0.4728 - val_accuracy: 0.8431\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.3926 - accuracy: 0.8664 - val_loss: 0.4085 - val_accuracy: 0.8631\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.3375 - accuracy: 0.8800 - val_loss: 0.3682 - val_accuracy: 0.8691\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3026 - accuracy: 0.8913 - val_loss: 0.3752 - val_accuracy: 0.8678\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2774 - accuracy: 0.8984 - val_loss: 0.3659 - val_accuracy: 0.8719\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2489 - accuracy: 0.9067 - val_loss: 0.3618 - val_accuracy: 0.8762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2240 - accuracy: 0.9142 - val_loss: 0.3910 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2035 - accuracy: 0.9210 - val_loss: 0.3774 - val_accuracy: 0.8725\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1843 - accuracy: 0.9281 - val_loss: 0.3617 - val_accuracy: 0.8777\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1659 - accuracy: 0.9353 - val_loss: 0.3862 - val_accuracy: 0.8732\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1493 - accuracy: 0.9417 - val_loss: 0.4040 - val_accuracy: 0.8720\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1356 - accuracy: 0.9472 - val_loss: 0.4059 - val_accuracy: 0.8750\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:06.679059\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1487 - accuracy: 0.9438 - val_loss: 0.3621 - val_accuracy: 0.8797\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1327 - accuracy: 0.9506 - val_loss: 0.3659 - val_accuracy: 0.8798\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1250 - accuracy: 0.9535 - val_loss: 0.3654 - val_accuracy: 0.8792\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1208 - accuracy: 0.9560 - val_loss: 0.3666 - val_accuracy: 0.8800\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1192 - accuracy: 0.9571 - val_loss: 0.3673 - val_accuracy: 0.8797\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.1181 - accuracy: 0.9572 - val_loss: 0.3679 - val_accuracy: 0.8798\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1178 - accuracy: 0.9574 - val_loss: 0.3677 - val_accuracy: 0.8803\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1173 - accuracy: 0.9578 - val_loss: 0.3679 - val_accuracy: 0.8801\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1173 - accuracy: 0.9578 - val_loss: 0.3679 - val_accuracy: 0.8803\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1174 - accuracy: 0.9575 - val_loss: 0.3675 - val_accuracy: 0.8803\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:16.832925\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.6950 - accuracy: 0.7957 - val_loss: 0.4567 - val_accuracy: 0.8461\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3894 - accuracy: 0.8662 - val_loss: 0.4149 - val_accuracy: 0.8567\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3344 - accuracy: 0.8824 - val_loss: 0.3827 - val_accuracy: 0.8654\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2988 - accuracy: 0.8912 - val_loss: 0.3611 - val_accuracy: 0.8684\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2725 - accuracy: 0.8994 - val_loss: 0.3624 - val_accuracy: 0.8699\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2446 - accuracy: 0.9086 - val_loss: 0.3663 - val_accuracy: 0.8698\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2194 - accuracy: 0.9153 - val_loss: 0.3620 - val_accuracy: 0.8678\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.1979 - accuracy: 0.9236 - val_loss: 0.3606 - val_accuracy: 0.8703\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1766 - accuracy: 0.9310 - val_loss: 0.3685 - val_accuracy: 0.8720\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.1593 - accuracy: 0.9372 - val_loss: 0.3771 - val_accuracy: 0.8690\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1447 - accuracy: 0.9431 - val_loss: 0.3854 - val_accuracy: 0.8719\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1293 - accuracy: 0.9494 - val_loss: 0.4061 - val_accuracy: 0.8685\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:06.409662\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1421 - accuracy: 0.9452 - val_loss: 0.3572 - val_accuracy: 0.8756\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.1263 - accuracy: 0.9531 - val_loss: 0.3589 - val_accuracy: 0.8767\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1184 - accuracy: 0.9563 - val_loss: 0.3596 - val_accuracy: 0.8780\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1148 - accuracy: 0.9585 - val_loss: 0.3603 - val_accuracy: 0.8765\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1127 - accuracy: 0.9592 - val_loss: 0.3608 - val_accuracy: 0.8773\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1110 - accuracy: 0.9602 - val_loss: 0.3609 - val_accuracy: 0.8774\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:31.824410\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6979 - accuracy: 0.7963 - val_loss: 0.5132 - val_accuracy: 0.8348\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3878 - accuracy: 0.8669 - val_loss: 0.4718 - val_accuracy: 0.8523\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3301 - accuracy: 0.8837 - val_loss: 0.3905 - val_accuracy: 0.8644\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2946 - accuracy: 0.8928 - val_loss: 0.3884 - val_accuracy: 0.8647\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2675 - accuracy: 0.9000 - val_loss: 0.3679 - val_accuracy: 0.8710\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2397 - accuracy: 0.9084 - val_loss: 0.3895 - val_accuracy: 0.8689\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2142 - accuracy: 0.9166 - val_loss: 0.3700 - val_accuracy: 0.8762\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1916 - accuracy: 0.9248 - val_loss: 0.3969 - val_accuracy: 0.8703\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1720 - accuracy: 0.9321 - val_loss: 0.3917 - val_accuracy: 0.8704\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1538 - accuracy: 0.9392 - val_loss: 0.4087 - val_accuracy: 0.8707\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:23.525531\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1706 - accuracy: 0.9340 - val_loss: 0.3613 - val_accuracy: 0.8789\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1490 - accuracy: 0.9432 - val_loss: 0.3583 - val_accuracy: 0.8821\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1385 - accuracy: 0.9480 - val_loss: 0.3614 - val_accuracy: 0.8804\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.1337 - accuracy: 0.9504 - val_loss: 0.3610 - val_accuracy: 0.8805\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1304 - accuracy: 0.9522 - val_loss: 0.3616 - val_accuracy: 0.8802\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:13.239203\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7157 - accuracy: 0.7838 - val_loss: 0.5137 - val_accuracy: 0.8342\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4486 - accuracy: 0.8503 - val_loss: 0.4949 - val_accuracy: 0.8388\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3907 - accuracy: 0.8661 - val_loss: 0.4432 - val_accuracy: 0.8530\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3508 - accuracy: 0.8766 - val_loss: 0.4022 - val_accuracy: 0.8625\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3182 - accuracy: 0.8863 - val_loss: 0.4004 - val_accuracy: 0.8661\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2847 - accuracy: 0.8960 - val_loss: 0.3913 - val_accuracy: 0.8664\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2568 - accuracy: 0.9053 - val_loss: 0.3901 - val_accuracy: 0.8711\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2319 - accuracy: 0.9129 - val_loss: 0.3957 - val_accuracy: 0.8670\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2108 - accuracy: 0.9198 - val_loss: 0.4103 - val_accuracy: 0.8664\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1900 - accuracy: 0.9265 - val_loss: 0.4011 - val_accuracy: 0.8712\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1746 - accuracy: 0.9329 - val_loss: 0.4057 - val_accuracy: 0.8705\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1590 - accuracy: 0.9394 - val_loss: 0.4159 - val_accuracy: 0.8679\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1455 - accuracy: 0.9434 - val_loss: 0.4297 - val_accuracy: 0.8694\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:53.566649\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1575 - accuracy: 0.9415 - val_loss: 0.3911 - val_accuracy: 0.8742\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1430 - accuracy: 0.9478 - val_loss: 0.3901 - val_accuracy: 0.8756\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1360 - accuracy: 0.9503 - val_loss: 0.3927 - val_accuracy: 0.8738\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1325 - accuracy: 0.9517 - val_loss: 0.3904 - val_accuracy: 0.8760\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1305 - accuracy: 0.9523 - val_loss: 0.3920 - val_accuracy: 0.8746\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1298 - accuracy: 0.9529 - val_loss: 0.3918 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1291 - accuracy: 0.9528 - val_loss: 0.3924 - val_accuracy: 0.8754\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:12.691707\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7127 - accuracy: 0.7872 - val_loss: 0.5037 - val_accuracy: 0.8375\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4467 - accuracy: 0.8522 - val_loss: 0.4784 - val_accuracy: 0.8409\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25770s 37s/step - loss: 0.3895 - accuracy: 0.8671 - val_loss: 0.4723 - val_accuracy: 0.8382\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.3490 - accuracy: 0.8790 - val_loss: 0.4440 - val_accuracy: 0.8526\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3160 - accuracy: 0.8874 - val_loss: 0.5004 - val_accuracy: 0.8399\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2833 - accuracy: 0.8979 - val_loss: 0.4028 - val_accuracy: 0.8608\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2566 - accuracy: 0.9059 - val_loss: 0.3955 - val_accuracy: 0.8667\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.2322 - accuracy: 0.9137 - val_loss: 0.4117 - val_accuracy: 0.8627\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2111 - accuracy: 0.9208 - val_loss: 0.4002 - val_accuracy: 0.8668\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.1915 - accuracy: 0.9270 - val_loss: 0.4091 - val_accuracy: 0.8669\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1752 - accuracy: 0.9332 - val_loss: 0.4018 - val_accuracy: 0.8699\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.1607 - accuracy: 0.9379 - val_loss: 0.4169 - val_accuracy: 0.8681\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1472 - accuracy: 0.9429 - val_loss: 0.4325 - val_accuracy: 0.8656\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1356 - accuracy: 0.9484 - val_loss: 0.4384 - val_accuracy: 0.8658\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 7:15:22.279292\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1464 - accuracy: 0.9447 - val_loss: 0.3944 - val_accuracy: 0.8734\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1330 - accuracy: 0.9512 - val_loss: 0.3985 - val_accuracy: 0.8735\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1273 - accuracy: 0.9538 - val_loss: 0.3986 - val_accuracy: 0.8736\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1244 - accuracy: 0.9548 - val_loss: 0.3989 - val_accuracy: 0.8733\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1227 - accuracy: 0.9553 - val_loss: 0.4000 - val_accuracy: 0.8728\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1215 - accuracy: 0.9565 - val_loss: 0.4002 - val_accuracy: 0.8726\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:39.754274\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7050 - accuracy: 0.7889 - val_loss: 0.5442 - val_accuracy: 0.8246\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4438 - accuracy: 0.8523 - val_loss: 0.4708 - val_accuracy: 0.8451\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3887 - accuracy: 0.8676 - val_loss: 0.4544 - val_accuracy: 0.8437\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3477 - accuracy: 0.8784 - val_loss: 0.4157 - val_accuracy: 0.8607\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3179 - accuracy: 0.8867 - val_loss: 0.5156 - val_accuracy: 0.8308\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2859 - accuracy: 0.8957 - val_loss: 0.4108 - val_accuracy: 0.8599\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 462s 656ms/step - loss: 0.2588 - accuracy: 0.9042 - val_loss: 0.4116 - val_accuracy: 0.8606\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:10:22.465045\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2882 - accuracy: 0.8980 - val_loss: 0.3863 - val_accuracy: 0.8667\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2560 - accuracy: 0.9091 - val_loss: 0.3751 - val_accuracy: 0.8722\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2382 - accuracy: 0.9158 - val_loss: 0.3709 - val_accuracy: 0.8740\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2287 - accuracy: 0.9193 - val_loss: 0.3690 - val_accuracy: 0.8753\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2241 - accuracy: 0.9215 - val_loss: 0.3690 - val_accuracy: 0.8754\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2214 - accuracy: 0.9220 - val_loss: 0.3693 - val_accuracy: 0.8755\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2204 - accuracy: 0.9224 - val_loss: 0.3691 - val_accuracy: 0.8755\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2200 - accuracy: 0.9226 - val_loss: 0.3693 - val_accuracy: 0.8751\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2202 - accuracy: 0.9226 - val_loss: 0.3692 - val_accuracy: 0.8754\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:07.835628\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7134 - accuracy: 0.7860 - val_loss: 0.5512 - val_accuracy: 0.8179\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4467 - accuracy: 0.8505 - val_loss: 0.4698 - val_accuracy: 0.8415\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3896 - accuracy: 0.8657 - val_loss: 0.4538 - val_accuracy: 0.8452\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3489 - accuracy: 0.8780 - val_loss: 0.4943 - val_accuracy: 0.8397\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3170 - accuracy: 0.8866 - val_loss: 0.4062 - val_accuracy: 0.8622\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2828 - accuracy: 0.8977 - val_loss: 0.4100 - val_accuracy: 0.8638\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2561 - accuracy: 0.9056 - val_loss: 0.4163 - val_accuracy: 0.8582\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2332 - accuracy: 0.9120 - val_loss: 0.4038 - val_accuracy: 0.8648\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2102 - accuracy: 0.9202 - val_loss: 0.4014 - val_accuracy: 0.8659\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1911 - accuracy: 0.9262 - val_loss: 0.4204 - val_accuracy: 0.8643\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1759 - accuracy: 0.9312 - val_loss: 0.4187 - val_accuracy: 0.8682\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1607 - accuracy: 0.9375 - val_loss: 0.4300 - val_accuracy: 0.8633\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1475 - accuracy: 0.9429 - val_loss: 0.4320 - val_accuracy: 0.8673\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1362 - accuracy: 0.9471 - val_loss: 0.4505 - val_accuracy: 0.8649\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:06:31.117055\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.1463 - accuracy: 0.9439 - val_loss: 0.4108 - val_accuracy: 0.8697\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1330 - accuracy: 0.9499 - val_loss: 0.4082 - val_accuracy: 0.8697\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1272 - accuracy: 0.9529 - val_loss: 0.4098 - val_accuracy: 0.8698\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1240 - accuracy: 0.9537 - val_loss: 0.4101 - val_accuracy: 0.8705\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1227 - accuracy: 0.9550 - val_loss: 0.4113 - val_accuracy: 0.8705\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1215 - accuracy: 0.9557 - val_loss: 0.4116 - val_accuracy: 0.8702\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1213 - accuracy: 0.9557 - val_loss: 0.4120 - val_accuracy: 0.8704\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1215 - accuracy: 0.9549 - val_loss: 0.4119 - val_accuracy: 0.8707\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1217 - accuracy: 0.9551 - val_loss: 0.4117 - val_accuracy: 0.8707\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1213 - accuracy: 0.9553 - val_loss: 0.4117 - val_accuracy: 0.8703\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1211 - accuracy: 0.9558 - val_loss: 0.4121 - val_accuracy: 0.8706\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1214 - accuracy: 0.9556 - val_loss: 0.4118 - val_accuracy: 0.8705\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:35.693225\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7077 - accuracy: 0.7860 - val_loss: 0.5347 - val_accuracy: 0.8204\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4478 - accuracy: 0.8516 - val_loss: 0.5080 - val_accuracy: 0.8302\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3907 - accuracy: 0.8667 - val_loss: 0.5346 - val_accuracy: 0.8281\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3495 - accuracy: 0.8770 - val_loss: 0.4208 - val_accuracy: 0.8584\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3188 - accuracy: 0.8855 - val_loss: 0.4541 - val_accuracy: 0.8473\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2875 - accuracy: 0.8958 - val_loss: 0.4078 - val_accuracy: 0.8650\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2609 - accuracy: 0.9039 - val_loss: 0.3825 - val_accuracy: 0.8688\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2371 - accuracy: 0.9107 - val_loss: 0.3855 - val_accuracy: 0.8725\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2145 - accuracy: 0.9184 - val_loss: 0.4297 - val_accuracy: 0.8611\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1959 - accuracy: 0.9248 - val_loss: 0.3993 - val_accuracy: 0.8706\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1785 - accuracy: 0.9312 - val_loss: 0.4118 - val_accuracy: 0.8684\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:05.288304\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.1944 - accuracy: 0.9274 - val_loss: 0.3702 - val_accuracy: 0.8768\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1750 - accuracy: 0.9350 - val_loss: 0.3708 - val_accuracy: 0.8756\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1667 - accuracy: 0.9381 - val_loss: 0.3713 - val_accuracy: 0.8768\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1605 - accuracy: 0.9412 - val_loss: 0.3714 - val_accuracy: 0.8767\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:55.304364\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6603 - accuracy: 0.7989 - val_loss: 0.4733 - val_accuracy: 0.8412\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4016 - accuracy: 0.8616 - val_loss: 0.5450 - val_accuracy: 0.8183\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3471 - accuracy: 0.8786 - val_loss: 0.3895 - val_accuracy: 0.8642\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3134 - accuracy: 0.8872 - val_loss: 0.3929 - val_accuracy: 0.8626\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2850 - accuracy: 0.8960 - val_loss: 0.3687 - val_accuracy: 0.8742\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2573 - accuracy: 0.9040 - val_loss: 0.3738 - val_accuracy: 0.8707\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2341 - accuracy: 0.9111 - val_loss: 0.3681 - val_accuracy: 0.8749\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2109 - accuracy: 0.9196 - val_loss: 0.3780 - val_accuracy: 0.8727\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1931 - accuracy: 0.9254 - val_loss: 0.3767 - val_accuracy: 0.8762\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1763 - accuracy: 0.9309 - val_loss: 0.3963 - val_accuracy: 0.8718\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1611 - accuracy: 0.9363 - val_loss: 0.3996 - val_accuracy: 0.8723\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1456 - accuracy: 0.9427 - val_loss: 0.4173 - val_accuracy: 0.8679\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:33.273764\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1570 - accuracy: 0.9395 - val_loss: 0.3644 - val_accuracy: 0.8785\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1410 - accuracy: 0.9468 - val_loss: 0.3666 - val_accuracy: 0.8804\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.1324 - accuracy: 0.9504 - val_loss: 0.3675 - val_accuracy: 0.8801\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1285 - accuracy: 0.9528 - val_loss: 0.3683 - val_accuracy: 0.8808\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1265 - accuracy: 0.9534 - val_loss: 0.3686 - val_accuracy: 0.8800\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1254 - accuracy: 0.9538 - val_loss: 0.3687 - val_accuracy: 0.8811\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1244 - accuracy: 0.9542 - val_loss: 0.3688 - val_accuracy: 0.8808\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1244 - accuracy: 0.9547 - val_loss: 0.3689 - val_accuracy: 0.8809\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1248 - accuracy: 0.9545 - val_loss: 0.3690 - val_accuracy: 0.8811\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:14.461798\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6719 - accuracy: 0.7961 - val_loss: 0.4852 - val_accuracy: 0.8372\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4050 - accuracy: 0.8617 - val_loss: 0.4094 - val_accuracy: 0.8619\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3479 - accuracy: 0.8783 - val_loss: 0.3920 - val_accuracy: 0.8664\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3141 - accuracy: 0.8867 - val_loss: 0.3892 - val_accuracy: 0.8621\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2877 - accuracy: 0.8945 - val_loss: 0.3958 - val_accuracy: 0.8658\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2592 - accuracy: 0.9028 - val_loss: 0.3713 - val_accuracy: 0.8763\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2332 - accuracy: 0.9114 - val_loss: 0.3837 - val_accuracy: 0.8661\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2115 - accuracy: 0.9183 - val_loss: 0.3854 - val_accuracy: 0.8715\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1922 - accuracy: 0.9254 - val_loss: 0.4005 - val_accuracy: 0.8671\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:06.855876\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2091 - accuracy: 0.9222 - val_loss: 0.3530 - val_accuracy: 0.8805\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1846 - accuracy: 0.9307 - val_loss: 0.3488 - val_accuracy: 0.8827\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1719 - accuracy: 0.9357 - val_loss: 0.3519 - val_accuracy: 0.8803\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1649 - accuracy: 0.9388 - val_loss: 0.3500 - val_accuracy: 0.8801\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1621 - accuracy: 0.9401 - val_loss: 0.3507 - val_accuracy: 0.8804\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:16.850110\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6879 - accuracy: 0.7934 - val_loss: 0.4892 - val_accuracy: 0.8401\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4111 - accuracy: 0.8619 - val_loss: 0.4193 - val_accuracy: 0.8563\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3545 - accuracy: 0.8758 - val_loss: 0.3894 - val_accuracy: 0.8674\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3207 - accuracy: 0.8856 - val_loss: 0.3978 - val_accuracy: 0.8635\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2904 - accuracy: 0.8942 - val_loss: 0.3910 - val_accuracy: 0.8698\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2644 - accuracy: 0.9019 - val_loss: 0.3777 - val_accuracy: 0.8701\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2374 - accuracy: 0.9100 - val_loss: 0.3658 - val_accuracy: 0.8752\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2170 - accuracy: 0.9169 - val_loss: 0.3776 - val_accuracy: 0.8754\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1964 - accuracy: 0.9238 - val_loss: 0.3901 - val_accuracy: 0.8715\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1800 - accuracy: 0.9295 - val_loss: 0.3957 - val_accuracy: 0.8719\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1639 - accuracy: 0.9352 - val_loss: 0.4062 - val_accuracy: 0.8725\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:00.181080\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1757 - accuracy: 0.9331 - val_loss: 0.3617 - val_accuracy: 0.8797\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1570 - accuracy: 0.9409 - val_loss: 0.3602 - val_accuracy: 0.8810\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1479 - accuracy: 0.9447 - val_loss: 0.3628 - val_accuracy: 0.8794\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1433 - accuracy: 0.9470 - val_loss: 0.3635 - val_accuracy: 0.8801\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1410 - accuracy: 0.9484 - val_loss: 0.3643 - val_accuracy: 0.8793\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:16.542902\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6759 - accuracy: 0.7957 - val_loss: 0.4723 - val_accuracy: 0.8419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4042 - accuracy: 0.8627 - val_loss: 0.4375 - val_accuracy: 0.8504\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3473 - accuracy: 0.8775 - val_loss: 0.4197 - val_accuracy: 0.8539\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3156 - accuracy: 0.8875 - val_loss: 0.3894 - val_accuracy: 0.8609\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2872 - accuracy: 0.8961 - val_loss: 0.3845 - val_accuracy: 0.8636\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2590 - accuracy: 0.9040 - val_loss: 0.3831 - val_accuracy: 0.8666\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2347 - accuracy: 0.9115 - val_loss: 0.3775 - val_accuracy: 0.8704\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2117 - accuracy: 0.9193 - val_loss: 0.3863 - val_accuracy: 0.8681\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1924 - accuracy: 0.9259 - val_loss: 0.4075 - val_accuracy: 0.8624\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1746 - accuracy: 0.9324 - val_loss: 0.3991 - val_accuracy: 0.8681\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:34.193204\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1898 - accuracy: 0.9291 - val_loss: 0.3546 - val_accuracy: 0.8771\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1680 - accuracy: 0.9383 - val_loss: 0.3576 - val_accuracy: 0.8780\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1571 - accuracy: 0.9425 - val_loss: 0.3574 - val_accuracy: 0.8780\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1517 - accuracy: 0.9446 - val_loss: 0.3586 - val_accuracy: 0.8772\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1487 - accuracy: 0.9462 - val_loss: 0.3587 - val_accuracy: 0.8784\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1479 - accuracy: 0.9465 - val_loss: 0.3590 - val_accuracy: 0.8779\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1464 - accuracy: 0.9467 - val_loss: 0.3593 - val_accuracy: 0.8778\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1464 - accuracy: 0.9468 - val_loss: 0.3591 - val_accuracy: 0.8777\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:40.238355\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6717 - accuracy: 0.7979 - val_loss: 0.4732 - val_accuracy: 0.8436\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3996 - accuracy: 0.8640 - val_loss: 0.4353 - val_accuracy: 0.8534\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3453 - accuracy: 0.8801 - val_loss: 0.4210 - val_accuracy: 0.8559\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3097 - accuracy: 0.8887 - val_loss: 0.4161 - val_accuracy: 0.8580\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2846 - accuracy: 0.8965 - val_loss: 0.4004 - val_accuracy: 0.8652\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2565 - accuracy: 0.9042 - val_loss: 0.3944 - val_accuracy: 0.8662\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2326 - accuracy: 0.9117 - val_loss: 0.3772 - val_accuracy: 0.8677\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2115 - accuracy: 0.9181 - val_loss: 0.3892 - val_accuracy: 0.8700\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1906 - accuracy: 0.9270 - val_loss: 0.3820 - val_accuracy: 0.8706\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1745 - accuracy: 0.9323 - val_loss: 0.4037 - val_accuracy: 0.8664\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1594 - accuracy: 0.9376 - val_loss: 0.4083 - val_accuracy: 0.8672\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1444 - accuracy: 0.9434 - val_loss: 0.4481 - val_accuracy: 0.8602\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:25.835012\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1557 - accuracy: 0.9404 - val_loss: 0.3772 - val_accuracy: 0.8743\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1396 - accuracy: 0.9478 - val_loss: 0.3783 - val_accuracy: 0.8742\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1316 - accuracy: 0.9509 - val_loss: 0.3790 - val_accuracy: 0.8746\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1278 - accuracy: 0.9528 - val_loss: 0.3812 - val_accuracy: 0.8744\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1251 - accuracy: 0.9538 - val_loss: 0.3818 - val_accuracy: 0.8742\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1242 - accuracy: 0.9542 - val_loss: 0.3826 - val_accuracy: 0.8738\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:42.682743\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 1.7639 - accuracy: 0.7771 - val_loss: 0.9518 - val_accuracy: 0.8086\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.8048 - accuracy: 0.8361 - val_loss: 0.8432 - val_accuracy: 0.8246\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.7362 - accuracy: 0.8465 - val_loss: 0.7788 - val_accuracy: 0.8354\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.7040 - accuracy: 0.8511 - val_loss: 0.7590 - val_accuracy: 0.8348\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.6860 - accuracy: 0.8548 - val_loss: 0.7738 - val_accuracy: 0.8329\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.6524 - accuracy: 0.8606 - val_loss: 0.7711 - val_accuracy: 0.8313\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:33.265748\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5964 - accuracy: 0.8658 - val_loss: 0.6442 - val_accuracy: 0.8499\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5153 - accuracy: 0.8752 - val_loss: 0.5577 - val_accuracy: 0.8621\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4659 - accuracy: 0.8816 - val_loss: 0.4991 - val_accuracy: 0.8724\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4370 - accuracy: 0.8847 - val_loss: 0.4729 - val_accuracy: 0.8752\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4214 - accuracy: 0.8867 - val_loss: 0.4629 - val_accuracy: 0.8757\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4132 - accuracy: 0.8877 - val_loss: 0.4571 - val_accuracy: 0.8769\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4097 - accuracy: 0.8889 - val_loss: 0.4551 - val_accuracy: 0.8768\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4079 - accuracy: 0.8897 - val_loss: 0.4545 - val_accuracy: 0.8770\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4077 - accuracy: 0.8891 - val_loss: 0.4543 - val_accuracy: 0.8770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4071 - accuracy: 0.8895 - val_loss: 0.4543 - val_accuracy: 0.8770\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4070 - accuracy: 0.8895 - val_loss: 0.4543 - val_accuracy: 0.8767\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:05.282328\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7956 - accuracy: 0.7748 - val_loss: 1.0915 - val_accuracy: 0.7614\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8186 - accuracy: 0.8343 - val_loss: 0.8675 - val_accuracy: 0.8109\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7474 - accuracy: 0.8446 - val_loss: 0.7861 - val_accuracy: 0.8271\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7112 - accuracy: 0.8500 - val_loss: 0.7344 - val_accuracy: 0.8424\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6881 - accuracy: 0.8541 - val_loss: 0.7571 - val_accuracy: 0.8352\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6567 - accuracy: 0.8597 - val_loss: 0.7088 - val_accuracy: 0.8410\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6285 - accuracy: 0.8634 - val_loss: 0.6462 - val_accuracy: 0.8556\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6045 - accuracy: 0.8668 - val_loss: 0.6636 - val_accuracy: 0.8465\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5841 - accuracy: 0.8697 - val_loss: 0.6190 - val_accuracy: 0.8609\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5634 - accuracy: 0.8716 - val_loss: 0.5913 - val_accuracy: 0.8640\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5465 - accuracy: 0.8729 - val_loss: 0.6065 - val_accuracy: 0.8593\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5313 - accuracy: 0.8758 - val_loss: 0.5817 - val_accuracy: 0.8629\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5121 - accuracy: 0.8778 - val_loss: 0.5580 - val_accuracy: 0.8628\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:55.248580\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4682 - accuracy: 0.8858 - val_loss: 0.5044 - val_accuracy: 0.8718\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4246 - accuracy: 0.8911 - val_loss: 0.4612 - val_accuracy: 0.8768\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4007 - accuracy: 0.8934 - val_loss: 0.4431 - val_accuracy: 0.8778\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3882 - accuracy: 0.8953 - val_loss: 0.4348 - val_accuracy: 0.8785\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3806 - accuracy: 0.8961 - val_loss: 0.4293 - val_accuracy: 0.8788\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3769 - accuracy: 0.8968 - val_loss: 0.4276 - val_accuracy: 0.8795\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3756 - accuracy: 0.8970 - val_loss: 0.4270 - val_accuracy: 0.8790\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3751 - accuracy: 0.8969 - val_loss: 0.4267 - val_accuracy: 0.8789\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3747 - accuracy: 0.8971 - val_loss: 0.4266 - val_accuracy: 0.8788\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:06.077193\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7940 - accuracy: 0.7749 - val_loss: 0.9613 - val_accuracy: 0.8129\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8115 - accuracy: 0.8371 - val_loss: 0.8570 - val_accuracy: 0.8127\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7456 - accuracy: 0.8450 - val_loss: 0.7651 - val_accuracy: 0.8370\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7164 - accuracy: 0.8512 - val_loss: 0.7999 - val_accuracy: 0.8258\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6918 - accuracy: 0.8560 - val_loss: 0.7561 - val_accuracy: 0.8302\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6603 - accuracy: 0.8605 - val_loss: 0.7038 - val_accuracy: 0.8487\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6368 - accuracy: 0.8631 - val_loss: 0.6673 - val_accuracy: 0.8497\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6130 - accuracy: 0.8654 - val_loss: 0.6492 - val_accuracy: 0.8574\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5884 - accuracy: 0.8692 - val_loss: 0.6330 - val_accuracy: 0.8521\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5689 - accuracy: 0.8715 - val_loss: 0.6505 - val_accuracy: 0.8446\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5531 - accuracy: 0.8731 - val_loss: 0.5805 - val_accuracy: 0.8635\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5328 - accuracy: 0.8751 - val_loss: 0.5654 - val_accuracy: 0.8656\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5196 - accuracy: 0.8778 - val_loss: 0.5676 - val_accuracy: 0.8606\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5029 - accuracy: 0.8797 - val_loss: 0.5623 - val_accuracy: 0.8614\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4906 - accuracy: 0.8821 - val_loss: 0.5304 - val_accuracy: 0.8688\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4772 - accuracy: 0.8831 - val_loss: 0.5413 - val_accuracy: 0.8618\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4646 - accuracy: 0.8848 - val_loss: 0.5100 - val_accuracy: 0.8732\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4522 - accuracy: 0.8869 - val_loss: 0.5147 - val_accuracy: 0.8701\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4431 - accuracy: 0.8877 - val_loss: 0.4924 - val_accuracy: 0.8740\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4321 - accuracy: 0.8903 - val_loss: 0.4730 - val_accuracy: 0.8781\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.047813\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3953 - accuracy: 0.8964 - val_loss: 0.4583 - val_accuracy: 0.8733\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3683 - accuracy: 0.9003 - val_loss: 0.4207 - val_accuracy: 0.8816\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3538 - accuracy: 0.9025 - val_loss: 0.4108 - val_accuracy: 0.8826\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3463 - accuracy: 0.9044 - val_loss: 0.4049 - val_accuracy: 0.8838\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3415 - accuracy: 0.9052 - val_loss: 0.4030 - val_accuracy: 0.8839\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3395 - accuracy: 0.9049 - val_loss: 0.4021 - val_accuracy: 0.8841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3391 - accuracy: 0.9053 - val_loss: 0.4017 - val_accuracy: 0.8842\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3386 - accuracy: 0.9054 - val_loss: 0.4016 - val_accuracy: 0.8839\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3383 - accuracy: 0.9054 - val_loss: 0.4015 - val_accuracy: 0.8840\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3385 - accuracy: 0.9055 - val_loss: 0.4016 - val_accuracy: 0.8840\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:31.801438\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7667 - accuracy: 0.7754 - val_loss: 0.9728 - val_accuracy: 0.7950\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7910 - accuracy: 0.8355 - val_loss: 0.8140 - val_accuracy: 0.8234\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7272 - accuracy: 0.8449 - val_loss: 0.7469 - val_accuracy: 0.8393\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6936 - accuracy: 0.8508 - val_loss: 0.7509 - val_accuracy: 0.8334\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6775 - accuracy: 0.8554 - val_loss: 0.7236 - val_accuracy: 0.8395\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6468 - accuracy: 0.8584 - val_loss: 0.7053 - val_accuracy: 0.8429\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6198 - accuracy: 0.8623 - val_loss: 0.6620 - val_accuracy: 0.8509\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5984 - accuracy: 0.8648 - val_loss: 0.6317 - val_accuracy: 0.8576\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5755 - accuracy: 0.8687 - val_loss: 0.6202 - val_accuracy: 0.8587\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5573 - accuracy: 0.8697 - val_loss: 0.5934 - val_accuracy: 0.8664\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5406 - accuracy: 0.8727 - val_loss: 0.5926 - val_accuracy: 0.8552\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5243 - accuracy: 0.8751 - val_loss: 0.5661 - val_accuracy: 0.8655\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5085 - accuracy: 0.8780 - val_loss: 0.5546 - val_accuracy: 0.8675\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4935 - accuracy: 0.8794 - val_loss: 0.5388 - val_accuracy: 0.8686\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4810 - accuracy: 0.8812 - val_loss: 0.5374 - val_accuracy: 0.8664\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4702 - accuracy: 0.8822 - val_loss: 0.5214 - val_accuracy: 0.8674\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4590 - accuracy: 0.8847 - val_loss: 0.5157 - val_accuracy: 0.8703\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4465 - accuracy: 0.8871 - val_loss: 0.5171 - val_accuracy: 0.8647\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4363 - accuracy: 0.8874 - val_loss: 0.4873 - val_accuracy: 0.8749\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4266 - accuracy: 0.8896 - val_loss: 0.4814 - val_accuracy: 0.8742\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:10.910668\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3912 - accuracy: 0.8955 - val_loss: 0.4394 - val_accuracy: 0.8806\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3666 - accuracy: 0.9002 - val_loss: 0.4240 - val_accuracy: 0.8812\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3536 - accuracy: 0.9025 - val_loss: 0.4140 - val_accuracy: 0.8816\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3471 - accuracy: 0.9029 - val_loss: 0.4103 - val_accuracy: 0.8823\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3428 - accuracy: 0.9036 - val_loss: 0.4083 - val_accuracy: 0.8828\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3407 - accuracy: 0.9044 - val_loss: 0.4076 - val_accuracy: 0.8822\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3402 - accuracy: 0.9046 - val_loss: 0.4074 - val_accuracy: 0.8826\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3394 - accuracy: 0.9053 - val_loss: 0.4072 - val_accuracy: 0.8822\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:36.887497\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7463 - accuracy: 0.7703 - val_loss: 0.9354 - val_accuracy: 0.8043\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8021 - accuracy: 0.8353 - val_loss: 0.8245 - val_accuracy: 0.8273\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7377 - accuracy: 0.8448 - val_loss: 0.7760 - val_accuracy: 0.8313\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7035 - accuracy: 0.8517 - val_loss: 0.7705 - val_accuracy: 0.8338\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6874 - accuracy: 0.8547 - val_loss: 0.7483 - val_accuracy: 0.8348\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6543 - accuracy: 0.8593 - val_loss: 0.6926 - val_accuracy: 0.8478\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6298 - accuracy: 0.8634 - val_loss: 0.6560 - val_accuracy: 0.8539\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6060 - accuracy: 0.8662 - val_loss: 0.6495 - val_accuracy: 0.8523\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5825 - accuracy: 0.8697 - val_loss: 0.6234 - val_accuracy: 0.8570\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5627 - accuracy: 0.8721 - val_loss: 0.6170 - val_accuracy: 0.8551\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5483 - accuracy: 0.8730 - val_loss: 0.5812 - val_accuracy: 0.8648\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5269 - accuracy: 0.8777 - val_loss: 0.5624 - val_accuracy: 0.8655\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5151 - accuracy: 0.8778 - val_loss: 0.5502 - val_accuracy: 0.8693\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4990 - accuracy: 0.8789 - val_loss: 0.5289 - val_accuracy: 0.8701\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4853 - accuracy: 0.8822 - val_loss: 0.5444 - val_accuracy: 0.8628\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4718 - accuracy: 0.8838 - val_loss: 0.5281 - val_accuracy: 0.8678\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4603 - accuracy: 0.8852 - val_loss: 0.5108 - val_accuracy: 0.8688\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:38.282030\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4289 - accuracy: 0.8924 - val_loss: 0.4624 - val_accuracy: 0.8792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3957 - accuracy: 0.8952 - val_loss: 0.4335 - val_accuracy: 0.8822\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3796 - accuracy: 0.8977 - val_loss: 0.4216 - val_accuracy: 0.8824\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3694 - accuracy: 0.9003 - val_loss: 0.4161 - val_accuracy: 0.8842\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3651 - accuracy: 0.8999 - val_loss: 0.4134 - val_accuracy: 0.8840\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3625 - accuracy: 0.8999 - val_loss: 0.4122 - val_accuracy: 0.8841\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3612 - accuracy: 0.9001 - val_loss: 0.4119 - val_accuracy: 0.8839\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:04.108917\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.0204 - accuracy: 0.7560 - val_loss: 1.1068 - val_accuracy: 0.7745\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9219 - accuracy: 0.8147 - val_loss: 1.1372 - val_accuracy: 0.7468\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8489 - accuracy: 0.8252 - val_loss: 0.9634 - val_accuracy: 0.7859\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8152 - accuracy: 0.8309 - val_loss: 1.3174 - val_accuracy: 0.6969\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7881 - accuracy: 0.8348 - val_loss: 1.1141 - val_accuracy: 0.7299\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7527 - accuracy: 0.8396 - val_loss: 1.0951 - val_accuracy: 0.7455\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:41.824190\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6955 - accuracy: 0.8452 - val_loss: 0.7812 - val_accuracy: 0.8186\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6088 - accuracy: 0.8544 - val_loss: 0.6288 - val_accuracy: 0.8468\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5533 - accuracy: 0.8602 - val_loss: 0.5713 - val_accuracy: 0.8535\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5200 - accuracy: 0.8649 - val_loss: 0.5406 - val_accuracy: 0.8574\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5034 - accuracy: 0.8666 - val_loss: 0.5254 - val_accuracy: 0.8580\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4945 - accuracy: 0.8668 - val_loss: 0.5192 - val_accuracy: 0.8582\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4906 - accuracy: 0.8687 - val_loss: 0.5163 - val_accuracy: 0.8592\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4878 - accuracy: 0.8687 - val_loss: 0.5155 - val_accuracy: 0.8597\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4873 - accuracy: 0.8686 - val_loss: 0.5151 - val_accuracy: 0.8592\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4875 - accuracy: 0.8682 - val_loss: 0.5149 - val_accuracy: 0.8593\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4875 - accuracy: 0.8685 - val_loss: 0.5150 - val_accuracy: 0.8590\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:54.932591\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9821 - accuracy: 0.7619 - val_loss: 1.1440 - val_accuracy: 0.7620\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9314 - accuracy: 0.8134 - val_loss: 1.0074 - val_accuracy: 0.7916\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8708 - accuracy: 0.8241 - val_loss: 1.1390 - val_accuracy: 0.7416\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8350 - accuracy: 0.8299 - val_loss: 1.1527 - val_accuracy: 0.7487\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8037 - accuracy: 0.8336 - val_loss: 1.5531 - val_accuracy: 0.6309\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:13.483184\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7692 - accuracy: 0.8353 - val_loss: 0.8127 - val_accuracy: 0.8182\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6465 - accuracy: 0.8479 - val_loss: 0.7077 - val_accuracy: 0.8280\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5785 - accuracy: 0.8561 - val_loss: 0.6036 - val_accuracy: 0.8452\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5393 - accuracy: 0.8612 - val_loss: 0.5473 - val_accuracy: 0.8591\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5180 - accuracy: 0.8635 - val_loss: 0.5303 - val_accuracy: 0.8608\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5076 - accuracy: 0.8653 - val_loss: 0.5210 - val_accuracy: 0.8615\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5025 - accuracy: 0.8657 - val_loss: 0.5182 - val_accuracy: 0.8628\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5000 - accuracy: 0.8663 - val_loss: 0.5169 - val_accuracy: 0.8625\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4988 - accuracy: 0.8668 - val_loss: 0.5165 - val_accuracy: 0.8628\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4990 - accuracy: 0.8663 - val_loss: 0.5165 - val_accuracy: 0.8627\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:31.107378\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9972 - accuracy: 0.7620 - val_loss: 1.0241 - val_accuracy: 0.7983\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9298 - accuracy: 0.8151 - val_loss: 1.1480 - val_accuracy: 0.7617\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8530 - accuracy: 0.8261 - val_loss: 1.0104 - val_accuracy: 0.7816\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8222 - accuracy: 0.8317 - val_loss: 1.0468 - val_accuracy: 0.7662\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:48.696281\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8320 - accuracy: 0.8297 - val_loss: 0.8518 - val_accuracy: 0.8159\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6848 - accuracy: 0.8428 - val_loss: 0.6909 - val_accuracy: 0.8378\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6049 - accuracy: 0.8532 - val_loss: 0.6258 - val_accuracy: 0.8450\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5614 - accuracy: 0.8577 - val_loss: 0.5776 - val_accuracy: 0.8521\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5363 - accuracy: 0.8626 - val_loss: 0.5571 - val_accuracy: 0.8534\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5244 - accuracy: 0.8632 - val_loss: 0.5484 - val_accuracy: 0.8550\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5178 - accuracy: 0.8645 - val_loss: 0.5452 - val_accuracy: 0.8551\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5153 - accuracy: 0.8654 - val_loss: 0.5436 - val_accuracy: 0.8554\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5144 - accuracy: 0.8652 - val_loss: 0.5432 - val_accuracy: 0.8553\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5149 - accuracy: 0.8654 - val_loss: 0.5430 - val_accuracy: 0.8552\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5146 - accuracy: 0.8649 - val_loss: 0.5431 - val_accuracy: 0.8555\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5140 - accuracy: 0.8653 - val_loss: 0.5429 - val_accuracy: 0.8556\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5142 - accuracy: 0.8644 - val_loss: 0.5429 - val_accuracy: 0.8556\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5136 - accuracy: 0.8653 - val_loss: 0.5429 - val_accuracy: 0.8551\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5143 - accuracy: 0.8655 - val_loss: 0.5430 - val_accuracy: 0.8553\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5139 - accuracy: 0.8650 - val_loss: 0.5431 - val_accuracy: 0.8551\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:07:16.264814\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9906 - accuracy: 0.7611 - val_loss: 1.0511 - val_accuracy: 0.7881\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9213 - accuracy: 0.8146 - val_loss: 1.0258 - val_accuracy: 0.7731\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8498 - accuracy: 0.8250 - val_loss: 0.9328 - val_accuracy: 0.8008\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8183 - accuracy: 0.8303 - val_loss: 0.9285 - val_accuracy: 0.7937\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7928 - accuracy: 0.8348 - val_loss: 1.0332 - val_accuracy: 0.7607\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7552 - accuracy: 0.8372 - val_loss: 0.9553 - val_accuracy: 0.7761\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:40.624663\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7035 - accuracy: 0.8424 - val_loss: 0.7959 - val_accuracy: 0.8194\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6150 - accuracy: 0.8506 - val_loss: 0.6691 - val_accuracy: 0.8297\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5563 - accuracy: 0.8581 - val_loss: 0.5877 - val_accuracy: 0.8446\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5243 - accuracy: 0.8618 - val_loss: 0.5561 - val_accuracy: 0.8507\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5067 - accuracy: 0.8638 - val_loss: 0.5390 - val_accuracy: 0.8531\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4987 - accuracy: 0.8643 - val_loss: 0.5324 - val_accuracy: 0.8544\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4940 - accuracy: 0.8656 - val_loss: 0.5301 - val_accuracy: 0.8540\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4929 - accuracy: 0.8649 - val_loss: 0.5291 - val_accuracy: 0.8545\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4919 - accuracy: 0.8652 - val_loss: 0.5287 - val_accuracy: 0.8547\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4912 - accuracy: 0.8655 - val_loss: 0.5287 - val_accuracy: 0.8541\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4910 - accuracy: 0.8655 - val_loss: 0.5285 - val_accuracy: 0.8544\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4914 - accuracy: 0.8657 - val_loss: 0.5286 - val_accuracy: 0.8543\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:21.314150\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 2.0239 - accuracy: 0.7578 - val_loss: 1.0774 - val_accuracy: 0.7793\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9299 - accuracy: 0.8135 - val_loss: 1.0037 - val_accuracy: 0.7771\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8673 - accuracy: 0.8240 - val_loss: 1.0210 - val_accuracy: 0.7691\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8285 - accuracy: 0.8305 - val_loss: 1.4941 - val_accuracy: 0.6395\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:46.954876\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8340 - accuracy: 0.8269 - val_loss: 0.8704 - val_accuracy: 0.8052\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6837 - accuracy: 0.8427 - val_loss: 0.7078 - val_accuracy: 0.8244\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6070 - accuracy: 0.8533 - val_loss: 0.6245 - val_accuracy: 0.8409\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5637 - accuracy: 0.8587 - val_loss: 0.5704 - val_accuracy: 0.8529\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5379 - accuracy: 0.8631 - val_loss: 0.5536 - val_accuracy: 0.8531\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5268 - accuracy: 0.8636 - val_loss: 0.5441 - val_accuracy: 0.8552\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5206 - accuracy: 0.8642 - val_loss: 0.5404 - val_accuracy: 0.8555\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5178 - accuracy: 0.8654 - val_loss: 0.5394 - val_accuracy: 0.8549\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5165 - accuracy: 0.8661 - val_loss: 0.5390 - val_accuracy: 0.8550\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5176 - accuracy: 0.8654 - val_loss: 0.5390 - val_accuracy: 0.8552\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:22.924652\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8376 - accuracy: 0.7729 - val_loss: 0.9731 - val_accuracy: 0.8061\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8721 - accuracy: 0.8295 - val_loss: 0.8501 - val_accuracy: 0.8260\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8032 - accuracy: 0.8417 - val_loss: 0.8439 - val_accuracy: 0.8309\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7753 - accuracy: 0.8482 - val_loss: 0.7971 - val_accuracy: 0.8348\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7558 - accuracy: 0.8513 - val_loss: 0.7778 - val_accuracy: 0.8400\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7160 - accuracy: 0.8567 - val_loss: 0.7320 - val_accuracy: 0.8450\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6894 - accuracy: 0.8610 - val_loss: 0.7094 - val_accuracy: 0.8534\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6645 - accuracy: 0.8625 - val_loss: 0.7080 - val_accuracy: 0.8476\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6384 - accuracy: 0.8654 - val_loss: 0.6624 - val_accuracy: 0.8578\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6106 - accuracy: 0.8682 - val_loss: 0.6361 - val_accuracy: 0.8641\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5941 - accuracy: 0.8710 - val_loss: 0.6218 - val_accuracy: 0.8625\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5745 - accuracy: 0.8728 - val_loss: 0.6096 - val_accuracy: 0.8627\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5562 - accuracy: 0.8739 - val_loss: 0.5682 - val_accuracy: 0.8685\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5368 - accuracy: 0.8773 - val_loss: 0.5667 - val_accuracy: 0.8665\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5245 - accuracy: 0.8788 - val_loss: 0.5631 - val_accuracy: 0.8666\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5071 - accuracy: 0.8806 - val_loss: 0.5411 - val_accuracy: 0.8676\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:12.123713\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4583 - accuracy: 0.8881 - val_loss: 0.4805 - val_accuracy: 0.8766\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4187 - accuracy: 0.8925 - val_loss: 0.4469 - val_accuracy: 0.8810\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3976 - accuracy: 0.8940 - val_loss: 0.4300 - val_accuracy: 0.8809\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3861 - accuracy: 0.8962 - val_loss: 0.4214 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3803 - accuracy: 0.8963 - val_loss: 0.4175 - val_accuracy: 0.8816\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3770 - accuracy: 0.8966 - val_loss: 0.4156 - val_accuracy: 0.8825\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3752 - accuracy: 0.8976 - val_loss: 0.4151 - val_accuracy: 0.8824\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3749 - accuracy: 0.8973 - val_loss: 0.4148 - val_accuracy: 0.8824\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3746 - accuracy: 0.8972 - val_loss: 0.4148 - val_accuracy: 0.8822\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:03.342932\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8662 - accuracy: 0.7729 - val_loss: 1.0774 - val_accuracy: 0.7775\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8782 - accuracy: 0.8293 - val_loss: 0.9117 - val_accuracy: 0.8160\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8154 - accuracy: 0.8413 - val_loss: 0.8534 - val_accuracy: 0.8276\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7789 - accuracy: 0.8469 - val_loss: 0.8176 - val_accuracy: 0.8353\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7559 - accuracy: 0.8505 - val_loss: 0.7952 - val_accuracy: 0.8408\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7197 - accuracy: 0.8567 - val_loss: 0.7685 - val_accuracy: 0.8438\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6870 - accuracy: 0.8597 - val_loss: 0.7298 - val_accuracy: 0.8500\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6622 - accuracy: 0.8635 - val_loss: 0.6899 - val_accuracy: 0.8544\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6304 - accuracy: 0.8660 - val_loss: 0.6821 - val_accuracy: 0.8545\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6106 - accuracy: 0.8676 - val_loss: 0.6573 - val_accuracy: 0.8600\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5874 - accuracy: 0.8707 - val_loss: 0.6636 - val_accuracy: 0.8526\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5708 - accuracy: 0.8732 - val_loss: 0.6316 - val_accuracy: 0.8601\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5509 - accuracy: 0.8748 - val_loss: 0.5815 - val_accuracy: 0.8655\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5317 - accuracy: 0.8776 - val_loss: 0.5693 - val_accuracy: 0.8679\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5192 - accuracy: 0.8793 - val_loss: 0.5688 - val_accuracy: 0.8668\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5040 - accuracy: 0.8806 - val_loss: 0.5512 - val_accuracy: 0.8673\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4896 - accuracy: 0.8819 - val_loss: 0.5365 - val_accuracy: 0.8683\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4777 - accuracy: 0.8834 - val_loss: 0.5206 - val_accuracy: 0.8720\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4651 - accuracy: 0.8849 - val_loss: 0.5211 - val_accuracy: 0.8700\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4552 - accuracy: 0.8859 - val_loss: 0.5111 - val_accuracy: 0.8719\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.968244\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4109 - accuracy: 0.8922 - val_loss: 0.4576 - val_accuracy: 0.8783\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3825 - accuracy: 0.8969 - val_loss: 0.4350 - val_accuracy: 0.8803\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3674 - accuracy: 0.8975 - val_loss: 0.4190 - val_accuracy: 0.8824\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3588 - accuracy: 0.8992 - val_loss: 0.4125 - val_accuracy: 0.8819\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3541 - accuracy: 0.8997 - val_loss: 0.4102 - val_accuracy: 0.8831\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3522 - accuracy: 0.9002 - val_loss: 0.4092 - val_accuracy: 0.8828\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3515 - accuracy: 0.9001 - val_loss: 0.4087 - val_accuracy: 0.8830\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3510 - accuracy: 0.9005 - val_loss: 0.4085 - val_accuracy: 0.8828\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:50.735512\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8732 - accuracy: 0.7722 - val_loss: 1.0899 - val_accuracy: 0.7753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8823 - accuracy: 0.8293 - val_loss: 0.8806 - val_accuracy: 0.8198\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8053 - accuracy: 0.8414 - val_loss: 0.8186 - val_accuracy: 0.8378\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7765 - accuracy: 0.8485 - val_loss: 0.7962 - val_accuracy: 0.8383\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7558 - accuracy: 0.8525 - val_loss: 0.8554 - val_accuracy: 0.8282\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7214 - accuracy: 0.8571 - val_loss: 0.7738 - val_accuracy: 0.8378\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6870 - accuracy: 0.8602 - val_loss: 0.7513 - val_accuracy: 0.8386\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6576 - accuracy: 0.8634 - val_loss: 0.7277 - val_accuracy: 0.8436\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6354 - accuracy: 0.8662 - val_loss: 0.7277 - val_accuracy: 0.8396\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6134 - accuracy: 0.8693 - val_loss: 0.6574 - val_accuracy: 0.8582\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5938 - accuracy: 0.8712 - val_loss: 0.6533 - val_accuracy: 0.8549\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5713 - accuracy: 0.8741 - val_loss: 0.6216 - val_accuracy: 0.8626\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5538 - accuracy: 0.8763 - val_loss: 0.6230 - val_accuracy: 0.8549\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5363 - accuracy: 0.8771 - val_loss: 0.5818 - val_accuracy: 0.8628\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5237 - accuracy: 0.8785 - val_loss: 0.5909 - val_accuracy: 0.8585\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5039 - accuracy: 0.8808 - val_loss: 0.5591 - val_accuracy: 0.8622\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4913 - accuracy: 0.8814 - val_loss: 0.5607 - val_accuracy: 0.8628\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4787 - accuracy: 0.8842 - val_loss: 0.5370 - val_accuracy: 0.8678\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4681 - accuracy: 0.8849 - val_loss: 0.5371 - val_accuracy: 0.8661\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4554 - accuracy: 0.8866 - val_loss: 0.5124 - val_accuracy: 0.8716\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:30.590299\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4112 - accuracy: 0.8930 - val_loss: 0.4654 - val_accuracy: 0.8774\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3819 - accuracy: 0.8974 - val_loss: 0.4388 - val_accuracy: 0.8796\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3664 - accuracy: 0.8995 - val_loss: 0.4264 - val_accuracy: 0.8803\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3581 - accuracy: 0.9006 - val_loss: 0.4207 - val_accuracy: 0.8810\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3534 - accuracy: 0.9007 - val_loss: 0.4183 - val_accuracy: 0.8813\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3517 - accuracy: 0.9020 - val_loss: 0.4173 - val_accuracy: 0.8815\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3501 - accuracy: 0.9012 - val_loss: 0.4168 - val_accuracy: 0.8812\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3496 - accuracy: 0.9016 - val_loss: 0.4167 - val_accuracy: 0.8814\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3497 - accuracy: 0.9020 - val_loss: 0.4166 - val_accuracy: 0.8813\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:17.293112\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8924 - accuracy: 0.7687 - val_loss: 1.0804 - val_accuracy: 0.7850\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8874 - accuracy: 0.8294 - val_loss: 0.9215 - val_accuracy: 0.8075\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8251 - accuracy: 0.8391 - val_loss: 0.8475 - val_accuracy: 0.8292\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7886 - accuracy: 0.8460 - val_loss: 0.8287 - val_accuracy: 0.8352\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7693 - accuracy: 0.8510 - val_loss: 0.8018 - val_accuracy: 0.8403\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7320 - accuracy: 0.8555 - val_loss: 0.7839 - val_accuracy: 0.8396\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6972 - accuracy: 0.8600 - val_loss: 0.7691 - val_accuracy: 0.8391\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6659 - accuracy: 0.8633 - val_loss: 0.7278 - val_accuracy: 0.8507\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6450 - accuracy: 0.8662 - val_loss: 0.6920 - val_accuracy: 0.8555\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6198 - accuracy: 0.8691 - val_loss: 0.6534 - val_accuracy: 0.8568\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5974 - accuracy: 0.8698 - val_loss: 0.6538 - val_accuracy: 0.8552\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5755 - accuracy: 0.8741 - val_loss: 0.6024 - val_accuracy: 0.8658\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5572 - accuracy: 0.8754 - val_loss: 0.6168 - val_accuracy: 0.8579\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5397 - accuracy: 0.8781 - val_loss: 0.5789 - val_accuracy: 0.8650\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5240 - accuracy: 0.8791 - val_loss: 0.5755 - val_accuracy: 0.8617\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:07.910137\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4710 - accuracy: 0.8870 - val_loss: 0.4960 - val_accuracy: 0.8734\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4268 - accuracy: 0.8895 - val_loss: 0.4625 - val_accuracy: 0.8783\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4031 - accuracy: 0.8934 - val_loss: 0.4433 - val_accuracy: 0.8813\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3907 - accuracy: 0.8954 - val_loss: 0.4329 - val_accuracy: 0.8818\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3835 - accuracy: 0.8957 - val_loss: 0.4284 - val_accuracy: 0.8824\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3801 - accuracy: 0.8966 - val_loss: 0.4267 - val_accuracy: 0.8827\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3779 - accuracy: 0.8966 - val_loss: 0.4258 - val_accuracy: 0.8826\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3773 - accuracy: 0.8962 - val_loss: 0.4255 - val_accuracy: 0.8830\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3776 - accuracy: 0.8965 - val_loss: 0.4254 - val_accuracy: 0.8830\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3778 - accuracy: 0.8969 - val_loss: 0.4253 - val_accuracy: 0.8827\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3773 - accuracy: 0.8964 - val_loss: 0.4254 - val_accuracy: 0.8829\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3776 - accuracy: 0.8969 - val_loss: 0.4253 - val_accuracy: 0.8828\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:41.517314\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8521 - accuracy: 0.7674 - val_loss: 0.9942 - val_accuracy: 0.7954\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8408 - accuracy: 0.8303 - val_loss: 0.8255 - val_accuracy: 0.8262\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7700 - accuracy: 0.8408 - val_loss: 0.8459 - val_accuracy: 0.8112\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7475 - accuracy: 0.8455 - val_loss: 0.8111 - val_accuracy: 0.8307\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7276 - accuracy: 0.8511 - val_loss: 0.7898 - val_accuracy: 0.8363\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6984 - accuracy: 0.8551 - val_loss: 0.7618 - val_accuracy: 0.8399\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6705 - accuracy: 0.8598 - val_loss: 0.7171 - val_accuracy: 0.8457\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6402 - accuracy: 0.8623 - val_loss: 0.7163 - val_accuracy: 0.8407\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6239 - accuracy: 0.8644 - val_loss: 0.6684 - val_accuracy: 0.8538\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6017 - accuracy: 0.8680 - val_loss: 0.6341 - val_accuracy: 0.8551\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5810 - accuracy: 0.8695 - val_loss: 0.6286 - val_accuracy: 0.8519\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5640 - accuracy: 0.8716 - val_loss: 0.6129 - val_accuracy: 0.8589\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5432 - accuracy: 0.8743 - val_loss: 0.6269 - val_accuracy: 0.8531\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5295 - accuracy: 0.8762 - val_loss: 0.5986 - val_accuracy: 0.8575\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5156 - accuracy: 0.8778 - val_loss: 0.5948 - val_accuracy: 0.8581\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:03.622584\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4676 - accuracy: 0.8833 - val_loss: 0.5064 - val_accuracy: 0.8719\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4260 - accuracy: 0.8887 - val_loss: 0.4657 - val_accuracy: 0.8762\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4054 - accuracy: 0.8908 - val_loss: 0.4458 - val_accuracy: 0.8792\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3933 - accuracy: 0.8924 - val_loss: 0.4390 - val_accuracy: 0.8793\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3873 - accuracy: 0.8937 - val_loss: 0.4345 - val_accuracy: 0.8791\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3844 - accuracy: 0.8941 - val_loss: 0.4328 - val_accuracy: 0.8800\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3829 - accuracy: 0.8942 - val_loss: 0.4322 - val_accuracy: 0.8802\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3833 - accuracy: 0.8942 - val_loss: 0.4319 - val_accuracy: 0.8803\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3819 - accuracy: 0.8944 - val_loss: 0.4319 - val_accuracy: 0.8801\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3821 - accuracy: 0.8939 - val_loss: 0.4318 - val_accuracy: 0.8802\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3818 - accuracy: 0.8937 - val_loss: 0.4318 - val_accuracy: 0.8800\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:11.663629\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8707 - accuracy: 0.7914 - val_loss: 0.6126 - val_accuracy: 0.8369\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5014 - accuracy: 0.8612 - val_loss: 0.5672 - val_accuracy: 0.8330\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4407 - accuracy: 0.8731 - val_loss: 0.4656 - val_accuracy: 0.8673\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4132 - accuracy: 0.8796 - val_loss: 0.4648 - val_accuracy: 0.8641\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3957 - accuracy: 0.8848 - val_loss: 0.4937 - val_accuracy: 0.8581\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3738 - accuracy: 0.8893 - val_loss: 0.4624 - val_accuracy: 0.8675\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3553 - accuracy: 0.8950 - val_loss: 0.4578 - val_accuracy: 0.8687\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3331 - accuracy: 0.9003 - val_loss: 0.4483 - val_accuracy: 0.8699\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3162 - accuracy: 0.9051 - val_loss: 0.4285 - val_accuracy: 0.8754\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2971 - accuracy: 0.9107 - val_loss: 0.4573 - val_accuracy: 0.8687\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2798 - accuracy: 0.9167 - val_loss: 0.4609 - val_accuracy: 0.8683\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2646 - accuracy: 0.9205 - val_loss: 0.4404 - val_accuracy: 0.8728\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:19.158946\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.2582 - accuracy: 0.9257 - val_loss: 0.3964 - val_accuracy: 0.8816\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2235 - accuracy: 0.9368 - val_loss: 0.3839 - val_accuracy: 0.8849\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2068 - accuracy: 0.9416 - val_loss: 0.3837 - val_accuracy: 0.8845\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1976 - accuracy: 0.9457 - val_loss: 0.3831 - val_accuracy: 0.8836\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1931 - accuracy: 0.9469 - val_loss: 0.3825 - val_accuracy: 0.8850\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.1910 - accuracy: 0.9479 - val_loss: 0.3827 - val_accuracy: 0.8851\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1902 - accuracy: 0.9486 - val_loss: 0.3825 - val_accuracy: 0.8848\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1895 - accuracy: 0.9488 - val_loss: 0.3826 - val_accuracy: 0.8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1895 - accuracy: 0.9482 - val_loss: 0.3826 - val_accuracy: 0.8847\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:59.597845\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8613 - accuracy: 0.7938 - val_loss: 0.6133 - val_accuracy: 0.8278\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4923 - accuracy: 0.8635 - val_loss: 0.5186 - val_accuracy: 0.8479\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4330 - accuracy: 0.8745 - val_loss: 0.4890 - val_accuracy: 0.8583\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4093 - accuracy: 0.8797 - val_loss: 0.4823 - val_accuracy: 0.8576\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3916 - accuracy: 0.8864 - val_loss: 0.4927 - val_accuracy: 0.8559\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3711 - accuracy: 0.8906 - val_loss: 0.4669 - val_accuracy: 0.8671\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3522 - accuracy: 0.8961 - val_loss: 0.4909 - val_accuracy: 0.8605\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3312 - accuracy: 0.9015 - val_loss: 0.4674 - val_accuracy: 0.8625\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3116 - accuracy: 0.9080 - val_loss: 0.4356 - val_accuracy: 0.8738\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2962 - accuracy: 0.9116 - val_loss: 0.4422 - val_accuracy: 0.8717\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2779 - accuracy: 0.9166 - val_loss: 0.4501 - val_accuracy: 0.8705\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2588 - accuracy: 0.9229 - val_loss: 0.4572 - val_accuracy: 0.8656\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:11.595329\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2546 - accuracy: 0.9265 - val_loss: 0.4087 - val_accuracy: 0.8813\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2209 - accuracy: 0.9378 - val_loss: 0.3991 - val_accuracy: 0.8822\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2042 - accuracy: 0.9433 - val_loss: 0.3944 - val_accuracy: 0.8825\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1948 - accuracy: 0.9471 - val_loss: 0.3943 - val_accuracy: 0.8830\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1901 - accuracy: 0.9488 - val_loss: 0.3946 - val_accuracy: 0.8818\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1882 - accuracy: 0.9494 - val_loss: 0.3946 - val_accuracy: 0.8821\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1872 - accuracy: 0.9502 - val_loss: 0.3947 - val_accuracy: 0.8819\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:01.305773\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8606 - accuracy: 0.7942 - val_loss: 0.6158 - val_accuracy: 0.8364\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5047 - accuracy: 0.8616 - val_loss: 0.5073 - val_accuracy: 0.8542\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.4446 - accuracy: 0.8716 - val_loss: 0.4900 - val_accuracy: 0.8618\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.4140 - accuracy: 0.8806 - val_loss: 0.4976 - val_accuracy: 0.8609\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3996 - accuracy: 0.8833 - val_loss: 0.5080 - val_accuracy: 0.8535\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3761 - accuracy: 0.8905 - val_loss: 0.4500 - val_accuracy: 0.8672\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3543 - accuracy: 0.8957 - val_loss: 0.4430 - val_accuracy: 0.8730\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3366 - accuracy: 0.9004 - val_loss: 0.4504 - val_accuracy: 0.8700\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3155 - accuracy: 0.9062 - val_loss: 0.4483 - val_accuracy: 0.8729\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2962 - accuracy: 0.9119 - val_loss: 0.4462 - val_accuracy: 0.8705\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:15.994449\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2883 - accuracy: 0.9176 - val_loss: 0.3968 - val_accuracy: 0.8805\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2445 - accuracy: 0.9298 - val_loss: 0.3793 - val_accuracy: 0.8857\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2229 - accuracy: 0.9364 - val_loss: 0.3725 - val_accuracy: 0.8852\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2104 - accuracy: 0.9405 - val_loss: 0.3713 - val_accuracy: 0.8867\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2047 - accuracy: 0.9427 - val_loss: 0.3708 - val_accuracy: 0.8867\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2016 - accuracy: 0.9439 - val_loss: 0.3708 - val_accuracy: 0.8872\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2002 - accuracy: 0.9445 - val_loss: 0.3708 - val_accuracy: 0.8871\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1999 - accuracy: 0.9445 - val_loss: 0.3707 - val_accuracy: 0.8869\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1992 - accuracy: 0.9448 - val_loss: 0.3707 - val_accuracy: 0.8870\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:47.009057\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.8534 - accuracy: 0.7962 - val_loss: 0.6722 - val_accuracy: 0.8184\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.4981 - accuracy: 0.8643 - val_loss: 0.5228 - val_accuracy: 0.8522\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.4354 - accuracy: 0.8755 - val_loss: 0.4747 - val_accuracy: 0.8664\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4107 - accuracy: 0.8819 - val_loss: 0.4896 - val_accuracy: 0.8585\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.3934 - accuracy: 0.8857 - val_loss: 0.4631 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.3714 - accuracy: 0.8925 - val_loss: 0.4791 - val_accuracy: 0.8638\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.3512 - accuracy: 0.8972 - val_loss: 0.4545 - val_accuracy: 0.8694\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.3311 - accuracy: 0.9023 - val_loss: 0.4494 - val_accuracy: 0.8709\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3107 - accuracy: 0.9085 - val_loss: 0.4446 - val_accuracy: 0.8703\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2932 - accuracy: 0.9126 - val_loss: 0.4374 - val_accuracy: 0.8714\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2777 - accuracy: 0.9171 - val_loss: 0.4372 - val_accuracy: 0.8764\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2598 - accuracy: 0.9231 - val_loss: 0.4361 - val_accuracy: 0.8742\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2427 - accuracy: 0.9287 - val_loss: 0.4523 - val_accuracy: 0.8709\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2260 - accuracy: 0.9343 - val_loss: 0.4479 - val_accuracy: 0.8702\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:50.482396\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2267 - accuracy: 0.9368 - val_loss: 0.4045 - val_accuracy: 0.8825\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1964 - accuracy: 0.9473 - val_loss: 0.4024 - val_accuracy: 0.8830\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1825 - accuracy: 0.9522 - val_loss: 0.4010 - val_accuracy: 0.8827\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.1750 - accuracy: 0.9550 - val_loss: 0.4006 - val_accuracy: 0.8835\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1713 - accuracy: 0.9560 - val_loss: 0.4005 - val_accuracy: 0.8838\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1692 - accuracy: 0.9574 - val_loss: 0.4005 - val_accuracy: 0.8841\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1688 - accuracy: 0.9574 - val_loss: 0.4008 - val_accuracy: 0.8840\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1685 - accuracy: 0.9573 - val_loss: 0.4006 - val_accuracy: 0.8842\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1683 - accuracy: 0.9578 - val_loss: 0.4007 - val_accuracy: 0.8843\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1680 - accuracy: 0.9576 - val_loss: 0.4006 - val_accuracy: 0.8846\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1683 - accuracy: 0.9575 - val_loss: 0.4006 - val_accuracy: 0.8844\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1679 - accuracy: 0.9577 - val_loss: 0.4006 - val_accuracy: 0.8845\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1678 - accuracy: 0.9576 - val_loss: 0.4008 - val_accuracy: 0.8841\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:25.916286\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.8516 - accuracy: 0.7939 - val_loss: 0.5771 - val_accuracy: 0.8422\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.5051 - accuracy: 0.8610 - val_loss: 0.5042 - val_accuracy: 0.8569\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4464 - accuracy: 0.8727 - val_loss: 0.4603 - val_accuracy: 0.8658\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.4211 - accuracy: 0.8779 - val_loss: 0.4880 - val_accuracy: 0.8574\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.4041 - accuracy: 0.8832 - val_loss: 0.4452 - val_accuracy: 0.8709\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3808 - accuracy: 0.8895 - val_loss: 0.4546 - val_accuracy: 0.8706\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.3608 - accuracy: 0.8946 - val_loss: 0.4290 - val_accuracy: 0.8761\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.3395 - accuracy: 0.9006 - val_loss: 0.4278 - val_accuracy: 0.8752\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.3207 - accuracy: 0.9057 - val_loss: 0.4180 - val_accuracy: 0.8780\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.3021 - accuracy: 0.9106 - val_loss: 0.4397 - val_accuracy: 0.8707\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2844 - accuracy: 0.9155 - val_loss: 0.4317 - val_accuracy: 0.8760\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2653 - accuracy: 0.9220 - val_loss: 0.4250 - val_accuracy: 0.8743\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:00.141106\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2603 - accuracy: 0.9265 - val_loss: 0.3801 - val_accuracy: 0.8874\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2242 - accuracy: 0.9377 - val_loss: 0.3731 - val_accuracy: 0.8882\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2065 - accuracy: 0.9431 - val_loss: 0.3707 - val_accuracy: 0.8889\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1969 - accuracy: 0.9462 - val_loss: 0.3697 - val_accuracy: 0.8894\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1919 - accuracy: 0.9485 - val_loss: 0.3692 - val_accuracy: 0.8889\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1896 - accuracy: 0.9495 - val_loss: 0.3695 - val_accuracy: 0.8888\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1883 - accuracy: 0.9502 - val_loss: 0.3693 - val_accuracy: 0.8889\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:06.429901\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.9034 - accuracy: 0.7846 - val_loss: 0.6900 - val_accuracy: 0.8132\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.5824 - accuracy: 0.8439 - val_loss: 0.6446 - val_accuracy: 0.8174\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.5228 - accuracy: 0.8540 - val_loss: 0.5843 - val_accuracy: 0.8325\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4977 - accuracy: 0.8592 - val_loss: 0.5404 - val_accuracy: 0.8461\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.4776 - accuracy: 0.8652 - val_loss: 0.5968 - val_accuracy: 0.8237\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.4511 - accuracy: 0.8720 - val_loss: 0.5463 - val_accuracy: 0.8417\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.4288 - accuracy: 0.8774 - val_loss: 0.4975 - val_accuracy: 0.8556\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4082 - accuracy: 0.8819 - val_loss: 0.4976 - val_accuracy: 0.8552\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3890 - accuracy: 0.8873 - val_loss: 0.4708 - val_accuracy: 0.8633\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3730 - accuracy: 0.8908 - val_loss: 0.5173 - val_accuracy: 0.8503\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3543 - accuracy: 0.8956 - val_loss: 0.4899 - val_accuracy: 0.8595\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3409 - accuracy: 0.8993 - val_loss: 0.4554 - val_accuracy: 0.8677\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3214 - accuracy: 0.9054 - val_loss: 0.4501 - val_accuracy: 0.8657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3098 - accuracy: 0.9079 - val_loss: 0.4439 - val_accuracy: 0.8678\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2934 - accuracy: 0.9123 - val_loss: 0.4431 - val_accuracy: 0.8688\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2824 - accuracy: 0.9162 - val_loss: 0.4382 - val_accuracy: 0.8693\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2671 - accuracy: 0.9204 - val_loss: 0.4455 - val_accuracy: 0.8674\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2545 - accuracy: 0.9243 - val_loss: 0.4381 - val_accuracy: 0.8711\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2423 - accuracy: 0.9283 - val_loss: 0.4390 - val_accuracy: 0.8704\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2322 - accuracy: 0.9307 - val_loss: 0.4448 - val_accuracy: 0.8691\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:31.353606\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2072 - accuracy: 0.9414 - val_loss: 0.4307 - val_accuracy: 0.8737\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1902 - accuracy: 0.9484 - val_loss: 0.4243 - val_accuracy: 0.8753\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.1814 - accuracy: 0.9521 - val_loss: 0.4239 - val_accuracy: 0.8763\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1770 - accuracy: 0.9533 - val_loss: 0.4243 - val_accuracy: 0.8764\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1754 - accuracy: 0.9544 - val_loss: 0.4247 - val_accuracy: 0.8755\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1735 - accuracy: 0.9553 - val_loss: 0.4245 - val_accuracy: 0.8756\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1732 - accuracy: 0.9552 - val_loss: 0.4246 - val_accuracy: 0.8757\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:58.970711\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9130 - accuracy: 0.7825 - val_loss: 0.7031 - val_accuracy: 0.8161\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5860 - accuracy: 0.8415 - val_loss: 0.6379 - val_accuracy: 0.8196\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5270 - accuracy: 0.8524 - val_loss: 0.6046 - val_accuracy: 0.8249\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5009 - accuracy: 0.8581 - val_loss: 0.5580 - val_accuracy: 0.8383\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4807 - accuracy: 0.8631 - val_loss: 0.6058 - val_accuracy: 0.8260\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4533 - accuracy: 0.8707 - val_loss: 0.6532 - val_accuracy: 0.8085\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4311 - accuracy: 0.8760 - val_loss: 0.5451 - val_accuracy: 0.8422\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4100 - accuracy: 0.8811 - val_loss: 0.5629 - val_accuracy: 0.8426\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3904 - accuracy: 0.8864 - val_loss: 0.5307 - val_accuracy: 0.8492\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3716 - accuracy: 0.8919 - val_loss: 0.4648 - val_accuracy: 0.8668\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3557 - accuracy: 0.8947 - val_loss: 0.4872 - val_accuracy: 0.8585\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3399 - accuracy: 0.8990 - val_loss: 0.4669 - val_accuracy: 0.8642\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3220 - accuracy: 0.9047 - val_loss: 0.4587 - val_accuracy: 0.8673\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3086 - accuracy: 0.9078 - val_loss: 0.4569 - val_accuracy: 0.8685\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2931 - accuracy: 0.9135 - val_loss: 0.4509 - val_accuracy: 0.8678\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2795 - accuracy: 0.9170 - val_loss: 0.4531 - val_accuracy: 0.8716\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2658 - accuracy: 0.9215 - val_loss: 0.4487 - val_accuracy: 0.8690\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2523 - accuracy: 0.9252 - val_loss: 0.4606 - val_accuracy: 0.8673\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2425 - accuracy: 0.9278 - val_loss: 0.4536 - val_accuracy: 0.8719\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2293 - accuracy: 0.9328 - val_loss: 0.4501 - val_accuracy: 0.8694\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:18.722501\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2054 - accuracy: 0.9422 - val_loss: 0.4300 - val_accuracy: 0.8758\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1877 - accuracy: 0.9485 - val_loss: 0.4284 - val_accuracy: 0.8773\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1803 - accuracy: 0.9523 - val_loss: 0.4310 - val_accuracy: 0.8756\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1754 - accuracy: 0.9535 - val_loss: 0.4293 - val_accuracy: 0.8770\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1732 - accuracy: 0.9552 - val_loss: 0.4293 - val_accuracy: 0.8766\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:19.739956\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9040 - accuracy: 0.7848 - val_loss: 0.7068 - val_accuracy: 0.8160\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5871 - accuracy: 0.8429 - val_loss: 0.6211 - val_accuracy: 0.8263\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5286 - accuracy: 0.8519 - val_loss: 0.6290 - val_accuracy: 0.8210\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4998 - accuracy: 0.8580 - val_loss: 0.6798 - val_accuracy: 0.8029\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4812 - accuracy: 0.8643 - val_loss: 0.5310 - val_accuracy: 0.8486\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4523 - accuracy: 0.8712 - val_loss: 0.5977 - val_accuracy: 0.8275\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4308 - accuracy: 0.8762 - val_loss: 0.5347 - val_accuracy: 0.8484\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4089 - accuracy: 0.8808 - val_loss: 0.5201 - val_accuracy: 0.8494\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3891 - accuracy: 0.8863 - val_loss: 0.5000 - val_accuracy: 0.8551\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3716 - accuracy: 0.8912 - val_loss: 0.4811 - val_accuracy: 0.8564\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3534 - accuracy: 0.8961 - val_loss: 0.4762 - val_accuracy: 0.8581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3386 - accuracy: 0.8992 - val_loss: 0.4584 - val_accuracy: 0.8651\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3201 - accuracy: 0.9051 - val_loss: 0.4564 - val_accuracy: 0.8642\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3067 - accuracy: 0.9086 - val_loss: 0.4436 - val_accuracy: 0.8696\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2925 - accuracy: 0.9128 - val_loss: 0.4721 - val_accuracy: 0.8584\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2781 - accuracy: 0.9169 - val_loss: 0.4393 - val_accuracy: 0.8736\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2650 - accuracy: 0.9218 - val_loss: 0.4452 - val_accuracy: 0.8691\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2513 - accuracy: 0.9259 - val_loss: 0.4443 - val_accuracy: 0.8691\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2406 - accuracy: 0.9287 - val_loss: 0.4404 - val_accuracy: 0.8711\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:41.639827\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2372 - accuracy: 0.9336 - val_loss: 0.4111 - val_accuracy: 0.8803\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2175 - accuracy: 0.9402 - val_loss: 0.4059 - val_accuracy: 0.8806\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2084 - accuracy: 0.9425 - val_loss: 0.4046 - val_accuracy: 0.8808\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2028 - accuracy: 0.9455 - val_loss: 0.4053 - val_accuracy: 0.8812\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2002 - accuracy: 0.9461 - val_loss: 0.4050 - val_accuracy: 0.8814\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1993 - accuracy: 0.9464 - val_loss: 0.4052 - val_accuracy: 0.8809\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1982 - accuracy: 0.9472 - val_loss: 0.4053 - val_accuracy: 0.8807\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1984 - accuracy: 0.9469 - val_loss: 0.4052 - val_accuracy: 0.8809\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:38.534445\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9073 - accuracy: 0.7859 - val_loss: 0.7076 - val_accuracy: 0.8113\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5826 - accuracy: 0.8431 - val_loss: 0.6087 - val_accuracy: 0.8260\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5266 - accuracy: 0.8528 - val_loss: 0.5679 - val_accuracy: 0.8368\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4999 - accuracy: 0.8582 - val_loss: 0.5487 - val_accuracy: 0.8457\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4778 - accuracy: 0.8642 - val_loss: 0.5956 - val_accuracy: 0.8318\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4520 - accuracy: 0.8701 - val_loss: 0.5221 - val_accuracy: 0.8516\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4287 - accuracy: 0.8771 - val_loss: 0.5696 - val_accuracy: 0.8309\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4082 - accuracy: 0.8818 - val_loss: 0.4966 - val_accuracy: 0.8566\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3888 - accuracy: 0.8869 - val_loss: 0.5123 - val_accuracy: 0.8529\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3708 - accuracy: 0.8915 - val_loss: 0.4790 - val_accuracy: 0.8610\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3528 - accuracy: 0.8960 - val_loss: 0.5054 - val_accuracy: 0.8547\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3345 - accuracy: 0.9008 - val_loss: 0.4701 - val_accuracy: 0.8630\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3202 - accuracy: 0.9052 - val_loss: 0.4719 - val_accuracy: 0.8633\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3056 - accuracy: 0.9093 - val_loss: 0.4682 - val_accuracy: 0.8632\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2913 - accuracy: 0.9135 - val_loss: 0.4662 - val_accuracy: 0.8613\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2765 - accuracy: 0.9177 - val_loss: 0.4623 - val_accuracy: 0.8676\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2638 - accuracy: 0.9216 - val_loss: 0.4549 - val_accuracy: 0.8674\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2519 - accuracy: 0.9252 - val_loss: 0.4447 - val_accuracy: 0.8694\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2400 - accuracy: 0.9289 - val_loss: 0.4568 - val_accuracy: 0.8690\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2273 - accuracy: 0.9334 - val_loss: 0.4568 - val_accuracy: 0.8693\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:05.475601\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2036 - accuracy: 0.9432 - val_loss: 0.4310 - val_accuracy: 0.8744\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1872 - accuracy: 0.9496 - val_loss: 0.4285 - val_accuracy: 0.8766\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1790 - accuracy: 0.9529 - val_loss: 0.4284 - val_accuracy: 0.8768\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1745 - accuracy: 0.9542 - val_loss: 0.4282 - val_accuracy: 0.8767\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1724 - accuracy: 0.9553 - val_loss: 0.4283 - val_accuracy: 0.8761\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1713 - accuracy: 0.9560 - val_loss: 0.4282 - val_accuracy: 0.8760\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:43.459709\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8913 - accuracy: 0.7873 - val_loss: 0.8565 - val_accuracy: 0.7741\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5767 - accuracy: 0.8449 - val_loss: 0.6800 - val_accuracy: 0.8121\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5224 - accuracy: 0.8531 - val_loss: 0.7008 - val_accuracy: 0.8021\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4965 - accuracy: 0.8588 - val_loss: 0.5963 - val_accuracy: 0.8324\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4749 - accuracy: 0.8640 - val_loss: 0.5670 - val_accuracy: 0.8399\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4529 - accuracy: 0.8694 - val_loss: 0.5396 - val_accuracy: 0.8486\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4279 - accuracy: 0.8777 - val_loss: 0.6555 - val_accuracy: 0.8145\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4087 - accuracy: 0.8814 - val_loss: 0.5231 - val_accuracy: 0.8519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3878 - accuracy: 0.8858 - val_loss: 0.5330 - val_accuracy: 0.8484\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3714 - accuracy: 0.8910 - val_loss: 0.5036 - val_accuracy: 0.8566\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3533 - accuracy: 0.8971 - val_loss: 0.4997 - val_accuracy: 0.8576\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3362 - accuracy: 0.9011 - val_loss: 0.4867 - val_accuracy: 0.8623\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3221 - accuracy: 0.9049 - val_loss: 0.4888 - val_accuracy: 0.8648\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3050 - accuracy: 0.9090 - val_loss: 0.4771 - val_accuracy: 0.8677\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2909 - accuracy: 0.9135 - val_loss: 0.4823 - val_accuracy: 0.8634\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2763 - accuracy: 0.9178 - val_loss: 0.4950 - val_accuracy: 0.8574\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2634 - accuracy: 0.9214 - val_loss: 0.4882 - val_accuracy: 0.8617\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:07:41.745266\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2592 - accuracy: 0.9264 - val_loss: 0.4398 - val_accuracy: 0.8754\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2353 - accuracy: 0.9339 - val_loss: 0.4382 - val_accuracy: 0.8751\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2227 - accuracy: 0.9387 - val_loss: 0.4363 - val_accuracy: 0.8753\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2163 - accuracy: 0.9410 - val_loss: 0.4359 - val_accuracy: 0.8749\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:48.403612\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8755 - accuracy: 0.7933 - val_loss: 0.6831 - val_accuracy: 0.8107\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5337 - accuracy: 0.8547 - val_loss: 0.5332 - val_accuracy: 0.8508\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4655 - accuracy: 0.8683 - val_loss: 0.5395 - val_accuracy: 0.8482\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4397 - accuracy: 0.8756 - val_loss: 0.4751 - val_accuracy: 0.8669\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4234 - accuracy: 0.8784 - val_loss: 0.4781 - val_accuracy: 0.8669\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3985 - accuracy: 0.8855 - val_loss: 0.4643 - val_accuracy: 0.8693\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3818 - accuracy: 0.8894 - val_loss: 0.4595 - val_accuracy: 0.8684\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3602 - accuracy: 0.8944 - val_loss: 0.4480 - val_accuracy: 0.8711\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3434 - accuracy: 0.8990 - val_loss: 0.4378 - val_accuracy: 0.8735\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3258 - accuracy: 0.9030 - val_loss: 0.4290 - val_accuracy: 0.8760\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3075 - accuracy: 0.9083 - val_loss: 0.4267 - val_accuracy: 0.8754\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2905 - accuracy: 0.9132 - val_loss: 0.4505 - val_accuracy: 0.8684\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2749 - accuracy: 0.9183 - val_loss: 0.4250 - val_accuracy: 0.8780\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2577 - accuracy: 0.9235 - val_loss: 0.4380 - val_accuracy: 0.8744\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2452 - accuracy: 0.9263 - val_loss: 0.4310 - val_accuracy: 0.8738\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2289 - accuracy: 0.9325 - val_loss: 0.4329 - val_accuracy: 0.8763\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:26.100009\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2271 - accuracy: 0.9359 - val_loss: 0.3988 - val_accuracy: 0.8856\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1997 - accuracy: 0.9451 - val_loss: 0.3949 - val_accuracy: 0.8848\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1866 - accuracy: 0.9498 - val_loss: 0.3948 - val_accuracy: 0.8837\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1794 - accuracy: 0.9530 - val_loss: 0.3952 - val_accuracy: 0.8836\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:01:52.056300\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8660 - accuracy: 0.7945 - val_loss: 0.6730 - val_accuracy: 0.8234\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5271 - accuracy: 0.8569 - val_loss: 0.5365 - val_accuracy: 0.8503\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4628 - accuracy: 0.8697 - val_loss: 0.5010 - val_accuracy: 0.8549\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4377 - accuracy: 0.8738 - val_loss: 0.4725 - val_accuracy: 0.8669\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4203 - accuracy: 0.8798 - val_loss: 0.4745 - val_accuracy: 0.8625\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3990 - accuracy: 0.8839 - val_loss: 0.4724 - val_accuracy: 0.8594\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3765 - accuracy: 0.8903 - val_loss: 0.4603 - val_accuracy: 0.8672\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3579 - accuracy: 0.8959 - val_loss: 0.4564 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3406 - accuracy: 0.8992 - val_loss: 0.4598 - val_accuracy: 0.8649\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3242 - accuracy: 0.9043 - val_loss: 0.4370 - val_accuracy: 0.8726\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3058 - accuracy: 0.9092 - val_loss: 0.4423 - val_accuracy: 0.8704\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2900 - accuracy: 0.9139 - val_loss: 0.4358 - val_accuracy: 0.8738\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2720 - accuracy: 0.9201 - val_loss: 0.4447 - val_accuracy: 0.8704\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2578 - accuracy: 0.9238 - val_loss: 0.4400 - val_accuracy: 0.8703\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2423 - accuracy: 0.9286 - val_loss: 0.4408 - val_accuracy: 0.8689\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:58.878318\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2379 - accuracy: 0.9333 - val_loss: 0.4051 - val_accuracy: 0.8810\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2076 - accuracy: 0.9433 - val_loss: 0.3975 - val_accuracy: 0.8826\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1933 - accuracy: 0.9484 - val_loss: 0.3955 - val_accuracy: 0.8822\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1857 - accuracy: 0.9514 - val_loss: 0.3955 - val_accuracy: 0.8826\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1822 - accuracy: 0.9529 - val_loss: 0.3956 - val_accuracy: 0.8820\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:18.240357\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8513 - accuracy: 0.7988 - val_loss: 0.6619 - val_accuracy: 0.8312\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5290 - accuracy: 0.8560 - val_loss: 0.5398 - val_accuracy: 0.8488\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4677 - accuracy: 0.8672 - val_loss: 0.4856 - val_accuracy: 0.8619\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4414 - accuracy: 0.8748 - val_loss: 0.4824 - val_accuracy: 0.8658\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4258 - accuracy: 0.8767 - val_loss: 0.4774 - val_accuracy: 0.8674\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4023 - accuracy: 0.8836 - val_loss: 0.4662 - val_accuracy: 0.8695\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3826 - accuracy: 0.8889 - val_loss: 0.4653 - val_accuracy: 0.8641\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3641 - accuracy: 0.8944 - val_loss: 0.4470 - val_accuracy: 0.8744\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3451 - accuracy: 0.8990 - val_loss: 0.4555 - val_accuracy: 0.8697\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3298 - accuracy: 0.9031 - val_loss: 0.4473 - val_accuracy: 0.8714\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3112 - accuracy: 0.9063 - val_loss: 0.4380 - val_accuracy: 0.8767\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2933 - accuracy: 0.9127 - val_loss: 0.4508 - val_accuracy: 0.8723\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2756 - accuracy: 0.9172 - val_loss: 0.4432 - val_accuracy: 0.8735\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2611 - accuracy: 0.9226 - val_loss: 0.4343 - val_accuracy: 0.8738\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:21.507590\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2551 - accuracy: 0.9282 - val_loss: 0.3987 - val_accuracy: 0.8848\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2218 - accuracy: 0.9388 - val_loss: 0.3895 - val_accuracy: 0.8866\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2056 - accuracy: 0.9438 - val_loss: 0.3867 - val_accuracy: 0.8859\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1969 - accuracy: 0.9472 - val_loss: 0.3865 - val_accuracy: 0.8859\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1924 - accuracy: 0.9488 - val_loss: 0.3864 - val_accuracy: 0.8861\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:16.384409\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8762 - accuracy: 0.7923 - val_loss: 0.6444 - val_accuracy: 0.8318\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5410 - accuracy: 0.8545 - val_loss: 0.5531 - val_accuracy: 0.8442\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4720 - accuracy: 0.8663 - val_loss: 0.5158 - val_accuracy: 0.8497\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4385 - accuracy: 0.8747 - val_loss: 0.5221 - val_accuracy: 0.8512\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4212 - accuracy: 0.8799 - val_loss: 0.4768 - val_accuracy: 0.8628\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3993 - accuracy: 0.8862 - val_loss: 0.4679 - val_accuracy: 0.8694\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3793 - accuracy: 0.8896 - val_loss: 0.4586 - val_accuracy: 0.8642\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3580 - accuracy: 0.8954 - val_loss: 0.4561 - val_accuracy: 0.8686\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3404 - accuracy: 0.9002 - val_loss: 0.4412 - val_accuracy: 0.8729\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3231 - accuracy: 0.9044 - val_loss: 0.4625 - val_accuracy: 0.8692\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3059 - accuracy: 0.9103 - val_loss: 0.4350 - val_accuracy: 0.8723\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2889 - accuracy: 0.9150 - val_loss: 0.4250 - val_accuracy: 0.8773\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2711 - accuracy: 0.9204 - val_loss: 0.4373 - val_accuracy: 0.8728\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2562 - accuracy: 0.9242 - val_loss: 0.4333 - val_accuracy: 0.8697\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2397 - accuracy: 0.9294 - val_loss: 0.4386 - val_accuracy: 0.8739\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:48.920076\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2379 - accuracy: 0.9326 - val_loss: 0.4025 - val_accuracy: 0.8806\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2073 - accuracy: 0.9429 - val_loss: 0.3958 - val_accuracy: 0.8825\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1927 - accuracy: 0.9485 - val_loss: 0.3940 - val_accuracy: 0.8825\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1850 - accuracy: 0.9508 - val_loss: 0.3938 - val_accuracy: 0.8819\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1809 - accuracy: 0.9520 - val_loss: 0.3939 - val_accuracy: 0.8812\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1793 - accuracy: 0.9532 - val_loss: 0.3941 - val_accuracy: 0.8816\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:42.942134\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8671 - accuracy: 0.7942 - val_loss: 0.6254 - val_accuracy: 0.8363\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5331 - accuracy: 0.8558 - val_loss: 0.5214 - val_accuracy: 0.8560\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4691 - accuracy: 0.8672 - val_loss: 0.5110 - val_accuracy: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4404 - accuracy: 0.8740 - val_loss: 0.5326 - val_accuracy: 0.8493\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4241 - accuracy: 0.8778 - val_loss: 0.4673 - val_accuracy: 0.8681\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4039 - accuracy: 0.8833 - val_loss: 0.4837 - val_accuracy: 0.8634\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3815 - accuracy: 0.8904 - val_loss: 0.4447 - val_accuracy: 0.8729\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3655 - accuracy: 0.8931 - val_loss: 0.4541 - val_accuracy: 0.8722\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3466 - accuracy: 0.8998 - val_loss: 0.4426 - val_accuracy: 0.8714\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3275 - accuracy: 0.9041 - val_loss: 0.4353 - val_accuracy: 0.8730\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3089 - accuracy: 0.9091 - val_loss: 0.4414 - val_accuracy: 0.8713\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2934 - accuracy: 0.9137 - val_loss: 0.4434 - val_accuracy: 0.8707\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2779 - accuracy: 0.9175 - val_loss: 0.4313 - val_accuracy: 0.8733\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2585 - accuracy: 0.9242 - val_loss: 0.4284 - val_accuracy: 0.8730\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2451 - accuracy: 0.9278 - val_loss: 0.4337 - val_accuracy: 0.8745\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2293 - accuracy: 0.9330 - val_loss: 0.4311 - val_accuracy: 0.8766\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2152 - accuracy: 0.9380 - val_loss: 0.4353 - val_accuracy: 0.8734\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2021 - accuracy: 0.9418 - val_loss: 0.4446 - val_accuracy: 0.8726\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1888 - accuracy: 0.9465 - val_loss: 0.4390 - val_accuracy: 0.8748\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:08:29.194752\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1913 - accuracy: 0.9487 - val_loss: 0.4032 - val_accuracy: 0.8806\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1704 - accuracy: 0.9565 - val_loss: 0.4040 - val_accuracy: 0.8836\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1606 - accuracy: 0.9607 - val_loss: 0.4030 - val_accuracy: 0.8828\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1555 - accuracy: 0.9621 - val_loss: 0.4032 - val_accuracy: 0.8825\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1531 - accuracy: 0.9636 - val_loss: 0.4033 - val_accuracy: 0.8830\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:14.514733\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 1.0334 - accuracy: 0.6902 - val_loss: 0.5243 - val_accuracy: 0.8252\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.5433 - accuracy: 0.8189 - val_loss: 0.4370 - val_accuracy: 0.8516\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.4635 - accuracy: 0.8421 - val_loss: 0.4085 - val_accuracy: 0.8577\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.4187 - accuracy: 0.8549 - val_loss: 0.3949 - val_accuracy: 0.8630\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.3858 - accuracy: 0.8640 - val_loss: 0.3777 - val_accuracy: 0.8678\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3569 - accuracy: 0.8720 - val_loss: 0.3644 - val_accuracy: 0.8733\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3342 - accuracy: 0.8785 - val_loss: 0.3594 - val_accuracy: 0.8756\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3124 - accuracy: 0.8850 - val_loss: 0.3529 - val_accuracy: 0.8789\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2958 - accuracy: 0.8904 - val_loss: 0.3545 - val_accuracy: 0.8784\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.2781 - accuracy: 0.8961 - val_loss: 0.3589 - val_accuracy: 0.8775\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2669 - accuracy: 0.8986 - val_loss: 0.3568 - val_accuracy: 0.8798\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2544 - accuracy: 0.9029 - val_loss: 0.3503 - val_accuracy: 0.8819\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.2394 - accuracy: 0.9070 - val_loss: 0.3606 - val_accuracy: 0.8813\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2317 - accuracy: 0.9096 - val_loss: 0.3688 - val_accuracy: 0.8809\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.2232 - accuracy: 0.9124 - val_loss: 0.3660 - val_accuracy: 0.8821\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.2124 - accuracy: 0.9161 - val_loss: 0.3714 - val_accuracy: 0.8829\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2064 - accuracy: 0.9182 - val_loss: 0.3733 - val_accuracy: 0.8804\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2014 - accuracy: 0.9201 - val_loss: 0.3779 - val_accuracy: 0.8797\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.1934 - accuracy: 0.9228 - val_loss: 0.3821 - val_accuracy: 0.8808\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:42.481359\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1977 - accuracy: 0.9215 - val_loss: 0.3743 - val_accuracy: 0.8832\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.1892 - accuracy: 0.9254 - val_loss: 0.3714 - val_accuracy: 0.8831\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.1856 - accuracy: 0.9261 - val_loss: 0.3744 - val_accuracy: 0.8832\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.1843 - accuracy: 0.9267 - val_loss: 0.3737 - val_accuracy: 0.8834\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.1840 - accuracy: 0.9273 - val_loss: 0.3735 - val_accuracy: 0.8834\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1833 - accuracy: 0.9273 - val_loss: 0.3736 - val_accuracy: 0.8833\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1833 - accuracy: 0.9279 - val_loss: 0.3737 - val_accuracy: 0.8834\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.1820 - accuracy: 0.9283 - val_loss: 0.3737 - val_accuracy: 0.8835\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.1816 - accuracy: 0.9277 - val_loss: 0.3738 - val_accuracy: 0.8835\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.1834 - accuracy: 0.9273 - val_loss: 0.3738 - val_accuracy: 0.8835\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.1816 - accuracy: 0.9284 - val_loss: 0.3738 - val_accuracy: 0.8835\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:29.731491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 1.0972 - accuracy: 0.6715 - val_loss: 0.5253 - val_accuracy: 0.8245\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.5628 - accuracy: 0.8138 - val_loss: 0.4476 - val_accuracy: 0.8478\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.4795 - accuracy: 0.8378 - val_loss: 0.4048 - val_accuracy: 0.8582\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.4325 - accuracy: 0.8512 - val_loss: 0.3871 - val_accuracy: 0.8662\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.4030 - accuracy: 0.8586 - val_loss: 0.3818 - val_accuracy: 0.8650\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3719 - accuracy: 0.8685 - val_loss: 0.3634 - val_accuracy: 0.8710\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3494 - accuracy: 0.8748 - val_loss: 0.3544 - val_accuracy: 0.8723\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3296 - accuracy: 0.8807 - val_loss: 0.3545 - val_accuracy: 0.8731\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3130 - accuracy: 0.8853 - val_loss: 0.3472 - val_accuracy: 0.8753\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.2996 - accuracy: 0.8893 - val_loss: 0.3454 - val_accuracy: 0.8775\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2847 - accuracy: 0.8933 - val_loss: 0.3442 - val_accuracy: 0.8797\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2730 - accuracy: 0.8972 - val_loss: 0.3479 - val_accuracy: 0.8790\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2621 - accuracy: 0.8994 - val_loss: 0.3489 - val_accuracy: 0.8798\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2521 - accuracy: 0.9027 - val_loss: 0.3508 - val_accuracy: 0.8793\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2441 - accuracy: 0.9059 - val_loss: 0.3600 - val_accuracy: 0.8793\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2359 - accuracy: 0.9087 - val_loss: 0.3559 - val_accuracy: 0.8780\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:06:27.428856\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2397 - accuracy: 0.9081 - val_loss: 0.3439 - val_accuracy: 0.8818\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2310 - accuracy: 0.9116 - val_loss: 0.3458 - val_accuracy: 0.8815\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2248 - accuracy: 0.9127 - val_loss: 0.3458 - val_accuracy: 0.8814\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2233 - accuracy: 0.9138 - val_loss: 0.3467 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2218 - accuracy: 0.9149 - val_loss: 0.3467 - val_accuracy: 0.8820\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.2214 - accuracy: 0.9145 - val_loss: 0.3465 - val_accuracy: 0.8824\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2204 - accuracy: 0.9150 - val_loss: 0.3467 - val_accuracy: 0.8824\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2196 - accuracy: 0.9150 - val_loss: 0.3467 - val_accuracy: 0.8825\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2208 - accuracy: 0.9148 - val_loss: 0.3467 - val_accuracy: 0.8825\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2213 - accuracy: 0.9142 - val_loss: 0.3467 - val_accuracy: 0.8825\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2203 - accuracy: 0.9155 - val_loss: 0.3467 - val_accuracy: 0.8825\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:24.364818\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 1.0121 - accuracy: 0.6958 - val_loss: 0.5206 - val_accuracy: 0.8289\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.5366 - accuracy: 0.8196 - val_loss: 0.4468 - val_accuracy: 0.8469\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.4566 - accuracy: 0.8432 - val_loss: 0.4097 - val_accuracy: 0.8607\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.4152 - accuracy: 0.8560 - val_loss: 0.3923 - val_accuracy: 0.8601\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3820 - accuracy: 0.8642 - val_loss: 0.3792 - val_accuracy: 0.8701\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3518 - accuracy: 0.8728 - val_loss: 0.3747 - val_accuracy: 0.8677\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3285 - accuracy: 0.8810 - val_loss: 0.3578 - val_accuracy: 0.8771\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3086 - accuracy: 0.8871 - val_loss: 0.3602 - val_accuracy: 0.8756\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2918 - accuracy: 0.8905 - val_loss: 0.3506 - val_accuracy: 0.8809\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2764 - accuracy: 0.8961 - val_loss: 0.3533 - val_accuracy: 0.8797\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2629 - accuracy: 0.8999 - val_loss: 0.3522 - val_accuracy: 0.8774\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2502 - accuracy: 0.9038 - val_loss: 0.3570 - val_accuracy: 0.8787\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:48.766871\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2582 - accuracy: 0.9020 - val_loss: 0.3461 - val_accuracy: 0.8789\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2442 - accuracy: 0.9074 - val_loss: 0.3455 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2372 - accuracy: 0.9097 - val_loss: 0.3461 - val_accuracy: 0.8821\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2320 - accuracy: 0.9121 - val_loss: 0.3466 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2314 - accuracy: 0.9111 - val_loss: 0.3465 - val_accuracy: 0.8829\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 25s 35ms/step - loss: 0.2307 - accuracy: 0.9124 - val_loss: 0.3465 - val_accuracy: 0.8826\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 24s 35ms/step - loss: 0.2290 - accuracy: 0.9117 - val_loss: 0.3465 - val_accuracy: 0.8826\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.2283 - accuracy: 0.9123 - val_loss: 0.3465 - val_accuracy: 0.8827\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:16.982001\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 1.0587 - accuracy: 0.6844 - val_loss: 0.5063 - val_accuracy: 0.8311\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.5562 - accuracy: 0.8146 - val_loss: 0.4404 - val_accuracy: 0.8477\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.4709 - accuracy: 0.8403 - val_loss: 0.3994 - val_accuracy: 0.8593\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.4260 - accuracy: 0.8510 - val_loss: 0.3922 - val_accuracy: 0.8625\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 24s 33ms/step - loss: 0.3939 - accuracy: 0.8617 - val_loss: 0.3631 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "705/705 [==============================] - 24s 33ms/step - loss: 0.3648 - accuracy: 0.8696 - val_loss: 0.3614 - val_accuracy: 0.8752\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3445 - accuracy: 0.8752 - val_loss: 0.3550 - val_accuracy: 0.8752\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 24s 34ms/step - loss: 0.3192 - accuracy: 0.8828 - val_loss: 0.3461 - val_accuracy: 0.8797\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.3053 - accuracy: 0.8871 - val_loss: 0.3446 - val_accuracy: 0.8783\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.2881 - accuracy: 0.8926 - val_loss: 0.3441 - val_accuracy: 0.8792\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.2739 - accuracy: 0.8963 - val_loss: 0.3503 - val_accuracy: 0.8806\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.2634 - accuracy: 0.9001 - val_loss: 0.3505 - val_accuracy: 0.8816\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 24s 33ms/step - loss: 0.2507 - accuracy: 0.9033 - val_loss: 0.3545 - val_accuracy: 0.8813\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.2406 - accuracy: 0.9068 - val_loss: 0.3490 - val_accuracy: 0.8824\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.2322 - accuracy: 0.9102 - val_loss: 0.3536 - val_accuracy: 0.8820\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.2220 - accuracy: 0.9134 - val_loss: 0.3541 - val_accuracy: 0.8824\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.2154 - accuracy: 0.9154 - val_loss: 0.3599 - val_accuracy: 0.8828\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 24s 33ms/step - loss: 0.2097 - accuracy: 0.9174 - val_loss: 0.3627 - val_accuracy: 0.8811\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.2026 - accuracy: 0.9188 - val_loss: 0.3639 - val_accuracy: 0.8834\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 23s 33ms/step - loss: 0.1976 - accuracy: 0.9217 - val_loss: 0.3728 - val_accuracy: 0.8812\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:51.332861\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1881 - accuracy: 0.9248 - val_loss: 0.3686 - val_accuracy: 0.8826\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1821 - accuracy: 0.9279 - val_loss: 0.3720 - val_accuracy: 0.8831\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1783 - accuracy: 0.9287 - val_loss: 0.3728 - val_accuracy: 0.8832\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1766 - accuracy: 0.9298 - val_loss: 0.3742 - val_accuracy: 0.8836\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1749 - accuracy: 0.9310 - val_loss: 0.3739 - val_accuracy: 0.8836\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1754 - accuracy: 0.9305 - val_loss: 0.3741 - val_accuracy: 0.8835\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1751 - accuracy: 0.9306 - val_loss: 0.3741 - val_accuracy: 0.8835\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:11.896200\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0507 - accuracy: 0.6854 - val_loss: 0.5135 - val_accuracy: 0.8273\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5464 - accuracy: 0.8185 - val_loss: 0.4459 - val_accuracy: 0.8493\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4632 - accuracy: 0.8424 - val_loss: 0.3929 - val_accuracy: 0.8637\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4189 - accuracy: 0.8548 - val_loss: 0.3830 - val_accuracy: 0.8647\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3877 - accuracy: 0.8647 - val_loss: 0.3653 - val_accuracy: 0.8724\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3592 - accuracy: 0.8722 - val_loss: 0.3558 - val_accuracy: 0.8755\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3346 - accuracy: 0.8778 - val_loss: 0.3486 - val_accuracy: 0.8776\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3155 - accuracy: 0.8839 - val_loss: 0.3416 - val_accuracy: 0.8806\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3001 - accuracy: 0.8890 - val_loss: 0.3421 - val_accuracy: 0.8807\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2823 - accuracy: 0.8946 - val_loss: 0.3425 - val_accuracy: 0.8804\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2712 - accuracy: 0.8980 - val_loss: 0.3397 - val_accuracy: 0.8805\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2560 - accuracy: 0.9029 - val_loss: 0.3439 - val_accuracy: 0.8809\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2470 - accuracy: 0.9056 - val_loss: 0.3425 - val_accuracy: 0.8832\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2365 - accuracy: 0.9094 - val_loss: 0.3473 - val_accuracy: 0.8821\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2286 - accuracy: 0.9115 - val_loss: 0.3497 - val_accuracy: 0.8826\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2179 - accuracy: 0.9145 - val_loss: 0.3531 - val_accuracy: 0.8828\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:08.863277\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2245 - accuracy: 0.9136 - val_loss: 0.3450 - val_accuracy: 0.8852\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2148 - accuracy: 0.9167 - val_loss: 0.3437 - val_accuracy: 0.8854\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2093 - accuracy: 0.9200 - val_loss: 0.3445 - val_accuracy: 0.8849\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2071 - accuracy: 0.9202 - val_loss: 0.3447 - val_accuracy: 0.8855\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2072 - accuracy: 0.9196 - val_loss: 0.3446 - val_accuracy: 0.8851\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2055 - accuracy: 0.9207 - val_loss: 0.3447 - val_accuracy: 0.8852\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2039 - accuracy: 0.9207 - val_loss: 0.3447 - val_accuracy: 0.8853\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:07.786022\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8920 - accuracy: 0.7311 - val_loss: 0.4867 - val_accuracy: 0.8358\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4864 - accuracy: 0.8362 - val_loss: 0.4331 - val_accuracy: 0.8560\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4247 - accuracy: 0.8533 - val_loss: 0.4162 - val_accuracy: 0.8563\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3878 - accuracy: 0.8639 - val_loss: 0.3880 - val_accuracy: 0.8666\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3624 - accuracy: 0.8703 - val_loss: 0.3875 - val_accuracy: 0.8689\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3347 - accuracy: 0.8787 - val_loss: 0.3797 - val_accuracy: 0.8708\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3134 - accuracy: 0.8840 - val_loss: 0.3764 - val_accuracy: 0.8735\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2938 - accuracy: 0.8906 - val_loss: 0.3783 - val_accuracy: 0.8765\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2769 - accuracy: 0.8963 - val_loss: 0.3699 - val_accuracy: 0.8752\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2613 - accuracy: 0.8996 - val_loss: 0.3707 - val_accuracy: 0.8770\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2485 - accuracy: 0.9044 - val_loss: 0.3755 - val_accuracy: 0.8786\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2341 - accuracy: 0.9089 - val_loss: 0.3771 - val_accuracy: 0.8788\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2250 - accuracy: 0.9114 - val_loss: 0.3802 - val_accuracy: 0.8770\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2142 - accuracy: 0.9146 - val_loss: 0.3938 - val_accuracy: 0.8781\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2055 - accuracy: 0.9176 - val_loss: 0.3871 - val_accuracy: 0.8783\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:06:48.889484\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2109 - accuracy: 0.9169 - val_loss: 0.3739 - val_accuracy: 0.8802\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1993 - accuracy: 0.9209 - val_loss: 0.3738 - val_accuracy: 0.8823\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1935 - accuracy: 0.9234 - val_loss: 0.3734 - val_accuracy: 0.8832\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1904 - accuracy: 0.9249 - val_loss: 0.3736 - val_accuracy: 0.8818\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1895 - accuracy: 0.9256 - val_loss: 0.3736 - val_accuracy: 0.8825\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1883 - accuracy: 0.9252 - val_loss: 0.3735 - val_accuracy: 0.8828\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:43.528486\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9034 - accuracy: 0.7269 - val_loss: 0.4901 - val_accuracy: 0.8365\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4978 - accuracy: 0.8318 - val_loss: 0.4263 - val_accuracy: 0.8526\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4327 - accuracy: 0.8501 - val_loss: 0.3939 - val_accuracy: 0.8666\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3951 - accuracy: 0.8630 - val_loss: 0.3846 - val_accuracy: 0.8652\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3706 - accuracy: 0.8684 - val_loss: 0.3743 - val_accuracy: 0.8699\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3433 - accuracy: 0.8763 - val_loss: 0.3655 - val_accuracy: 0.8743\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3215 - accuracy: 0.8824 - val_loss: 0.3564 - val_accuracy: 0.8746\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3029 - accuracy: 0.8880 - val_loss: 0.3528 - val_accuracy: 0.8769\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2858 - accuracy: 0.8930 - val_loss: 0.3531 - val_accuracy: 0.8783\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2716 - accuracy: 0.8973 - val_loss: 0.3604 - val_accuracy: 0.8768\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2563 - accuracy: 0.9011 - val_loss: 0.3578 - val_accuracy: 0.8792\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2441 - accuracy: 0.9061 - val_loss: 0.3627 - val_accuracy: 0.8793\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2331 - accuracy: 0.9088 - val_loss: 0.3640 - val_accuracy: 0.8791\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2237 - accuracy: 0.9122 - val_loss: 0.3635 - val_accuracy: 0.8815\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2142 - accuracy: 0.9155 - val_loss: 0.3676 - val_accuracy: 0.8825\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2076 - accuracy: 0.9183 - val_loss: 0.3702 - val_accuracy: 0.8800\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1963 - accuracy: 0.9211 - val_loss: 0.3742 - val_accuracy: 0.8813\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1923 - accuracy: 0.9228 - val_loss: 0.3838 - val_accuracy: 0.8807\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:10.356218\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1940 - accuracy: 0.9218 - val_loss: 0.3657 - val_accuracy: 0.8825\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1850 - accuracy: 0.9258 - val_loss: 0.3647 - val_accuracy: 0.8821\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1837 - accuracy: 0.9269 - val_loss: 0.3664 - val_accuracy: 0.8827\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1799 - accuracy: 0.9279 - val_loss: 0.3663 - val_accuracy: 0.8835\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1790 - accuracy: 0.9291 - val_loss: 0.3662 - val_accuracy: 0.8833\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1780 - accuracy: 0.9290 - val_loss: 0.3663 - val_accuracy: 0.8834\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1785 - accuracy: 0.9291 - val_loss: 0.3663 - val_accuracy: 0.8831\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:10.973172\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9040 - accuracy: 0.7260 - val_loss: 0.4980 - val_accuracy: 0.8325\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4875 - accuracy: 0.8357 - val_loss: 0.4149 - val_accuracy: 0.8565\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4254 - accuracy: 0.8531 - val_loss: 0.3824 - val_accuracy: 0.8676\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3906 - accuracy: 0.8619 - val_loss: 0.3739 - val_accuracy: 0.8694\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3637 - accuracy: 0.8693 - val_loss: 0.3561 - val_accuracy: 0.8761\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3381 - accuracy: 0.8768 - val_loss: 0.3634 - val_accuracy: 0.8734\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3181 - accuracy: 0.8831 - val_loss: 0.3576 - val_accuracy: 0.8753\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2980 - accuracy: 0.8871 - val_loss: 0.3554 - val_accuracy: 0.8746\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:38.268643\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3141 - accuracy: 0.8853 - val_loss: 0.3409 - val_accuracy: 0.8810\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2857 - accuracy: 0.8945 - val_loss: 0.3357 - val_accuracy: 0.8827\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2746 - accuracy: 0.8980 - val_loss: 0.3329 - val_accuracy: 0.8847\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2671 - accuracy: 0.9011 - val_loss: 0.3318 - val_accuracy: 0.8841\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2648 - accuracy: 0.9011 - val_loss: 0.3313 - val_accuracy: 0.8846\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2629 - accuracy: 0.9024 - val_loss: 0.3313 - val_accuracy: 0.8841\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:43.214492\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8994 - accuracy: 0.7305 - val_loss: 0.4956 - val_accuracy: 0.8352\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4901 - accuracy: 0.8348 - val_loss: 0.4241 - val_accuracy: 0.8562\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4262 - accuracy: 0.8532 - val_loss: 0.4012 - val_accuracy: 0.8629\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3924 - accuracy: 0.8621 - val_loss: 0.3902 - val_accuracy: 0.8655\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3669 - accuracy: 0.8695 - val_loss: 0.3790 - val_accuracy: 0.8703\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3386 - accuracy: 0.8766 - val_loss: 0.3753 - val_accuracy: 0.8701\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3168 - accuracy: 0.8846 - val_loss: 0.3707 - val_accuracy: 0.8719\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2970 - accuracy: 0.8884 - val_loss: 0.3671 - val_accuracy: 0.8753\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2785 - accuracy: 0.8954 - val_loss: 0.3684 - val_accuracy: 0.8752\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2638 - accuracy: 0.8999 - val_loss: 0.3706 - val_accuracy: 0.8759\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2504 - accuracy: 0.9030 - val_loss: 0.3767 - val_accuracy: 0.8756\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2399 - accuracy: 0.9068 - val_loss: 0.3719 - val_accuracy: 0.8751\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2274 - accuracy: 0.9098 - val_loss: 0.3797 - val_accuracy: 0.8777\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2174 - accuracy: 0.9140 - val_loss: 0.3767 - val_accuracy: 0.8755\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2099 - accuracy: 0.9162 - val_loss: 0.3811 - val_accuracy: 0.8742\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2005 - accuracy: 0.9205 - val_loss: 0.3841 - val_accuracy: 0.8779\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1926 - accuracy: 0.9229 - val_loss: 0.3899 - val_accuracy: 0.8760\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1873 - accuracy: 0.9246 - val_loss: 0.3938 - val_accuracy: 0.8761\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1815 - accuracy: 0.9259 - val_loss: 0.3952 - val_accuracy: 0.8773\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:37.000773\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1839 - accuracy: 0.9263 - val_loss: 0.3858 - val_accuracy: 0.8780\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1769 - accuracy: 0.9287 - val_loss: 0.3849 - val_accuracy: 0.8784\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1723 - accuracy: 0.9307 - val_loss: 0.3856 - val_accuracy: 0.8787\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1711 - accuracy: 0.9317 - val_loss: 0.3856 - val_accuracy: 0.8789\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1700 - accuracy: 0.9320 - val_loss: 0.3855 - val_accuracy: 0.8789\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1688 - accuracy: 0.9319 - val_loss: 0.3860 - val_accuracy: 0.8787\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1690 - accuracy: 0.9322 - val_loss: 0.3861 - val_accuracy: 0.8788\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:10.575805\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9001 - accuracy: 0.7284 - val_loss: 0.5100 - val_accuracy: 0.8266\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4920 - accuracy: 0.8344 - val_loss: 0.4305 - val_accuracy: 0.8501\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4276 - accuracy: 0.8521 - val_loss: 0.4024 - val_accuracy: 0.8631\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3909 - accuracy: 0.8625 - val_loss: 0.3937 - val_accuracy: 0.8625\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3664 - accuracy: 0.8691 - val_loss: 0.3849 - val_accuracy: 0.8626\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3391 - accuracy: 0.8767 - val_loss: 0.3692 - val_accuracy: 0.8708\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3178 - accuracy: 0.8830 - val_loss: 0.3751 - val_accuracy: 0.8693\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2999 - accuracy: 0.8891 - val_loss: 0.3648 - val_accuracy: 0.8763\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2824 - accuracy: 0.8938 - val_loss: 0.3698 - val_accuracy: 0.8750\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2668 - accuracy: 0.8975 - val_loss: 0.3666 - val_accuracy: 0.8784\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2526 - accuracy: 0.9028 - val_loss: 0.3682 - val_accuracy: 0.8756\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2401 - accuracy: 0.9065 - val_loss: 0.3767 - val_accuracy: 0.8773\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2288 - accuracy: 0.9105 - val_loss: 0.3777 - val_accuracy: 0.8769\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:55.387645\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2364 - accuracy: 0.9088 - val_loss: 0.3561 - val_accuracy: 0.8806\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2198 - accuracy: 0.9157 - val_loss: 0.3553 - val_accuracy: 0.8819\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2142 - accuracy: 0.9171 - val_loss: 0.3556 - val_accuracy: 0.8813\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2103 - accuracy: 0.9183 - val_loss: 0.3568 - val_accuracy: 0.8815\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2080 - accuracy: 0.9189 - val_loss: 0.3566 - val_accuracy: 0.8812\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:16.311216\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9498 - accuracy: 0.7142 - val_loss: 0.4939 - val_accuracy: 0.8377\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4970 - accuracy: 0.8334 - val_loss: 0.4302 - val_accuracy: 0.8533\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4303 - accuracy: 0.8521 - val_loss: 0.3899 - val_accuracy: 0.8656\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3913 - accuracy: 0.8620 - val_loss: 0.3770 - val_accuracy: 0.8692\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3660 - accuracy: 0.8695 - val_loss: 0.3673 - val_accuracy: 0.8703\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3391 - accuracy: 0.8781 - val_loss: 0.3635 - val_accuracy: 0.8721\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3198 - accuracy: 0.8841 - val_loss: 0.3495 - val_accuracy: 0.8794\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2998 - accuracy: 0.8894 - val_loss: 0.3479 - val_accuracy: 0.8782\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2845 - accuracy: 0.8931 - val_loss: 0.3420 - val_accuracy: 0.8827\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2697 - accuracy: 0.8978 - val_loss: 0.3476 - val_accuracy: 0.8798\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2573 - accuracy: 0.9022 - val_loss: 0.3441 - val_accuracy: 0.8815\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2445 - accuracy: 0.9066 - val_loss: 0.3507 - val_accuracy: 0.8806\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:37.125723\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2516 - accuracy: 0.9051 - val_loss: 0.3388 - val_accuracy: 0.8836\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2375 - accuracy: 0.9097 - val_loss: 0.3350 - val_accuracy: 0.8853\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2317 - accuracy: 0.9118 - val_loss: 0.3341 - val_accuracy: 0.8860\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2276 - accuracy: 0.9138 - val_loss: 0.3342 - val_accuracy: 0.8866\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2254 - accuracy: 0.9143 - val_loss: 0.3343 - val_accuracy: 0.8862\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2244 - accuracy: 0.9149 - val_loss: 0.3344 - val_accuracy: 0.8864\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2230 - accuracy: 0.9144 - val_loss: 0.3344 - val_accuracy: 0.8863\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:17.362457\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9197 - accuracy: 0.7218 - val_loss: 0.5074 - val_accuracy: 0.8314\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4959 - accuracy: 0.8332 - val_loss: 0.4328 - val_accuracy: 0.8543\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4284 - accuracy: 0.8527 - val_loss: 0.4036 - val_accuracy: 0.8640\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3925 - accuracy: 0.8624 - val_loss: 0.3920 - val_accuracy: 0.8666\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3633 - accuracy: 0.8701 - val_loss: 0.3790 - val_accuracy: 0.8722\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3373 - accuracy: 0.8791 - val_loss: 0.3701 - val_accuracy: 0.8727\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3155 - accuracy: 0.8838 - val_loss: 0.3754 - val_accuracy: 0.8730\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2961 - accuracy: 0.8900 - val_loss: 0.3613 - val_accuracy: 0.8761\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2824 - accuracy: 0.8949 - val_loss: 0.3657 - val_accuracy: 0.8730\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2684 - accuracy: 0.8983 - val_loss: 0.3654 - val_accuracy: 0.8751\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2565 - accuracy: 0.9030 - val_loss: 0.3681 - val_accuracy: 0.8758\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:10.708827\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2627 - accuracy: 0.9009 - val_loss: 0.3513 - val_accuracy: 0.8808\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2482 - accuracy: 0.9060 - val_loss: 0.3494 - val_accuracy: 0.8828\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2390 - accuracy: 0.9098 - val_loss: 0.3473 - val_accuracy: 0.8829\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2351 - accuracy: 0.9108 - val_loss: 0.3470 - val_accuracy: 0.8833\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2326 - accuracy: 0.9128 - val_loss: 0.3469 - val_accuracy: 0.8831\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2317 - accuracy: 0.9124 - val_loss: 0.3468 - val_accuracy: 0.8830\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2302 - accuracy: 0.9126 - val_loss: 0.3469 - val_accuracy: 0.8831\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:18.215836\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9606 - accuracy: 0.7131 - val_loss: 0.4961 - val_accuracy: 0.8297\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5090 - accuracy: 0.8299 - val_loss: 0.4138 - val_accuracy: 0.8598\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4386 - accuracy: 0.8500 - val_loss: 0.3848 - val_accuracy: 0.8686\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4007 - accuracy: 0.8606 - val_loss: 0.3788 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3732 - accuracy: 0.8679 - val_loss: 0.3576 - val_accuracy: 0.8740\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3468 - accuracy: 0.8748 - val_loss: 0.3502 - val_accuracy: 0.8758\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3262 - accuracy: 0.8815 - val_loss: 0.3482 - val_accuracy: 0.8766\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3068 - accuracy: 0.8864 - val_loss: 0.3443 - val_accuracy: 0.8776\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2915 - accuracy: 0.8919 - val_loss: 0.3389 - val_accuracy: 0.8822\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2746 - accuracy: 0.8971 - val_loss: 0.3364 - val_accuracy: 0.8808\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2641 - accuracy: 0.9003 - val_loss: 0.3358 - val_accuracy: 0.8823\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2518 - accuracy: 0.9037 - val_loss: 0.3400 - val_accuracy: 0.8802\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2418 - accuracy: 0.9070 - val_loss: 0.3428 - val_accuracy: 0.8801\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2315 - accuracy: 0.9102 - val_loss: 0.3405 - val_accuracy: 0.8817\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:33.330764\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2364 - accuracy: 0.9102 - val_loss: 0.3297 - val_accuracy: 0.8853\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2229 - accuracy: 0.9143 - val_loss: 0.3292 - val_accuracy: 0.8863\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2186 - accuracy: 0.9160 - val_loss: 0.3284 - val_accuracy: 0.8866\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2150 - accuracy: 0.9173 - val_loss: 0.3289 - val_accuracy: 0.8869\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2140 - accuracy: 0.9175 - val_loss: 0.3291 - val_accuracy: 0.8867\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2105 - accuracy: 0.9192 - val_loss: 0.3290 - val_accuracy: 0.8870\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2118 - accuracy: 0.9186 - val_loss: 0.3290 - val_accuracy: 0.8869\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2110 - accuracy: 0.9178 - val_loss: 0.3291 - val_accuracy: 0.8869\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2124 - accuracy: 0.9180 - val_loss: 0.3291 - val_accuracy: 0.8869\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:12.471796\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9328 - accuracy: 0.7194 - val_loss: 0.4877 - val_accuracy: 0.8365\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4954 - accuracy: 0.8340 - val_loss: 0.4139 - val_accuracy: 0.8582\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4279 - accuracy: 0.8535 - val_loss: 0.3868 - val_accuracy: 0.8670\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3893 - accuracy: 0.8640 - val_loss: 0.3735 - val_accuracy: 0.8695\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3600 - accuracy: 0.8726 - val_loss: 0.3595 - val_accuracy: 0.8745\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3336 - accuracy: 0.8799 - val_loss: 0.3485 - val_accuracy: 0.8782\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3133 - accuracy: 0.8851 - val_loss: 0.3465 - val_accuracy: 0.8778\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2977 - accuracy: 0.8910 - val_loss: 0.3474 - val_accuracy: 0.8773\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2790 - accuracy: 0.8963 - val_loss: 0.3422 - val_accuracy: 0.8789\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2673 - accuracy: 0.8991 - val_loss: 0.3381 - val_accuracy: 0.8806\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2542 - accuracy: 0.9038 - val_loss: 0.3392 - val_accuracy: 0.8802\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2433 - accuracy: 0.9063 - val_loss: 0.3421 - val_accuracy: 0.8819\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2332 - accuracy: 0.9090 - val_loss: 0.3421 - val_accuracy: 0.8839\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2247 - accuracy: 0.9124 - val_loss: 0.3412 - val_accuracy: 0.8835\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2163 - accuracy: 0.9153 - val_loss: 0.3475 - val_accuracy: 0.8812\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2078 - accuracy: 0.9180 - val_loss: 0.3484 - val_accuracy: 0.8827\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:29.371008\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2124 - accuracy: 0.9185 - val_loss: 0.3359 - val_accuracy: 0.8856\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2032 - accuracy: 0.9210 - val_loss: 0.3362 - val_accuracy: 0.8855\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1973 - accuracy: 0.9234 - val_loss: 0.3358 - val_accuracy: 0.8863\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1947 - accuracy: 0.9245 - val_loss: 0.3365 - val_accuracy: 0.8861\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1934 - accuracy: 0.9249 - val_loss: 0.3364 - val_accuracy: 0.8863\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1935 - accuracy: 0.9249 - val_loss: 0.3366 - val_accuracy: 0.8867\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1926 - accuracy: 0.9250 - val_loss: 0.3366 - val_accuracy: 0.8866\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1933 - accuracy: 0.9249 - val_loss: 0.3366 - val_accuracy: 0.8865\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1930 - accuracy: 0.9247 - val_loss: 0.3367 - val_accuracy: 0.8865\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:15.251846\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9238 - accuracy: 0.7227 - val_loss: 0.4940 - val_accuracy: 0.8349\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4934 - accuracy: 0.8355 - val_loss: 0.4317 - val_accuracy: 0.8522\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4285 - accuracy: 0.8542 - val_loss: 0.4008 - val_accuracy: 0.8638\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3908 - accuracy: 0.8641 - val_loss: 0.3864 - val_accuracy: 0.8639\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3593 - accuracy: 0.8726 - val_loss: 0.3770 - val_accuracy: 0.8695\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3349 - accuracy: 0.8789 - val_loss: 0.3743 - val_accuracy: 0.8705\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3129 - accuracy: 0.8856 - val_loss: 0.3640 - val_accuracy: 0.8719\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2963 - accuracy: 0.8907 - val_loss: 0.3537 - val_accuracy: 0.8766\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.2804 - accuracy: 0.8952 - val_loss: 0.3626 - val_accuracy: 0.8736\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2650 - accuracy: 0.9005 - val_loss: 0.3527 - val_accuracy: 0.8774\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2525 - accuracy: 0.9041 - val_loss: 0.3587 - val_accuracy: 0.8776\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2439 - accuracy: 0.9065 - val_loss: 0.3641 - val_accuracy: 0.8746\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2315 - accuracy: 0.9108 - val_loss: 0.3547 - val_accuracy: 0.8798\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2215 - accuracy: 0.9138 - val_loss: 0.3653 - val_accuracy: 0.8781\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2130 - accuracy: 0.9172 - val_loss: 0.3668 - val_accuracy: 0.8796\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2079 - accuracy: 0.9186 - val_loss: 0.3621 - val_accuracy: 0.8782\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:32.375101\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.2085 - accuracy: 0.9199 - val_loss: 0.3529 - val_accuracy: 0.8813\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2007 - accuracy: 0.9226 - val_loss: 0.3541 - val_accuracy: 0.8810\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1978 - accuracy: 0.9238 - val_loss: 0.3540 - val_accuracy: 0.8816\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1933 - accuracy: 0.9251 - val_loss: 0.3542 - val_accuracy: 0.8817\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1923 - accuracy: 0.9257 - val_loss: 0.3540 - val_accuracy: 0.8826\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1897 - accuracy: 0.9269 - val_loss: 0.3542 - val_accuracy: 0.8822\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1925 - accuracy: 0.9252 - val_loss: 0.3542 - val_accuracy: 0.8822\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1926 - accuracy: 0.9257 - val_loss: 0.3542 - val_accuracy: 0.8823\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:48.429640\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.0059 - accuracy: 0.6345 - val_loss: 1.1038 - val_accuracy: 0.7855\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0956 - accuracy: 0.7755 - val_loss: 0.9171 - val_accuracy: 0.8237\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9834 - accuracy: 0.7955 - val_loss: 0.8754 - val_accuracy: 0.8256\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9285 - accuracy: 0.8069 - val_loss: 0.8313 - val_accuracy: 0.8323\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8942 - accuracy: 0.8135 - val_loss: 0.7909 - val_accuracy: 0.8429\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8469 - accuracy: 0.8204 - val_loss: 0.7770 - val_accuracy: 0.8414\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8146 - accuracy: 0.8244 - val_loss: 0.7335 - val_accuracy: 0.8485\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7873 - accuracy: 0.8288 - val_loss: 0.7221 - val_accuracy: 0.8455\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7645 - accuracy: 0.8312 - val_loss: 0.7022 - val_accuracy: 0.8502\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7375 - accuracy: 0.8355 - val_loss: 0.6747 - val_accuracy: 0.8515\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7155 - accuracy: 0.8376 - val_loss: 0.6530 - val_accuracy: 0.8564\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6951 - accuracy: 0.8412 - val_loss: 0.6357 - val_accuracy: 0.8584\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6763 - accuracy: 0.8426 - val_loss: 0.6292 - val_accuracy: 0.8559\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6618 - accuracy: 0.8459 - val_loss: 0.6125 - val_accuracy: 0.8589\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6478 - accuracy: 0.8468 - val_loss: 0.6009 - val_accuracy: 0.8597\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6315 - accuracy: 0.8501 - val_loss: 0.5941 - val_accuracy: 0.8599\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6174 - accuracy: 0.8511 - val_loss: 0.5737 - val_accuracy: 0.8618\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6070 - accuracy: 0.8524 - val_loss: 0.5683 - val_accuracy: 0.8624\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5953 - accuracy: 0.8540 - val_loss: 0.5545 - val_accuracy: 0.8662\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5843 - accuracy: 0.8555 - val_loss: 0.5577 - val_accuracy: 0.8641\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:03.689633\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.5469 - accuracy: 0.8623 - val_loss: 0.5214 - val_accuracy: 0.8684\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5233 - accuracy: 0.8670 - val_loss: 0.5022 - val_accuracy: 0.8695\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5100 - accuracy: 0.8686 - val_loss: 0.4926 - val_accuracy: 0.8723\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5008 - accuracy: 0.8700 - val_loss: 0.4878 - val_accuracy: 0.8713\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4985 - accuracy: 0.8702 - val_loss: 0.4859 - val_accuracy: 0.8718\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4982 - accuracy: 0.8701 - val_loss: 0.4853 - val_accuracy: 0.8721\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:48.171530\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0399 - accuracy: 0.6328 - val_loss: 1.1277 - val_accuracy: 0.7902\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1195 - accuracy: 0.7736 - val_loss: 0.9481 - val_accuracy: 0.8158\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9782 - accuracy: 0.7966 - val_loss: 0.8831 - val_accuracy: 0.8165\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9238 - accuracy: 0.8048 - val_loss: 0.8407 - val_accuracy: 0.8287\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8882 - accuracy: 0.8138 - val_loss: 0.8183 - val_accuracy: 0.8287\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8498 - accuracy: 0.8196 - val_loss: 0.7962 - val_accuracy: 0.8346\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8171 - accuracy: 0.8246 - val_loss: 0.7702 - val_accuracy: 0.8355\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7863 - accuracy: 0.8277 - val_loss: 0.7407 - val_accuracy: 0.8429\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7576 - accuracy: 0.8331 - val_loss: 0.7134 - val_accuracy: 0.8450\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7387 - accuracy: 0.8343 - val_loss: 0.6948 - val_accuracy: 0.8472\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7118 - accuracy: 0.8383 - val_loss: 0.6719 - val_accuracy: 0.8513\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6955 - accuracy: 0.8400 - val_loss: 0.6583 - val_accuracy: 0.8525\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6756 - accuracy: 0.8428 - val_loss: 0.6446 - val_accuracy: 0.8540\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6611 - accuracy: 0.8456 - val_loss: 0.6304 - val_accuracy: 0.8541\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6472 - accuracy: 0.8470 - val_loss: 0.6149 - val_accuracy: 0.8541\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6298 - accuracy: 0.8498 - val_loss: 0.6002 - val_accuracy: 0.8576\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6186 - accuracy: 0.8521 - val_loss: 0.5993 - val_accuracy: 0.8559\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6028 - accuracy: 0.8534 - val_loss: 0.5792 - val_accuracy: 0.8620\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5946 - accuracy: 0.8548 - val_loss: 0.5807 - val_accuracy: 0.8590\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5838 - accuracy: 0.8562 - val_loss: 0.5741 - val_accuracy: 0.8585\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:57.504951\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5475 - accuracy: 0.8616 - val_loss: 0.5321 - val_accuracy: 0.8643\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5209 - accuracy: 0.8669 - val_loss: 0.5187 - val_accuracy: 0.8660\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5060 - accuracy: 0.8691 - val_loss: 0.5093 - val_accuracy: 0.8672\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5018 - accuracy: 0.8708 - val_loss: 0.5050 - val_accuracy: 0.8671\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4971 - accuracy: 0.8702 - val_loss: 0.5042 - val_accuracy: 0.8669\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4953 - accuracy: 0.8699 - val_loss: 0.5029 - val_accuracy: 0.8676\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4946 - accuracy: 0.8693 - val_loss: 0.5026 - val_accuracy: 0.8673\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4948 - accuracy: 0.8716 - val_loss: 0.5025 - val_accuracy: 0.8672\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4935 - accuracy: 0.8703 - val_loss: 0.5024 - val_accuracy: 0.8672\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:01.854849\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.0959 - accuracy: 0.6303 - val_loss: 1.1246 - val_accuracy: 0.7852\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1226 - accuracy: 0.7707 - val_loss: 0.9172 - val_accuracy: 0.8246\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0033 - accuracy: 0.7912 - val_loss: 0.8908 - val_accuracy: 0.8251\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9490 - accuracy: 0.8029 - val_loss: 0.8397 - val_accuracy: 0.8327\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9139 - accuracy: 0.8106 - val_loss: 0.8142 - val_accuracy: 0.8353\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8694 - accuracy: 0.8175 - val_loss: 0.7886 - val_accuracy: 0.8381\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8320 - accuracy: 0.8225 - val_loss: 0.7539 - val_accuracy: 0.8505\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7979 - accuracy: 0.8270 - val_loss: 0.7329 - val_accuracy: 0.8491\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7708 - accuracy: 0.8302 - val_loss: 0.7034 - val_accuracy: 0.8495\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7453 - accuracy: 0.8332 - val_loss: 0.6942 - val_accuracy: 0.8525\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7249 - accuracy: 0.8367 - val_loss: 0.6579 - val_accuracy: 0.8581\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7036 - accuracy: 0.8399 - val_loss: 0.6558 - val_accuracy: 0.8541\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6844 - accuracy: 0.8410 - val_loss: 0.6317 - val_accuracy: 0.8590\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6647 - accuracy: 0.8444 - val_loss: 0.6225 - val_accuracy: 0.8579\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6543 - accuracy: 0.8457 - val_loss: 0.6063 - val_accuracy: 0.8632\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6386 - accuracy: 0.8478 - val_loss: 0.5954 - val_accuracy: 0.8617\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6247 - accuracy: 0.8483 - val_loss: 0.5911 - val_accuracy: 0.8626\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6101 - accuracy: 0.8520 - val_loss: 0.5680 - val_accuracy: 0.8662\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5961 - accuracy: 0.8535 - val_loss: 0.5632 - val_accuracy: 0.8661\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5884 - accuracy: 0.8546 - val_loss: 0.5543 - val_accuracy: 0.8673\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:01.188728\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5522 - accuracy: 0.8608 - val_loss: 0.5239 - val_accuracy: 0.8718\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5283 - accuracy: 0.8653 - val_loss: 0.5082 - val_accuracy: 0.8731\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5156 - accuracy: 0.8660 - val_loss: 0.4981 - val_accuracy: 0.8756\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5056 - accuracy: 0.8670 - val_loss: 0.4951 - val_accuracy: 0.8744\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5028 - accuracy: 0.8679 - val_loss: 0.4926 - val_accuracy: 0.8752\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5022 - accuracy: 0.8685 - val_loss: 0.4916 - val_accuracy: 0.8756\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5019 - accuracy: 0.8684 - val_loss: 0.4912 - val_accuracy: 0.8756\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4996 - accuracy: 0.8688 - val_loss: 0.4911 - val_accuracy: 0.8755\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4989 - accuracy: 0.8690 - val_loss: 0.4911 - val_accuracy: 0.8756\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:02.960896\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0387 - accuracy: 0.6308 - val_loss: 1.0810 - val_accuracy: 0.7937\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0844 - accuracy: 0.7719 - val_loss: 0.9186 - val_accuracy: 0.8141\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9745 - accuracy: 0.7900 - val_loss: 0.8515 - val_accuracy: 0.8280\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9258 - accuracy: 0.8018 - val_loss: 0.8361 - val_accuracy: 0.8290\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8921 - accuracy: 0.8085 - val_loss: 0.8006 - val_accuracy: 0.8363\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8543 - accuracy: 0.8153 - val_loss: 0.7740 - val_accuracy: 0.8365\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8207 - accuracy: 0.8213 - val_loss: 0.7458 - val_accuracy: 0.8439\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7926 - accuracy: 0.8256 - val_loss: 0.7291 - val_accuracy: 0.8472\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7669 - accuracy: 0.8290 - val_loss: 0.7035 - val_accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7421 - accuracy: 0.8338 - val_loss: 0.6894 - val_accuracy: 0.8501\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7228 - accuracy: 0.8353 - val_loss: 0.6681 - val_accuracy: 0.8547\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7004 - accuracy: 0.8387 - val_loss: 0.6486 - val_accuracy: 0.8560\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6867 - accuracy: 0.8418 - val_loss: 0.6484 - val_accuracy: 0.8542\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6704 - accuracy: 0.8427 - val_loss: 0.6224 - val_accuracy: 0.8597\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6511 - accuracy: 0.8457 - val_loss: 0.6178 - val_accuracy: 0.8562\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6389 - accuracy: 0.8456 - val_loss: 0.6044 - val_accuracy: 0.8589\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6232 - accuracy: 0.8484 - val_loss: 0.5903 - val_accuracy: 0.8612\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6113 - accuracy: 0.8501 - val_loss: 0.5885 - val_accuracy: 0.8631\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6015 - accuracy: 0.8505 - val_loss: 0.5752 - val_accuracy: 0.8627\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5921 - accuracy: 0.8531 - val_loss: 0.5612 - val_accuracy: 0.8642\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:12.950228\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5534 - accuracy: 0.8607 - val_loss: 0.5295 - val_accuracy: 0.8678\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5317 - accuracy: 0.8635 - val_loss: 0.5172 - val_accuracy: 0.8704\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5180 - accuracy: 0.8651 - val_loss: 0.5104 - val_accuracy: 0.8696\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5100 - accuracy: 0.8657 - val_loss: 0.5034 - val_accuracy: 0.8714\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5055 - accuracy: 0.8680 - val_loss: 0.5017 - val_accuracy: 0.8718\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5031 - accuracy: 0.8687 - val_loss: 0.5007 - val_accuracy: 0.8716\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5036 - accuracy: 0.8668 - val_loss: 0.5003 - val_accuracy: 0.8717\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5026 - accuracy: 0.8670 - val_loss: 0.5001 - val_accuracy: 0.8717\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:40.266434\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.0471 - accuracy: 0.6302 - val_loss: 1.1289 - val_accuracy: 0.7793\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1010 - accuracy: 0.7707 - val_loss: 0.9198 - val_accuracy: 0.8134\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9775 - accuracy: 0.7905 - val_loss: 0.8447 - val_accuracy: 0.8271\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9224 - accuracy: 0.8028 - val_loss: 0.8186 - val_accuracy: 0.8293\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8953 - accuracy: 0.8079 - val_loss: 0.7984 - val_accuracy: 0.8330\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8479 - accuracy: 0.8187 - val_loss: 0.7768 - val_accuracy: 0.8353\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8143 - accuracy: 0.8215 - val_loss: 0.7393 - val_accuracy: 0.8414\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7868 - accuracy: 0.8252 - val_loss: 0.7179 - val_accuracy: 0.8459\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7626 - accuracy: 0.8301 - val_loss: 0.6937 - val_accuracy: 0.8481\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7377 - accuracy: 0.8331 - val_loss: 0.6785 - val_accuracy: 0.8511\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7145 - accuracy: 0.8373 - val_loss: 0.6635 - val_accuracy: 0.8507\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6988 - accuracy: 0.8399 - val_loss: 0.6400 - val_accuracy: 0.8552\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6802 - accuracy: 0.8406 - val_loss: 0.6233 - val_accuracy: 0.8578\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6613 - accuracy: 0.8435 - val_loss: 0.6186 - val_accuracy: 0.8574\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6475 - accuracy: 0.8447 - val_loss: 0.5993 - val_accuracy: 0.8588\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6329 - accuracy: 0.8487 - val_loss: 0.5911 - val_accuracy: 0.8594\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6216 - accuracy: 0.8485 - val_loss: 0.5842 - val_accuracy: 0.8592\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6077 - accuracy: 0.8514 - val_loss: 0.5692 - val_accuracy: 0.8619\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5960 - accuracy: 0.8529 - val_loss: 0.5611 - val_accuracy: 0.8617\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5855 - accuracy: 0.8534 - val_loss: 0.5509 - val_accuracy: 0.8652\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:11.270815\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5511 - accuracy: 0.8606 - val_loss: 0.5212 - val_accuracy: 0.8689\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5261 - accuracy: 0.8648 - val_loss: 0.5048 - val_accuracy: 0.8703\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5130 - accuracy: 0.8670 - val_loss: 0.4969 - val_accuracy: 0.8715\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5071 - accuracy: 0.8678 - val_loss: 0.4932 - val_accuracy: 0.8712\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5033 - accuracy: 0.8688 - val_loss: 0.4913 - val_accuracy: 0.8717\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4997 - accuracy: 0.8692 - val_loss: 0.4903 - val_accuracy: 0.8724\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5013 - accuracy: 0.8689 - val_loss: 0.4900 - val_accuracy: 0.8720\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4989 - accuracy: 0.8698 - val_loss: 0.4899 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5007 - accuracy: 0.8683 - val_loss: 0.4899 - val_accuracy: 0.8722\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:08.035963\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0906 - accuracy: 0.6766 - val_loss: 1.1759 - val_accuracy: 0.7874\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1116 - accuracy: 0.7902 - val_loss: 1.0207 - val_accuracy: 0.8086\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0212 - accuracy: 0.8063 - val_loss: 0.9483 - val_accuracy: 0.8277\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9796 - accuracy: 0.8164 - val_loss: 0.9699 - val_accuracy: 0.8308\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9489 - accuracy: 0.8233 - val_loss: 0.9151 - val_accuracy: 0.8384\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8843 - accuracy: 0.8303 - val_loss: 0.8526 - val_accuracy: 0.8435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8669 - accuracy: 0.8340 - val_loss: 0.8266 - val_accuracy: 0.8416\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8219 - accuracy: 0.8381 - val_loss: 0.8034 - val_accuracy: 0.8449\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7913 - accuracy: 0.8413 - val_loss: 0.7876 - val_accuracy: 0.8505\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7641 - accuracy: 0.8449 - val_loss: 0.7550 - val_accuracy: 0.8471\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7337 - accuracy: 0.8464 - val_loss: 0.7261 - val_accuracy: 0.8553\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7152 - accuracy: 0.8487 - val_loss: 0.7009 - val_accuracy: 0.8568\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6890 - accuracy: 0.8509 - val_loss: 0.6720 - val_accuracy: 0.8569\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6698 - accuracy: 0.8514 - val_loss: 0.6531 - val_accuracy: 0.8608\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6564 - accuracy: 0.8545 - val_loss: 0.6416 - val_accuracy: 0.8621\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6398 - accuracy: 0.8558 - val_loss: 0.6267 - val_accuracy: 0.8617\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6233 - accuracy: 0.8574 - val_loss: 0.6169 - val_accuracy: 0.8617\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6091 - accuracy: 0.8593 - val_loss: 0.6017 - val_accuracy: 0.8657\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5946 - accuracy: 0.8607 - val_loss: 0.5887 - val_accuracy: 0.8640\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5824 - accuracy: 0.8621 - val_loss: 0.5799 - val_accuracy: 0.8658\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:19.292050\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5352 - accuracy: 0.8675 - val_loss: 0.5334 - val_accuracy: 0.8703\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5056 - accuracy: 0.8711 - val_loss: 0.5095 - val_accuracy: 0.8730\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4905 - accuracy: 0.8718 - val_loss: 0.4971 - val_accuracy: 0.8714\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4807 - accuracy: 0.8735 - val_loss: 0.4902 - val_accuracy: 0.8741\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4748 - accuracy: 0.8751 - val_loss: 0.4874 - val_accuracy: 0.8735\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4732 - accuracy: 0.8754 - val_loss: 0.4860 - val_accuracy: 0.8737\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4729 - accuracy: 0.8740 - val_loss: 0.4854 - val_accuracy: 0.8739\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:16.045515\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0637 - accuracy: 0.6752 - val_loss: 1.1645 - val_accuracy: 0.7952\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1317 - accuracy: 0.7898 - val_loss: 1.0169 - val_accuracy: 0.8215\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0263 - accuracy: 0.8089 - val_loss: 0.9551 - val_accuracy: 0.8265\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9737 - accuracy: 0.8181 - val_loss: 0.9037 - val_accuracy: 0.8330\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9460 - accuracy: 0.8237 - val_loss: 0.8967 - val_accuracy: 0.8400\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8948 - accuracy: 0.8292 - val_loss: 0.8426 - val_accuracy: 0.8457\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8470 - accuracy: 0.8335 - val_loss: 0.8128 - val_accuracy: 0.8436\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8161 - accuracy: 0.8374 - val_loss: 0.7921 - val_accuracy: 0.8505\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7873 - accuracy: 0.8410 - val_loss: 0.7610 - val_accuracy: 0.8514\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7637 - accuracy: 0.8416 - val_loss: 0.7269 - val_accuracy: 0.8521\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7331 - accuracy: 0.8472 - val_loss: 0.7152 - val_accuracy: 0.8518\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7211 - accuracy: 0.8484 - val_loss: 0.6950 - val_accuracy: 0.8550\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6919 - accuracy: 0.8492 - val_loss: 0.6650 - val_accuracy: 0.8567\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6734 - accuracy: 0.8534 - val_loss: 0.6456 - val_accuracy: 0.8624\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6582 - accuracy: 0.8528 - val_loss: 0.6456 - val_accuracy: 0.8602\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6412 - accuracy: 0.8565 - val_loss: 0.6170 - val_accuracy: 0.8625\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6218 - accuracy: 0.8578 - val_loss: 0.6038 - val_accuracy: 0.8640\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6115 - accuracy: 0.8582 - val_loss: 0.5888 - val_accuracy: 0.8657\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5971 - accuracy: 0.8596 - val_loss: 0.5788 - val_accuracy: 0.8666\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5849 - accuracy: 0.8612 - val_loss: 0.5734 - val_accuracy: 0.8644\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:20.009220\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5382 - accuracy: 0.8667 - val_loss: 0.5265 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5099 - accuracy: 0.8705 - val_loss: 0.5012 - val_accuracy: 0.8705\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4928 - accuracy: 0.8714 - val_loss: 0.4882 - val_accuracy: 0.8713\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4840 - accuracy: 0.8735 - val_loss: 0.4818 - val_accuracy: 0.8711\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4789 - accuracy: 0.8745 - val_loss: 0.4788 - val_accuracy: 0.8723\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4776 - accuracy: 0.8732 - val_loss: 0.4776 - val_accuracy: 0.8722\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4770 - accuracy: 0.8739 - val_loss: 0.4770 - val_accuracy: 0.8720\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4757 - accuracy: 0.8744 - val_loss: 0.4768 - val_accuracy: 0.8721\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:44.358304\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.1089 - accuracy: 0.6731 - val_loss: 1.1643 - val_accuracy: 0.7968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1412 - accuracy: 0.7869 - val_loss: 0.9968 - val_accuracy: 0.8206\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0356 - accuracy: 0.8055 - val_loss: 0.9498 - val_accuracy: 0.8349\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9867 - accuracy: 0.8154 - val_loss: 0.9183 - val_accuracy: 0.8343\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9587 - accuracy: 0.8200 - val_loss: 0.9014 - val_accuracy: 0.8467\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9093 - accuracy: 0.8270 - val_loss: 0.8584 - val_accuracy: 0.8462\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8739 - accuracy: 0.8315 - val_loss: 0.8228 - val_accuracy: 0.8497\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8269 - accuracy: 0.8353 - val_loss: 0.7829 - val_accuracy: 0.8566\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8097 - accuracy: 0.8395 - val_loss: 0.7611 - val_accuracy: 0.8555\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7750 - accuracy: 0.8404 - val_loss: 0.7531 - val_accuracy: 0.8523\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7476 - accuracy: 0.8441 - val_loss: 0.7067 - val_accuracy: 0.8597\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7234 - accuracy: 0.8474 - val_loss: 0.6879 - val_accuracy: 0.8586\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7046 - accuracy: 0.8497 - val_loss: 0.6619 - val_accuracy: 0.8649\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6820 - accuracy: 0.8516 - val_loss: 0.6457 - val_accuracy: 0.8633\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6663 - accuracy: 0.8521 - val_loss: 0.6328 - val_accuracy: 0.8655\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6502 - accuracy: 0.8538 - val_loss: 0.6205 - val_accuracy: 0.8681\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6313 - accuracy: 0.8564 - val_loss: 0.5932 - val_accuracy: 0.8690\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6166 - accuracy: 0.8574 - val_loss: 0.5975 - val_accuracy: 0.8658\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6047 - accuracy: 0.8576 - val_loss: 0.5765 - val_accuracy: 0.8684\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5912 - accuracy: 0.8603 - val_loss: 0.5672 - val_accuracy: 0.8693\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:20.784219\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5427 - accuracy: 0.8661 - val_loss: 0.5234 - val_accuracy: 0.8740\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5133 - accuracy: 0.8676 - val_loss: 0.4958 - val_accuracy: 0.8753\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4966 - accuracy: 0.8714 - val_loss: 0.4817 - val_accuracy: 0.8773\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4870 - accuracy: 0.8709 - val_loss: 0.4757 - val_accuracy: 0.8767\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4813 - accuracy: 0.8727 - val_loss: 0.4728 - val_accuracy: 0.8773\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4794 - accuracy: 0.8730 - val_loss: 0.4714 - val_accuracy: 0.8774\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4776 - accuracy: 0.8725 - val_loss: 0.4707 - val_accuracy: 0.8773\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4782 - accuracy: 0.8727 - val_loss: 0.4704 - val_accuracy: 0.8772\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4788 - accuracy: 0.8728 - val_loss: 0.4704 - val_accuracy: 0.8772\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:12.192948\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0131 - accuracy: 0.6749 - val_loss: 1.1407 - val_accuracy: 0.7932\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1022 - accuracy: 0.7897 - val_loss: 0.9955 - val_accuracy: 0.8155\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0032 - accuracy: 0.8071 - val_loss: 0.9504 - val_accuracy: 0.8241\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9591 - accuracy: 0.8169 - val_loss: 0.9024 - val_accuracy: 0.8315\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9365 - accuracy: 0.8220 - val_loss: 0.8860 - val_accuracy: 0.8320\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8852 - accuracy: 0.8284 - val_loss: 0.8389 - val_accuracy: 0.8420\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8438 - accuracy: 0.8331 - val_loss: 0.8179 - val_accuracy: 0.8385\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8133 - accuracy: 0.8360 - val_loss: 0.7674 - val_accuracy: 0.8485\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7807 - accuracy: 0.8393 - val_loss: 0.7420 - val_accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7635 - accuracy: 0.8421 - val_loss: 0.7537 - val_accuracy: 0.8475\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7328 - accuracy: 0.8453 - val_loss: 0.6993 - val_accuracy: 0.8557\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7079 - accuracy: 0.8469 - val_loss: 0.6933 - val_accuracy: 0.8539\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6803 - accuracy: 0.8491 - val_loss: 0.6630 - val_accuracy: 0.8570\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6673 - accuracy: 0.8511 - val_loss: 0.6486 - val_accuracy: 0.8560\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6482 - accuracy: 0.8532 - val_loss: 0.6211 - val_accuracy: 0.8612\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6374 - accuracy: 0.8539 - val_loss: 0.6258 - val_accuracy: 0.8595\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6208 - accuracy: 0.8555 - val_loss: 0.5982 - val_accuracy: 0.8601\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6055 - accuracy: 0.8577 - val_loss: 0.5928 - val_accuracy: 0.8624\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5961 - accuracy: 0.8596 - val_loss: 0.5983 - val_accuracy: 0.8618\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5864 - accuracy: 0.8598 - val_loss: 0.5738 - val_accuracy: 0.8623\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:19.525720\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5374 - accuracy: 0.8670 - val_loss: 0.5311 - val_accuracy: 0.8674\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5102 - accuracy: 0.8692 - val_loss: 0.5111 - val_accuracy: 0.8673\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4954 - accuracy: 0.8708 - val_loss: 0.4984 - val_accuracy: 0.8698\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4870 - accuracy: 0.8720 - val_loss: 0.4920 - val_accuracy: 0.8706\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4822 - accuracy: 0.8726 - val_loss: 0.4893 - val_accuracy: 0.8701\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4808 - accuracy: 0.8729 - val_loss: 0.4883 - val_accuracy: 0.8700\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4783 - accuracy: 0.8741 - val_loss: 0.4880 - val_accuracy: 0.8699\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:15.494104\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0900 - accuracy: 0.6738 - val_loss: 1.1858 - val_accuracy: 0.7825\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1131 - accuracy: 0.7896 - val_loss: 0.9716 - val_accuracy: 0.8224\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0075 - accuracy: 0.8083 - val_loss: 0.9369 - val_accuracy: 0.8230\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9588 - accuracy: 0.8181 - val_loss: 0.8948 - val_accuracy: 0.8346\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9381 - accuracy: 0.8234 - val_loss: 0.8681 - val_accuracy: 0.8321\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8856 - accuracy: 0.8297 - val_loss: 0.8234 - val_accuracy: 0.8414\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8463 - accuracy: 0.8331 - val_loss: 0.8244 - val_accuracy: 0.8457\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8163 - accuracy: 0.8366 - val_loss: 0.7703 - val_accuracy: 0.8486\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7911 - accuracy: 0.8399 - val_loss: 0.7315 - val_accuracy: 0.8535\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7658 - accuracy: 0.8426 - val_loss: 0.7123 - val_accuracy: 0.8562\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7322 - accuracy: 0.8447 - val_loss: 0.7122 - val_accuracy: 0.8522\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7138 - accuracy: 0.8475 - val_loss: 0.6928 - val_accuracy: 0.8552\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6953 - accuracy: 0.8487 - val_loss: 0.6633 - val_accuracy: 0.8588\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6766 - accuracy: 0.8505 - val_loss: 0.6425 - val_accuracy: 0.8598\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6556 - accuracy: 0.8520 - val_loss: 0.6287 - val_accuracy: 0.8605\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6418 - accuracy: 0.8544 - val_loss: 0.6193 - val_accuracy: 0.8590\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6249 - accuracy: 0.8555 - val_loss: 0.5991 - val_accuracy: 0.8645\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6139 - accuracy: 0.8563 - val_loss: 0.5846 - val_accuracy: 0.8640\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5991 - accuracy: 0.8594 - val_loss: 0.5808 - val_accuracy: 0.8670\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5917 - accuracy: 0.8598 - val_loss: 0.5629 - val_accuracy: 0.8689\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:16.128160\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5426 - accuracy: 0.8666 - val_loss: 0.5236 - val_accuracy: 0.8710\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5146 - accuracy: 0.8690 - val_loss: 0.5018 - val_accuracy: 0.8724\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4984 - accuracy: 0.8712 - val_loss: 0.4899 - val_accuracy: 0.8720\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4908 - accuracy: 0.8720 - val_loss: 0.4841 - val_accuracy: 0.8726\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4851 - accuracy: 0.8721 - val_loss: 0.4812 - val_accuracy: 0.8730\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4835 - accuracy: 0.8725 - val_loss: 0.4800 - val_accuracy: 0.8728\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4830 - accuracy: 0.8720 - val_loss: 0.4793 - val_accuracy: 0.8729\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4835 - accuracy: 0.8714 - val_loss: 0.4790 - val_accuracy: 0.8730\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:44.962715\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 2.1354 - accuracy: 0.6482 - val_loss: 1.1696 - val_accuracy: 0.7849\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1240 - accuracy: 0.7796 - val_loss: 0.9963 - val_accuracy: 0.8100\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0105 - accuracy: 0.7992 - val_loss: 0.9261 - val_accuracy: 0.8192\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9510 - accuracy: 0.8085 - val_loss: 0.8996 - val_accuracy: 0.8228\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9167 - accuracy: 0.8146 - val_loss: 0.8557 - val_accuracy: 0.8279\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8632 - accuracy: 0.8206 - val_loss: 0.8055 - val_accuracy: 0.8406\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8281 - accuracy: 0.8257 - val_loss: 0.7858 - val_accuracy: 0.8438\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8013 - accuracy: 0.8281 - val_loss: 0.7561 - val_accuracy: 0.8395\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.7744 - accuracy: 0.8315 - val_loss: 0.7488 - val_accuracy: 0.8381\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.7520 - accuracy: 0.8348 - val_loss: 0.6988 - val_accuracy: 0.8477\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7250 - accuracy: 0.8393 - val_loss: 0.6877 - val_accuracy: 0.8473\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.7099 - accuracy: 0.8405 - val_loss: 0.6702 - val_accuracy: 0.8529\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.6906 - accuracy: 0.8430 - val_loss: 0.6618 - val_accuracy: 0.8515\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6739 - accuracy: 0.8445 - val_loss: 0.6408 - val_accuracy: 0.8516\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.6576 - accuracy: 0.8462 - val_loss: 0.6234 - val_accuracy: 0.8529\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:22.674459\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.6214 - accuracy: 0.8515 - val_loss: 0.5828 - val_accuracy: 0.8578\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 32s 46ms/step - loss: 0.5780 - accuracy: 0.8562 - val_loss: 0.5531 - val_accuracy: 0.8603\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.5559 - accuracy: 0.8585 - val_loss: 0.5340 - val_accuracy: 0.8631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5439 - accuracy: 0.8599 - val_loss: 0.5268 - val_accuracy: 0.8631\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5393 - accuracy: 0.8596 - val_loss: 0.5229 - val_accuracy: 0.8616\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5363 - accuracy: 0.8608 - val_loss: 0.5211 - val_accuracy: 0.8626\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:59.725339\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.0523 - accuracy: 0.6522 - val_loss: 1.1442 - val_accuracy: 0.7884\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1051 - accuracy: 0.7846 - val_loss: 0.9890 - val_accuracy: 0.8067\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0005 - accuracy: 0.8039 - val_loss: 0.9392 - val_accuracy: 0.8207\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9499 - accuracy: 0.8109 - val_loss: 0.9022 - val_accuracy: 0.8221\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9185 - accuracy: 0.8172 - val_loss: 0.8705 - val_accuracy: 0.8289\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8713 - accuracy: 0.8253 - val_loss: 0.8295 - val_accuracy: 0.8363\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8355 - accuracy: 0.8291 - val_loss: 0.7874 - val_accuracy: 0.8398\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8051 - accuracy: 0.8334 - val_loss: 0.7670 - val_accuracy: 0.8431\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7806 - accuracy: 0.8372 - val_loss: 0.7378 - val_accuracy: 0.8469\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7553 - accuracy: 0.8402 - val_loss: 0.7325 - val_accuracy: 0.8487\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7310 - accuracy: 0.8410 - val_loss: 0.6995 - val_accuracy: 0.8504\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7111 - accuracy: 0.8435 - val_loss: 0.6838 - val_accuracy: 0.8488\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6945 - accuracy: 0.8463 - val_loss: 0.6668 - val_accuracy: 0.8546\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6733 - accuracy: 0.8479 - val_loss: 0.6511 - val_accuracy: 0.8562\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6595 - accuracy: 0.8493 - val_loss: 0.6442 - val_accuracy: 0.8558\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6408 - accuracy: 0.8529 - val_loss: 0.6176 - val_accuracy: 0.8590\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6277 - accuracy: 0.8533 - val_loss: 0.6069 - val_accuracy: 0.8591\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6142 - accuracy: 0.8556 - val_loss: 0.6014 - val_accuracy: 0.8578\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6023 - accuracy: 0.8583 - val_loss: 0.5865 - val_accuracy: 0.8606\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5909 - accuracy: 0.8589 - val_loss: 0.5782 - val_accuracy: 0.8619\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:38.226464\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5485 - accuracy: 0.8642 - val_loss: 0.5354 - val_accuracy: 0.8650\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5215 - accuracy: 0.8672 - val_loss: 0.5147 - val_accuracy: 0.8664\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5046 - accuracy: 0.8698 - val_loss: 0.5036 - val_accuracy: 0.8667\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4949 - accuracy: 0.8709 - val_loss: 0.4983 - val_accuracy: 0.8663\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4913 - accuracy: 0.8708 - val_loss: 0.4963 - val_accuracy: 0.8670\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4890 - accuracy: 0.8703 - val_loss: 0.4949 - val_accuracy: 0.8672\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4889 - accuracy: 0.8716 - val_loss: 0.4943 - val_accuracy: 0.8675\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4880 - accuracy: 0.8711 - val_loss: 0.4942 - val_accuracy: 0.8674\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4883 - accuracy: 0.8706 - val_loss: 0.4941 - val_accuracy: 0.8672\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4890 - accuracy: 0.8703 - val_loss: 0.4941 - val_accuracy: 0.8672\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:48.981976\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.1149 - accuracy: 0.6453 - val_loss: 1.2010 - val_accuracy: 0.7777\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1490 - accuracy: 0.7805 - val_loss: 0.9690 - val_accuracy: 0.8131\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0227 - accuracy: 0.8016 - val_loss: 0.9223 - val_accuracy: 0.8227\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9661 - accuracy: 0.8114 - val_loss: 0.8865 - val_accuracy: 0.8351\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9386 - accuracy: 0.8180 - val_loss: 0.8909 - val_accuracy: 0.8301\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8869 - accuracy: 0.8242 - val_loss: 0.8351 - val_accuracy: 0.8371\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8503 - accuracy: 0.8288 - val_loss: 0.7968 - val_accuracy: 0.8447\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8191 - accuracy: 0.8323 - val_loss: 0.7760 - val_accuracy: 0.8426\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7841 - accuracy: 0.8374 - val_loss: 0.7413 - val_accuracy: 0.8490\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7643 - accuracy: 0.8392 - val_loss: 0.7150 - val_accuracy: 0.8513\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7377 - accuracy: 0.8428 - val_loss: 0.6916 - val_accuracy: 0.8544\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7168 - accuracy: 0.8443 - val_loss: 0.6784 - val_accuracy: 0.8558\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6966 - accuracy: 0.8462 - val_loss: 0.6557 - val_accuracy: 0.8573\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6802 - accuracy: 0.8480 - val_loss: 0.6409 - val_accuracy: 0.8580\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6584 - accuracy: 0.8520 - val_loss: 0.6217 - val_accuracy: 0.8588\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6444 - accuracy: 0.8521 - val_loss: 0.6110 - val_accuracy: 0.8620\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6315 - accuracy: 0.8545 - val_loss: 0.5991 - val_accuracy: 0.8610\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6130 - accuracy: 0.8557 - val_loss: 0.5836 - val_accuracy: 0.8633\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6049 - accuracy: 0.8568 - val_loss: 0.5754 - val_accuracy: 0.8656\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5920 - accuracy: 0.8580 - val_loss: 0.5681 - val_accuracy: 0.8636\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:36.252525\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5493 - accuracy: 0.8633 - val_loss: 0.5237 - val_accuracy: 0.8698\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5179 - accuracy: 0.8681 - val_loss: 0.4992 - val_accuracy: 0.8715\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5030 - accuracy: 0.8697 - val_loss: 0.4889 - val_accuracy: 0.8727\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4937 - accuracy: 0.8700 - val_loss: 0.4831 - val_accuracy: 0.8729\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4913 - accuracy: 0.8707 - val_loss: 0.4805 - val_accuracy: 0.8733\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4898 - accuracy: 0.8700 - val_loss: 0.4792 - val_accuracy: 0.8735\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4881 - accuracy: 0.8708 - val_loss: 0.4787 - val_accuracy: 0.8736\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4879 - accuracy: 0.8712 - val_loss: 0.4784 - val_accuracy: 0.8737\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4870 - accuracy: 0.8706 - val_loss: 0.4783 - val_accuracy: 0.8736\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4869 - accuracy: 0.8710 - val_loss: 0.4783 - val_accuracy: 0.8736\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4856 - accuracy: 0.8709 - val_loss: 0.4783 - val_accuracy: 0.8736\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:10.842639\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 2.0860 - accuracy: 0.6508 - val_loss: 1.1703 - val_accuracy: 0.7827\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1396 - accuracy: 0.7793 - val_loss: 1.0181 - val_accuracy: 0.8062\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0257 - accuracy: 0.8001 - val_loss: 0.9346 - val_accuracy: 0.8227\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9554 - accuracy: 0.8119 - val_loss: 0.8832 - val_accuracy: 0.8323\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9251 - accuracy: 0.8168 - val_loss: 0.8661 - val_accuracy: 0.8304\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8746 - accuracy: 0.8226 - val_loss: 0.8448 - val_accuracy: 0.8350\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8378 - accuracy: 0.8278 - val_loss: 0.8235 - val_accuracy: 0.8357\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8113 - accuracy: 0.8309 - val_loss: 0.7828 - val_accuracy: 0.8423\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7804 - accuracy: 0.8348 - val_loss: 0.7584 - val_accuracy: 0.8459\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7539 - accuracy: 0.8385 - val_loss: 0.7375 - val_accuracy: 0.8440\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7369 - accuracy: 0.8397 - val_loss: 0.7156 - val_accuracy: 0.8457\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7107 - accuracy: 0.8426 - val_loss: 0.6899 - val_accuracy: 0.8575\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6937 - accuracy: 0.8449 - val_loss: 0.6738 - val_accuracy: 0.8514\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6746 - accuracy: 0.8474 - val_loss: 0.6709 - val_accuracy: 0.8538\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6605 - accuracy: 0.8469 - val_loss: 0.6469 - val_accuracy: 0.8566\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:06.523297\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6143 - accuracy: 0.8546 - val_loss: 0.5942 - val_accuracy: 0.8617\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5707 - accuracy: 0.8585 - val_loss: 0.5631 - val_accuracy: 0.8645\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5485 - accuracy: 0.8621 - val_loss: 0.5458 - val_accuracy: 0.8658\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5385 - accuracy: 0.8611 - val_loss: 0.5374 - val_accuracy: 0.8674\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5314 - accuracy: 0.8628 - val_loss: 0.5325 - val_accuracy: 0.8682\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5270 - accuracy: 0.8635 - val_loss: 0.5309 - val_accuracy: 0.8664\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5245 - accuracy: 0.8644 - val_loss: 0.5301 - val_accuracy: 0.8670\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5266 - accuracy: 0.8628 - val_loss: 0.5299 - val_accuracy: 0.8670\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:47.519581\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.1116 - accuracy: 0.6512 - val_loss: 1.1554 - val_accuracy: 0.7779\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1188 - accuracy: 0.7765 - val_loss: 0.9762 - val_accuracy: 0.8162\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0157 - accuracy: 0.7972 - val_loss: 0.9460 - val_accuracy: 0.8206\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9716 - accuracy: 0.8054 - val_loss: 0.9042 - val_accuracy: 0.8295\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9477 - accuracy: 0.8124 - val_loss: 0.8661 - val_accuracy: 0.8382\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8948 - accuracy: 0.8202 - val_loss: 0.8226 - val_accuracy: 0.8391\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8596 - accuracy: 0.8235 - val_loss: 0.7988 - val_accuracy: 0.8441\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8323 - accuracy: 0.8281 - val_loss: 0.7720 - val_accuracy: 0.8471\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8007 - accuracy: 0.8325 - val_loss: 0.7410 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7781 - accuracy: 0.8358 - val_loss: 0.7430 - val_accuracy: 0.8504\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7539 - accuracy: 0.8394 - val_loss: 0.7169 - val_accuracy: 0.8504\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7284 - accuracy: 0.8406 - val_loss: 0.6812 - val_accuracy: 0.8562\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7127 - accuracy: 0.8429 - val_loss: 0.6702 - val_accuracy: 0.8594\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6911 - accuracy: 0.8463 - val_loss: 0.6499 - val_accuracy: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6731 - accuracy: 0.8470 - val_loss: 0.6459 - val_accuracy: 0.8607\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6560 - accuracy: 0.8506 - val_loss: 0.6234 - val_accuracy: 0.8615\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6450 - accuracy: 0.8512 - val_loss: 0.6146 - val_accuracy: 0.8618\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6275 - accuracy: 0.8534 - val_loss: 0.6031 - val_accuracy: 0.8618\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6147 - accuracy: 0.8536 - val_loss: 0.5886 - val_accuracy: 0.8649\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5999 - accuracy: 0.8558 - val_loss: 0.5794 - val_accuracy: 0.8659\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:28.378273\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5576 - accuracy: 0.8627 - val_loss: 0.5346 - val_accuracy: 0.8714\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5282 - accuracy: 0.8655 - val_loss: 0.5127 - val_accuracy: 0.8733\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5119 - accuracy: 0.8687 - val_loss: 0.5008 - val_accuracy: 0.8738\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5043 - accuracy: 0.8686 - val_loss: 0.4950 - val_accuracy: 0.8749\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4978 - accuracy: 0.8695 - val_loss: 0.4926 - val_accuracy: 0.8745\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4959 - accuracy: 0.8691 - val_loss: 0.4911 - val_accuracy: 0.8747\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4955 - accuracy: 0.8692 - val_loss: 0.4906 - val_accuracy: 0.8750\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4928 - accuracy: 0.8699 - val_loss: 0.4904 - val_accuracy: 0.8749\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4928 - accuracy: 0.8708 - val_loss: 0.4903 - val_accuracy: 0.8749\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4939 - accuracy: 0.8690 - val_loss: 0.4903 - val_accuracy: 0.8749\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:45.053935\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2093 - accuracy: 0.6826 - val_loss: 0.6666 - val_accuracy: 0.8180\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6856 - accuracy: 0.8123 - val_loss: 0.5603 - val_accuracy: 0.8423\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5966 - accuracy: 0.8342 - val_loss: 0.5195 - val_accuracy: 0.8535\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5507 - accuracy: 0.8451 - val_loss: 0.4992 - val_accuracy: 0.8580\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5268 - accuracy: 0.8531 - val_loss: 0.4880 - val_accuracy: 0.8628\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5008 - accuracy: 0.8585 - val_loss: 0.4698 - val_accuracy: 0.8664\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4760 - accuracy: 0.8649 - val_loss: 0.4577 - val_accuracy: 0.8682\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4584 - accuracy: 0.8698 - val_loss: 0.4399 - val_accuracy: 0.8719\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4388 - accuracy: 0.8733 - val_loss: 0.4292 - val_accuracy: 0.8764\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4223 - accuracy: 0.8776 - val_loss: 0.4231 - val_accuracy: 0.8769\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4075 - accuracy: 0.8809 - val_loss: 0.4158 - val_accuracy: 0.8795\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3921 - accuracy: 0.8852 - val_loss: 0.4150 - val_accuracy: 0.8779\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3804 - accuracy: 0.8880 - val_loss: 0.4058 - val_accuracy: 0.8828\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3659 - accuracy: 0.8913 - val_loss: 0.4007 - val_accuracy: 0.8832\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.3544 - accuracy: 0.8946 - val_loss: 0.3988 - val_accuracy: 0.8834\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3432 - accuracy: 0.8976 - val_loss: 0.4038 - val_accuracy: 0.8829\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3344 - accuracy: 0.9001 - val_loss: 0.3942 - val_accuracy: 0.8832\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3243 - accuracy: 0.9024 - val_loss: 0.3940 - val_accuracy: 0.8852\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3130 - accuracy: 0.9053 - val_loss: 0.3897 - val_accuracy: 0.8855\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3072 - accuracy: 0.9070 - val_loss: 0.3872 - val_accuracy: 0.8848\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:55.431068\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2837 - accuracy: 0.9152 - val_loss: 0.3850 - val_accuracy: 0.8865\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2709 - accuracy: 0.9197 - val_loss: 0.3819 - val_accuracy: 0.8880\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2643 - accuracy: 0.9216 - val_loss: 0.3810 - val_accuracy: 0.8888\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2599 - accuracy: 0.9232 - val_loss: 0.3796 - val_accuracy: 0.8893\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2575 - accuracy: 0.9244 - val_loss: 0.3798 - val_accuracy: 0.8895\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2565 - accuracy: 0.9247 - val_loss: 0.3799 - val_accuracy: 0.8896\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2567 - accuracy: 0.9241 - val_loss: 0.3799 - val_accuracy: 0.8894\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2565 - accuracy: 0.9248 - val_loss: 0.3799 - val_accuracy: 0.8895\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2549 - accuracy: 0.9246 - val_loss: 0.3799 - val_accuracy: 0.8894\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:02.592523\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2118 - accuracy: 0.6840 - val_loss: 0.6681 - val_accuracy: 0.8249\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6896 - accuracy: 0.8115 - val_loss: 0.5693 - val_accuracy: 0.8414\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5955 - accuracy: 0.8346 - val_loss: 0.5272 - val_accuracy: 0.8541\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5529 - accuracy: 0.8450 - val_loss: 0.5174 - val_accuracy: 0.8531\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5285 - accuracy: 0.8507 - val_loss: 0.4857 - val_accuracy: 0.8632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4992 - accuracy: 0.8586 - val_loss: 0.4770 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4748 - accuracy: 0.8652 - val_loss: 0.4538 - val_accuracy: 0.8739\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4566 - accuracy: 0.8694 - val_loss: 0.4482 - val_accuracy: 0.8746\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4376 - accuracy: 0.8733 - val_loss: 0.4469 - val_accuracy: 0.8723\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4224 - accuracy: 0.8776 - val_loss: 0.4383 - val_accuracy: 0.8742\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4073 - accuracy: 0.8818 - val_loss: 0.4253 - val_accuracy: 0.8777\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3926 - accuracy: 0.8854 - val_loss: 0.4215 - val_accuracy: 0.8793\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3776 - accuracy: 0.8896 - val_loss: 0.4170 - val_accuracy: 0.8808\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3640 - accuracy: 0.8916 - val_loss: 0.4126 - val_accuracy: 0.8792\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3542 - accuracy: 0.8938 - val_loss: 0.4115 - val_accuracy: 0.8797\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3423 - accuracy: 0.8973 - val_loss: 0.4100 - val_accuracy: 0.8803\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:02.478773\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3390 - accuracy: 0.8999 - val_loss: 0.4003 - val_accuracy: 0.8845\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3165 - accuracy: 0.9079 - val_loss: 0.3937 - val_accuracy: 0.8864\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3056 - accuracy: 0.9100 - val_loss: 0.3919 - val_accuracy: 0.8867\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3004 - accuracy: 0.9123 - val_loss: 0.3909 - val_accuracy: 0.8869\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2983 - accuracy: 0.9122 - val_loss: 0.3899 - val_accuracy: 0.8871\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2963 - accuracy: 0.9128 - val_loss: 0.3898 - val_accuracy: 0.8875\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2955 - accuracy: 0.9136 - val_loss: 0.3898 - val_accuracy: 0.8877\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2953 - accuracy: 0.9141 - val_loss: 0.3898 - val_accuracy: 0.8876\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2947 - accuracy: 0.9137 - val_loss: 0.3898 - val_accuracy: 0.8877\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2952 - accuracy: 0.9134 - val_loss: 0.3898 - val_accuracy: 0.8876\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:17.877703\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1952 - accuracy: 0.6865 - val_loss: 0.6782 - val_accuracy: 0.8189\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6823 - accuracy: 0.8138 - val_loss: 0.5739 - val_accuracy: 0.8439\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5949 - accuracy: 0.8344 - val_loss: 0.5322 - val_accuracy: 0.8516\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5571 - accuracy: 0.8435 - val_loss: 0.5170 - val_accuracy: 0.8547\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5273 - accuracy: 0.8499 - val_loss: 0.5020 - val_accuracy: 0.8600\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4985 - accuracy: 0.8589 - val_loss: 0.4801 - val_accuracy: 0.8633\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4735 - accuracy: 0.8666 - val_loss: 0.4713 - val_accuracy: 0.8637\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.4542 - accuracy: 0.8691 - val_loss: 0.4681 - val_accuracy: 0.8652\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.4353 - accuracy: 0.8748 - val_loss: 0.4549 - val_accuracy: 0.8686\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.4188 - accuracy: 0.8777 - val_loss: 0.4440 - val_accuracy: 0.8726\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.4017 - accuracy: 0.8826 - val_loss: 0.4371 - val_accuracy: 0.8743\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3909 - accuracy: 0.8850 - val_loss: 0.4319 - val_accuracy: 0.8720\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3762 - accuracy: 0.8883 - val_loss: 0.4250 - val_accuracy: 0.8756\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.3640 - accuracy: 0.8923 - val_loss: 0.4282 - val_accuracy: 0.8730\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3521 - accuracy: 0.8949 - val_loss: 0.4224 - val_accuracy: 0.8752\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.3416 - accuracy: 0.8975 - val_loss: 0.4182 - val_accuracy: 0.8762\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.3305 - accuracy: 0.9007 - val_loss: 0.4173 - val_accuracy: 0.8769\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.3193 - accuracy: 0.9042 - val_loss: 0.4090 - val_accuracy: 0.8781\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.3113 - accuracy: 0.9059 - val_loss: 0.4128 - val_accuracy: 0.8774\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.3031 - accuracy: 0.9079 - val_loss: 0.4128 - val_accuracy: 0.8758\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:34.738371\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2811 - accuracy: 0.9155 - val_loss: 0.4063 - val_accuracy: 0.8811\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2690 - accuracy: 0.9196 - val_loss: 0.4003 - val_accuracy: 0.8816\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2622 - accuracy: 0.9225 - val_loss: 0.4006 - val_accuracy: 0.8828\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2574 - accuracy: 0.9243 - val_loss: 0.3995 - val_accuracy: 0.8818\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 25s 36ms/step - loss: 0.2563 - accuracy: 0.9242 - val_loss: 0.3997 - val_accuracy: 0.8824\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.2560 - accuracy: 0.9247 - val_loss: 0.3997 - val_accuracy: 0.8822\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:33.447495\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2159 - accuracy: 0.6826 - val_loss: 0.6725 - val_accuracy: 0.8274\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6967 - accuracy: 0.8108 - val_loss: 0.5516 - val_accuracy: 0.8513\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6054 - accuracy: 0.8314 - val_loss: 0.5062 - val_accuracy: 0.8615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5612 - accuracy: 0.8424 - val_loss: 0.4852 - val_accuracy: 0.8623\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5334 - accuracy: 0.8490 - val_loss: 0.4721 - val_accuracy: 0.8703\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5070 - accuracy: 0.8558 - val_loss: 0.4591 - val_accuracy: 0.8731\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4834 - accuracy: 0.8628 - val_loss: 0.4509 - val_accuracy: 0.8731\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4610 - accuracy: 0.8671 - val_loss: 0.4431 - val_accuracy: 0.8746\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4430 - accuracy: 0.8713 - val_loss: 0.4269 - val_accuracy: 0.8768\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4289 - accuracy: 0.8756 - val_loss: 0.4215 - val_accuracy: 0.8808\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4098 - accuracy: 0.8794 - val_loss: 0.4080 - val_accuracy: 0.8816\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4020 - accuracy: 0.8818 - val_loss: 0.4088 - val_accuracy: 0.8811\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3874 - accuracy: 0.8845 - val_loss: 0.4052 - val_accuracy: 0.8819\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3725 - accuracy: 0.8890 - val_loss: 0.4048 - val_accuracy: 0.8814\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3631 - accuracy: 0.8913 - val_loss: 0.3954 - val_accuracy: 0.8859\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3499 - accuracy: 0.8952 - val_loss: 0.3911 - val_accuracy: 0.8850\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3398 - accuracy: 0.8971 - val_loss: 0.3927 - val_accuracy: 0.8849\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3314 - accuracy: 0.8994 - val_loss: 0.3872 - val_accuracy: 0.8851\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:11.441013\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3275 - accuracy: 0.9024 - val_loss: 0.3779 - val_accuracy: 0.8880\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3100 - accuracy: 0.9087 - val_loss: 0.3743 - val_accuracy: 0.8889\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3014 - accuracy: 0.9116 - val_loss: 0.3735 - val_accuracy: 0.8893\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2956 - accuracy: 0.9126 - val_loss: 0.3727 - val_accuracy: 0.8893\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2949 - accuracy: 0.9132 - val_loss: 0.3725 - val_accuracy: 0.8894\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2925 - accuracy: 0.9142 - val_loss: 0.3723 - val_accuracy: 0.8896\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2937 - accuracy: 0.9137 - val_loss: 0.3723 - val_accuracy: 0.8897\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2918 - accuracy: 0.9140 - val_loss: 0.3723 - val_accuracy: 0.8896\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2914 - accuracy: 0.9142 - val_loss: 0.3723 - val_accuracy: 0.8895\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2925 - accuracy: 0.9147 - val_loss: 0.3723 - val_accuracy: 0.8895\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:31.756288\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1860 - accuracy: 0.6943 - val_loss: 0.6715 - val_accuracy: 0.8225\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6786 - accuracy: 0.8175 - val_loss: 0.5766 - val_accuracy: 0.8413\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5913 - accuracy: 0.8359 - val_loss: 0.5249 - val_accuracy: 0.8548\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5483 - accuracy: 0.8472 - val_loss: 0.5052 - val_accuracy: 0.8610\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5267 - accuracy: 0.8515 - val_loss: 0.4893 - val_accuracy: 0.8625\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4952 - accuracy: 0.8597 - val_loss: 0.4776 - val_accuracy: 0.8676\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4743 - accuracy: 0.8648 - val_loss: 0.4647 - val_accuracy: 0.8712\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4508 - accuracy: 0.8713 - val_loss: 0.4516 - val_accuracy: 0.8719\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4352 - accuracy: 0.8752 - val_loss: 0.4409 - val_accuracy: 0.8762\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4170 - accuracy: 0.8798 - val_loss: 0.4466 - val_accuracy: 0.8730\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4023 - accuracy: 0.8830 - val_loss: 0.4321 - val_accuracy: 0.8763\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3888 - accuracy: 0.8853 - val_loss: 0.4243 - val_accuracy: 0.8793\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3741 - accuracy: 0.8897 - val_loss: 0.4244 - val_accuracy: 0.8762\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3619 - accuracy: 0.8922 - val_loss: 0.4165 - val_accuracy: 0.8804\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3493 - accuracy: 0.8955 - val_loss: 0.4151 - val_accuracy: 0.8808\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3393 - accuracy: 0.8986 - val_loss: 0.4120 - val_accuracy: 0.8808\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3280 - accuracy: 0.9003 - val_loss: 0.4099 - val_accuracy: 0.8807\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3191 - accuracy: 0.9042 - val_loss: 0.4028 - val_accuracy: 0.8829\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3093 - accuracy: 0.9066 - val_loss: 0.4026 - val_accuracy: 0.8831\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2978 - accuracy: 0.9101 - val_loss: 0.4021 - val_accuracy: 0.8823\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:03.164404\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2779 - accuracy: 0.9173 - val_loss: 0.3976 - val_accuracy: 0.8830\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2630 - accuracy: 0.9231 - val_loss: 0.3946 - val_accuracy: 0.8844\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2560 - accuracy: 0.9252 - val_loss: 0.3935 - val_accuracy: 0.8859\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2521 - accuracy: 0.9266 - val_loss: 0.3927 - val_accuracy: 0.8858\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2493 - accuracy: 0.9279 - val_loss: 0.3926 - val_accuracy: 0.8859\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2496 - accuracy: 0.9276 - val_loss: 0.3925 - val_accuracy: 0.8860\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2480 - accuracy: 0.9277 - val_loss: 0.3926 - val_accuracy: 0.8859\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2475 - accuracy: 0.9285 - val_loss: 0.3926 - val_accuracy: 0.8859\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2479 - accuracy: 0.9287 - val_loss: 0.3926 - val_accuracy: 0.8858\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:03.231279\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0981 - accuracy: 0.7266 - val_loss: 0.6479 - val_accuracy: 0.8343\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6389 - accuracy: 0.8290 - val_loss: 0.5478 - val_accuracy: 0.8507\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5676 - accuracy: 0.8420 - val_loss: 0.5111 - val_accuracy: 0.8571\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5335 - accuracy: 0.8494 - val_loss: 0.4935 - val_accuracy: 0.8617\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5134 - accuracy: 0.8551 - val_loss: 0.4838 - val_accuracy: 0.8660\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4900 - accuracy: 0.8609 - val_loss: 0.4801 - val_accuracy: 0.8666\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4673 - accuracy: 0.8663 - val_loss: 0.4621 - val_accuracy: 0.8698\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4462 - accuracy: 0.8716 - val_loss: 0.4507 - val_accuracy: 0.8719\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4293 - accuracy: 0.8752 - val_loss: 0.4451 - val_accuracy: 0.8732\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4143 - accuracy: 0.8789 - val_loss: 0.4302 - val_accuracy: 0.8758\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4006 - accuracy: 0.8818 - val_loss: 0.4264 - val_accuracy: 0.8783\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3863 - accuracy: 0.8846 - val_loss: 0.4209 - val_accuracy: 0.8776\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3741 - accuracy: 0.8891 - val_loss: 0.4186 - val_accuracy: 0.8780\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3616 - accuracy: 0.8919 - val_loss: 0.4129 - val_accuracy: 0.8802\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3499 - accuracy: 0.8943 - val_loss: 0.4083 - val_accuracy: 0.8786\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3386 - accuracy: 0.8983 - val_loss: 0.4027 - val_accuracy: 0.8811\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3295 - accuracy: 0.9000 - val_loss: 0.4044 - val_accuracy: 0.8802\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3202 - accuracy: 0.9022 - val_loss: 0.3958 - val_accuracy: 0.8833\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3101 - accuracy: 0.9057 - val_loss: 0.3957 - val_accuracy: 0.8823\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3008 - accuracy: 0.9078 - val_loss: 0.3943 - val_accuracy: 0.8832\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:10.669288\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2798 - accuracy: 0.9154 - val_loss: 0.3893 - val_accuracy: 0.8860\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2666 - accuracy: 0.9197 - val_loss: 0.3851 - val_accuracy: 0.8867\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2600 - accuracy: 0.9226 - val_loss: 0.3828 - val_accuracy: 0.8872\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2551 - accuracy: 0.9246 - val_loss: 0.3821 - val_accuracy: 0.8875\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2535 - accuracy: 0.9249 - val_loss: 0.3818 - val_accuracy: 0.8871\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2524 - accuracy: 0.9251 - val_loss: 0.3816 - val_accuracy: 0.8878\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2527 - accuracy: 0.9252 - val_loss: 0.3816 - val_accuracy: 0.8879\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2527 - accuracy: 0.9246 - val_loss: 0.3816 - val_accuracy: 0.8878\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2517 - accuracy: 0.9248 - val_loss: 0.3816 - val_accuracy: 0.8877\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2523 - accuracy: 0.9251 - val_loss: 0.3816 - val_accuracy: 0.8877\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:38.703063\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0932 - accuracy: 0.7320 - val_loss: 0.6521 - val_accuracy: 0.8331\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6386 - accuracy: 0.8282 - val_loss: 0.5393 - val_accuracy: 0.8554\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5653 - accuracy: 0.8425 - val_loss: 0.5133 - val_accuracy: 0.8609\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5363 - accuracy: 0.8489 - val_loss: 0.5049 - val_accuracy: 0.8593\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5161 - accuracy: 0.8537 - val_loss: 0.4900 - val_accuracy: 0.8647\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4902 - accuracy: 0.8610 - val_loss: 0.4731 - val_accuracy: 0.8665\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4655 - accuracy: 0.8655 - val_loss: 0.4583 - val_accuracy: 0.8686\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4459 - accuracy: 0.8714 - val_loss: 0.4438 - val_accuracy: 0.8748\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4321 - accuracy: 0.8742 - val_loss: 0.4447 - val_accuracy: 0.8729\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4144 - accuracy: 0.8771 - val_loss: 0.4291 - val_accuracy: 0.8761\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4017 - accuracy: 0.8818 - val_loss: 0.4217 - val_accuracy: 0.8786\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3860 - accuracy: 0.8843 - val_loss: 0.4166 - val_accuracy: 0.8798\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3750 - accuracy: 0.8876 - val_loss: 0.4091 - val_accuracy: 0.8822\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3617 - accuracy: 0.8915 - val_loss: 0.4065 - val_accuracy: 0.8809\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3508 - accuracy: 0.8935 - val_loss: 0.3995 - val_accuracy: 0.8812\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3394 - accuracy: 0.8972 - val_loss: 0.4013 - val_accuracy: 0.8832\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3296 - accuracy: 0.8996 - val_loss: 0.3983 - val_accuracy: 0.8820\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3200 - accuracy: 0.9026 - val_loss: 0.3927 - val_accuracy: 0.8850\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3123 - accuracy: 0.9037 - val_loss: 0.3907 - val_accuracy: 0.8852\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3043 - accuracy: 0.9067 - val_loss: 0.3912 - val_accuracy: 0.8824\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:18.487862\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2822 - accuracy: 0.9145 - val_loss: 0.3846 - val_accuracy: 0.8865\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2687 - accuracy: 0.9190 - val_loss: 0.3791 - val_accuracy: 0.8874\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2614 - accuracy: 0.9219 - val_loss: 0.3774 - val_accuracy: 0.8873\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2578 - accuracy: 0.9232 - val_loss: 0.3775 - val_accuracy: 0.8877\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2543 - accuracy: 0.9240 - val_loss: 0.3768 - val_accuracy: 0.8886\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2549 - accuracy: 0.9242 - val_loss: 0.3767 - val_accuracy: 0.8887\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2551 - accuracy: 0.9237 - val_loss: 0.3767 - val_accuracy: 0.8888\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2528 - accuracy: 0.9253 - val_loss: 0.3767 - val_accuracy: 0.8888\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2542 - accuracy: 0.9238 - val_loss: 0.3767 - val_accuracy: 0.8887\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2548 - accuracy: 0.9232 - val_loss: 0.3767 - val_accuracy: 0.8887\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:38.542968\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0892 - accuracy: 0.7311 - val_loss: 0.6503 - val_accuracy: 0.8335\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6388 - accuracy: 0.8279 - val_loss: 0.5564 - val_accuracy: 0.8494\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5646 - accuracy: 0.8426 - val_loss: 0.5275 - val_accuracy: 0.8534\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5305 - accuracy: 0.8519 - val_loss: 0.5106 - val_accuracy: 0.8572\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5111 - accuracy: 0.8561 - val_loss: 0.5008 - val_accuracy: 0.8594\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4849 - accuracy: 0.8623 - val_loss: 0.4824 - val_accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4661 - accuracy: 0.8664 - val_loss: 0.4719 - val_accuracy: 0.8655\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4444 - accuracy: 0.8713 - val_loss: 0.4602 - val_accuracy: 0.8695\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.4253 - accuracy: 0.8755 - val_loss: 0.4573 - val_accuracy: 0.8672\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4132 - accuracy: 0.8791 - val_loss: 0.4483 - val_accuracy: 0.8706\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3957 - accuracy: 0.8837 - val_loss: 0.4323 - val_accuracy: 0.8757\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3836 - accuracy: 0.8865 - val_loss: 0.4279 - val_accuracy: 0.8787\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3719 - accuracy: 0.8897 - val_loss: 0.4314 - val_accuracy: 0.8752\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3577 - accuracy: 0.8923 - val_loss: 0.4248 - val_accuracy: 0.8777\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3485 - accuracy: 0.8959 - val_loss: 0.4211 - val_accuracy: 0.8759\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:07:07.927725\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3397 - accuracy: 0.8992 - val_loss: 0.4026 - val_accuracy: 0.8838\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3170 - accuracy: 0.9069 - val_loss: 0.3986 - val_accuracy: 0.8849\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3052 - accuracy: 0.9093 - val_loss: 0.3947 - val_accuracy: 0.8855\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.2992 - accuracy: 0.9123 - val_loss: 0.3932 - val_accuracy: 0.8858\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.2951 - accuracy: 0.9127 - val_loss: 0.3926 - val_accuracy: 0.8858\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.2948 - accuracy: 0.9128 - val_loss: 0.3925 - val_accuracy: 0.8857\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2943 - accuracy: 0.9132 - val_loss: 0.3924 - val_accuracy: 0.8859\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2942 - accuracy: 0.9129 - val_loss: 0.3924 - val_accuracy: 0.8858\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.2938 - accuracy: 0.9138 - val_loss: 0.3924 - val_accuracy: 0.8858\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2940 - accuracy: 0.9133 - val_loss: 0.3924 - val_accuracy: 0.8858\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:53.493281\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1063 - accuracy: 0.7266 - val_loss: 0.6516 - val_accuracy: 0.8330\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6370 - accuracy: 0.8280 - val_loss: 0.5528 - val_accuracy: 0.8525\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5653 - accuracy: 0.8427 - val_loss: 0.5272 - val_accuracy: 0.8503\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5328 - accuracy: 0.8508 - val_loss: 0.5072 - val_accuracy: 0.8609\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5147 - accuracy: 0.8553 - val_loss: 0.4963 - val_accuracy: 0.8590\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4899 - accuracy: 0.8601 - val_loss: 0.4793 - val_accuracy: 0.8644\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4650 - accuracy: 0.8676 - val_loss: 0.4636 - val_accuracy: 0.8691\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4493 - accuracy: 0.8708 - val_loss: 0.4600 - val_accuracy: 0.8695\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4308 - accuracy: 0.8759 - val_loss: 0.4478 - val_accuracy: 0.8752\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4151 - accuracy: 0.8783 - val_loss: 0.4366 - val_accuracy: 0.8741\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4004 - accuracy: 0.8811 - val_loss: 0.4290 - val_accuracy: 0.8761\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3856 - accuracy: 0.8857 - val_loss: 0.4194 - val_accuracy: 0.8772\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3744 - accuracy: 0.8882 - val_loss: 0.4184 - val_accuracy: 0.8797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3629 - accuracy: 0.8910 - val_loss: 0.4106 - val_accuracy: 0.8790\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3510 - accuracy: 0.8941 - val_loss: 0.4117 - val_accuracy: 0.8807\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3396 - accuracy: 0.8972 - val_loss: 0.4108 - val_accuracy: 0.8790\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3296 - accuracy: 0.8992 - val_loss: 0.4043 - val_accuracy: 0.8804\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3220 - accuracy: 0.9018 - val_loss: 0.4027 - val_accuracy: 0.8819\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3114 - accuracy: 0.9046 - val_loss: 0.4009 - val_accuracy: 0.8824\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3035 - accuracy: 0.9069 - val_loss: 0.4003 - val_accuracy: 0.8820\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:19.050318\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.2831 - accuracy: 0.9139 - val_loss: 0.3929 - val_accuracy: 0.8829\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2696 - accuracy: 0.9184 - val_loss: 0.3857 - val_accuracy: 0.8850\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2614 - accuracy: 0.9215 - val_loss: 0.3852 - val_accuracy: 0.8859\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2604 - accuracy: 0.9211 - val_loss: 0.3849 - val_accuracy: 0.8863\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2565 - accuracy: 0.9230 - val_loss: 0.3846 - val_accuracy: 0.8857\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2562 - accuracy: 0.9233 - val_loss: 0.3845 - val_accuracy: 0.8859\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2553 - accuracy: 0.9232 - val_loss: 0.3844 - val_accuracy: 0.8859\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:19.781164\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1090 - accuracy: 0.7270 - val_loss: 0.6664 - val_accuracy: 0.8307\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6417 - accuracy: 0.8284 - val_loss: 0.5681 - val_accuracy: 0.8440\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5681 - accuracy: 0.8422 - val_loss: 0.5226 - val_accuracy: 0.8552\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5324 - accuracy: 0.8496 - val_loss: 0.5184 - val_accuracy: 0.8562\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5136 - accuracy: 0.8554 - val_loss: 0.5093 - val_accuracy: 0.8567\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4855 - accuracy: 0.8613 - val_loss: 0.4922 - val_accuracy: 0.8608\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4676 - accuracy: 0.8667 - val_loss: 0.4848 - val_accuracy: 0.8612\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4462 - accuracy: 0.8718 - val_loss: 0.4584 - val_accuracy: 0.8697\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4306 - accuracy: 0.8748 - val_loss: 0.4579 - val_accuracy: 0.8680\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4138 - accuracy: 0.8792 - val_loss: 0.4489 - val_accuracy: 0.8705\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4012 - accuracy: 0.8833 - val_loss: 0.4348 - val_accuracy: 0.8738\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3845 - accuracy: 0.8868 - val_loss: 0.4341 - val_accuracy: 0.8712\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3713 - accuracy: 0.8889 - val_loss: 0.4288 - val_accuracy: 0.8738\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3577 - accuracy: 0.8946 - val_loss: 0.4248 - val_accuracy: 0.8760\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3470 - accuracy: 0.8969 - val_loss: 0.4302 - val_accuracy: 0.8735\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3371 - accuracy: 0.8987 - val_loss: 0.4196 - val_accuracy: 0.8757\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3262 - accuracy: 0.9018 - val_loss: 0.4128 - val_accuracy: 0.8803\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3186 - accuracy: 0.9029 - val_loss: 0.4138 - val_accuracy: 0.8804\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3093 - accuracy: 0.9060 - val_loss: 0.4127 - val_accuracy: 0.8776\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3007 - accuracy: 0.9077 - val_loss: 0.4121 - val_accuracy: 0.8789\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:19.139541\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2791 - accuracy: 0.9154 - val_loss: 0.4019 - val_accuracy: 0.8802\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2650 - accuracy: 0.9208 - val_loss: 0.3975 - val_accuracy: 0.8820\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2581 - accuracy: 0.9228 - val_loss: 0.3958 - val_accuracy: 0.8828\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2556 - accuracy: 0.9234 - val_loss: 0.3946 - val_accuracy: 0.8832\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2521 - accuracy: 0.9254 - val_loss: 0.3951 - val_accuracy: 0.8828\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2510 - accuracy: 0.9248 - val_loss: 0.3950 - val_accuracy: 0.8829\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2502 - accuracy: 0.9254 - val_loss: 0.3949 - val_accuracy: 0.8831\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:16.313315\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1265 - accuracy: 0.7146 - val_loss: 0.6512 - val_accuracy: 0.8335\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.6482 - accuracy: 0.8258 - val_loss: 0.5597 - val_accuracy: 0.8477\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5728 - accuracy: 0.8421 - val_loss: 0.5275 - val_accuracy: 0.8562\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5386 - accuracy: 0.8497 - val_loss: 0.5050 - val_accuracy: 0.8585\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5149 - accuracy: 0.8562 - val_loss: 0.4929 - val_accuracy: 0.8644\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4882 - accuracy: 0.8617 - val_loss: 0.4800 - val_accuracy: 0.8644\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4703 - accuracy: 0.8659 - val_loss: 0.4685 - val_accuracy: 0.8670\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4498 - accuracy: 0.8708 - val_loss: 0.4561 - val_accuracy: 0.8693\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4311 - accuracy: 0.8762 - val_loss: 0.4418 - val_accuracy: 0.8737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4143 - accuracy: 0.8788 - val_loss: 0.4315 - val_accuracy: 0.8746\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4032 - accuracy: 0.8818 - val_loss: 0.4289 - val_accuracy: 0.8759\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3913 - accuracy: 0.8844 - val_loss: 0.4142 - val_accuracy: 0.8810\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3778 - accuracy: 0.8886 - val_loss: 0.4119 - val_accuracy: 0.8792\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3677 - accuracy: 0.8913 - val_loss: 0.4102 - val_accuracy: 0.8799\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3572 - accuracy: 0.8929 - val_loss: 0.4015 - val_accuracy: 0.8817\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3456 - accuracy: 0.8959 - val_loss: 0.3982 - val_accuracy: 0.8832\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3366 - accuracy: 0.8976 - val_loss: 0.3970 - val_accuracy: 0.8839\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3259 - accuracy: 0.9007 - val_loss: 0.3927 - val_accuracy: 0.8828\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3188 - accuracy: 0.9024 - val_loss: 0.3897 - val_accuracy: 0.8852\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3116 - accuracy: 0.9052 - val_loss: 0.3892 - val_accuracy: 0.8852\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:35.576703\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2901 - accuracy: 0.9123 - val_loss: 0.3814 - val_accuracy: 0.8864\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2761 - accuracy: 0.9171 - val_loss: 0.3775 - val_accuracy: 0.8880\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2701 - accuracy: 0.9189 - val_loss: 0.3760 - val_accuracy: 0.8894\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2642 - accuracy: 0.9218 - val_loss: 0.3756 - val_accuracy: 0.8891\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2634 - accuracy: 0.9208 - val_loss: 0.3755 - val_accuracy: 0.8898\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2623 - accuracy: 0.9223 - val_loss: 0.3754 - val_accuracy: 0.8898\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2629 - accuracy: 0.9215 - val_loss: 0.3753 - val_accuracy: 0.8898\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.2627 - accuracy: 0.9211 - val_loss: 0.3752 - val_accuracy: 0.8897\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:50.256290\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.1313 - accuracy: 0.7145 - val_loss: 0.6544 - val_accuracy: 0.8322\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6623 - accuracy: 0.8231 - val_loss: 0.5612 - val_accuracy: 0.8455\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5810 - accuracy: 0.8393 - val_loss: 0.5270 - val_accuracy: 0.8533\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5452 - accuracy: 0.8472 - val_loss: 0.5156 - val_accuracy: 0.8559\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5226 - accuracy: 0.8540 - val_loss: 0.5078 - val_accuracy: 0.8575\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4978 - accuracy: 0.8599 - val_loss: 0.4938 - val_accuracy: 0.8594\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4754 - accuracy: 0.8643 - val_loss: 0.4596 - val_accuracy: 0.8707\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4562 - accuracy: 0.8688 - val_loss: 0.4507 - val_accuracy: 0.8712\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4395 - accuracy: 0.8724 - val_loss: 0.4372 - val_accuracy: 0.8749\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4243 - accuracy: 0.8766 - val_loss: 0.4394 - val_accuracy: 0.8740\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4094 - accuracy: 0.8799 - val_loss: 0.4248 - val_accuracy: 0.8783\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3949 - accuracy: 0.8846 - val_loss: 0.4203 - val_accuracy: 0.8747\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3856 - accuracy: 0.8860 - val_loss: 0.4233 - val_accuracy: 0.8746\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3730 - accuracy: 0.8896 - val_loss: 0.4085 - val_accuracy: 0.8777\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:42.355220\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3643 - accuracy: 0.8941 - val_loss: 0.3949 - val_accuracy: 0.8852\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3395 - accuracy: 0.9001 - val_loss: 0.3851 - val_accuracy: 0.8854\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3261 - accuracy: 0.9043 - val_loss: 0.3823 - val_accuracy: 0.8858\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3201 - accuracy: 0.9059 - val_loss: 0.3818 - val_accuracy: 0.8861\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3158 - accuracy: 0.9081 - val_loss: 0.3805 - val_accuracy: 0.8873\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3143 - accuracy: 0.9071 - val_loss: 0.3804 - val_accuracy: 0.8871\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3133 - accuracy: 0.9079 - val_loss: 0.3802 - val_accuracy: 0.8871\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3122 - accuracy: 0.9091 - val_loss: 0.3802 - val_accuracy: 0.8870\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:50.703909\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1412 - accuracy: 0.7116 - val_loss: 0.6782 - val_accuracy: 0.8292\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6547 - accuracy: 0.8258 - val_loss: 0.5660 - val_accuracy: 0.8481\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5782 - accuracy: 0.8401 - val_loss: 0.5391 - val_accuracy: 0.8453\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5402 - accuracy: 0.8490 - val_loss: 0.5126 - val_accuracy: 0.8573\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5186 - accuracy: 0.8547 - val_loss: 0.5062 - val_accuracy: 0.8561\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4962 - accuracy: 0.8609 - val_loss: 0.4819 - val_accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4746 - accuracy: 0.8650 - val_loss: 0.4668 - val_accuracy: 0.8658\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4553 - accuracy: 0.8683 - val_loss: 0.4545 - val_accuracy: 0.8701\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4408 - accuracy: 0.8729 - val_loss: 0.4415 - val_accuracy: 0.8731\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4242 - accuracy: 0.8767 - val_loss: 0.4404 - val_accuracy: 0.8695\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4094 - accuracy: 0.8799 - val_loss: 0.4280 - val_accuracy: 0.8738\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3951 - accuracy: 0.8833 - val_loss: 0.4265 - val_accuracy: 0.8757\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3830 - accuracy: 0.8862 - val_loss: 0.4193 - val_accuracy: 0.8770\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3728 - accuracy: 0.8890 - val_loss: 0.4128 - val_accuracy: 0.8775\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3612 - accuracy: 0.8908 - val_loss: 0.4082 - val_accuracy: 0.8789\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3505 - accuracy: 0.8937 - val_loss: 0.4013 - val_accuracy: 0.8789\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3405 - accuracy: 0.8978 - val_loss: 0.4019 - val_accuracy: 0.8784\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3327 - accuracy: 0.8988 - val_loss: 0.4001 - val_accuracy: 0.8800\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3217 - accuracy: 0.9024 - val_loss: 0.3952 - val_accuracy: 0.8808\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3150 - accuracy: 0.9046 - val_loss: 0.3953 - val_accuracy: 0.8825\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:32.215341\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2943 - accuracy: 0.9105 - val_loss: 0.3836 - val_accuracy: 0.8842\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2805 - accuracy: 0.9156 - val_loss: 0.3814 - val_accuracy: 0.8843\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2731 - accuracy: 0.9187 - val_loss: 0.3795 - val_accuracy: 0.8853\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2684 - accuracy: 0.9201 - val_loss: 0.3791 - val_accuracy: 0.8856\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.2669 - accuracy: 0.9195 - val_loss: 0.3785 - val_accuracy: 0.8855\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.2647 - accuracy: 0.9214 - val_loss: 0.3785 - val_accuracy: 0.8852\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2649 - accuracy: 0.9211 - val_loss: 0.3785 - val_accuracy: 0.8852\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:21.705253\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1237 - accuracy: 0.7185 - val_loss: 0.6677 - val_accuracy: 0.8302\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6514 - accuracy: 0.8267 - val_loss: 0.5604 - val_accuracy: 0.8522\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5703 - accuracy: 0.8423 - val_loss: 0.5251 - val_accuracy: 0.8555\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.5382 - accuracy: 0.8505 - val_loss: 0.5053 - val_accuracy: 0.8655\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.5168 - accuracy: 0.8536 - val_loss: 0.4959 - val_accuracy: 0.8637\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.4911 - accuracy: 0.8604 - val_loss: 0.4756 - val_accuracy: 0.8700\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4705 - accuracy: 0.8660 - val_loss: 0.4701 - val_accuracy: 0.8681\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4503 - accuracy: 0.8718 - val_loss: 0.4491 - val_accuracy: 0.8753\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4337 - accuracy: 0.8746 - val_loss: 0.4410 - val_accuracy: 0.8785\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4188 - accuracy: 0.8785 - val_loss: 0.4347 - val_accuracy: 0.8760\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4030 - accuracy: 0.8818 - val_loss: 0.4347 - val_accuracy: 0.8762\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3909 - accuracy: 0.8834 - val_loss: 0.4314 - val_accuracy: 0.8743\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:52.249918\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3812 - accuracy: 0.8897 - val_loss: 0.4071 - val_accuracy: 0.8846\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3524 - accuracy: 0.8961 - val_loss: 0.3974 - val_accuracy: 0.8854\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3364 - accuracy: 0.9011 - val_loss: 0.3934 - val_accuracy: 0.8871\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.3267 - accuracy: 0.9042 - val_loss: 0.3904 - val_accuracy: 0.8887\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.3227 - accuracy: 0.9052 - val_loss: 0.3896 - val_accuracy: 0.8878\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3210 - accuracy: 0.9061 - val_loss: 0.3893 - val_accuracy: 0.8879\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3192 - accuracy: 0.9074 - val_loss: 0.3891 - val_accuracy: 0.8880\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:24.362268\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1309 - accuracy: 0.7154 - val_loss: 0.6711 - val_accuracy: 0.8297\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6471 - accuracy: 0.8268 - val_loss: 0.5741 - val_accuracy: 0.8478\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5688 - accuracy: 0.8434 - val_loss: 0.5306 - val_accuracy: 0.8510\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5337 - accuracy: 0.8505 - val_loss: 0.5083 - val_accuracy: 0.8587\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5119 - accuracy: 0.8562 - val_loss: 0.4999 - val_accuracy: 0.8619\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4889 - accuracy: 0.8623 - val_loss: 0.4791 - val_accuracy: 0.8674\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4665 - accuracy: 0.8666 - val_loss: 0.4739 - val_accuracy: 0.8676\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4484 - accuracy: 0.8703 - val_loss: 0.4544 - val_accuracy: 0.8712\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4309 - accuracy: 0.8752 - val_loss: 0.4455 - val_accuracy: 0.8722\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4164 - accuracy: 0.8780 - val_loss: 0.4419 - val_accuracy: 0.8739\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4048 - accuracy: 0.8823 - val_loss: 0.4288 - val_accuracy: 0.8773\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3898 - accuracy: 0.8846 - val_loss: 0.4228 - val_accuracy: 0.8769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3778 - accuracy: 0.8875 - val_loss: 0.4173 - val_accuracy: 0.8783\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3654 - accuracy: 0.8899 - val_loss: 0.4103 - val_accuracy: 0.8810\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3550 - accuracy: 0.8931 - val_loss: 0.4101 - val_accuracy: 0.8789\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3441 - accuracy: 0.8957 - val_loss: 0.4076 - val_accuracy: 0.8812\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3351 - accuracy: 0.8979 - val_loss: 0.4002 - val_accuracy: 0.8821\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3276 - accuracy: 0.9002 - val_loss: 0.4008 - val_accuracy: 0.8809\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3164 - accuracy: 0.9031 - val_loss: 0.4013 - val_accuracy: 0.8822\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3103 - accuracy: 0.9039 - val_loss: 0.3926 - val_accuracy: 0.8833\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:29.682522\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2893 - accuracy: 0.9123 - val_loss: 0.3837 - val_accuracy: 0.8868\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2755 - accuracy: 0.9163 - val_loss: 0.3829 - val_accuracy: 0.8875\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2691 - accuracy: 0.9200 - val_loss: 0.3805 - val_accuracy: 0.8877\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2640 - accuracy: 0.9212 - val_loss: 0.3799 - val_accuracy: 0.8880\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2630 - accuracy: 0.9218 - val_loss: 0.3796 - val_accuracy: 0.8890\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2609 - accuracy: 0.9225 - val_loss: 0.3795 - val_accuracy: 0.8887\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2610 - accuracy: 0.9224 - val_loss: 0.3795 - val_accuracy: 0.8886\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2605 - accuracy: 0.9219 - val_loss: 0.3795 - val_accuracy: 0.8887\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:48.353566\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9227 - accuracy: 0.7255 - val_loss: 0.5665 - val_accuracy: 0.8180\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4850 - accuracy: 0.8369 - val_loss: 0.4574 - val_accuracy: 0.8468\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4127 - accuracy: 0.8573 - val_loss: 0.4280 - val_accuracy: 0.8561\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3708 - accuracy: 0.8702 - val_loss: 0.4086 - val_accuracy: 0.8611\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.3391 - accuracy: 0.8785 - val_loss: 0.4111 - val_accuracy: 0.8588\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3090 - accuracy: 0.8865 - val_loss: 0.3849 - val_accuracy: 0.8688\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2835 - accuracy: 0.8947 - val_loss: 0.3732 - val_accuracy: 0.8708\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2622 - accuracy: 0.9027 - val_loss: 0.3791 - val_accuracy: 0.8720\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2428 - accuracy: 0.9073 - val_loss: 0.3721 - val_accuracy: 0.8735\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2253 - accuracy: 0.9131 - val_loss: 0.3879 - val_accuracy: 0.8686\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2085 - accuracy: 0.9193 - val_loss: 0.3862 - val_accuracy: 0.8741\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1941 - accuracy: 0.9240 - val_loss: 0.4021 - val_accuracy: 0.8719\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1822 - accuracy: 0.9273 - val_loss: 0.4044 - val_accuracy: 0.8715\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1698 - accuracy: 0.9313 - val_loss: 0.4124 - val_accuracy: 0.8746\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1586 - accuracy: 0.9369 - val_loss: 0.4299 - val_accuracy: 0.8719\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1492 - accuracy: 0.9405 - val_loss: 0.4376 - val_accuracy: 0.8727\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.1409 - accuracy: 0.9433 - val_loss: 0.4569 - val_accuracy: 0.8721\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:31.665122\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1456 - accuracy: 0.9428 - val_loss: 0.4164 - val_accuracy: 0.8742\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1357 - accuracy: 0.9475 - val_loss: 0.4212 - val_accuracy: 0.8754\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1308 - accuracy: 0.9495 - val_loss: 0.4258 - val_accuracy: 0.8749\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.1283 - accuracy: 0.9504 - val_loss: 0.4263 - val_accuracy: 0.8759\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1270 - accuracy: 0.9513 - val_loss: 0.4276 - val_accuracy: 0.8748\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1263 - accuracy: 0.9518 - val_loss: 0.4280 - val_accuracy: 0.8747\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1260 - accuracy: 0.9520 - val_loss: 0.4282 - val_accuracy: 0.8750\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:08.209911\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9092 - accuracy: 0.7286 - val_loss: 0.5337 - val_accuracy: 0.8204\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4789 - accuracy: 0.8401 - val_loss: 0.4445 - val_accuracy: 0.8480\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4085 - accuracy: 0.8598 - val_loss: 0.4132 - val_accuracy: 0.8574\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3663 - accuracy: 0.8703 - val_loss: 0.3877 - val_accuracy: 0.8628\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3332 - accuracy: 0.8800 - val_loss: 0.3826 - val_accuracy: 0.8643\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3041 - accuracy: 0.8892 - val_loss: 0.3836 - val_accuracy: 0.8677\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2781 - accuracy: 0.8969 - val_loss: 0.3671 - val_accuracy: 0.8731\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2565 - accuracy: 0.9044 - val_loss: 0.3665 - val_accuracy: 0.8738\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2363 - accuracy: 0.9099 - val_loss: 0.3642 - val_accuracy: 0.8758\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2180 - accuracy: 0.9155 - val_loss: 0.3789 - val_accuracy: 0.8735\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2023 - accuracy: 0.9212 - val_loss: 0.3741 - val_accuracy: 0.8746\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1861 - accuracy: 0.9270 - val_loss: 0.3914 - val_accuracy: 0.8722\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:14.495270\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1962 - accuracy: 0.9256 - val_loss: 0.3635 - val_accuracy: 0.8793\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1784 - accuracy: 0.9316 - val_loss: 0.3655 - val_accuracy: 0.8784\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1696 - accuracy: 0.9354 - val_loss: 0.3674 - val_accuracy: 0.8797\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1647 - accuracy: 0.9375 - val_loss: 0.3701 - val_accuracy: 0.8798\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1624 - accuracy: 0.9382 - val_loss: 0.3706 - val_accuracy: 0.8799\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1613 - accuracy: 0.9392 - val_loss: 0.3707 - val_accuracy: 0.8807\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1607 - accuracy: 0.9393 - val_loss: 0.3708 - val_accuracy: 0.8803\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1605 - accuracy: 0.9394 - val_loss: 0.3708 - val_accuracy: 0.8804\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.1604 - accuracy: 0.9395 - val_loss: 0.3709 - val_accuracy: 0.8804\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:55.477746\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8843 - accuracy: 0.7356 - val_loss: 0.5398 - val_accuracy: 0.8218\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4606 - accuracy: 0.8447 - val_loss: 0.4572 - val_accuracy: 0.8425\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3937 - accuracy: 0.8638 - val_loss: 0.4205 - val_accuracy: 0.8566\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3531 - accuracy: 0.8745 - val_loss: 0.4028 - val_accuracy: 0.8562\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3215 - accuracy: 0.8830 - val_loss: 0.3932 - val_accuracy: 0.8632\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2916 - accuracy: 0.8932 - val_loss: 0.3899 - val_accuracy: 0.8638\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2671 - accuracy: 0.8998 - val_loss: 0.3834 - val_accuracy: 0.8687\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2443 - accuracy: 0.9073 - val_loss: 0.3823 - val_accuracy: 0.8721\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2248 - accuracy: 0.9135 - val_loss: 0.3833 - val_accuracy: 0.8692\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2066 - accuracy: 0.9181 - val_loss: 0.3896 - val_accuracy: 0.8702\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1905 - accuracy: 0.9243 - val_loss: 0.4050 - val_accuracy: 0.8691\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:57.805722\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2029 - accuracy: 0.9223 - val_loss: 0.3777 - val_accuracy: 0.8715\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1837 - accuracy: 0.9293 - val_loss: 0.3760 - val_accuracy: 0.8749\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1740 - accuracy: 0.9334 - val_loss: 0.3769 - val_accuracy: 0.8774\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1688 - accuracy: 0.9359 - val_loss: 0.3780 - val_accuracy: 0.8771\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1661 - accuracy: 0.9370 - val_loss: 0.3784 - val_accuracy: 0.8778\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1648 - accuracy: 0.9376 - val_loss: 0.3792 - val_accuracy: 0.8776\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1642 - accuracy: 0.9376 - val_loss: 0.3794 - val_accuracy: 0.8777\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1639 - accuracy: 0.9379 - val_loss: 0.3794 - val_accuracy: 0.8777\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:34.647039\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9088 - accuracy: 0.7281 - val_loss: 0.5628 - val_accuracy: 0.8152\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4753 - accuracy: 0.8403 - val_loss: 0.4668 - val_accuracy: 0.8418\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4025 - accuracy: 0.8613 - val_loss: 0.4203 - val_accuracy: 0.8586\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3601 - accuracy: 0.8736 - val_loss: 0.4072 - val_accuracy: 0.8600\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3303 - accuracy: 0.8820 - val_loss: 0.3756 - val_accuracy: 0.8695\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3000 - accuracy: 0.8905 - val_loss: 0.3793 - val_accuracy: 0.8720\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2747 - accuracy: 0.8982 - val_loss: 0.3778 - val_accuracy: 0.8719\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2534 - accuracy: 0.9053 - val_loss: 0.3745 - val_accuracy: 0.8770\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2341 - accuracy: 0.9112 - val_loss: 0.3706 - val_accuracy: 0.8747\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2177 - accuracy: 0.9159 - val_loss: 0.3830 - val_accuracy: 0.8741\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2009 - accuracy: 0.9218 - val_loss: 0.3889 - val_accuracy: 0.8732\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:54.173771\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2130 - accuracy: 0.9193 - val_loss: 0.3660 - val_accuracy: 0.8760\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1932 - accuracy: 0.9271 - val_loss: 0.3640 - val_accuracy: 0.8812\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1832 - accuracy: 0.9320 - val_loss: 0.3670 - val_accuracy: 0.8792\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1782 - accuracy: 0.9334 - val_loss: 0.3679 - val_accuracy: 0.8807\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1755 - accuracy: 0.9345 - val_loss: 0.3685 - val_accuracy: 0.8801\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:14.010366\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9023 - accuracy: 0.7296 - val_loss: 0.5757 - val_accuracy: 0.8162\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4745 - accuracy: 0.8410 - val_loss: 0.4430 - val_accuracy: 0.8505\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4058 - accuracy: 0.8597 - val_loss: 0.4146 - val_accuracy: 0.8575\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3638 - accuracy: 0.8723 - val_loss: 0.4344 - val_accuracy: 0.8462\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3323 - accuracy: 0.8804 - val_loss: 0.3820 - val_accuracy: 0.8673\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3022 - accuracy: 0.8898 - val_loss: 0.3736 - val_accuracy: 0.8693\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.2782 - accuracy: 0.8968 - val_loss: 0.3689 - val_accuracy: 0.8726\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2561 - accuracy: 0.9028 - val_loss: 0.3547 - val_accuracy: 0.8770\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2358 - accuracy: 0.9098 - val_loss: 0.3642 - val_accuracy: 0.8734\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.2173 - accuracy: 0.9160 - val_loss: 0.3702 - val_accuracy: 0.8752\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2007 - accuracy: 0.9219 - val_loss: 0.3935 - val_accuracy: 0.8737\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:53.272315\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2135 - accuracy: 0.9203 - val_loss: 0.3608 - val_accuracy: 0.8771\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1941 - accuracy: 0.9258 - val_loss: 0.3592 - val_accuracy: 0.8773\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1837 - accuracy: 0.9307 - val_loss: 0.3589 - val_accuracy: 0.8806\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1785 - accuracy: 0.9323 - val_loss: 0.3593 - val_accuracy: 0.8807\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1757 - accuracy: 0.9333 - val_loss: 0.3601 - val_accuracy: 0.8811\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1744 - accuracy: 0.9340 - val_loss: 0.3606 - val_accuracy: 0.8805\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1738 - accuracy: 0.9343 - val_loss: 0.3606 - val_accuracy: 0.8805\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1736 - accuracy: 0.9342 - val_loss: 0.3606 - val_accuracy: 0.8805\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:33.308080\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8179 - accuracy: 0.7529 - val_loss: 0.4936 - val_accuracy: 0.8367\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4395 - accuracy: 0.8517 - val_loss: 0.4411 - val_accuracy: 0.8493\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3744 - accuracy: 0.8688 - val_loss: 0.3990 - val_accuracy: 0.8593\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3374 - accuracy: 0.8814 - val_loss: 0.3983 - val_accuracy: 0.8580\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3054 - accuracy: 0.8893 - val_loss: 0.3924 - val_accuracy: 0.8633\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2764 - accuracy: 0.8971 - val_loss: 0.3829 - val_accuracy: 0.8667\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2503 - accuracy: 0.9063 - val_loss: 0.3961 - val_accuracy: 0.8646\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2261 - accuracy: 0.9133 - val_loss: 0.4009 - val_accuracy: 0.8648\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2061 - accuracy: 0.9201 - val_loss: 0.3987 - val_accuracy: 0.8666\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:05.035343\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2215 - accuracy: 0.9166 - val_loss: 0.3730 - val_accuracy: 0.8724\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1957 - accuracy: 0.9268 - val_loss: 0.3716 - val_accuracy: 0.8732\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1829 - accuracy: 0.9315 - val_loss: 0.3715 - val_accuracy: 0.8742\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1760 - accuracy: 0.9347 - val_loss: 0.3732 - val_accuracy: 0.8749\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1724 - accuracy: 0.9361 - val_loss: 0.3744 - val_accuracy: 0.8735\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1707 - accuracy: 0.9367 - val_loss: 0.3744 - val_accuracy: 0.8735\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1699 - accuracy: 0.9372 - val_loss: 0.3744 - val_accuracy: 0.8733\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:10.410010\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7971 - accuracy: 0.7585 - val_loss: 0.4970 - val_accuracy: 0.8339\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4325 - accuracy: 0.8531 - val_loss: 0.4274 - val_accuracy: 0.8524\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3716 - accuracy: 0.8702 - val_loss: 0.3955 - val_accuracy: 0.8625\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3345 - accuracy: 0.8801 - val_loss: 0.4019 - val_accuracy: 0.8607\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3055 - accuracy: 0.8885 - val_loss: 0.3933 - val_accuracy: 0.8629\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2754 - accuracy: 0.8969 - val_loss: 0.3790 - val_accuracy: 0.8696\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2492 - accuracy: 0.9048 - val_loss: 0.3868 - val_accuracy: 0.8684\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2246 - accuracy: 0.9139 - val_loss: 0.3975 - val_accuracy: 0.8684\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2043 - accuracy: 0.9205 - val_loss: 0.4098 - val_accuracy: 0.8642\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:05.608365\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2207 - accuracy: 0.9175 - val_loss: 0.3639 - val_accuracy: 0.8762\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1959 - accuracy: 0.9267 - val_loss: 0.3629 - val_accuracy: 0.8778\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1832 - accuracy: 0.9314 - val_loss: 0.3643 - val_accuracy: 0.8780\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1765 - accuracy: 0.9343 - val_loss: 0.3655 - val_accuracy: 0.8783\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1731 - accuracy: 0.9357 - val_loss: 0.3668 - val_accuracy: 0.8780\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1714 - accuracy: 0.9357 - val_loss: 0.3668 - val_accuracy: 0.8775\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1707 - accuracy: 0.9361 - val_loss: 0.3671 - val_accuracy: 0.8779\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:10.931879\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8116 - accuracy: 0.7544 - val_loss: 0.5047 - val_accuracy: 0.8302\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4362 - accuracy: 0.8509 - val_loss: 0.4299 - val_accuracy: 0.8579\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3740 - accuracy: 0.8681 - val_loss: 0.4073 - val_accuracy: 0.8611\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3353 - accuracy: 0.8792 - val_loss: 0.3976 - val_accuracy: 0.8677\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3070 - accuracy: 0.8880 - val_loss: 0.4050 - val_accuracy: 0.8655\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2770 - accuracy: 0.8967 - val_loss: 0.3908 - val_accuracy: 0.8684\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2510 - accuracy: 0.9038 - val_loss: 0.3907 - val_accuracy: 0.8677\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2277 - accuracy: 0.9110 - val_loss: 0.4053 - val_accuracy: 0.8708\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2078 - accuracy: 0.9193 - val_loss: 0.4144 - val_accuracy: 0.8660\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1888 - accuracy: 0.9242 - val_loss: 0.4210 - val_accuracy: 0.8684\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1713 - accuracy: 0.9307 - val_loss: 0.4358 - val_accuracy: 0.8678\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:59.631097\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1838 - accuracy: 0.9292 - val_loss: 0.3944 - val_accuracy: 0.8763\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1642 - accuracy: 0.9367 - val_loss: 0.3959 - val_accuracy: 0.8777\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1542 - accuracy: 0.9407 - val_loss: 0.3969 - val_accuracy: 0.8794\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1492 - accuracy: 0.9426 - val_loss: 0.4001 - val_accuracy: 0.8791\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1465 - accuracy: 0.9440 - val_loss: 0.4008 - val_accuracy: 0.8785\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1453 - accuracy: 0.9446 - val_loss: 0.4010 - val_accuracy: 0.8786\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:43.322845\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8103 - accuracy: 0.7572 - val_loss: 0.5146 - val_accuracy: 0.8269\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4366 - accuracy: 0.8516 - val_loss: 0.4355 - val_accuracy: 0.8551\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3716 - accuracy: 0.8694 - val_loss: 0.4277 - val_accuracy: 0.8551\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3343 - accuracy: 0.8801 - val_loss: 0.3955 - val_accuracy: 0.8627\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3049 - accuracy: 0.8871 - val_loss: 0.3934 - val_accuracy: 0.8660\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2743 - accuracy: 0.8977 - val_loss: 0.3981 - val_accuracy: 0.8649\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2475 - accuracy: 0.9063 - val_loss: 0.3935 - val_accuracy: 0.8712\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2247 - accuracy: 0.9133 - val_loss: 0.4002 - val_accuracy: 0.8721\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2048 - accuracy: 0.9192 - val_loss: 0.4117 - val_accuracy: 0.8716\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1847 - accuracy: 0.9263 - val_loss: 0.4309 - val_accuracy: 0.8648\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1691 - accuracy: 0.9315 - val_loss: 0.4412 - val_accuracy: 0.8665\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:57.849038\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1808 - accuracy: 0.9305 - val_loss: 0.3968 - val_accuracy: 0.8730\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1603 - accuracy: 0.9387 - val_loss: 0.3972 - val_accuracy: 0.8757\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1509 - accuracy: 0.9422 - val_loss: 0.3997 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1458 - accuracy: 0.9450 - val_loss: 0.4027 - val_accuracy: 0.8758\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1433 - accuracy: 0.9461 - val_loss: 0.4037 - val_accuracy: 0.8755\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1420 - accuracy: 0.9467 - val_loss: 0.4047 - val_accuracy: 0.8754\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1414 - accuracy: 0.9467 - val_loss: 0.4049 - val_accuracy: 0.8752\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:09.226954\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8072 - accuracy: 0.7554 - val_loss: 0.4883 - val_accuracy: 0.8395\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4344 - accuracy: 0.8516 - val_loss: 0.4421 - val_accuracy: 0.8497\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3730 - accuracy: 0.8681 - val_loss: 0.4062 - val_accuracy: 0.8633\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3363 - accuracy: 0.8798 - val_loss: 0.3881 - val_accuracy: 0.8637\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3080 - accuracy: 0.8874 - val_loss: 0.3907 - val_accuracy: 0.8654\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2785 - accuracy: 0.8951 - val_loss: 0.3910 - val_accuracy: 0.8698\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2515 - accuracy: 0.9050 - val_loss: 0.3877 - val_accuracy: 0.8723\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2288 - accuracy: 0.9112 - val_loss: 0.3949 - val_accuracy: 0.8717\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2070 - accuracy: 0.9188 - val_loss: 0.4103 - val_accuracy: 0.8669\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1882 - accuracy: 0.9266 - val_loss: 0.4329 - val_accuracy: 0.8668\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:30.171047\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2027 - accuracy: 0.9226 - val_loss: 0.3771 - val_accuracy: 0.8746\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1799 - accuracy: 0.9318 - val_loss: 0.3796 - val_accuracy: 0.8781\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1687 - accuracy: 0.9362 - val_loss: 0.3812 - val_accuracy: 0.8775\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1628 - accuracy: 0.9389 - val_loss: 0.3834 - val_accuracy: 0.8773\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1597 - accuracy: 0.9401 - val_loss: 0.3839 - val_accuracy: 0.8784\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1582 - accuracy: 0.9409 - val_loss: 0.3842 - val_accuracy: 0.8788\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1575 - accuracy: 0.9411 - val_loss: 0.3843 - val_accuracy: 0.8787\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1573 - accuracy: 0.9413 - val_loss: 0.3844 - val_accuracy: 0.8788\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1571 - accuracy: 0.9413 - val_loss: 0.3844 - val_accuracy: 0.8789\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1571 - accuracy: 0.9413 - val_loss: 0.3844 - val_accuracy: 0.8789\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1571 - accuracy: 0.9413 - val_loss: 0.3844 - val_accuracy: 0.8789\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1571 - accuracy: 0.9413 - val_loss: 0.3844 - val_accuracy: 0.8789\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.1571 - accuracy: 0.9413 - val_loss: 0.3844 - val_accuracy: 0.8789\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:51.106548\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8488 - accuracy: 0.7457 - val_loss: 0.5101 - val_accuracy: 0.8299\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4466 - accuracy: 0.8494 - val_loss: 0.4208 - val_accuracy: 0.8566\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3817 - accuracy: 0.8676 - val_loss: 0.3985 - val_accuracy: 0.8573\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3406 - accuracy: 0.8799 - val_loss: 0.3813 - val_accuracy: 0.8667\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3128 - accuracy: 0.8867 - val_loss: 0.3703 - val_accuracy: 0.8687\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2835 - accuracy: 0.8956 - val_loss: 0.3747 - val_accuracy: 0.8715\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2610 - accuracy: 0.9019 - val_loss: 0.3654 - val_accuracy: 0.8694\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2384 - accuracy: 0.9092 - val_loss: 0.3639 - val_accuracy: 0.8767\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2191 - accuracy: 0.9155 - val_loss: 0.3734 - val_accuracy: 0.8733\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2022 - accuracy: 0.9207 - val_loss: 0.3782 - val_accuracy: 0.8766\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1860 - accuracy: 0.9263 - val_loss: 0.3914 - val_accuracy: 0.8733\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:08.175046\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1969 - accuracy: 0.9252 - val_loss: 0.3552 - val_accuracy: 0.8803\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1771 - accuracy: 0.9332 - val_loss: 0.3595 - val_accuracy: 0.8788\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1677 - accuracy: 0.9363 - val_loss: 0.3601 - val_accuracy: 0.8805\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1625 - accuracy: 0.9386 - val_loss: 0.3603 - val_accuracy: 0.8820\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1598 - accuracy: 0.9401 - val_loss: 0.3615 - val_accuracy: 0.8809\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1585 - accuracy: 0.9405 - val_loss: 0.3620 - val_accuracy: 0.8810\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1579 - accuracy: 0.9407 - val_loss: 0.3621 - val_accuracy: 0.8812\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:15.966138\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8382 - accuracy: 0.7464 - val_loss: 0.5244 - val_accuracy: 0.8223\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4561 - accuracy: 0.8470 - val_loss: 0.4394 - val_accuracy: 0.8498\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3904 - accuracy: 0.8653 - val_loss: 0.4042 - val_accuracy: 0.8611\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3521 - accuracy: 0.8755 - val_loss: 0.3890 - val_accuracy: 0.8641\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3226 - accuracy: 0.8832 - val_loss: 0.3881 - val_accuracy: 0.8656\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2939 - accuracy: 0.8920 - val_loss: 0.3856 - val_accuracy: 0.8623\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2707 - accuracy: 0.8982 - val_loss: 0.3940 - val_accuracy: 0.8633\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2484 - accuracy: 0.9063 - val_loss: 0.3825 - val_accuracy: 0.8723\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2292 - accuracy: 0.9116 - val_loss: 0.3865 - val_accuracy: 0.8719\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2101 - accuracy: 0.9179 - val_loss: 0.3905 - val_accuracy: 0.8685\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1939 - accuracy: 0.9243 - val_loss: 0.3986 - val_accuracy: 0.8687\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:08.531437\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2044 - accuracy: 0.9217 - val_loss: 0.3740 - val_accuracy: 0.8742\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1843 - accuracy: 0.9294 - val_loss: 0.3766 - val_accuracy: 0.8759\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1737 - accuracy: 0.9340 - val_loss: 0.3773 - val_accuracy: 0.8777\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1681 - accuracy: 0.9362 - val_loss: 0.3791 - val_accuracy: 0.8773\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1653 - accuracy: 0.9373 - val_loss: 0.3801 - val_accuracy: 0.8771\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1640 - accuracy: 0.9376 - val_loss: 0.3808 - val_accuracy: 0.8769\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:47.571993\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8276 - accuracy: 0.7491 - val_loss: 0.5025 - val_accuracy: 0.8318\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4426 - accuracy: 0.8502 - val_loss: 0.4463 - val_accuracy: 0.8477\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3805 - accuracy: 0.8683 - val_loss: 0.4032 - val_accuracy: 0.8593\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3410 - accuracy: 0.8788 - val_loss: 0.3832 - val_accuracy: 0.8645\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3110 - accuracy: 0.8877 - val_loss: 0.3853 - val_accuracy: 0.8661\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2829 - accuracy: 0.8962 - val_loss: 0.3898 - val_accuracy: 0.8625\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2576 - accuracy: 0.9034 - val_loss: 0.3858 - val_accuracy: 0.8645\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2366 - accuracy: 0.9092 - val_loss: 0.3807 - val_accuracy: 0.8694\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2166 - accuracy: 0.9162 - val_loss: 0.3888 - val_accuracy: 0.8689\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2003 - accuracy: 0.9223 - val_loss: 0.3939 - val_accuracy: 0.8732\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1842 - accuracy: 0.9275 - val_loss: 0.4124 - val_accuracy: 0.8690\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1701 - accuracy: 0.9325 - val_loss: 0.4227 - val_accuracy: 0.8713\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1582 - accuracy: 0.9364 - val_loss: 0.4236 - val_accuracy: 0.8727\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:02.199334\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1645 - accuracy: 0.9356 - val_loss: 0.3959 - val_accuracy: 0.8731\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1497 - accuracy: 0.9423 - val_loss: 0.3998 - val_accuracy: 0.8744\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1416 - accuracy: 0.9458 - val_loss: 0.4032 - val_accuracy: 0.8748\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1377 - accuracy: 0.9476 - val_loss: 0.4052 - val_accuracy: 0.8755\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1356 - accuracy: 0.9483 - val_loss: 0.4065 - val_accuracy: 0.8752\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1347 - accuracy: 0.9487 - val_loss: 0.4069 - val_accuracy: 0.8753\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1342 - accuracy: 0.9487 - val_loss: 0.4073 - val_accuracy: 0.8754\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:16.069399\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8302 - accuracy: 0.7482 - val_loss: 0.4937 - val_accuracy: 0.8394\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4474 - accuracy: 0.8477 - val_loss: 0.4297 - val_accuracy: 0.8599\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3835 - accuracy: 0.8669 - val_loss: 0.4123 - val_accuracy: 0.8628\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3449 - accuracy: 0.8783 - val_loss: 0.3927 - val_accuracy: 0.8681\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3166 - accuracy: 0.8854 - val_loss: 0.3858 - val_accuracy: 0.8683\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2898 - accuracy: 0.8931 - val_loss: 0.3894 - val_accuracy: 0.8671\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2644 - accuracy: 0.8996 - val_loss: 0.3778 - val_accuracy: 0.8715\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2428 - accuracy: 0.9072 - val_loss: 0.3681 - val_accuracy: 0.8749\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2217 - accuracy: 0.9136 - val_loss: 0.3812 - val_accuracy: 0.8739\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2043 - accuracy: 0.9199 - val_loss: 0.3851 - val_accuracy: 0.8776\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1880 - accuracy: 0.9253 - val_loss: 0.3987 - val_accuracy: 0.8761\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1733 - accuracy: 0.9305 - val_loss: 0.4163 - val_accuracy: 0.8719\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1596 - accuracy: 0.9355 - val_loss: 0.4315 - val_accuracy: 0.8721\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:05.015278\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.1679 - accuracy: 0.9348 - val_loss: 0.3856 - val_accuracy: 0.8811\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1521 - accuracy: 0.9411 - val_loss: 0.3910 - val_accuracy: 0.8815\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.1443 - accuracy: 0.9440 - val_loss: 0.3938 - val_accuracy: 0.8805\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1403 - accuracy: 0.9462 - val_loss: 0.3958 - val_accuracy: 0.8815\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1382 - accuracy: 0.9472 - val_loss: 0.3968 - val_accuracy: 0.8801\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:22.197853\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8468 - accuracy: 0.7434 - val_loss: 0.5137 - val_accuracy: 0.8245\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4595 - accuracy: 0.8453 - val_loss: 0.4420 - val_accuracy: 0.8500\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3931 - accuracy: 0.8629 - val_loss: 0.3950 - val_accuracy: 0.8610\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3520 - accuracy: 0.8762 - val_loss: 0.3811 - val_accuracy: 0.8673\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3225 - accuracy: 0.8838 - val_loss: 0.3817 - val_accuracy: 0.8640\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2931 - accuracy: 0.8927 - val_loss: 0.3676 - val_accuracy: 0.8732\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2689 - accuracy: 0.9000 - val_loss: 0.3703 - val_accuracy: 0.8722\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2479 - accuracy: 0.9074 - val_loss: 0.3673 - val_accuracy: 0.8722\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2278 - accuracy: 0.9132 - val_loss: 0.3738 - val_accuracy: 0.8729\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:10.147290\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2428 - accuracy: 0.9100 - val_loss: 0.3500 - val_accuracy: 0.8796\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2173 - accuracy: 0.9193 - val_loss: 0.3509 - val_accuracy: 0.8791\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2041 - accuracy: 0.9245 - val_loss: 0.3505 - val_accuracy: 0.8806\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1969 - accuracy: 0.9269 - val_loss: 0.3504 - val_accuracy: 0.8814\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1931 - accuracy: 0.9289 - val_loss: 0.3509 - val_accuracy: 0.8808\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1914 - accuracy: 0.9291 - val_loss: 0.3510 - val_accuracy: 0.8813\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1906 - accuracy: 0.9297 - val_loss: 0.3511 - val_accuracy: 0.8814\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1902 - accuracy: 0.9298 - val_loss: 0.3511 - val_accuracy: 0.8813\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1901 - accuracy: 0.9299 - val_loss: 0.3512 - val_accuracy: 0.8814\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1901 - accuracy: 0.9299 - val_loss: 0.3512 - val_accuracy: 0.8814\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:37.037504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9823 - accuracy: 0.6723 - val_loss: 1.1205 - val_accuracy: 0.7901\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0114 - accuracy: 0.7912 - val_loss: 0.9218 - val_accuracy: 0.8049\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.8771 - accuracy: 0.8115 - val_loss: 0.8339 - val_accuracy: 0.8217\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8152 - accuracy: 0.8237 - val_loss: 0.7913 - val_accuracy: 0.8282\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7772 - accuracy: 0.8288 - val_loss: 0.7682 - val_accuracy: 0.8329\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7346 - accuracy: 0.8370 - val_loss: 0.7462 - val_accuracy: 0.8342\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7010 - accuracy: 0.8421 - val_loss: 0.7088 - val_accuracy: 0.8411\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6755 - accuracy: 0.8443 - val_loss: 0.6874 - val_accuracy: 0.8414\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6506 - accuracy: 0.8485 - val_loss: 0.6675 - val_accuracy: 0.8444\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.6324 - accuracy: 0.8516 - val_loss: 0.6563 - val_accuracy: 0.8465\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6125 - accuracy: 0.8554 - val_loss: 0.6322 - val_accuracy: 0.8541\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5977 - accuracy: 0.8574 - val_loss: 0.6274 - val_accuracy: 0.8505\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5813 - accuracy: 0.8596 - val_loss: 0.6070 - val_accuracy: 0.8527\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5664 - accuracy: 0.8625 - val_loss: 0.5986 - val_accuracy: 0.8552\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5519 - accuracy: 0.8644 - val_loss: 0.5896 - val_accuracy: 0.8557\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5412 - accuracy: 0.8656 - val_loss: 0.5885 - val_accuracy: 0.8541\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5279 - accuracy: 0.8683 - val_loss: 0.5726 - val_accuracy: 0.8560\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5178 - accuracy: 0.8698 - val_loss: 0.5602 - val_accuracy: 0.8588\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5080 - accuracy: 0.8720 - val_loss: 0.5547 - val_accuracy: 0.8609\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4996 - accuracy: 0.8729 - val_loss: 0.5436 - val_accuracy: 0.8620\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:52.435759\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4686 - accuracy: 0.8803 - val_loss: 0.5192 - val_accuracy: 0.8657\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4489 - accuracy: 0.8840 - val_loss: 0.5064 - val_accuracy: 0.8684\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4381 - accuracy: 0.8861 - val_loss: 0.4988 - val_accuracy: 0.8682\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4326 - accuracy: 0.8873 - val_loss: 0.4960 - val_accuracy: 0.8690\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4294 - accuracy: 0.8879 - val_loss: 0.4947 - val_accuracy: 0.8694\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4280 - accuracy: 0.8887 - val_loss: 0.4938 - val_accuracy: 0.8696\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4272 - accuracy: 0.8887 - val_loss: 0.4937 - val_accuracy: 0.8703\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4269 - accuracy: 0.8887 - val_loss: 0.4936 - val_accuracy: 0.8701\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4268 - accuracy: 0.8887 - val_loss: 0.4936 - val_accuracy: 0.8700\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4267 - accuracy: 0.8888 - val_loss: 0.4936 - val_accuracy: 0.8700\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:28.441325\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9079 - accuracy: 0.6741 - val_loss: 1.1269 - val_accuracy: 0.7828\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9953 - accuracy: 0.7998 - val_loss: 0.8997 - val_accuracy: 0.8137\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8646 - accuracy: 0.8186 - val_loss: 0.8453 - val_accuracy: 0.8204\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8059 - accuracy: 0.8283 - val_loss: 0.8207 - val_accuracy: 0.8204\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7665 - accuracy: 0.8339 - val_loss: 0.7814 - val_accuracy: 0.8291\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7209 - accuracy: 0.8428 - val_loss: 0.7406 - val_accuracy: 0.8333\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6934 - accuracy: 0.8461 - val_loss: 0.7069 - val_accuracy: 0.8408\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6616 - accuracy: 0.8521 - val_loss: 0.6982 - val_accuracy: 0.8398\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6413 - accuracy: 0.8534 - val_loss: 0.6653 - val_accuracy: 0.8452\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6212 - accuracy: 0.8573 - val_loss: 0.6450 - val_accuracy: 0.8489\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6019 - accuracy: 0.8597 - val_loss: 0.6394 - val_accuracy: 0.8477\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5832 - accuracy: 0.8630 - val_loss: 0.6296 - val_accuracy: 0.8490\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5677 - accuracy: 0.8649 - val_loss: 0.6100 - val_accuracy: 0.8499\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5552 - accuracy: 0.8668 - val_loss: 0.5892 - val_accuracy: 0.8537\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5404 - accuracy: 0.8676 - val_loss: 0.5865 - val_accuracy: 0.8549\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5280 - accuracy: 0.8709 - val_loss: 0.5790 - val_accuracy: 0.8553\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5153 - accuracy: 0.8732 - val_loss: 0.5760 - val_accuracy: 0.8523\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5061 - accuracy: 0.8733 - val_loss: 0.5571 - val_accuracy: 0.8581\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4970 - accuracy: 0.8749 - val_loss: 0.5393 - val_accuracy: 0.8600\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4876 - accuracy: 0.8765 - val_loss: 0.5342 - val_accuracy: 0.8634\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:55.079287\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4565 - accuracy: 0.8826 - val_loss: 0.5103 - val_accuracy: 0.8635\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4369 - accuracy: 0.8866 - val_loss: 0.4963 - val_accuracy: 0.8669\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4255 - accuracy: 0.8887 - val_loss: 0.4888 - val_accuracy: 0.8667\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4198 - accuracy: 0.8898 - val_loss: 0.4849 - val_accuracy: 0.8668\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4166 - accuracy: 0.8905 - val_loss: 0.4836 - val_accuracy: 0.8671\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4151 - accuracy: 0.8905 - val_loss: 0.4828 - val_accuracy: 0.8676\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4143 - accuracy: 0.8906 - val_loss: 0.4826 - val_accuracy: 0.8674\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4139 - accuracy: 0.8908 - val_loss: 0.4825 - val_accuracy: 0.8672\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4138 - accuracy: 0.8908 - val_loss: 0.4824 - val_accuracy: 0.8672\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:02.913437\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9524 - accuracy: 0.6794 - val_loss: 1.1553 - val_accuracy: 0.7672\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9885 - accuracy: 0.7960 - val_loss: 0.9311 - val_accuracy: 0.7995\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8579 - accuracy: 0.8156 - val_loss: 0.8618 - val_accuracy: 0.8112\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8029 - accuracy: 0.8258 - val_loss: 0.8117 - val_accuracy: 0.8279\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7687 - accuracy: 0.8314 - val_loss: 0.7895 - val_accuracy: 0.8285\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7277 - accuracy: 0.8384 - val_loss: 0.7521 - val_accuracy: 0.8342\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6973 - accuracy: 0.8434 - val_loss: 0.7374 - val_accuracy: 0.8353\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6723 - accuracy: 0.8471 - val_loss: 0.7236 - val_accuracy: 0.8340\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6491 - accuracy: 0.8518 - val_loss: 0.7020 - val_accuracy: 0.8380\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6274 - accuracy: 0.8538 - val_loss: 0.6700 - val_accuracy: 0.8446\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6088 - accuracy: 0.8579 - val_loss: 0.6553 - val_accuracy: 0.8430\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5901 - accuracy: 0.8599 - val_loss: 0.6486 - val_accuracy: 0.8454\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5746 - accuracy: 0.8615 - val_loss: 0.6363 - val_accuracy: 0.8468\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5588 - accuracy: 0.8647 - val_loss: 0.6147 - val_accuracy: 0.8491\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5473 - accuracy: 0.8664 - val_loss: 0.6125 - val_accuracy: 0.8525\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5327 - accuracy: 0.8691 - val_loss: 0.5890 - val_accuracy: 0.8537\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5207 - accuracy: 0.8704 - val_loss: 0.5809 - val_accuracy: 0.8569\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5101 - accuracy: 0.8716 - val_loss: 0.5764 - val_accuracy: 0.8554\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5004 - accuracy: 0.8733 - val_loss: 0.5692 - val_accuracy: 0.8547\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4912 - accuracy: 0.8745 - val_loss: 0.5615 - val_accuracy: 0.8574\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:46.475037\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4617 - accuracy: 0.8814 - val_loss: 0.5340 - val_accuracy: 0.8648\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4411 - accuracy: 0.8852 - val_loss: 0.5168 - val_accuracy: 0.8652\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4303 - accuracy: 0.8882 - val_loss: 0.5110 - val_accuracy: 0.8672\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4243 - accuracy: 0.8891 - val_loss: 0.5072 - val_accuracy: 0.8673\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4214 - accuracy: 0.8896 - val_loss: 0.5060 - val_accuracy: 0.8679\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4197 - accuracy: 0.8902 - val_loss: 0.5051 - val_accuracy: 0.8679\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4190 - accuracy: 0.8903 - val_loss: 0.5049 - val_accuracy: 0.8678\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4187 - accuracy: 0.8903 - val_loss: 0.5048 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4186 - accuracy: 0.8903 - val_loss: 0.5048 - val_accuracy: 0.8680\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4185 - accuracy: 0.8904 - val_loss: 0.5048 - val_accuracy: 0.8680\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4185 - accuracy: 0.8904 - val_loss: 0.5048 - val_accuracy: 0.8680\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:49.570275\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.9169 - accuracy: 0.6760 - val_loss: 1.0645 - val_accuracy: 0.7925\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9795 - accuracy: 0.8017 - val_loss: 0.8846 - val_accuracy: 0.8115\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8485 - accuracy: 0.8185 - val_loss: 0.8494 - val_accuracy: 0.8100\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7939 - accuracy: 0.8276 - val_loss: 0.7828 - val_accuracy: 0.8273\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7616 - accuracy: 0.8343 - val_loss: 0.7631 - val_accuracy: 0.8294\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7219 - accuracy: 0.8414 - val_loss: 0.7233 - val_accuracy: 0.8337\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6939 - accuracy: 0.8448 - val_loss: 0.7017 - val_accuracy: 0.8449\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6661 - accuracy: 0.8486 - val_loss: 0.6966 - val_accuracy: 0.8393\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6401 - accuracy: 0.8529 - val_loss: 0.6698 - val_accuracy: 0.8410\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6227 - accuracy: 0.8555 - val_loss: 0.6498 - val_accuracy: 0.8468\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6036 - accuracy: 0.8589 - val_loss: 0.6295 - val_accuracy: 0.8504\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5888 - accuracy: 0.8616 - val_loss: 0.6045 - val_accuracy: 0.8534\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5707 - accuracy: 0.8641 - val_loss: 0.5960 - val_accuracy: 0.8563\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5580 - accuracy: 0.8646 - val_loss: 0.5813 - val_accuracy: 0.8568\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5453 - accuracy: 0.8665 - val_loss: 0.5725 - val_accuracy: 0.8569\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5328 - accuracy: 0.8693 - val_loss: 0.5614 - val_accuracy: 0.8596\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5209 - accuracy: 0.8708 - val_loss: 0.5469 - val_accuracy: 0.8620\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5116 - accuracy: 0.8728 - val_loss: 0.5551 - val_accuracy: 0.8595\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5013 - accuracy: 0.8738 - val_loss: 0.5343 - val_accuracy: 0.8634\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4919 - accuracy: 0.8752 - val_loss: 0.5345 - val_accuracy: 0.8623\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:09.965921\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4620 - accuracy: 0.8816 - val_loss: 0.5050 - val_accuracy: 0.8674\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4420 - accuracy: 0.8859 - val_loss: 0.4918 - val_accuracy: 0.8686\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4310 - accuracy: 0.8875 - val_loss: 0.4853 - val_accuracy: 0.8688\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4255 - accuracy: 0.8890 - val_loss: 0.4807 - val_accuracy: 0.8694\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4223 - accuracy: 0.8892 - val_loss: 0.4793 - val_accuracy: 0.8690\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4208 - accuracy: 0.8896 - val_loss: 0.4787 - val_accuracy: 0.8690\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4200 - accuracy: 0.8895 - val_loss: 0.4785 - val_accuracy: 0.8689\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:11.879630\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8778 - accuracy: 0.6697 - val_loss: 1.1102 - val_accuracy: 0.7816\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9885 - accuracy: 0.7993 - val_loss: 0.9157 - val_accuracy: 0.8079\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8538 - accuracy: 0.8205 - val_loss: 0.8358 - val_accuracy: 0.8204\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8008 - accuracy: 0.8274 - val_loss: 0.7864 - val_accuracy: 0.8305\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7617 - accuracy: 0.8341 - val_loss: 0.7617 - val_accuracy: 0.8341\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7239 - accuracy: 0.8423 - val_loss: 0.7240 - val_accuracy: 0.8356\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6946 - accuracy: 0.8459 - val_loss: 0.6994 - val_accuracy: 0.8446\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6682 - accuracy: 0.8503 - val_loss: 0.6709 - val_accuracy: 0.8472\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6417 - accuracy: 0.8551 - val_loss: 0.6690 - val_accuracy: 0.8457\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6210 - accuracy: 0.8572 - val_loss: 0.6451 - val_accuracy: 0.8486\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6045 - accuracy: 0.8587 - val_loss: 0.6129 - val_accuracy: 0.8555\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5865 - accuracy: 0.8623 - val_loss: 0.5980 - val_accuracy: 0.8584\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5682 - accuracy: 0.8654 - val_loss: 0.5874 - val_accuracy: 0.8600\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5575 - accuracy: 0.8663 - val_loss: 0.5825 - val_accuracy: 0.8579\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5443 - accuracy: 0.8678 - val_loss: 0.5597 - val_accuracy: 0.8629\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5314 - accuracy: 0.8707 - val_loss: 0.5497 - val_accuracy: 0.8639\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5202 - accuracy: 0.8716 - val_loss: 0.5497 - val_accuracy: 0.8603\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5101 - accuracy: 0.8732 - val_loss: 0.5311 - val_accuracy: 0.8659\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4989 - accuracy: 0.8749 - val_loss: 0.5238 - val_accuracy: 0.8660\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4907 - accuracy: 0.8765 - val_loss: 0.5220 - val_accuracy: 0.8672\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.895246\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4607 - accuracy: 0.8835 - val_loss: 0.4951 - val_accuracy: 0.8698\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4406 - accuracy: 0.8870 - val_loss: 0.4801 - val_accuracy: 0.8715\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4299 - accuracy: 0.8887 - val_loss: 0.4733 - val_accuracy: 0.8726\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4240 - accuracy: 0.8900 - val_loss: 0.4700 - val_accuracy: 0.8728\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4209 - accuracy: 0.8904 - val_loss: 0.4683 - val_accuracy: 0.8724\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4194 - accuracy: 0.8905 - val_loss: 0.4677 - val_accuracy: 0.8733\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4186 - accuracy: 0.8905 - val_loss: 0.4674 - val_accuracy: 0.8732\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4183 - accuracy: 0.8906 - val_loss: 0.4674 - val_accuracy: 0.8734\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4182 - accuracy: 0.8907 - val_loss: 0.4673 - val_accuracy: 0.8733\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4181 - accuracy: 0.8907 - val_loss: 0.4673 - val_accuracy: 0.8733\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4181 - accuracy: 0.8907 - val_loss: 0.4673 - val_accuracy: 0.8733\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:55.962713\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9169 - accuracy: 0.6969 - val_loss: 1.1658 - val_accuracy: 0.7739\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0162 - accuracy: 0.8098 - val_loss: 0.9649 - val_accuracy: 0.8184\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9085 - accuracy: 0.8261 - val_loss: 0.8753 - val_accuracy: 0.8310\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8546 - accuracy: 0.8352 - val_loss: 0.8730 - val_accuracy: 0.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8301 - accuracy: 0.8407 - val_loss: 0.8262 - val_accuracy: 0.8374\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7731 - accuracy: 0.8461 - val_loss: 0.7692 - val_accuracy: 0.8467\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7373 - accuracy: 0.8514 - val_loss: 0.7727 - val_accuracy: 0.8463\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7068 - accuracy: 0.8550 - val_loss: 0.7250 - val_accuracy: 0.8508\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6757 - accuracy: 0.8579 - val_loss: 0.6925 - val_accuracy: 0.8524\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6470 - accuracy: 0.8608 - val_loss: 0.7012 - val_accuracy: 0.8465\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6326 - accuracy: 0.8635 - val_loss: 0.6328 - val_accuracy: 0.8549\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6068 - accuracy: 0.8652 - val_loss: 0.6479 - val_accuracy: 0.8552\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5887 - accuracy: 0.8669 - val_loss: 0.6247 - val_accuracy: 0.8596\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5724 - accuracy: 0.8696 - val_loss: 0.6053 - val_accuracy: 0.8595\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5573 - accuracy: 0.8714 - val_loss: 0.5907 - val_accuracy: 0.8650\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5428 - accuracy: 0.8727 - val_loss: 0.5705 - val_accuracy: 0.8628\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5302 - accuracy: 0.8741 - val_loss: 0.5589 - val_accuracy: 0.8665\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5188 - accuracy: 0.8758 - val_loss: 0.5504 - val_accuracy: 0.8667\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5071 - accuracy: 0.8768 - val_loss: 0.5450 - val_accuracy: 0.8650\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4973 - accuracy: 0.8794 - val_loss: 0.5437 - val_accuracy: 0.8651\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:05.325847\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4590 - accuracy: 0.8853 - val_loss: 0.5041 - val_accuracy: 0.8703\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4356 - accuracy: 0.8878 - val_loss: 0.4841 - val_accuracy: 0.8719\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4222 - accuracy: 0.8901 - val_loss: 0.4746 - val_accuracy: 0.8730\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4153 - accuracy: 0.8910 - val_loss: 0.4703 - val_accuracy: 0.8731\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4116 - accuracy: 0.8915 - val_loss: 0.4681 - val_accuracy: 0.8731\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4098 - accuracy: 0.8923 - val_loss: 0.4673 - val_accuracy: 0.8727\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4089 - accuracy: 0.8920 - val_loss: 0.4669 - val_accuracy: 0.8730\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4085 - accuracy: 0.8921 - val_loss: 0.4667 - val_accuracy: 0.8730\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:38.077291\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9660 - accuracy: 0.7015 - val_loss: 1.1536 - val_accuracy: 0.7815\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0102 - accuracy: 0.8072 - val_loss: 0.9552 - val_accuracy: 0.8140\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9002 - accuracy: 0.8240 - val_loss: 0.9011 - val_accuracy: 0.8195\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8427 - accuracy: 0.8339 - val_loss: 0.8565 - val_accuracy: 0.8278\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8140 - accuracy: 0.8404 - val_loss: 0.8448 - val_accuracy: 0.8341\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7629 - accuracy: 0.8464 - val_loss: 0.7695 - val_accuracy: 0.8410\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7222 - accuracy: 0.8520 - val_loss: 0.7569 - val_accuracy: 0.8439\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7024 - accuracy: 0.8545 - val_loss: 0.7155 - val_accuracy: 0.8494\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6642 - accuracy: 0.8589 - val_loss: 0.6916 - val_accuracy: 0.8479\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6406 - accuracy: 0.8621 - val_loss: 0.6776 - val_accuracy: 0.8512\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6250 - accuracy: 0.8640 - val_loss: 0.6595 - val_accuracy: 0.8507\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6008 - accuracy: 0.8658 - val_loss: 0.6368 - val_accuracy: 0.8542\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5851 - accuracy: 0.8681 - val_loss: 0.6287 - val_accuracy: 0.8578\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5668 - accuracy: 0.8703 - val_loss: 0.6040 - val_accuracy: 0.8570\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5502 - accuracy: 0.8724 - val_loss: 0.5904 - val_accuracy: 0.8616\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5393 - accuracy: 0.8737 - val_loss: 0.5767 - val_accuracy: 0.8626\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5236 - accuracy: 0.8753 - val_loss: 0.5689 - val_accuracy: 0.8631\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5126 - accuracy: 0.8756 - val_loss: 0.5569 - val_accuracy: 0.8625\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4995 - accuracy: 0.8801 - val_loss: 0.5544 - val_accuracy: 0.8583\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4922 - accuracy: 0.8792 - val_loss: 0.5438 - val_accuracy: 0.8604\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:04.731567\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4651 - accuracy: 0.8844 - val_loss: 0.5157 - val_accuracy: 0.8660\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4402 - accuracy: 0.8883 - val_loss: 0.4945 - val_accuracy: 0.8681\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4276 - accuracy: 0.8900 - val_loss: 0.4840 - val_accuracy: 0.8690\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4209 - accuracy: 0.8906 - val_loss: 0.4805 - val_accuracy: 0.8686\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4174 - accuracy: 0.8910 - val_loss: 0.4780 - val_accuracy: 0.8695\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4157 - accuracy: 0.8913 - val_loss: 0.4772 - val_accuracy: 0.8695\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4149 - accuracy: 0.8912 - val_loss: 0.4768 - val_accuracy: 0.8691\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4145 - accuracy: 0.8916 - val_loss: 0.4767 - val_accuracy: 0.8693\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4144 - accuracy: 0.8915 - val_loss: 0.4766 - val_accuracy: 0.8693\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:05.145681\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9787 - accuracy: 0.7062 - val_loss: 1.1211 - val_accuracy: 0.7903\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0300 - accuracy: 0.8056 - val_loss: 0.9699 - val_accuracy: 0.8218\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9159 - accuracy: 0.8241 - val_loss: 0.8972 - val_accuracy: 0.8174\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8633 - accuracy: 0.8324 - val_loss: 0.8803 - val_accuracy: 0.8265\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8299 - accuracy: 0.8395 - val_loss: 0.8309 - val_accuracy: 0.8386\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7724 - accuracy: 0.8456 - val_loss: 0.7686 - val_accuracy: 0.8449\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7441 - accuracy: 0.8492 - val_loss: 0.7813 - val_accuracy: 0.8432\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7032 - accuracy: 0.8545 - val_loss: 0.7233 - val_accuracy: 0.8459\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6824 - accuracy: 0.8577 - val_loss: 0.7073 - val_accuracy: 0.8488\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6532 - accuracy: 0.8599 - val_loss: 0.6811 - val_accuracy: 0.8490\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6301 - accuracy: 0.8632 - val_loss: 0.6545 - val_accuracy: 0.8586\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6136 - accuracy: 0.8639 - val_loss: 0.6586 - val_accuracy: 0.8491\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5917 - accuracy: 0.8663 - val_loss: 0.6298 - val_accuracy: 0.8553\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5748 - accuracy: 0.8683 - val_loss: 0.6036 - val_accuracy: 0.8591\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5585 - accuracy: 0.8701 - val_loss: 0.6007 - val_accuracy: 0.8617\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5435 - accuracy: 0.8726 - val_loss: 0.5948 - val_accuracy: 0.8554\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5308 - accuracy: 0.8739 - val_loss: 0.5650 - val_accuracy: 0.8619\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5161 - accuracy: 0.8764 - val_loss: 0.5688 - val_accuracy: 0.8607\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5081 - accuracy: 0.8769 - val_loss: 0.5586 - val_accuracy: 0.8616\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4979 - accuracy: 0.8778 - val_loss: 0.5521 - val_accuracy: 0.8626\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:04.495386\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4590 - accuracy: 0.8840 - val_loss: 0.5147 - val_accuracy: 0.8676\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4350 - accuracy: 0.8884 - val_loss: 0.4921 - val_accuracy: 0.8694\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4221 - accuracy: 0.8898 - val_loss: 0.4820 - val_accuracy: 0.8713\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4146 - accuracy: 0.8907 - val_loss: 0.4774 - val_accuracy: 0.8706\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4108 - accuracy: 0.8910 - val_loss: 0.4757 - val_accuracy: 0.8712\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4090 - accuracy: 0.8915 - val_loss: 0.4747 - val_accuracy: 0.8713\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:43.563250\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9623 - accuracy: 0.6941 - val_loss: 1.1897 - val_accuracy: 0.7775\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0389 - accuracy: 0.8025 - val_loss: 0.9418 - val_accuracy: 0.8203\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9142 - accuracy: 0.8215 - val_loss: 0.9007 - val_accuracy: 0.8316\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8532 - accuracy: 0.8318 - val_loss: 0.8839 - val_accuracy: 0.8258\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8340 - accuracy: 0.8373 - val_loss: 0.8283 - val_accuracy: 0.8394\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7636 - accuracy: 0.8451 - val_loss: 0.7795 - val_accuracy: 0.8412\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7391 - accuracy: 0.8483 - val_loss: 0.7556 - val_accuracy: 0.8439\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7030 - accuracy: 0.8537 - val_loss: 0.7276 - val_accuracy: 0.8491\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6785 - accuracy: 0.8560 - val_loss: 0.7101 - val_accuracy: 0.8486\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6498 - accuracy: 0.8586 - val_loss: 0.6767 - val_accuracy: 0.8544\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6254 - accuracy: 0.8612 - val_loss: 0.6550 - val_accuracy: 0.8560\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6073 - accuracy: 0.8641 - val_loss: 0.6366 - val_accuracy: 0.8587\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5856 - accuracy: 0.8662 - val_loss: 0.6272 - val_accuracy: 0.8550\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5698 - accuracy: 0.8686 - val_loss: 0.6015 - val_accuracy: 0.8598\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5564 - accuracy: 0.8708 - val_loss: 0.5823 - val_accuracy: 0.8635\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5402 - accuracy: 0.8708 - val_loss: 0.5824 - val_accuracy: 0.8603\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5297 - accuracy: 0.8727 - val_loss: 0.5634 - val_accuracy: 0.8627\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5171 - accuracy: 0.8744 - val_loss: 0.5500 - val_accuracy: 0.8675\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5054 - accuracy: 0.8765 - val_loss: 0.5492 - val_accuracy: 0.8660\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4962 - accuracy: 0.8773 - val_loss: 0.5336 - val_accuracy: 0.8663\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:04.262814\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4592 - accuracy: 0.8836 - val_loss: 0.5022 - val_accuracy: 0.8705\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4363 - accuracy: 0.8870 - val_loss: 0.4872 - val_accuracy: 0.8731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4237 - accuracy: 0.8888 - val_loss: 0.4762 - val_accuracy: 0.8738\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4171 - accuracy: 0.8903 - val_loss: 0.4716 - val_accuracy: 0.8734\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4136 - accuracy: 0.8910 - val_loss: 0.4699 - val_accuracy: 0.8727\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4119 - accuracy: 0.8914 - val_loss: 0.4690 - val_accuracy: 0.8734\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:43.051502\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9357 - accuracy: 0.7005 - val_loss: 1.1233 - val_accuracy: 0.7894\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0083 - accuracy: 0.8053 - val_loss: 0.9855 - val_accuracy: 0.8020\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9037 - accuracy: 0.8215 - val_loss: 0.8940 - val_accuracy: 0.8258\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8462 - accuracy: 0.8324 - val_loss: 0.8494 - val_accuracy: 0.8287\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8154 - accuracy: 0.8381 - val_loss: 0.8382 - val_accuracy: 0.8338\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7592 - accuracy: 0.8452 - val_loss: 0.7918 - val_accuracy: 0.8415\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7311 - accuracy: 0.8499 - val_loss: 0.7535 - val_accuracy: 0.8434\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6984 - accuracy: 0.8539 - val_loss: 0.7229 - val_accuracy: 0.8458\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6689 - accuracy: 0.8563 - val_loss: 0.7082 - val_accuracy: 0.8530\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6476 - accuracy: 0.8594 - val_loss: 0.6775 - val_accuracy: 0.8520\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6252 - accuracy: 0.8625 - val_loss: 0.6531 - val_accuracy: 0.8558\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6054 - accuracy: 0.8638 - val_loss: 0.6448 - val_accuracy: 0.8548\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5882 - accuracy: 0.8673 - val_loss: 0.6377 - val_accuracy: 0.8562\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5742 - accuracy: 0.8689 - val_loss: 0.6160 - val_accuracy: 0.8582\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5578 - accuracy: 0.8700 - val_loss: 0.6013 - val_accuracy: 0.8621\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5443 - accuracy: 0.8725 - val_loss: 0.5855 - val_accuracy: 0.8616\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5284 - accuracy: 0.8740 - val_loss: 0.5804 - val_accuracy: 0.8600\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5160 - accuracy: 0.8763 - val_loss: 0.5712 - val_accuracy: 0.8585\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:09.891008\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4874 - accuracy: 0.8818 - val_loss: 0.5299 - val_accuracy: 0.8664\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4589 - accuracy: 0.8848 - val_loss: 0.5097 - val_accuracy: 0.8683\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4445 - accuracy: 0.8865 - val_loss: 0.4989 - val_accuracy: 0.8699\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4364 - accuracy: 0.8880 - val_loss: 0.4937 - val_accuracy: 0.8704\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4322 - accuracy: 0.8875 - val_loss: 0.4910 - val_accuracy: 0.8707\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4302 - accuracy: 0.8886 - val_loss: 0.4898 - val_accuracy: 0.8711\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4292 - accuracy: 0.8887 - val_loss: 0.4893 - val_accuracy: 0.8708\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4287 - accuracy: 0.8887 - val_loss: 0.4892 - val_accuracy: 0.8709\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4286 - accuracy: 0.8887 - val_loss: 0.4891 - val_accuracy: 0.8709\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:05.232693\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9475 - accuracy: 0.6802 - val_loss: 1.1476 - val_accuracy: 0.7897\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0492 - accuracy: 0.7971 - val_loss: 0.9579 - val_accuracy: 0.8124\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9063 - accuracy: 0.8168 - val_loss: 0.8836 - val_accuracy: 0.8150\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8407 - accuracy: 0.8271 - val_loss: 0.8275 - val_accuracy: 0.8254\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7978 - accuracy: 0.8338 - val_loss: 0.7840 - val_accuracy: 0.8403\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7480 - accuracy: 0.8419 - val_loss: 0.7553 - val_accuracy: 0.8421\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7186 - accuracy: 0.8466 - val_loss: 0.7365 - val_accuracy: 0.8422\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6919 - accuracy: 0.8505 - val_loss: 0.6977 - val_accuracy: 0.8439\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6628 - accuracy: 0.8535 - val_loss: 0.6720 - val_accuracy: 0.8539\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6400 - accuracy: 0.8562 - val_loss: 0.6609 - val_accuracy: 0.8530\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6202 - accuracy: 0.8595 - val_loss: 0.6367 - val_accuracy: 0.8545\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6027 - accuracy: 0.8613 - val_loss: 0.6312 - val_accuracy: 0.8537\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5866 - accuracy: 0.8634 - val_loss: 0.6081 - val_accuracy: 0.8580\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5734 - accuracy: 0.8651 - val_loss: 0.5934 - val_accuracy: 0.8605\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5545 - accuracy: 0.8676 - val_loss: 0.5851 - val_accuracy: 0.8624\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5423 - accuracy: 0.8696 - val_loss: 0.5716 - val_accuracy: 0.8646\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5327 - accuracy: 0.8696 - val_loss: 0.5587 - val_accuracy: 0.8666\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5200 - accuracy: 0.8726 - val_loss: 0.5523 - val_accuracy: 0.8621\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5091 - accuracy: 0.8735 - val_loss: 0.5479 - val_accuracy: 0.8631\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4993 - accuracy: 0.8754 - val_loss: 0.5297 - val_accuracy: 0.8658\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:25.367484\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4759 - accuracy: 0.8802 - val_loss: 0.5114 - val_accuracy: 0.8703\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4540 - accuracy: 0.8831 - val_loss: 0.4961 - val_accuracy: 0.8714\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4428 - accuracy: 0.8851 - val_loss: 0.4879 - val_accuracy: 0.8723\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4362 - accuracy: 0.8862 - val_loss: 0.4842 - val_accuracy: 0.8719\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4330 - accuracy: 0.8868 - val_loss: 0.4826 - val_accuracy: 0.8722\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4314 - accuracy: 0.8873 - val_loss: 0.4816 - val_accuracy: 0.8721\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:49.302314\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9404 - accuracy: 0.6786 - val_loss: 1.1840 - val_accuracy: 0.7680\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0268 - accuracy: 0.7969 - val_loss: 0.9679 - val_accuracy: 0.8114\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8986 - accuracy: 0.8160 - val_loss: 0.8839 - val_accuracy: 0.8170\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8451 - accuracy: 0.8251 - val_loss: 0.8417 - val_accuracy: 0.8220\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8063 - accuracy: 0.8319 - val_loss: 0.8058 - val_accuracy: 0.8350\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7557 - accuracy: 0.8396 - val_loss: 0.7636 - val_accuracy: 0.8375\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7262 - accuracy: 0.8433 - val_loss: 0.7595 - val_accuracy: 0.8389\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6960 - accuracy: 0.8485 - val_loss: 0.7239 - val_accuracy: 0.8404\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6717 - accuracy: 0.8512 - val_loss: 0.6973 - val_accuracy: 0.8491\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6456 - accuracy: 0.8539 - val_loss: 0.6794 - val_accuracy: 0.8469\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6247 - accuracy: 0.8572 - val_loss: 0.6565 - val_accuracy: 0.8494\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6052 - accuracy: 0.8598 - val_loss: 0.6368 - val_accuracy: 0.8546\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5924 - accuracy: 0.8610 - val_loss: 0.6186 - val_accuracy: 0.8533\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5749 - accuracy: 0.8634 - val_loss: 0.6133 - val_accuracy: 0.8529\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5615 - accuracy: 0.8657 - val_loss: 0.6031 - val_accuracy: 0.8575\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5472 - accuracy: 0.8680 - val_loss: 0.5836 - val_accuracy: 0.8590\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5338 - accuracy: 0.8691 - val_loss: 0.5811 - val_accuracy: 0.8553\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5249 - accuracy: 0.8701 - val_loss: 0.5737 - val_accuracy: 0.8589\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5138 - accuracy: 0.8725 - val_loss: 0.5684 - val_accuracy: 0.8610\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5053 - accuracy: 0.8726 - val_loss: 0.5474 - val_accuracy: 0.8648\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:24.722895\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4686 - accuracy: 0.8801 - val_loss: 0.5224 - val_accuracy: 0.8673\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4485 - accuracy: 0.8826 - val_loss: 0.5036 - val_accuracy: 0.8693\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4369 - accuracy: 0.8841 - val_loss: 0.4950 - val_accuracy: 0.8689\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4306 - accuracy: 0.8860 - val_loss: 0.4912 - val_accuracy: 0.8702\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4272 - accuracy: 0.8868 - val_loss: 0.4895 - val_accuracy: 0.8702\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4255 - accuracy: 0.8870 - val_loss: 0.4887 - val_accuracy: 0.8704\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4247 - accuracy: 0.8870 - val_loss: 0.4884 - val_accuracy: 0.8701\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4244 - accuracy: 0.8871 - val_loss: 0.4883 - val_accuracy: 0.8699\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4242 - accuracy: 0.8872 - val_loss: 0.4883 - val_accuracy: 0.8700\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:13.524924\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9781 - accuracy: 0.6840 - val_loss: 1.1430 - val_accuracy: 0.7797\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0299 - accuracy: 0.7953 - val_loss: 0.9917 - val_accuracy: 0.7879\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9066 - accuracy: 0.8163 - val_loss: 0.9021 - val_accuracy: 0.8218\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8418 - accuracy: 0.8272 - val_loss: 0.8171 - val_accuracy: 0.8224\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7983 - accuracy: 0.8344 - val_loss: 0.8083 - val_accuracy: 0.8303\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7553 - accuracy: 0.8396 - val_loss: 0.7642 - val_accuracy: 0.8355\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7204 - accuracy: 0.8454 - val_loss: 0.7756 - val_accuracy: 0.8347\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6923 - accuracy: 0.8491 - val_loss: 0.7193 - val_accuracy: 0.8417\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6637 - accuracy: 0.8519 - val_loss: 0.6932 - val_accuracy: 0.8459\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6441 - accuracy: 0.8543 - val_loss: 0.6630 - val_accuracy: 0.8465\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6218 - accuracy: 0.8576 - val_loss: 0.6431 - val_accuracy: 0.8480\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6003 - accuracy: 0.8617 - val_loss: 0.6275 - val_accuracy: 0.8531\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5881 - accuracy: 0.8623 - val_loss: 0.6314 - val_accuracy: 0.8508\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5723 - accuracy: 0.8652 - val_loss: 0.6083 - val_accuracy: 0.8532\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5577 - accuracy: 0.8655 - val_loss: 0.5873 - val_accuracy: 0.8578\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5441 - accuracy: 0.8681 - val_loss: 0.5824 - val_accuracy: 0.8538\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5324 - accuracy: 0.8701 - val_loss: 0.5675 - val_accuracy: 0.8595\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5209 - accuracy: 0.8713 - val_loss: 0.5666 - val_accuracy: 0.8572\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5109 - accuracy: 0.8735 - val_loss: 0.5563 - val_accuracy: 0.8585\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5023 - accuracy: 0.8750 - val_loss: 0.5427 - val_accuracy: 0.8604\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:21.150693\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4677 - accuracy: 0.8800 - val_loss: 0.5145 - val_accuracy: 0.8646\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4475 - accuracy: 0.8828 - val_loss: 0.4976 - val_accuracy: 0.8659\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4362 - accuracy: 0.8855 - val_loss: 0.4888 - val_accuracy: 0.8667\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4299 - accuracy: 0.8865 - val_loss: 0.4857 - val_accuracy: 0.8684\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4267 - accuracy: 0.8875 - val_loss: 0.4842 - val_accuracy: 0.8683\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4250 - accuracy: 0.8875 - val_loss: 0.4833 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4243 - accuracy: 0.8876 - val_loss: 0.4830 - val_accuracy: 0.8680\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:16.800696\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9908 - accuracy: 0.6863 - val_loss: 1.1010 - val_accuracy: 0.7929\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0033 - accuracy: 0.8026 - val_loss: 0.9322 - val_accuracy: 0.8127\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8869 - accuracy: 0.8204 - val_loss: 0.8630 - val_accuracy: 0.8231\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8267 - accuracy: 0.8308 - val_loss: 0.8124 - val_accuracy: 0.8322\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7921 - accuracy: 0.8354 - val_loss: 0.8154 - val_accuracy: 0.8275\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7453 - accuracy: 0.8427 - val_loss: 0.7708 - val_accuracy: 0.8310\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7096 - accuracy: 0.8481 - val_loss: 0.7371 - val_accuracy: 0.8402\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6879 - accuracy: 0.8501 - val_loss: 0.6945 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6611 - accuracy: 0.8542 - val_loss: 0.6964 - val_accuracy: 0.8513\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6395 - accuracy: 0.8575 - val_loss: 0.6715 - val_accuracy: 0.8505\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6207 - accuracy: 0.8595 - val_loss: 0.6454 - val_accuracy: 0.8532\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5982 - accuracy: 0.8625 - val_loss: 0.6253 - val_accuracy: 0.8571\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5828 - accuracy: 0.8634 - val_loss: 0.6137 - val_accuracy: 0.8572\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5674 - accuracy: 0.8658 - val_loss: 0.6122 - val_accuracy: 0.8503\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5549 - accuracy: 0.8680 - val_loss: 0.5922 - val_accuracy: 0.8570\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5410 - accuracy: 0.8691 - val_loss: 0.5880 - val_accuracy: 0.8551\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:30.188104\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5082 - accuracy: 0.8758 - val_loss: 0.5492 - val_accuracy: 0.8625\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4777 - accuracy: 0.8793 - val_loss: 0.5224 - val_accuracy: 0.8644\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4618 - accuracy: 0.8819 - val_loss: 0.5106 - val_accuracy: 0.8662\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4530 - accuracy: 0.8829 - val_loss: 0.5046 - val_accuracy: 0.8669\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4485 - accuracy: 0.8834 - val_loss: 0.5025 - val_accuracy: 0.8665\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4462 - accuracy: 0.8843 - val_loss: 0.5012 - val_accuracy: 0.8664\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4452 - accuracy: 0.8846 - val_loss: 0.5007 - val_accuracy: 0.8663\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:16.788124\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0067 - accuracy: 0.6766 - val_loss: 1.1761 - val_accuracy: 0.7717\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0486 - accuracy: 0.7909 - val_loss: 0.9753 - val_accuracy: 0.8079\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9124 - accuracy: 0.8139 - val_loss: 0.8845 - val_accuracy: 0.8198\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8533 - accuracy: 0.8256 - val_loss: 0.8149 - val_accuracy: 0.8293\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8163 - accuracy: 0.8325 - val_loss: 0.8047 - val_accuracy: 0.8289\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7694 - accuracy: 0.8382 - val_loss: 0.7728 - val_accuracy: 0.8343\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7310 - accuracy: 0.8437 - val_loss: 0.7290 - val_accuracy: 0.8389\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7077 - accuracy: 0.8476 - val_loss: 0.7143 - val_accuracy: 0.8420\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6763 - accuracy: 0.8521 - val_loss: 0.6881 - val_accuracy: 0.8496\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6555 - accuracy: 0.8551 - val_loss: 0.6712 - val_accuracy: 0.8461\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6331 - accuracy: 0.8565 - val_loss: 0.6564 - val_accuracy: 0.8457\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6152 - accuracy: 0.8604 - val_loss: 0.6375 - val_accuracy: 0.8491\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:37.520135\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5720 - accuracy: 0.8666 - val_loss: 0.5926 - val_accuracy: 0.8542\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5260 - accuracy: 0.8722 - val_loss: 0.5512 - val_accuracy: 0.8578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5021 - accuracy: 0.8745 - val_loss: 0.5344 - val_accuracy: 0.8593\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4884 - accuracy: 0.8771 - val_loss: 0.5249 - val_accuracy: 0.8603\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4815 - accuracy: 0.8780 - val_loss: 0.5195 - val_accuracy: 0.8612\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4778 - accuracy: 0.8787 - val_loss: 0.5176 - val_accuracy: 0.8624\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4762 - accuracy: 0.8789 - val_loss: 0.5167 - val_accuracy: 0.8623\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4754 - accuracy: 0.8790 - val_loss: 0.5164 - val_accuracy: 0.8621\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4751 - accuracy: 0.8792 - val_loss: 0.5163 - val_accuracy: 0.8621\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:12.463468\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0505 - accuracy: 0.7322 - val_loss: 0.7012 - val_accuracy: 0.8214\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6139 - accuracy: 0.8367 - val_loss: 0.5871 - val_accuracy: 0.8422\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5302 - accuracy: 0.8528 - val_loss: 0.5403 - val_accuracy: 0.8531\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4864 - accuracy: 0.8631 - val_loss: 0.5153 - val_accuracy: 0.8582\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4589 - accuracy: 0.8694 - val_loss: 0.4907 - val_accuracy: 0.8616\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4336 - accuracy: 0.8756 - val_loss: 0.4983 - val_accuracy: 0.8618\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4104 - accuracy: 0.8809 - val_loss: 0.4608 - val_accuracy: 0.8723\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3893 - accuracy: 0.8864 - val_loss: 0.4692 - val_accuracy: 0.8660\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.3728 - accuracy: 0.8899 - val_loss: 0.4571 - val_accuracy: 0.8702\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.3566 - accuracy: 0.8937 - val_loss: 0.4515 - val_accuracy: 0.8735\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3412 - accuracy: 0.8984 - val_loss: 0.4317 - val_accuracy: 0.8738\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3258 - accuracy: 0.9023 - val_loss: 0.4452 - val_accuracy: 0.8747\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3112 - accuracy: 0.9070 - val_loss: 0.4389 - val_accuracy: 0.8769\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2987 - accuracy: 0.9107 - val_loss: 0.4479 - val_accuracy: 0.8708\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2857 - accuracy: 0.9137 - val_loss: 0.4276 - val_accuracy: 0.8791\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2726 - accuracy: 0.9188 - val_loss: 0.4418 - val_accuracy: 0.8773\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2617 - accuracy: 0.9214 - val_loss: 0.4427 - val_accuracy: 0.8754\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.2505 - accuracy: 0.9250 - val_loss: 0.4422 - val_accuracy: 0.8762\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:00.148636\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.2464 - accuracy: 0.9285 - val_loss: 0.4182 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2284 - accuracy: 0.9346 - val_loss: 0.4164 - val_accuracy: 0.8833\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2195 - accuracy: 0.9385 - val_loss: 0.4157 - val_accuracy: 0.8843\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2148 - accuracy: 0.9403 - val_loss: 0.4161 - val_accuracy: 0.8844\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2123 - accuracy: 0.9414 - val_loss: 0.4158 - val_accuracy: 0.8840\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2111 - accuracy: 0.9415 - val_loss: 0.4160 - val_accuracy: 0.8841\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2105 - accuracy: 0.9418 - val_loss: 0.4160 - val_accuracy: 0.8840\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:11.229091\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0724 - accuracy: 0.7255 - val_loss: 0.6881 - val_accuracy: 0.8160\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6097 - accuracy: 0.8364 - val_loss: 0.5792 - val_accuracy: 0.8388\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5283 - accuracy: 0.8521 - val_loss: 0.5168 - val_accuracy: 0.8538\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4841 - accuracy: 0.8628 - val_loss: 0.5008 - val_accuracy: 0.8592\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4572 - accuracy: 0.8687 - val_loss: 0.4928 - val_accuracy: 0.8562\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4294 - accuracy: 0.8761 - val_loss: 0.4521 - val_accuracy: 0.8683\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4066 - accuracy: 0.8822 - val_loss: 0.4506 - val_accuracy: 0.8656\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3883 - accuracy: 0.8863 - val_loss: 0.4581 - val_accuracy: 0.8668\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3713 - accuracy: 0.8907 - val_loss: 0.4328 - val_accuracy: 0.8715\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3554 - accuracy: 0.8960 - val_loss: 0.4327 - val_accuracy: 0.8728\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3393 - accuracy: 0.8994 - val_loss: 0.4297 - val_accuracy: 0.8719\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3256 - accuracy: 0.9026 - val_loss: 0.4244 - val_accuracy: 0.8748\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3118 - accuracy: 0.9068 - val_loss: 0.4307 - val_accuracy: 0.8734\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2984 - accuracy: 0.9100 - val_loss: 0.4322 - val_accuracy: 0.8752\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2871 - accuracy: 0.9139 - val_loss: 0.4142 - val_accuracy: 0.8780\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2744 - accuracy: 0.9172 - val_loss: 0.4262 - val_accuracy: 0.8756\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.2641 - accuracy: 0.9206 - val_loss: 0.4254 - val_accuracy: 0.8756\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2524 - accuracy: 0.9246 - val_loss: 0.4188 - val_accuracy: 0.8745\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:58.491439\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2489 - accuracy: 0.9278 - val_loss: 0.4110 - val_accuracy: 0.8781\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2317 - accuracy: 0.9349 - val_loss: 0.4050 - val_accuracy: 0.8817\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2232 - accuracy: 0.9376 - val_loss: 0.4023 - val_accuracy: 0.8833\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2190 - accuracy: 0.9393 - val_loss: 0.4020 - val_accuracy: 0.8838\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.2165 - accuracy: 0.9404 - val_loss: 0.4022 - val_accuracy: 0.8838\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.2155 - accuracy: 0.9411 - val_loss: 0.4021 - val_accuracy: 0.8830\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2149 - accuracy: 0.9411 - val_loss: 0.4021 - val_accuracy: 0.8834\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2147 - accuracy: 0.9413 - val_loss: 0.4021 - val_accuracy: 0.8834\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:33.495746\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0703 - accuracy: 0.7241 - val_loss: 0.6841 - val_accuracy: 0.8194\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6183 - accuracy: 0.8337 - val_loss: 0.5800 - val_accuracy: 0.8422\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5343 - accuracy: 0.8535 - val_loss: 0.5308 - val_accuracy: 0.8477\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4906 - accuracy: 0.8605 - val_loss: 0.5010 - val_accuracy: 0.8557\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4601 - accuracy: 0.8686 - val_loss: 0.4919 - val_accuracy: 0.8590\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4351 - accuracy: 0.8755 - val_loss: 0.4674 - val_accuracy: 0.8675\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4104 - accuracy: 0.8810 - val_loss: 0.4587 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3913 - accuracy: 0.8862 - val_loss: 0.4522 - val_accuracy: 0.8679\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3740 - accuracy: 0.8908 - val_loss: 0.4422 - val_accuracy: 0.8699\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3563 - accuracy: 0.8953 - val_loss: 0.4501 - val_accuracy: 0.8677\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3404 - accuracy: 0.8997 - val_loss: 0.4384 - val_accuracy: 0.8696\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3272 - accuracy: 0.9030 - val_loss: 0.4334 - val_accuracy: 0.8720\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3127 - accuracy: 0.9072 - val_loss: 0.4404 - val_accuracy: 0.8694\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2994 - accuracy: 0.9106 - val_loss: 0.4317 - val_accuracy: 0.8715\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2868 - accuracy: 0.9145 - val_loss: 0.4271 - val_accuracy: 0.8725\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2739 - accuracy: 0.9177 - val_loss: 0.4277 - val_accuracy: 0.8738\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2626 - accuracy: 0.9213 - val_loss: 0.4379 - val_accuracy: 0.8690\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2514 - accuracy: 0.9262 - val_loss: 0.4399 - val_accuracy: 0.8695\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2417 - accuracy: 0.9281 - val_loss: 0.4362 - val_accuracy: 0.8714\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:29.315783\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2388 - accuracy: 0.9317 - val_loss: 0.4155 - val_accuracy: 0.8777\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2230 - accuracy: 0.9372 - val_loss: 0.4137 - val_accuracy: 0.8784\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2153 - accuracy: 0.9403 - val_loss: 0.4137 - val_accuracy: 0.8787\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2112 - accuracy: 0.9418 - val_loss: 0.4132 - val_accuracy: 0.8785\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2090 - accuracy: 0.9430 - val_loss: 0.4134 - val_accuracy: 0.8785\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2080 - accuracy: 0.9433 - val_loss: 0.4134 - val_accuracy: 0.8791\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2075 - accuracy: 0.9434 - val_loss: 0.4135 - val_accuracy: 0.8788\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2073 - accuracy: 0.9436 - val_loss: 0.4135 - val_accuracy: 0.8784\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2072 - accuracy: 0.9436 - val_loss: 0.4135 - val_accuracy: 0.8784\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:01.536546\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0589 - accuracy: 0.7294 - val_loss: 0.6665 - val_accuracy: 0.8262\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6174 - accuracy: 0.8344 - val_loss: 0.5615 - val_accuracy: 0.8482\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5331 - accuracy: 0.8522 - val_loss: 0.5210 - val_accuracy: 0.8531\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4882 - accuracy: 0.8600 - val_loss: 0.4954 - val_accuracy: 0.8583\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4623 - accuracy: 0.8680 - val_loss: 0.4869 - val_accuracy: 0.8627\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4345 - accuracy: 0.8755 - val_loss: 0.4674 - val_accuracy: 0.8668\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4127 - accuracy: 0.8814 - val_loss: 0.4611 - val_accuracy: 0.8668\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3936 - accuracy: 0.8855 - val_loss: 0.4513 - val_accuracy: 0.8664\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3772 - accuracy: 0.8894 - val_loss: 0.4393 - val_accuracy: 0.8714\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3596 - accuracy: 0.8943 - val_loss: 0.4311 - val_accuracy: 0.8708\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3426 - accuracy: 0.8988 - val_loss: 0.4248 - val_accuracy: 0.8746\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3284 - accuracy: 0.9020 - val_loss: 0.4239 - val_accuracy: 0.8722\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3157 - accuracy: 0.9065 - val_loss: 0.4277 - val_accuracy: 0.8726\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2996 - accuracy: 0.9104 - val_loss: 0.4226 - val_accuracy: 0.8770\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2877 - accuracy: 0.9134 - val_loss: 0.4235 - val_accuracy: 0.8757\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2757 - accuracy: 0.9175 - val_loss: 0.4352 - val_accuracy: 0.8708\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2635 - accuracy: 0.9211 - val_loss: 0.4273 - val_accuracy: 0.8734\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:38.184298\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2582 - accuracy: 0.9248 - val_loss: 0.4027 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2390 - accuracy: 0.9326 - val_loss: 0.4016 - val_accuracy: 0.8825\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2288 - accuracy: 0.9359 - val_loss: 0.4009 - val_accuracy: 0.8832\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2234 - accuracy: 0.9380 - val_loss: 0.4003 - val_accuracy: 0.8828\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2206 - accuracy: 0.9395 - val_loss: 0.3997 - val_accuracy: 0.8838\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.2192 - accuracy: 0.9393 - val_loss: 0.4000 - val_accuracy: 0.8836\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2186 - accuracy: 0.9400 - val_loss: 0.4000 - val_accuracy: 0.8837\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.2183 - accuracy: 0.9399 - val_loss: 0.4000 - val_accuracy: 0.8838\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:35.570568\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0606 - accuracy: 0.7297 - val_loss: 0.7121 - val_accuracy: 0.8131\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6093 - accuracy: 0.8371 - val_loss: 0.5842 - val_accuracy: 0.8387\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5247 - accuracy: 0.8544 - val_loss: 0.5348 - val_accuracy: 0.8477\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4843 - accuracy: 0.8610 - val_loss: 0.5128 - val_accuracy: 0.8526\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4546 - accuracy: 0.8695 - val_loss: 0.4978 - val_accuracy: 0.8570\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4289 - accuracy: 0.8759 - val_loss: 0.4839 - val_accuracy: 0.8570\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4091 - accuracy: 0.8811 - val_loss: 0.4811 - val_accuracy: 0.8629\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3896 - accuracy: 0.8857 - val_loss: 0.4555 - val_accuracy: 0.8676\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3714 - accuracy: 0.8905 - val_loss: 0.4508 - val_accuracy: 0.8701\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3569 - accuracy: 0.8951 - val_loss: 0.4517 - val_accuracy: 0.8687\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3418 - accuracy: 0.8980 - val_loss: 0.4523 - val_accuracy: 0.8696\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3260 - accuracy: 0.9022 - val_loss: 0.4474 - val_accuracy: 0.8679\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:34.564739\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3163 - accuracy: 0.9076 - val_loss: 0.4270 - val_accuracy: 0.8758\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2878 - accuracy: 0.9171 - val_loss: 0.4121 - val_accuracy: 0.8803\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2721 - accuracy: 0.9214 - val_loss: 0.4101 - val_accuracy: 0.8807\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2636 - accuracy: 0.9250 - val_loss: 0.4096 - val_accuracy: 0.8810\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2591 - accuracy: 0.9266 - val_loss: 0.4090 - val_accuracy: 0.8812\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2570 - accuracy: 0.9278 - val_loss: 0.4087 - val_accuracy: 0.8809\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2560 - accuracy: 0.9276 - val_loss: 0.4087 - val_accuracy: 0.8809\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2556 - accuracy: 0.9280 - val_loss: 0.4087 - val_accuracy: 0.8809\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:41.603804\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0042 - accuracy: 0.7554 - val_loss: 0.6599 - val_accuracy: 0.8348\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5822 - accuracy: 0.8448 - val_loss: 0.5539 - val_accuracy: 0.8512\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5086 - accuracy: 0.8577 - val_loss: 0.5280 - val_accuracy: 0.8479\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4754 - accuracy: 0.8661 - val_loss: 0.5056 - val_accuracy: 0.8563\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4547 - accuracy: 0.8708 - val_loss: 0.5036 - val_accuracy: 0.8568\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4278 - accuracy: 0.8779 - val_loss: 0.4912 - val_accuracy: 0.8615\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4065 - accuracy: 0.8830 - val_loss: 0.4697 - val_accuracy: 0.8641\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3864 - accuracy: 0.8879 - val_loss: 0.4609 - val_accuracy: 0.8685\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3686 - accuracy: 0.8930 - val_loss: 0.4551 - val_accuracy: 0.8678\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3512 - accuracy: 0.8970 - val_loss: 0.4531 - val_accuracy: 0.8673\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3341 - accuracy: 0.9014 - val_loss: 0.4396 - val_accuracy: 0.8714\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3183 - accuracy: 0.9059 - val_loss: 0.4423 - val_accuracy: 0.8723\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3041 - accuracy: 0.9094 - val_loss: 0.4332 - val_accuracy: 0.8748\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2898 - accuracy: 0.9136 - val_loss: 0.4381 - val_accuracy: 0.8699\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2766 - accuracy: 0.9175 - val_loss: 0.4333 - val_accuracy: 0.8740\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2650 - accuracy: 0.9212 - val_loss: 0.4373 - val_accuracy: 0.8777\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2537 - accuracy: 0.9249 - val_loss: 0.4369 - val_accuracy: 0.8749\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2423 - accuracy: 0.9283 - val_loss: 0.4426 - val_accuracy: 0.8737\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2319 - accuracy: 0.9319 - val_loss: 0.4399 - val_accuracy: 0.8753\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:46.170813\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2296 - accuracy: 0.9350 - val_loss: 0.4165 - val_accuracy: 0.8807\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2120 - accuracy: 0.9415 - val_loss: 0.4161 - val_accuracy: 0.8816\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2036 - accuracy: 0.9451 - val_loss: 0.4162 - val_accuracy: 0.8805\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.1993 - accuracy: 0.9467 - val_loss: 0.4159 - val_accuracy: 0.8826\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1970 - accuracy: 0.9474 - val_loss: 0.4160 - val_accuracy: 0.8831\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1959 - accuracy: 0.9481 - val_loss: 0.4163 - val_accuracy: 0.8828\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1954 - accuracy: 0.9485 - val_loss: 0.4163 - val_accuracy: 0.8829\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.1952 - accuracy: 0.9485 - val_loss: 0.4163 - val_accuracy: 0.8830\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:41.300900\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0151 - accuracy: 0.7513 - val_loss: 0.6601 - val_accuracy: 0.8311\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5809 - accuracy: 0.8461 - val_loss: 0.5529 - val_accuracy: 0.8458\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5081 - accuracy: 0.8583 - val_loss: 0.5295 - val_accuracy: 0.8490\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4751 - accuracy: 0.8653 - val_loss: 0.5044 - val_accuracy: 0.8548\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4509 - accuracy: 0.8719 - val_loss: 0.4941 - val_accuracy: 0.8586\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4272 - accuracy: 0.8788 - val_loss: 0.4753 - val_accuracy: 0.8613\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4039 - accuracy: 0.8837 - val_loss: 0.4649 - val_accuracy: 0.8680\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3835 - accuracy: 0.8895 - val_loss: 0.4647 - val_accuracy: 0.8638\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3641 - accuracy: 0.8938 - val_loss: 0.4450 - val_accuracy: 0.8707\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3470 - accuracy: 0.8990 - val_loss: 0.4506 - val_accuracy: 0.8688\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3326 - accuracy: 0.9010 - val_loss: 0.4404 - val_accuracy: 0.8707\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3171 - accuracy: 0.9066 - val_loss: 0.4418 - val_accuracy: 0.8704\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:31.172856\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3051 - accuracy: 0.9135 - val_loss: 0.4140 - val_accuracy: 0.8784\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2757 - accuracy: 0.9219 - val_loss: 0.4080 - val_accuracy: 0.8787\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2602 - accuracy: 0.9269 - val_loss: 0.4037 - val_accuracy: 0.8800\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2515 - accuracy: 0.9301 - val_loss: 0.4027 - val_accuracy: 0.8805\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2471 - accuracy: 0.9312 - val_loss: 0.4020 - val_accuracy: 0.8800\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2449 - accuracy: 0.9320 - val_loss: 0.4018 - val_accuracy: 0.8801\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2438 - accuracy: 0.9326 - val_loss: 0.4018 - val_accuracy: 0.8806\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2434 - accuracy: 0.9328 - val_loss: 0.4018 - val_accuracy: 0.8804\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2432 - accuracy: 0.9329 - val_loss: 0.4018 - val_accuracy: 0.8804\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2432 - accuracy: 0.9328 - val_loss: 0.4018 - val_accuracy: 0.8804\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:35.982240\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0285 - accuracy: 0.7497 - val_loss: 0.6688 - val_accuracy: 0.8287\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5935 - accuracy: 0.8406 - val_loss: 0.5511 - val_accuracy: 0.8516\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5136 - accuracy: 0.8553 - val_loss: 0.5259 - val_accuracy: 0.8547\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4777 - accuracy: 0.8639 - val_loss: 0.5024 - val_accuracy: 0.8599\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4582 - accuracy: 0.8689 - val_loss: 0.4884 - val_accuracy: 0.8660\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4294 - accuracy: 0.8756 - val_loss: 0.4978 - val_accuracy: 0.8559\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4080 - accuracy: 0.8821 - val_loss: 0.4641 - val_accuracy: 0.8691\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3865 - accuracy: 0.8866 - val_loss: 0.4607 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3697 - accuracy: 0.8912 - val_loss: 0.4521 - val_accuracy: 0.8707\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3537 - accuracy: 0.8950 - val_loss: 0.4372 - val_accuracy: 0.8762\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3358 - accuracy: 0.9009 - val_loss: 0.4536 - val_accuracy: 0.8691\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3224 - accuracy: 0.9039 - val_loss: 0.4429 - val_accuracy: 0.8734\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3074 - accuracy: 0.9080 - val_loss: 0.4347 - val_accuracy: 0.8781\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2927 - accuracy: 0.9122 - val_loss: 0.4377 - val_accuracy: 0.8781\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2815 - accuracy: 0.9155 - val_loss: 0.4342 - val_accuracy: 0.8763\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2681 - accuracy: 0.9198 - val_loss: 0.4396 - val_accuracy: 0.8759\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2562 - accuracy: 0.9234 - val_loss: 0.4410 - val_accuracy: 0.8747\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:07:49.160600\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2524 - accuracy: 0.9268 - val_loss: 0.4203 - val_accuracy: 0.8800\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2316 - accuracy: 0.9346 - val_loss: 0.4166 - val_accuracy: 0.8809\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2218 - accuracy: 0.9378 - val_loss: 0.4148 - val_accuracy: 0.8826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2163 - accuracy: 0.9395 - val_loss: 0.4159 - val_accuracy: 0.8821\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2137 - accuracy: 0.9408 - val_loss: 0.4158 - val_accuracy: 0.8825\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2124 - accuracy: 0.9411 - val_loss: 0.4159 - val_accuracy: 0.8824\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:45.815079\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9971 - accuracy: 0.7585 - val_loss: 0.6620 - val_accuracy: 0.8291\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5780 - accuracy: 0.8455 - val_loss: 0.5498 - val_accuracy: 0.8489\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5092 - accuracy: 0.8576 - val_loss: 0.5118 - val_accuracy: 0.8577\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4736 - accuracy: 0.8659 - val_loss: 0.5016 - val_accuracy: 0.8617\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4528 - accuracy: 0.8711 - val_loss: 0.4980 - val_accuracy: 0.8571\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4275 - accuracy: 0.8783 - val_loss: 0.4828 - val_accuracy: 0.8634\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4062 - accuracy: 0.8831 - val_loss: 0.4692 - val_accuracy: 0.8652\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3844 - accuracy: 0.8874 - val_loss: 0.4696 - val_accuracy: 0.8666\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3670 - accuracy: 0.8929 - val_loss: 0.4510 - val_accuracy: 0.8719\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3497 - accuracy: 0.8974 - val_loss: 0.4407 - val_accuracy: 0.8747\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3338 - accuracy: 0.9010 - val_loss: 0.4456 - val_accuracy: 0.8695\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3188 - accuracy: 0.9045 - val_loss: 0.4448 - val_accuracy: 0.8717\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3022 - accuracy: 0.9098 - val_loss: 0.4351 - val_accuracy: 0.8754\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2904 - accuracy: 0.9129 - val_loss: 0.4365 - val_accuracy: 0.8734\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2749 - accuracy: 0.9179 - val_loss: 0.4406 - val_accuracy: 0.8758\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2628 - accuracy: 0.9221 - val_loss: 0.4357 - val_accuracy: 0.8752\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2498 - accuracy: 0.9270 - val_loss: 0.4414 - val_accuracy: 0.8753\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2395 - accuracy: 0.9297 - val_loss: 0.4386 - val_accuracy: 0.8743\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:17.277849\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2370 - accuracy: 0.9332 - val_loss: 0.4157 - val_accuracy: 0.8816\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2181 - accuracy: 0.9402 - val_loss: 0.4144 - val_accuracy: 0.8832\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2097 - accuracy: 0.9426 - val_loss: 0.4142 - val_accuracy: 0.8828\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2048 - accuracy: 0.9443 - val_loss: 0.4145 - val_accuracy: 0.8832\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2024 - accuracy: 0.9450 - val_loss: 0.4144 - val_accuracy: 0.8832\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2013 - accuracy: 0.9455 - val_loss: 0.4145 - val_accuracy: 0.8827\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2007 - accuracy: 0.9455 - val_loss: 0.4145 - val_accuracy: 0.8828\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2005 - accuracy: 0.9456 - val_loss: 0.4146 - val_accuracy: 0.8829\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:41.357544\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0177 - accuracy: 0.7513 - val_loss: 0.6499 - val_accuracy: 0.8348\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5859 - accuracy: 0.8437 - val_loss: 0.5475 - val_accuracy: 0.8477\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5099 - accuracy: 0.8570 - val_loss: 0.5050 - val_accuracy: 0.8551\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4742 - accuracy: 0.8652 - val_loss: 0.5032 - val_accuracy: 0.8555\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4542 - accuracy: 0.8702 - val_loss: 0.4990 - val_accuracy: 0.8574\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4291 - accuracy: 0.8770 - val_loss: 0.4627 - val_accuracy: 0.8691\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4047 - accuracy: 0.8824 - val_loss: 0.4552 - val_accuracy: 0.8689\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3849 - accuracy: 0.8868 - val_loss: 0.4428 - val_accuracy: 0.8729\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3675 - accuracy: 0.8929 - val_loss: 0.4450 - val_accuracy: 0.8715\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3499 - accuracy: 0.8977 - val_loss: 0.4363 - val_accuracy: 0.8744\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3339 - accuracy: 0.9018 - val_loss: 0.4275 - val_accuracy: 0.8768\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3183 - accuracy: 0.9052 - val_loss: 0.4316 - val_accuracy: 0.8740\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3040 - accuracy: 0.9094 - val_loss: 0.4234 - val_accuracy: 0.8777\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2898 - accuracy: 0.9134 - val_loss: 0.4397 - val_accuracy: 0.8741\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2781 - accuracy: 0.9162 - val_loss: 0.4320 - val_accuracy: 0.8746\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2644 - accuracy: 0.9207 - val_loss: 0.4330 - val_accuracy: 0.8764\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:07:21.834891\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2597 - accuracy: 0.9253 - val_loss: 0.4029 - val_accuracy: 0.8838\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2377 - accuracy: 0.9329 - val_loss: 0.4023 - val_accuracy: 0.8846\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2268 - accuracy: 0.9367 - val_loss: 0.4012 - val_accuracy: 0.8859\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2211 - accuracy: 0.9395 - val_loss: 0.4009 - val_accuracy: 0.8857\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2181 - accuracy: 0.9399 - val_loss: 0.4006 - val_accuracy: 0.8856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2166 - accuracy: 0.9409 - val_loss: 0.4010 - val_accuracy: 0.8861\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2159 - accuracy: 0.9409 - val_loss: 0.4010 - val_accuracy: 0.8858\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.2157 - accuracy: 0.9410 - val_loss: 0.4010 - val_accuracy: 0.8859\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.2156 - accuracy: 0.9410 - val_loss: 0.4010 - val_accuracy: 0.8859\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:08.321161\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0563 - accuracy: 0.7380 - val_loss: 0.6853 - val_accuracy: 0.8270\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6083 - accuracy: 0.8397 - val_loss: 0.5740 - val_accuracy: 0.8418\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5269 - accuracy: 0.8535 - val_loss: 0.5248 - val_accuracy: 0.8543\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4884 - accuracy: 0.8615 - val_loss: 0.4983 - val_accuracy: 0.8598\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4652 - accuracy: 0.8662 - val_loss: 0.5046 - val_accuracy: 0.8549\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4384 - accuracy: 0.8738 - val_loss: 0.4832 - val_accuracy: 0.8648\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4192 - accuracy: 0.8786 - val_loss: 0.4715 - val_accuracy: 0.8663\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4008 - accuracy: 0.8832 - val_loss: 0.4588 - val_accuracy: 0.8680\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3841 - accuracy: 0.8867 - val_loss: 0.4487 - val_accuracy: 0.8714\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3678 - accuracy: 0.8913 - val_loss: 0.4402 - val_accuracy: 0.8725\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3511 - accuracy: 0.8958 - val_loss: 0.4282 - val_accuracy: 0.8768\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3395 - accuracy: 0.8976 - val_loss: 0.4365 - val_accuracy: 0.8767\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3246 - accuracy: 0.9025 - val_loss: 0.4271 - val_accuracy: 0.8778\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3116 - accuracy: 0.9061 - val_loss: 0.4295 - val_accuracy: 0.8769\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2989 - accuracy: 0.9086 - val_loss: 0.4328 - val_accuracy: 0.8717\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.2884 - accuracy: 0.9132 - val_loss: 0.4261 - val_accuracy: 0.8755\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:38.739032\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2807 - accuracy: 0.9176 - val_loss: 0.4069 - val_accuracy: 0.8808\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2595 - accuracy: 0.9253 - val_loss: 0.3998 - val_accuracy: 0.8840\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2484 - accuracy: 0.9292 - val_loss: 0.3971 - val_accuracy: 0.8843\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2426 - accuracy: 0.9310 - val_loss: 0.3965 - val_accuracy: 0.8836\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2394 - accuracy: 0.9324 - val_loss: 0.3956 - val_accuracy: 0.8836\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2379 - accuracy: 0.9332 - val_loss: 0.3956 - val_accuracy: 0.8836\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:52.446916\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0256 - accuracy: 0.7468 - val_loss: 0.6791 - val_accuracy: 0.8249\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5993 - accuracy: 0.8403 - val_loss: 0.5794 - val_accuracy: 0.8404\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5243 - accuracy: 0.8532 - val_loss: 0.5287 - val_accuracy: 0.8553\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4857 - accuracy: 0.8620 - val_loss: 0.5222 - val_accuracy: 0.8541\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4654 - accuracy: 0.8669 - val_loss: 0.4960 - val_accuracy: 0.8601\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4414 - accuracy: 0.8739 - val_loss: 0.4800 - val_accuracy: 0.8656\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4198 - accuracy: 0.8787 - val_loss: 0.4867 - val_accuracy: 0.8589\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4017 - accuracy: 0.8828 - val_loss: 0.4593 - val_accuracy: 0.8699\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3846 - accuracy: 0.8875 - val_loss: 0.4647 - val_accuracy: 0.8659\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3679 - accuracy: 0.8913 - val_loss: 0.4453 - val_accuracy: 0.8739\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3520 - accuracy: 0.8956 - val_loss: 0.4453 - val_accuracy: 0.8700\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3397 - accuracy: 0.8991 - val_loss: 0.4490 - val_accuracy: 0.8704\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3250 - accuracy: 0.9018 - val_loss: 0.4429 - val_accuracy: 0.8708\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:13.693823\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3132 - accuracy: 0.9086 - val_loss: 0.4194 - val_accuracy: 0.8785\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2855 - accuracy: 0.9182 - val_loss: 0.4069 - val_accuracy: 0.8826\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2705 - accuracy: 0.9222 - val_loss: 0.4047 - val_accuracy: 0.8821\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2623 - accuracy: 0.9254 - val_loss: 0.4020 - val_accuracy: 0.8841\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2581 - accuracy: 0.9269 - val_loss: 0.4017 - val_accuracy: 0.8842\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2559 - accuracy: 0.9276 - val_loss: 0.4015 - val_accuracy: 0.8841\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.2550 - accuracy: 0.9278 - val_loss: 0.4015 - val_accuracy: 0.8842\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2545 - accuracy: 0.9280 - val_loss: 0.4015 - val_accuracy: 0.8841\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:48.523388\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0310 - accuracy: 0.7445 - val_loss: 0.6847 - val_accuracy: 0.8277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6026 - accuracy: 0.8405 - val_loss: 0.5680 - val_accuracy: 0.8469\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5235 - accuracy: 0.8552 - val_loss: 0.5158 - val_accuracy: 0.8561\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4832 - accuracy: 0.8633 - val_loss: 0.4866 - val_accuracy: 0.8629\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4636 - accuracy: 0.8681 - val_loss: 0.4805 - val_accuracy: 0.8651\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4380 - accuracy: 0.8740 - val_loss: 0.4791 - val_accuracy: 0.8605\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4189 - accuracy: 0.8791 - val_loss: 0.4575 - val_accuracy: 0.8694\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.3999 - accuracy: 0.8839 - val_loss: 0.4553 - val_accuracy: 0.8679\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3820 - accuracy: 0.8880 - val_loss: 0.4415 - val_accuracy: 0.8690\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3652 - accuracy: 0.8928 - val_loss: 0.4437 - val_accuracy: 0.8703\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3514 - accuracy: 0.8953 - val_loss: 0.4399 - val_accuracy: 0.8649\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3363 - accuracy: 0.9000 - val_loss: 0.4308 - val_accuracy: 0.8736\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3221 - accuracy: 0.9037 - val_loss: 0.4361 - val_accuracy: 0.8716\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3111 - accuracy: 0.9071 - val_loss: 0.4312 - val_accuracy: 0.8735\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2982 - accuracy: 0.9108 - val_loss: 0.4244 - val_accuracy: 0.8737\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2863 - accuracy: 0.9137 - val_loss: 0.4284 - val_accuracy: 0.8727\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2757 - accuracy: 0.9175 - val_loss: 0.4210 - val_accuracy: 0.8788\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2656 - accuracy: 0.9194 - val_loss: 0.4225 - val_accuracy: 0.8764\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2561 - accuracy: 0.9232 - val_loss: 0.4248 - val_accuracy: 0.8752\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2466 - accuracy: 0.9262 - val_loss: 0.4229 - val_accuracy: 0.8786\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:29.659741\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2428 - accuracy: 0.9297 - val_loss: 0.4027 - val_accuracy: 0.8819\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2270 - accuracy: 0.9356 - val_loss: 0.4020 - val_accuracy: 0.8833\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2194 - accuracy: 0.9382 - val_loss: 0.4008 - val_accuracy: 0.8827\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2154 - accuracy: 0.9399 - val_loss: 0.4001 - val_accuracy: 0.8829\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.2133 - accuracy: 0.9410 - val_loss: 0.4001 - val_accuracy: 0.8836\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2123 - accuracy: 0.9411 - val_loss: 0.4001 - val_accuracy: 0.8834\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2118 - accuracy: 0.9412 - val_loss: 0.4001 - val_accuracy: 0.8833\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2116 - accuracy: 0.9414 - val_loss: 0.4001 - val_accuracy: 0.8832\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:48.179850\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0659 - accuracy: 0.7365 - val_loss: 0.6758 - val_accuracy: 0.8293\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6042 - accuracy: 0.8406 - val_loss: 0.5728 - val_accuracy: 0.8435\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5242 - accuracy: 0.8562 - val_loss: 0.5431 - val_accuracy: 0.8457\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4887 - accuracy: 0.8622 - val_loss: 0.5095 - val_accuracy: 0.8556\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4675 - accuracy: 0.8675 - val_loss: 0.5028 - val_accuracy: 0.8536\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4416 - accuracy: 0.8737 - val_loss: 0.4860 - val_accuracy: 0.8625\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4183 - accuracy: 0.8794 - val_loss: 0.4918 - val_accuracy: 0.8590\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4001 - accuracy: 0.8842 - val_loss: 0.4564 - val_accuracy: 0.8661\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3837 - accuracy: 0.8890 - val_loss: 0.4583 - val_accuracy: 0.8648\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3677 - accuracy: 0.8923 - val_loss: 0.4455 - val_accuracy: 0.8668\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3534 - accuracy: 0.8952 - val_loss: 0.4348 - val_accuracy: 0.8728\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3384 - accuracy: 0.8991 - val_loss: 0.4298 - val_accuracy: 0.8762\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3242 - accuracy: 0.9032 - val_loss: 0.4341 - val_accuracy: 0.8723\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3117 - accuracy: 0.9076 - val_loss: 0.4330 - val_accuracy: 0.8682\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3004 - accuracy: 0.9089 - val_loss: 0.4263 - val_accuracy: 0.8741\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:07.032331\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2905 - accuracy: 0.9168 - val_loss: 0.4083 - val_accuracy: 0.8796\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2662 - accuracy: 0.9241 - val_loss: 0.4020 - val_accuracy: 0.8814\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2540 - accuracy: 0.9281 - val_loss: 0.4000 - val_accuracy: 0.8819\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2472 - accuracy: 0.9308 - val_loss: 0.4001 - val_accuracy: 0.8813\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2436 - accuracy: 0.9320 - val_loss: 0.3998 - val_accuracy: 0.8816\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2420 - accuracy: 0.9329 - val_loss: 0.3999 - val_accuracy: 0.8813\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:50.282395\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0300 - accuracy: 0.7480 - val_loss: 0.6576 - val_accuracy: 0.8344\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5980 - accuracy: 0.8425 - val_loss: 0.5640 - val_accuracy: 0.8471\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5197 - accuracy: 0.8555 - val_loss: 0.5269 - val_accuracy: 0.8498\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4835 - accuracy: 0.8640 - val_loss: 0.5096 - val_accuracy: 0.8563\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4609 - accuracy: 0.8685 - val_loss: 0.4957 - val_accuracy: 0.8547\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4387 - accuracy: 0.8746 - val_loss: 0.4799 - val_accuracy: 0.8597\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4172 - accuracy: 0.8798 - val_loss: 0.4551 - val_accuracy: 0.8679\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3983 - accuracy: 0.8850 - val_loss: 0.4512 - val_accuracy: 0.8661\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3808 - accuracy: 0.8883 - val_loss: 0.4364 - val_accuracy: 0.8738\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3671 - accuracy: 0.8912 - val_loss: 0.4268 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3506 - accuracy: 0.8962 - val_loss: 0.4358 - val_accuracy: 0.8695\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3365 - accuracy: 0.9006 - val_loss: 0.4187 - val_accuracy: 0.8752\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3228 - accuracy: 0.9034 - val_loss: 0.4264 - val_accuracy: 0.8739\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3106 - accuracy: 0.9066 - val_loss: 0.4183 - val_accuracy: 0.8741\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2982 - accuracy: 0.9109 - val_loss: 0.4131 - val_accuracy: 0.8758\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2866 - accuracy: 0.9134 - val_loss: 0.4145 - val_accuracy: 0.8762\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2758 - accuracy: 0.9173 - val_loss: 0.4123 - val_accuracy: 0.8738\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2650 - accuracy: 0.9205 - val_loss: 0.4190 - val_accuracy: 0.8765\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2568 - accuracy: 0.9224 - val_loss: 0.4120 - val_accuracy: 0.8782\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2482 - accuracy: 0.9249 - val_loss: 0.4109 - val_accuracy: 0.8766\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:24.757509\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2240 - accuracy: 0.9346 - val_loss: 0.4023 - val_accuracy: 0.8796\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2107 - accuracy: 0.9398 - val_loss: 0.4000 - val_accuracy: 0.8809\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.2033 - accuracy: 0.9432 - val_loss: 0.3990 - val_accuracy: 0.8813\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1995 - accuracy: 0.9449 - val_loss: 0.3988 - val_accuracy: 0.8830\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1975 - accuracy: 0.9456 - val_loss: 0.3991 - val_accuracy: 0.8829\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1965 - accuracy: 0.9461 - val_loss: 0.3989 - val_accuracy: 0.8825\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.1960 - accuracy: 0.9462 - val_loss: 0.3989 - val_accuracy: 0.8828\n",
      " Hyperparameter combinations for training, {'optimizer': 'adam', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:17.401185\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6970 - accuracy: 0.5645 - val_loss: 1.0522 - val_accuracy: 0.7256\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9342 - accuracy: 0.7396 - val_loss: 0.7417 - val_accuracy: 0.7902\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7337 - accuracy: 0.7843 - val_loss: 0.6255 - val_accuracy: 0.8158\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6380 - accuracy: 0.8073 - val_loss: 0.5660 - val_accuracy: 0.8262\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5833 - accuracy: 0.8187 - val_loss: 0.5324 - val_accuracy: 0.8342\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5458 - accuracy: 0.8282 - val_loss: 0.4980 - val_accuracy: 0.8423\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5191 - accuracy: 0.8351 - val_loss: 0.4823 - val_accuracy: 0.8462\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4981 - accuracy: 0.8397 - val_loss: 0.4657 - val_accuracy: 0.8518\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4811 - accuracy: 0.8440 - val_loss: 0.4698 - val_accuracy: 0.8488\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4702 - accuracy: 0.8470 - val_loss: 0.4498 - val_accuracy: 0.8553\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4591 - accuracy: 0.8498 - val_loss: 0.4427 - val_accuracy: 0.8562\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4503 - accuracy: 0.8522 - val_loss: 0.4410 - val_accuracy: 0.8563\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4417 - accuracy: 0.8548 - val_loss: 0.4339 - val_accuracy: 0.8590\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4363 - accuracy: 0.8570 - val_loss: 0.4278 - val_accuracy: 0.8597\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4308 - accuracy: 0.8579 - val_loss: 0.4282 - val_accuracy: 0.8592\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4247 - accuracy: 0.8588 - val_loss: 0.4225 - val_accuracy: 0.8615\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4209 - accuracy: 0.8614 - val_loss: 0.4194 - val_accuracy: 0.8607\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4165 - accuracy: 0.8613 - val_loss: 0.4187 - val_accuracy: 0.8615\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4142 - accuracy: 0.8626 - val_loss: 0.4149 - val_accuracy: 0.8631\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4093 - accuracy: 0.8635 - val_loss: 0.4144 - val_accuracy: 0.8641\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:51.432839\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4057 - accuracy: 0.8648 - val_loss: 0.4123 - val_accuracy: 0.8641\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4031 - accuracy: 0.8655 - val_loss: 0.4099 - val_accuracy: 0.8650\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4037 - accuracy: 0.8660 - val_loss: 0.4097 - val_accuracy: 0.8650\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4020 - accuracy: 0.8665 - val_loss: 0.4094 - val_accuracy: 0.8652\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4025 - accuracy: 0.8654 - val_loss: 0.4095 - val_accuracy: 0.8657\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4019 - accuracy: 0.8660 - val_loss: 0.4094 - val_accuracy: 0.8652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4038 - accuracy: 0.8653 - val_loss: 0.4093 - val_accuracy: 0.8652\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4022 - accuracy: 0.8663 - val_loss: 0.4094 - val_accuracy: 0.8655\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:37.283238\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6539 - accuracy: 0.5734 - val_loss: 0.9818 - val_accuracy: 0.7456\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8817 - accuracy: 0.7528 - val_loss: 0.7070 - val_accuracy: 0.8007\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7040 - accuracy: 0.7923 - val_loss: 0.5959 - val_accuracy: 0.8199\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6231 - accuracy: 0.8101 - val_loss: 0.5510 - val_accuracy: 0.8312\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5732 - accuracy: 0.8225 - val_loss: 0.5086 - val_accuracy: 0.8358\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5355 - accuracy: 0.8322 - val_loss: 0.4858 - val_accuracy: 0.8447\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5137 - accuracy: 0.8374 - val_loss: 0.4702 - val_accuracy: 0.8458\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4929 - accuracy: 0.8419 - val_loss: 0.4551 - val_accuracy: 0.8526\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4792 - accuracy: 0.8454 - val_loss: 0.4525 - val_accuracy: 0.8500\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4651 - accuracy: 0.8495 - val_loss: 0.4379 - val_accuracy: 0.8545\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4579 - accuracy: 0.8513 - val_loss: 0.4308 - val_accuracy: 0.8574\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4474 - accuracy: 0.8548 - val_loss: 0.4224 - val_accuracy: 0.8596\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4403 - accuracy: 0.8557 - val_loss: 0.4241 - val_accuracy: 0.8600\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4341 - accuracy: 0.8575 - val_loss: 0.4163 - val_accuracy: 0.8613\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4298 - accuracy: 0.8588 - val_loss: 0.4146 - val_accuracy: 0.8619\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4232 - accuracy: 0.8606 - val_loss: 0.4085 - val_accuracy: 0.8633\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4199 - accuracy: 0.8605 - val_loss: 0.4050 - val_accuracy: 0.8641\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4159 - accuracy: 0.8631 - val_loss: 0.4041 - val_accuracy: 0.8632\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4135 - accuracy: 0.8631 - val_loss: 0.4017 - val_accuracy: 0.8657\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4107 - accuracy: 0.8640 - val_loss: 0.4011 - val_accuracy: 0.8637\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:52.767936\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4053 - accuracy: 0.8667 - val_loss: 0.3986 - val_accuracy: 0.8654\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4028 - accuracy: 0.8659 - val_loss: 0.3969 - val_accuracy: 0.8657\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4033 - accuracy: 0.8658 - val_loss: 0.3967 - val_accuracy: 0.8658\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4015 - accuracy: 0.8668 - val_loss: 0.3965 - val_accuracy: 0.8657\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4010 - accuracy: 0.8676 - val_loss: 0.3964 - val_accuracy: 0.8658\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4006 - accuracy: 0.8669 - val_loss: 0.3964 - val_accuracy: 0.8657\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:44.944306\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7219 - accuracy: 0.5661 - val_loss: 1.0583 - val_accuracy: 0.7318\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9442 - accuracy: 0.7391 - val_loss: 0.7382 - val_accuracy: 0.7874\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7393 - accuracy: 0.7836 - val_loss: 0.6192 - val_accuracy: 0.8141\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6464 - accuracy: 0.8036 - val_loss: 0.5616 - val_accuracy: 0.8283\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5871 - accuracy: 0.8182 - val_loss: 0.5261 - val_accuracy: 0.8341\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5498 - accuracy: 0.8262 - val_loss: 0.4913 - val_accuracy: 0.8453\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5231 - accuracy: 0.8337 - val_loss: 0.4676 - val_accuracy: 0.8489\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5031 - accuracy: 0.8384 - val_loss: 0.4574 - val_accuracy: 0.8527\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4882 - accuracy: 0.8417 - val_loss: 0.4429 - val_accuracy: 0.8573\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4739 - accuracy: 0.8459 - val_loss: 0.4365 - val_accuracy: 0.8575\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4640 - accuracy: 0.8481 - val_loss: 0.4305 - val_accuracy: 0.8608\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4542 - accuracy: 0.8518 - val_loss: 0.4295 - val_accuracy: 0.8590\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4480 - accuracy: 0.8518 - val_loss: 0.4237 - val_accuracy: 0.8623\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4420 - accuracy: 0.8540 - val_loss: 0.4152 - val_accuracy: 0.8641\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4343 - accuracy: 0.8569 - val_loss: 0.4145 - val_accuracy: 0.8643\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4314 - accuracy: 0.8566 - val_loss: 0.4087 - val_accuracy: 0.8660\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4269 - accuracy: 0.8581 - val_loss: 0.4055 - val_accuracy: 0.8672\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4204 - accuracy: 0.8600 - val_loss: 0.4027 - val_accuracy: 0.8673\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4185 - accuracy: 0.8604 - val_loss: 0.4015 - val_accuracy: 0.8676\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4150 - accuracy: 0.8626 - val_loss: 0.4006 - val_accuracy: 0.8677\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:54.963909\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4122 - accuracy: 0.8626 - val_loss: 0.3968 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4074 - accuracy: 0.8648 - val_loss: 0.3960 - val_accuracy: 0.8691\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4071 - accuracy: 0.8647 - val_loss: 0.3957 - val_accuracy: 0.8692\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4070 - accuracy: 0.8652 - val_loss: 0.3954 - val_accuracy: 0.8690\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4084 - accuracy: 0.8636 - val_loss: 0.3953 - val_accuracy: 0.8692\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4063 - accuracy: 0.8649 - val_loss: 0.3953 - val_accuracy: 0.8693\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4065 - accuracy: 0.8647 - val_loss: 0.3953 - val_accuracy: 0.8691\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4059 - accuracy: 0.8646 - val_loss: 0.3953 - val_accuracy: 0.8693\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4065 - accuracy: 0.8649 - val_loss: 0.3953 - val_accuracy: 0.8694\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4047 - accuracy: 0.8652 - val_loss: 0.3954 - val_accuracy: 0.8692\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4062 - accuracy: 0.8649 - val_loss: 0.3954 - val_accuracy: 0.8692\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4051 - accuracy: 0.8645 - val_loss: 0.3953 - val_accuracy: 0.8692\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:20.246653\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7333 - accuracy: 0.5668 - val_loss: 1.0304 - val_accuracy: 0.7349\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9207 - accuracy: 0.7451 - val_loss: 0.7369 - val_accuracy: 0.7867\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7261 - accuracy: 0.7875 - val_loss: 0.6203 - val_accuracy: 0.8135\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6351 - accuracy: 0.8076 - val_loss: 0.5529 - val_accuracy: 0.8292\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5806 - accuracy: 0.8195 - val_loss: 0.5165 - val_accuracy: 0.8348\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5446 - accuracy: 0.8290 - val_loss: 0.4876 - val_accuracy: 0.8418\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5171 - accuracy: 0.8353 - val_loss: 0.4704 - val_accuracy: 0.8472\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4988 - accuracy: 0.8399 - val_loss: 0.4597 - val_accuracy: 0.8493\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4811 - accuracy: 0.8456 - val_loss: 0.4497 - val_accuracy: 0.8511\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4697 - accuracy: 0.8485 - val_loss: 0.4392 - val_accuracy: 0.8545\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4572 - accuracy: 0.8514 - val_loss: 0.4310 - val_accuracy: 0.8571\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4515 - accuracy: 0.8535 - val_loss: 0.4240 - val_accuracy: 0.8562\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4434 - accuracy: 0.8547 - val_loss: 0.4223 - val_accuracy: 0.8580\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4363 - accuracy: 0.8562 - val_loss: 0.4146 - val_accuracy: 0.8614\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4312 - accuracy: 0.8570 - val_loss: 0.4162 - val_accuracy: 0.8607\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4255 - accuracy: 0.8604 - val_loss: 0.4125 - val_accuracy: 0.8606\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4209 - accuracy: 0.8605 - val_loss: 0.4056 - val_accuracy: 0.8633\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4173 - accuracy: 0.8618 - val_loss: 0.4034 - val_accuracy: 0.8628\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4135 - accuracy: 0.8629 - val_loss: 0.4018 - val_accuracy: 0.8639\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4109 - accuracy: 0.8640 - val_loss: 0.4008 - val_accuracy: 0.8640\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:10.692026\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4084 - accuracy: 0.8646 - val_loss: 0.3970 - val_accuracy: 0.8640\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4059 - accuracy: 0.8652 - val_loss: 0.3965 - val_accuracy: 0.8644\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4019 - accuracy: 0.8669 - val_loss: 0.3960 - val_accuracy: 0.8653\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4038 - accuracy: 0.8667 - val_loss: 0.3958 - val_accuracy: 0.8657\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4012 - accuracy: 0.8677 - val_loss: 0.3958 - val_accuracy: 0.8652\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4034 - accuracy: 0.8662 - val_loss: 0.3957 - val_accuracy: 0.8652\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4027 - accuracy: 0.8666 - val_loss: 0.3957 - val_accuracy: 0.8652\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:13.605388\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6357 - accuracy: 0.5810 - val_loss: 0.9858 - val_accuracy: 0.7411\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8954 - accuracy: 0.7528 - val_loss: 0.7096 - val_accuracy: 0.7949\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7161 - accuracy: 0.7904 - val_loss: 0.6145 - val_accuracy: 0.8125\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6307 - accuracy: 0.8099 - val_loss: 0.5485 - val_accuracy: 0.8293\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5780 - accuracy: 0.8218 - val_loss: 0.5178 - val_accuracy: 0.8351\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5421 - accuracy: 0.8291 - val_loss: 0.4875 - val_accuracy: 0.8414\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5169 - accuracy: 0.8363 - val_loss: 0.4741 - val_accuracy: 0.8435\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4984 - accuracy: 0.8407 - val_loss: 0.4592 - val_accuracy: 0.8466\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4822 - accuracy: 0.8440 - val_loss: 0.4459 - val_accuracy: 0.8502\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4694 - accuracy: 0.8482 - val_loss: 0.4494 - val_accuracy: 0.8526\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4595 - accuracy: 0.8518 - val_loss: 0.4306 - val_accuracy: 0.8563\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4502 - accuracy: 0.8534 - val_loss: 0.4267 - val_accuracy: 0.8560\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4434 - accuracy: 0.8560 - val_loss: 0.4213 - val_accuracy: 0.8572\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4356 - accuracy: 0.8583 - val_loss: 0.4203 - val_accuracy: 0.8567\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4299 - accuracy: 0.8590 - val_loss: 0.4132 - val_accuracy: 0.8600\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4252 - accuracy: 0.8591 - val_loss: 0.4112 - val_accuracy: 0.8600\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4206 - accuracy: 0.8612 - val_loss: 0.4067 - val_accuracy: 0.8605\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4184 - accuracy: 0.8621 - val_loss: 0.4059 - val_accuracy: 0.8605\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4152 - accuracy: 0.8640 - val_loss: 0.4065 - val_accuracy: 0.8624\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4109 - accuracy: 0.8651 - val_loss: 0.4018 - val_accuracy: 0.8625\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:02.954914\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4074 - accuracy: 0.8645 - val_loss: 0.3988 - val_accuracy: 0.8637\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4045 - accuracy: 0.8660 - val_loss: 0.3980 - val_accuracy: 0.8648\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4035 - accuracy: 0.8660 - val_loss: 0.3976 - val_accuracy: 0.8641\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4041 - accuracy: 0.8668 - val_loss: 0.3975 - val_accuracy: 0.8639\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4032 - accuracy: 0.8664 - val_loss: 0.3975 - val_accuracy: 0.8641\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:14.221817\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5712 - accuracy: 0.5757 - val_loss: 0.9988 - val_accuracy: 0.7242\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9062 - accuracy: 0.7406 - val_loss: 0.7451 - val_accuracy: 0.7804\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7344 - accuracy: 0.7813 - val_loss: 0.6399 - val_accuracy: 0.8014\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6523 - accuracy: 0.8006 - val_loss: 0.5833 - val_accuracy: 0.8213\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6019 - accuracy: 0.8137 - val_loss: 0.5610 - val_accuracy: 0.8228\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5683 - accuracy: 0.8218 - val_loss: 0.5268 - val_accuracy: 0.8319\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5438 - accuracy: 0.8280 - val_loss: 0.5043 - val_accuracy: 0.8409\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5253 - accuracy: 0.8320 - val_loss: 0.4960 - val_accuracy: 0.8423\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5097 - accuracy: 0.8364 - val_loss: 0.4895 - val_accuracy: 0.8438\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4992 - accuracy: 0.8400 - val_loss: 0.4748 - val_accuracy: 0.8474\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4861 - accuracy: 0.8428 - val_loss: 0.4719 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4766 - accuracy: 0.8455 - val_loss: 0.4623 - val_accuracy: 0.8506\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4721 - accuracy: 0.8468 - val_loss: 0.4603 - val_accuracy: 0.8504\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4670 - accuracy: 0.8476 - val_loss: 0.4524 - val_accuracy: 0.8536\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4609 - accuracy: 0.8500 - val_loss: 0.4525 - val_accuracy: 0.8522\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4565 - accuracy: 0.8512 - val_loss: 0.4476 - val_accuracy: 0.8550\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4526 - accuracy: 0.8528 - val_loss: 0.4437 - val_accuracy: 0.8566\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4479 - accuracy: 0.8535 - val_loss: 0.4425 - val_accuracy: 0.8567\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4446 - accuracy: 0.8548 - val_loss: 0.4408 - val_accuracy: 0.8562\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4430 - accuracy: 0.8543 - val_loss: 0.4391 - val_accuracy: 0.8559\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:06.523611\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4391 - accuracy: 0.8564 - val_loss: 0.4371 - val_accuracy: 0.8571\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4359 - accuracy: 0.8564 - val_loss: 0.4363 - val_accuracy: 0.8574\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4350 - accuracy: 0.8579 - val_loss: 0.4358 - val_accuracy: 0.8573\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4326 - accuracy: 0.8590 - val_loss: 0.4356 - val_accuracy: 0.8570\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4329 - accuracy: 0.8581 - val_loss: 0.4356 - val_accuracy: 0.8574\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:16.969027\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5862 - accuracy: 0.5699 - val_loss: 0.9729 - val_accuracy: 0.7341\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9016 - accuracy: 0.7392 - val_loss: 0.7121 - val_accuracy: 0.7952\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7311 - accuracy: 0.7825 - val_loss: 0.6181 - val_accuracy: 0.8123\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6509 - accuracy: 0.8017 - val_loss: 0.5655 - val_accuracy: 0.8261\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6006 - accuracy: 0.8137 - val_loss: 0.5363 - val_accuracy: 0.8302\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5676 - accuracy: 0.8220 - val_loss: 0.5075 - val_accuracy: 0.8412\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5415 - accuracy: 0.8288 - val_loss: 0.4997 - val_accuracy: 0.8411\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5261 - accuracy: 0.8327 - val_loss: 0.4816 - val_accuracy: 0.8439\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5077 - accuracy: 0.8383 - val_loss: 0.4717 - val_accuracy: 0.8473\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4979 - accuracy: 0.8395 - val_loss: 0.4640 - val_accuracy: 0.8489\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4883 - accuracy: 0.8433 - val_loss: 0.4600 - val_accuracy: 0.8495\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4799 - accuracy: 0.8453 - val_loss: 0.4594 - val_accuracy: 0.8511\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4748 - accuracy: 0.8463 - val_loss: 0.4505 - val_accuracy: 0.8516\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4674 - accuracy: 0.8487 - val_loss: 0.4446 - val_accuracy: 0.8544\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4606 - accuracy: 0.8500 - val_loss: 0.4424 - val_accuracy: 0.8554\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4565 - accuracy: 0.8507 - val_loss: 0.4396 - val_accuracy: 0.8558\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4526 - accuracy: 0.8525 - val_loss: 0.4369 - val_accuracy: 0.8562\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4489 - accuracy: 0.8534 - val_loss: 0.4374 - val_accuracy: 0.8560\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4473 - accuracy: 0.8542 - val_loss: 0.4357 - val_accuracy: 0.8563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4439 - accuracy: 0.8552 - val_loss: 0.4339 - val_accuracy: 0.8558\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:07.781152\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4396 - accuracy: 0.8558 - val_loss: 0.4304 - val_accuracy: 0.8581\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4374 - accuracy: 0.8562 - val_loss: 0.4288 - val_accuracy: 0.8583\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4372 - accuracy: 0.8567 - val_loss: 0.4289 - val_accuracy: 0.8582\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4358 - accuracy: 0.8572 - val_loss: 0.4286 - val_accuracy: 0.8581\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4364 - accuracy: 0.8568 - val_loss: 0.4285 - val_accuracy: 0.8576\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:16.958131\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5584 - accuracy: 0.5766 - val_loss: 0.9831 - val_accuracy: 0.7291\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9029 - accuracy: 0.7378 - val_loss: 0.7092 - val_accuracy: 0.7938\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7386 - accuracy: 0.7799 - val_loss: 0.6310 - val_accuracy: 0.8086\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6545 - accuracy: 0.8013 - val_loss: 0.5649 - val_accuracy: 0.8270\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6037 - accuracy: 0.8131 - val_loss: 0.5322 - val_accuracy: 0.8359\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5699 - accuracy: 0.8213 - val_loss: 0.5081 - val_accuracy: 0.8389\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5457 - accuracy: 0.8265 - val_loss: 0.4988 - val_accuracy: 0.8434\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5256 - accuracy: 0.8319 - val_loss: 0.4849 - val_accuracy: 0.8441\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5110 - accuracy: 0.8364 - val_loss: 0.4709 - val_accuracy: 0.8504\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4981 - accuracy: 0.8393 - val_loss: 0.4658 - val_accuracy: 0.8498\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4887 - accuracy: 0.8414 - val_loss: 0.4611 - val_accuracy: 0.8512\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4785 - accuracy: 0.8446 - val_loss: 0.4709 - val_accuracy: 0.8484\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4731 - accuracy: 0.8468 - val_loss: 0.4486 - val_accuracy: 0.8551\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4662 - accuracy: 0.8493 - val_loss: 0.4444 - val_accuracy: 0.8564\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4595 - accuracy: 0.8508 - val_loss: 0.4440 - val_accuracy: 0.8551\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4558 - accuracy: 0.8504 - val_loss: 0.4406 - val_accuracy: 0.8550\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4522 - accuracy: 0.8519 - val_loss: 0.4362 - val_accuracy: 0.8576\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4499 - accuracy: 0.8530 - val_loss: 0.4347 - val_accuracy: 0.8588\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4445 - accuracy: 0.8550 - val_loss: 0.4338 - val_accuracy: 0.8574\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4430 - accuracy: 0.8540 - val_loss: 0.4316 - val_accuracy: 0.8595\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:06.800504\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4372 - accuracy: 0.8571 - val_loss: 0.4297 - val_accuracy: 0.8605\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4359 - accuracy: 0.8566 - val_loss: 0.4287 - val_accuracy: 0.8599\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4354 - accuracy: 0.8575 - val_loss: 0.4280 - val_accuracy: 0.8598\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4339 - accuracy: 0.8588 - val_loss: 0.4278 - val_accuracy: 0.8603\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:49.994308\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5610 - accuracy: 0.5821 - val_loss: 0.9611 - val_accuracy: 0.7379\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8884 - accuracy: 0.7449 - val_loss: 0.7223 - val_accuracy: 0.7896\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7247 - accuracy: 0.7837 - val_loss: 0.6356 - val_accuracy: 0.8110\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6452 - accuracy: 0.8031 - val_loss: 0.5712 - val_accuracy: 0.8257\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5963 - accuracy: 0.8155 - val_loss: 0.5456 - val_accuracy: 0.8297\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5629 - accuracy: 0.8231 - val_loss: 0.5157 - val_accuracy: 0.8380\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5391 - accuracy: 0.8292 - val_loss: 0.5051 - val_accuracy: 0.8402\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5201 - accuracy: 0.8341 - val_loss: 0.4904 - val_accuracy: 0.8422\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5057 - accuracy: 0.8371 - val_loss: 0.4784 - val_accuracy: 0.8448\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4945 - accuracy: 0.8403 - val_loss: 0.4715 - val_accuracy: 0.8468\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4864 - accuracy: 0.8429 - val_loss: 0.4675 - val_accuracy: 0.8474\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4775 - accuracy: 0.8451 - val_loss: 0.4612 - val_accuracy: 0.8494\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4711 - accuracy: 0.8473 - val_loss: 0.4557 - val_accuracy: 0.8514\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4663 - accuracy: 0.8476 - val_loss: 0.4546 - val_accuracy: 0.8524\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4605 - accuracy: 0.8514 - val_loss: 0.4499 - val_accuracy: 0.8537\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4545 - accuracy: 0.8511 - val_loss: 0.4476 - val_accuracy: 0.8522\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4513 - accuracy: 0.8521 - val_loss: 0.4459 - val_accuracy: 0.8549\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4482 - accuracy: 0.8542 - val_loss: 0.4428 - val_accuracy: 0.8549\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4435 - accuracy: 0.8541 - val_loss: 0.4407 - val_accuracy: 0.8557\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4442 - accuracy: 0.8544 - val_loss: 0.4402 - val_accuracy: 0.8564\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:11.770382\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4374 - accuracy: 0.8567 - val_loss: 0.4373 - val_accuracy: 0.8555\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4364 - accuracy: 0.8575 - val_loss: 0.4356 - val_accuracy: 0.8572\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4331 - accuracy: 0.8576 - val_loss: 0.4357 - val_accuracy: 0.8569\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4356 - accuracy: 0.8572 - val_loss: 0.4355 - val_accuracy: 0.8574\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4339 - accuracy: 0.8580 - val_loss: 0.4355 - val_accuracy: 0.8575\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4344 - accuracy: 0.8573 - val_loss: 0.4353 - val_accuracy: 0.8570\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4333 - accuracy: 0.8581 - val_loss: 0.4354 - val_accuracy: 0.8567\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4338 - accuracy: 0.8577 - val_loss: 0.4356 - val_accuracy: 0.8574\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:38.636362\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5778 - accuracy: 0.5743 - val_loss: 0.9866 - val_accuracy: 0.7362\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8955 - accuracy: 0.7417 - val_loss: 0.7263 - val_accuracy: 0.7860\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7262 - accuracy: 0.7831 - val_loss: 0.6276 - val_accuracy: 0.8121\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6485 - accuracy: 0.8026 - val_loss: 0.5856 - val_accuracy: 0.8203\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5979 - accuracy: 0.8149 - val_loss: 0.5545 - val_accuracy: 0.8275\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5653 - accuracy: 0.8237 - val_loss: 0.5286 - val_accuracy: 0.8334\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5393 - accuracy: 0.8292 - val_loss: 0.5108 - val_accuracy: 0.8377\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5220 - accuracy: 0.8338 - val_loss: 0.4964 - val_accuracy: 0.8409\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5076 - accuracy: 0.8386 - val_loss: 0.4874 - val_accuracy: 0.8429\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4951 - accuracy: 0.8417 - val_loss: 0.4834 - val_accuracy: 0.8443\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4851 - accuracy: 0.8436 - val_loss: 0.4754 - val_accuracy: 0.8462\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4770 - accuracy: 0.8467 - val_loss: 0.4667 - val_accuracy: 0.8484\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4710 - accuracy: 0.8465 - val_loss: 0.4653 - val_accuracy: 0.8498\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4641 - accuracy: 0.8509 - val_loss: 0.4618 - val_accuracy: 0.8499\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4576 - accuracy: 0.8519 - val_loss: 0.4577 - val_accuracy: 0.8512\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4558 - accuracy: 0.8524 - val_loss: 0.4541 - val_accuracy: 0.8527\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4497 - accuracy: 0.8555 - val_loss: 0.4512 - val_accuracy: 0.8522\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4477 - accuracy: 0.8545 - val_loss: 0.4494 - val_accuracy: 0.8534\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4439 - accuracy: 0.8543 - val_loss: 0.4489 - val_accuracy: 0.8532\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4401 - accuracy: 0.8551 - val_loss: 0.4460 - val_accuracy: 0.8555\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:05.940312\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4374 - accuracy: 0.8570 - val_loss: 0.4448 - val_accuracy: 0.8555\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4351 - accuracy: 0.8587 - val_loss: 0.4439 - val_accuracy: 0.8550\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4344 - accuracy: 0.8581 - val_loss: 0.4435 - val_accuracy: 0.8556\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4317 - accuracy: 0.8587 - val_loss: 0.4433 - val_accuracy: 0.8559\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4333 - accuracy: 0.8579 - val_loss: 0.4433 - val_accuracy: 0.8561\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4325 - accuracy: 0.8594 - val_loss: 0.4434 - val_accuracy: 0.8558\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4328 - accuracy: 0.8586 - val_loss: 0.4433 - val_accuracy: 0.8561\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4319 - accuracy: 0.8590 - val_loss: 0.4433 - val_accuracy: 0.8559\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:38.007557\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.5574 - accuracy: 0.5864 - val_loss: 0.9355 - val_accuracy: 0.7406\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8587 - accuracy: 0.7543 - val_loss: 0.6850 - val_accuracy: 0.7972\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6961 - accuracy: 0.7920 - val_loss: 0.5991 - val_accuracy: 0.8175\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6189 - accuracy: 0.8097 - val_loss: 0.5424 - val_accuracy: 0.8327\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5720 - accuracy: 0.8221 - val_loss: 0.5144 - val_accuracy: 0.8377\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5385 - accuracy: 0.8307 - val_loss: 0.4861 - val_accuracy: 0.8430\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5150 - accuracy: 0.8355 - val_loss: 0.4700 - val_accuracy: 0.8490\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4966 - accuracy: 0.8408 - val_loss: 0.4568 - val_accuracy: 0.8505\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4809 - accuracy: 0.8438 - val_loss: 0.4472 - val_accuracy: 0.8532\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4710 - accuracy: 0.8479 - val_loss: 0.4428 - val_accuracy: 0.8546\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4614 - accuracy: 0.8493 - val_loss: 0.4339 - val_accuracy: 0.8564\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4523 - accuracy: 0.8516 - val_loss: 0.4309 - val_accuracy: 0.8574\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4457 - accuracy: 0.8535 - val_loss: 0.4260 - val_accuracy: 0.8598\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4401 - accuracy: 0.8556 - val_loss: 0.4195 - val_accuracy: 0.8618\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4349 - accuracy: 0.8562 - val_loss: 0.4199 - val_accuracy: 0.8611\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4298 - accuracy: 0.8594 - val_loss: 0.4132 - val_accuracy: 0.8629\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4258 - accuracy: 0.8595 - val_loss: 0.4128 - val_accuracy: 0.8629\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4226 - accuracy: 0.8594 - val_loss: 0.4099 - val_accuracy: 0.8645\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4196 - accuracy: 0.8616 - val_loss: 0.4072 - val_accuracy: 0.8645\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4173 - accuracy: 0.8611 - val_loss: 0.4056 - val_accuracy: 0.8641\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:27.131133\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4117 - accuracy: 0.8639 - val_loss: 0.4034 - val_accuracy: 0.8656\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4116 - accuracy: 0.8626 - val_loss: 0.4025 - val_accuracy: 0.8660\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4094 - accuracy: 0.8645 - val_loss: 0.4021 - val_accuracy: 0.8656\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4064 - accuracy: 0.8660 - val_loss: 0.4018 - val_accuracy: 0.8660\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4095 - accuracy: 0.8639 - val_loss: 0.4017 - val_accuracy: 0.8660\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4084 - accuracy: 0.8645 - val_loss: 0.4018 - val_accuracy: 0.8659\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4081 - accuracy: 0.8644 - val_loss: 0.4017 - val_accuracy: 0.8659\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4075 - accuracy: 0.8651 - val_loss: 0.4018 - val_accuracy: 0.8654\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:47.006440\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6438 - accuracy: 0.5625 - val_loss: 1.0148 - val_accuracy: 0.7226\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9153 - accuracy: 0.7371 - val_loss: 0.7215 - val_accuracy: 0.7842\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7230 - accuracy: 0.7827 - val_loss: 0.6321 - val_accuracy: 0.8097\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6337 - accuracy: 0.8048 - val_loss: 0.5747 - val_accuracy: 0.8207\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5812 - accuracy: 0.8178 - val_loss: 0.5274 - val_accuracy: 0.8300\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5452 - accuracy: 0.8278 - val_loss: 0.5016 - val_accuracy: 0.8399\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5204 - accuracy: 0.8339 - val_loss: 0.4983 - val_accuracy: 0.8372\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5018 - accuracy: 0.8379 - val_loss: 0.4786 - val_accuracy: 0.8427\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4842 - accuracy: 0.8428 - val_loss: 0.4702 - val_accuracy: 0.8462\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.4745 - accuracy: 0.8451 - val_loss: 0.4575 - val_accuracy: 0.8512\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4640 - accuracy: 0.8479 - val_loss: 0.4520 - val_accuracy: 0.8515\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4523 - accuracy: 0.8520 - val_loss: 0.4434 - val_accuracy: 0.8523\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4474 - accuracy: 0.8529 - val_loss: 0.4370 - val_accuracy: 0.8559\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4405 - accuracy: 0.8542 - val_loss: 0.4319 - val_accuracy: 0.8567\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4343 - accuracy: 0.8565 - val_loss: 0.4294 - val_accuracy: 0.8582\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4323 - accuracy: 0.8567 - val_loss: 0.4287 - val_accuracy: 0.8582\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4269 - accuracy: 0.8594 - val_loss: 0.4244 - val_accuracy: 0.8579\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4222 - accuracy: 0.8605 - val_loss: 0.4208 - val_accuracy: 0.8601\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4200 - accuracy: 0.8604 - val_loss: 0.4188 - val_accuracy: 0.8611\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4169 - accuracy: 0.8615 - val_loss: 0.4171 - val_accuracy: 0.8610\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:28.082670\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4130 - accuracy: 0.8628 - val_loss: 0.4150 - val_accuracy: 0.8606\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4116 - accuracy: 0.8642 - val_loss: 0.4138 - val_accuracy: 0.8609\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4103 - accuracy: 0.8648 - val_loss: 0.4132 - val_accuracy: 0.8613\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4094 - accuracy: 0.8638 - val_loss: 0.4131 - val_accuracy: 0.8615\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4087 - accuracy: 0.8638 - val_loss: 0.4130 - val_accuracy: 0.8618\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4098 - accuracy: 0.8636 - val_loss: 0.4130 - val_accuracy: 0.8614\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4092 - accuracy: 0.8646 - val_loss: 0.4131 - val_accuracy: 0.8615\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4087 - accuracy: 0.8635 - val_loss: 0.4130 - val_accuracy: 0.8616\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:46.445206\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5879 - accuracy: 0.5791 - val_loss: 0.9698 - val_accuracy: 0.7432\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8789 - accuracy: 0.7477 - val_loss: 0.7048 - val_accuracy: 0.7976\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7102 - accuracy: 0.7882 - val_loss: 0.6025 - val_accuracy: 0.8201\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6285 - accuracy: 0.8069 - val_loss: 0.5464 - val_accuracy: 0.8302\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5789 - accuracy: 0.8188 - val_loss: 0.5128 - val_accuracy: 0.8380\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5448 - accuracy: 0.8275 - val_loss: 0.4940 - val_accuracy: 0.8427\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5199 - accuracy: 0.8346 - val_loss: 0.4851 - val_accuracy: 0.8457\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5029 - accuracy: 0.8379 - val_loss: 0.4602 - val_accuracy: 0.8485\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4869 - accuracy: 0.8430 - val_loss: 0.4565 - val_accuracy: 0.8492\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4747 - accuracy: 0.8455 - val_loss: 0.4459 - val_accuracy: 0.8523\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4662 - accuracy: 0.8488 - val_loss: 0.4369 - val_accuracy: 0.8568\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4557 - accuracy: 0.8518 - val_loss: 0.4325 - val_accuracy: 0.8580\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4485 - accuracy: 0.8537 - val_loss: 0.4284 - val_accuracy: 0.8594\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4425 - accuracy: 0.8556 - val_loss: 0.4275 - val_accuracy: 0.8602\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4382 - accuracy: 0.8556 - val_loss: 0.4216 - val_accuracy: 0.8596\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4342 - accuracy: 0.8581 - val_loss: 0.4158 - val_accuracy: 0.8615\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4295 - accuracy: 0.8578 - val_loss: 0.4165 - val_accuracy: 0.8633\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4248 - accuracy: 0.8595 - val_loss: 0.4137 - val_accuracy: 0.8611\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4205 - accuracy: 0.8607 - val_loss: 0.4096 - val_accuracy: 0.8622\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4195 - accuracy: 0.8618 - val_loss: 0.4088 - val_accuracy: 0.8629\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:21.397831\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4224 - accuracy: 0.8599 - val_loss: 0.4103 - val_accuracy: 0.8626\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4207 - accuracy: 0.8610 - val_loss: 0.4089 - val_accuracy: 0.8638\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4200 - accuracy: 0.8615 - val_loss: 0.4089 - val_accuracy: 0.8632\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4181 - accuracy: 0.8618 - val_loss: 0.4089 - val_accuracy: 0.8632\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4185 - accuracy: 0.8620 - val_loss: 0.4087 - val_accuracy: 0.8634\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:22.470797\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5582 - accuracy: 0.5836 - val_loss: 0.9310 - val_accuracy: 0.7437\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8692 - accuracy: 0.7490 - val_loss: 0.6867 - val_accuracy: 0.7964\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7047 - accuracy: 0.7883 - val_loss: 0.5919 - val_accuracy: 0.8202\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6245 - accuracy: 0.8089 - val_loss: 0.5499 - val_accuracy: 0.8276\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5765 - accuracy: 0.8196 - val_loss: 0.5200 - val_accuracy: 0.8344\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5442 - accuracy: 0.8293 - val_loss: 0.4869 - val_accuracy: 0.8453\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5200 - accuracy: 0.8333 - val_loss: 0.4771 - val_accuracy: 0.8460\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5036 - accuracy: 0.8378 - val_loss: 0.4580 - val_accuracy: 0.8524\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4884 - accuracy: 0.8424 - val_loss: 0.4560 - val_accuracy: 0.8496\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4763 - accuracy: 0.8451 - val_loss: 0.4503 - val_accuracy: 0.8520\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4648 - accuracy: 0.8481 - val_loss: 0.4381 - val_accuracy: 0.8549\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4594 - accuracy: 0.8491 - val_loss: 0.4326 - val_accuracy: 0.8566\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4533 - accuracy: 0.8528 - val_loss: 0.4257 - val_accuracy: 0.8613\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4462 - accuracy: 0.8538 - val_loss: 0.4221 - val_accuracy: 0.8599\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4411 - accuracy: 0.8547 - val_loss: 0.4181 - val_accuracy: 0.8620\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4364 - accuracy: 0.8562 - val_loss: 0.4158 - val_accuracy: 0.8606\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4308 - accuracy: 0.8581 - val_loss: 0.4141 - val_accuracy: 0.8624\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4276 - accuracy: 0.8590 - val_loss: 0.4119 - val_accuracy: 0.8629\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.4255 - accuracy: 0.8601 - val_loss: 0.4083 - val_accuracy: 0.8647\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4215 - accuracy: 0.8609 - val_loss: 0.4055 - val_accuracy: 0.8649\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:22.848184\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 0.4179 - accuracy: 0.8613 - val_loss: 0.4040 - val_accuracy: 0.8660\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4159 - accuracy: 0.8631 - val_loss: 0.4034 - val_accuracy: 0.8660\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4161 - accuracy: 0.8618 - val_loss: 0.4034 - val_accuracy: 0.8664\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4158 - accuracy: 0.8624 - val_loss: 0.4032 - val_accuracy: 0.8662\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4148 - accuracy: 0.8619 - val_loss: 0.4030 - val_accuracy: 0.8668\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4158 - accuracy: 0.8625 - val_loss: 0.4030 - val_accuracy: 0.8665\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4152 - accuracy: 0.8627 - val_loss: 0.4030 - val_accuracy: 0.8668\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4138 - accuracy: 0.8632 - val_loss: 0.4031 - val_accuracy: 0.8667\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4139 - accuracy: 0.8628 - val_loss: 0.4031 - val_accuracy: 0.8667\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4135 - accuracy: 0.8619 - val_loss: 0.4030 - val_accuracy: 0.8670\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4159 - accuracy: 0.8633 - val_loss: 0.4030 - val_accuracy: 0.8665\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4129 - accuracy: 0.8630 - val_loss: 0.4032 - val_accuracy: 0.8670\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4147 - accuracy: 0.8625 - val_loss: 0.4031 - val_accuracy: 0.8665\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:08.034168\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5660 - accuracy: 0.5816 - val_loss: 0.9824 - val_accuracy: 0.7353\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8645 - accuracy: 0.7511 - val_loss: 0.7130 - val_accuracy: 0.7938\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6987 - accuracy: 0.7890 - val_loss: 0.6251 - val_accuracy: 0.8061\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6174 - accuracy: 0.8116 - val_loss: 0.5745 - val_accuracy: 0.8213\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5696 - accuracy: 0.8207 - val_loss: 0.5455 - val_accuracy: 0.8289\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5380 - accuracy: 0.8287 - val_loss: 0.5049 - val_accuracy: 0.8371\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5130 - accuracy: 0.8356 - val_loss: 0.4882 - val_accuracy: 0.8395\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4955 - accuracy: 0.8398 - val_loss: 0.4808 - val_accuracy: 0.8433\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4800 - accuracy: 0.8443 - val_loss: 0.4647 - val_accuracy: 0.8466\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4686 - accuracy: 0.8473 - val_loss: 0.4581 - val_accuracy: 0.8502\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4591 - accuracy: 0.8499 - val_loss: 0.4542 - val_accuracy: 0.8494\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4507 - accuracy: 0.8520 - val_loss: 0.4486 - val_accuracy: 0.8515\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4434 - accuracy: 0.8554 - val_loss: 0.4441 - val_accuracy: 0.8531\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4381 - accuracy: 0.8557 - val_loss: 0.4356 - val_accuracy: 0.8551\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4327 - accuracy: 0.8569 - val_loss: 0.4392 - val_accuracy: 0.8520\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4294 - accuracy: 0.8587 - val_loss: 0.4341 - val_accuracy: 0.8542\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4249 - accuracy: 0.8597 - val_loss: 0.4309 - val_accuracy: 0.8535\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:55.724622\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4303 - accuracy: 0.8583 - val_loss: 0.4342 - val_accuracy: 0.8547\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4262 - accuracy: 0.8598 - val_loss: 0.4326 - val_accuracy: 0.8551\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4249 - accuracy: 0.8599 - val_loss: 0.4311 - val_accuracy: 0.8555\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4231 - accuracy: 0.8611 - val_loss: 0.4313 - val_accuracy: 0.8555\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4234 - accuracy: 0.8603 - val_loss: 0.4311 - val_accuracy: 0.8554\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4233 - accuracy: 0.8609 - val_loss: 0.4309 - val_accuracy: 0.8553\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:47.245841\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.0616 - accuracy: 0.5686 - val_loss: 5.7547 - val_accuracy: 0.7231\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9765 - accuracy: 0.7533 - val_loss: 4.2424 - val_accuracy: 0.7899\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6941 - accuracy: 0.7962 - val_loss: 3.1435 - val_accuracy: 0.8112\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.7061 - accuracy: 0.8158 - val_loss: 2.2682 - val_accuracy: 0.8239\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9503 - accuracy: 0.8243 - val_loss: 1.6434 - val_accuracy: 0.8294\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4156 - accuracy: 0.8312 - val_loss: 1.2386 - val_accuracy: 0.8211\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0922 - accuracy: 0.8340 - val_loss: 0.9884 - val_accuracy: 0.8301\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9115 - accuracy: 0.8336 - val_loss: 0.8452 - val_accuracy: 0.8368\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8156 - accuracy: 0.8349 - val_loss: 0.8049 - val_accuracy: 0.8286\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7611 - accuracy: 0.8384 - val_loss: 0.7292 - val_accuracy: 0.8394\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7291 - accuracy: 0.8403 - val_loss: 0.7149 - val_accuracy: 0.8394\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7015 - accuracy: 0.8432 - val_loss: 0.7055 - val_accuracy: 0.8337\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6841 - accuracy: 0.8462 - val_loss: 0.6593 - val_accuracy: 0.8448\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6650 - accuracy: 0.8477 - val_loss: 0.6637 - val_accuracy: 0.8467\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6483 - accuracy: 0.8511 - val_loss: 0.6505 - val_accuracy: 0.8472\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6349 - accuracy: 0.8518 - val_loss: 0.6421 - val_accuracy: 0.8487\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6230 - accuracy: 0.8545 - val_loss: 0.6289 - val_accuracy: 0.8482\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6106 - accuracy: 0.8565 - val_loss: 0.6130 - val_accuracy: 0.8517\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6011 - accuracy: 0.8574 - val_loss: 0.5968 - val_accuracy: 0.8546\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5936 - accuracy: 0.8587 - val_loss: 0.5949 - val_accuracy: 0.8515\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:53.911236\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5629 - accuracy: 0.8651 - val_loss: 0.5661 - val_accuracy: 0.8604\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5413 - accuracy: 0.8686 - val_loss: 0.5415 - val_accuracy: 0.8635\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5314 - accuracy: 0.8709 - val_loss: 0.5341 - val_accuracy: 0.8656\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5246 - accuracy: 0.8724 - val_loss: 0.5297 - val_accuracy: 0.8669\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5213 - accuracy: 0.8736 - val_loss: 0.5276 - val_accuracy: 0.8669\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5197 - accuracy: 0.8732 - val_loss: 0.5272 - val_accuracy: 0.8668\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5196 - accuracy: 0.8742 - val_loss: 0.5268 - val_accuracy: 0.8667\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:12.218367\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 7.0207 - accuracy: 0.5691 - val_loss: 5.6999 - val_accuracy: 0.7355\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9840 - accuracy: 0.7501 - val_loss: 4.2238 - val_accuracy: 0.7963\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7058 - accuracy: 0.7935 - val_loss: 3.1167 - val_accuracy: 0.8213\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.7178 - accuracy: 0.8130 - val_loss: 2.2566 - val_accuracy: 0.8303\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9561 - accuracy: 0.8243 - val_loss: 1.6405 - val_accuracy: 0.8228\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4260 - accuracy: 0.8297 - val_loss: 1.2188 - val_accuracy: 0.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1007 - accuracy: 0.8317 - val_loss: 0.9824 - val_accuracy: 0.8355\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9190 - accuracy: 0.8347 - val_loss: 0.8453 - val_accuracy: 0.8398\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8205 - accuracy: 0.8363 - val_loss: 0.7972 - val_accuracy: 0.8305\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7677 - accuracy: 0.8386 - val_loss: 0.7533 - val_accuracy: 0.8335\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7339 - accuracy: 0.8406 - val_loss: 0.7334 - val_accuracy: 0.8302\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:01.824634\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7812 - accuracy: 0.8481 - val_loss: 0.7439 - val_accuracy: 0.8475\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7246 - accuracy: 0.8535 - val_loss: 0.6955 - val_accuracy: 0.8542\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6986 - accuracy: 0.8568 - val_loss: 0.6716 - val_accuracy: 0.8586\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6842 - accuracy: 0.8591 - val_loss: 0.6602 - val_accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6763 - accuracy: 0.8586 - val_loss: 0.6547 - val_accuracy: 0.8605\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6727 - accuracy: 0.8592 - val_loss: 0.6525 - val_accuracy: 0.8599\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6719 - accuracy: 0.8592 - val_loss: 0.6514 - val_accuracy: 0.8606\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6703 - accuracy: 0.8603 - val_loss: 0.6512 - val_accuracy: 0.8609\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6693 - accuracy: 0.8600 - val_loss: 0.6507 - val_accuracy: 0.8605\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6699 - accuracy: 0.8595 - val_loss: 0.6509 - val_accuracy: 0.8608\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6703 - accuracy: 0.8611 - val_loss: 0.6509 - val_accuracy: 0.8607\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:00.690666\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 7.0599 - accuracy: 0.5603 - val_loss: 5.7211 - val_accuracy: 0.7298\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9928 - accuracy: 0.7488 - val_loss: 4.2339 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7117 - accuracy: 0.7918 - val_loss: 3.1341 - val_accuracy: 0.8167\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.7246 - accuracy: 0.8119 - val_loss: 2.3109 - val_accuracy: 0.8093\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9668 - accuracy: 0.8210 - val_loss: 1.6520 - val_accuracy: 0.8251\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4376 - accuracy: 0.8257 - val_loss: 1.2478 - val_accuracy: 0.8197\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1129 - accuracy: 0.8287 - val_loss: 0.9751 - val_accuracy: 0.8404\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9244 - accuracy: 0.8316 - val_loss: 0.8594 - val_accuracy: 0.8303\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8253 - accuracy: 0.8312 - val_loss: 0.7934 - val_accuracy: 0.8352\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7685 - accuracy: 0.8361 - val_loss: 0.7458 - val_accuracy: 0.8400\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:32.070734\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9083 - accuracy: 0.8417 - val_loss: 0.8453 - val_accuracy: 0.8504\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8342 - accuracy: 0.8473 - val_loss: 0.7868 - val_accuracy: 0.8558\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7973 - accuracy: 0.8509 - val_loss: 0.7632 - val_accuracy: 0.8598\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7787 - accuracy: 0.8516 - val_loss: 0.7450 - val_accuracy: 0.8615\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7685 - accuracy: 0.8531 - val_loss: 0.7392 - val_accuracy: 0.8615\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7632 - accuracy: 0.8535 - val_loss: 0.7364 - val_accuracy: 0.8630\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7615 - accuracy: 0.8543 - val_loss: 0.7355 - val_accuracy: 0.8625\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7609 - accuracy: 0.8536 - val_loss: 0.7350 - val_accuracy: 0.8625\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7607 - accuracy: 0.8531 - val_loss: 0.7349 - val_accuracy: 0.8622\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:01.723175\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.0489 - accuracy: 0.5669 - val_loss: 5.7202 - val_accuracy: 0.7418\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9886 - accuracy: 0.7515 - val_loss: 4.2500 - val_accuracy: 0.7930\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7111 - accuracy: 0.7926 - val_loss: 3.1564 - val_accuracy: 0.8116\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.7188 - accuracy: 0.8139 - val_loss: 2.2895 - val_accuracy: 0.8251\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9579 - accuracy: 0.8246 - val_loss: 1.6628 - val_accuracy: 0.8214\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4242 - accuracy: 0.8291 - val_loss: 1.2697 - val_accuracy: 0.8208\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0949 - accuracy: 0.8331 - val_loss: 0.9882 - val_accuracy: 0.8302\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9066 - accuracy: 0.8357 - val_loss: 0.8741 - val_accuracy: 0.8246\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8087 - accuracy: 0.8362 - val_loss: 0.7678 - val_accuracy: 0.8425\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7568 - accuracy: 0.8378 - val_loss: 0.7548 - val_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7219 - accuracy: 0.8423 - val_loss: 0.7155 - val_accuracy: 0.8402\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6997 - accuracy: 0.8429 - val_loss: 0.6961 - val_accuracy: 0.8408\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:21.254657\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7101 - accuracy: 0.8500 - val_loss: 0.6927 - val_accuracy: 0.8519\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6680 - accuracy: 0.8554 - val_loss: 0.6537 - val_accuracy: 0.8573\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6479 - accuracy: 0.8576 - val_loss: 0.6359 - val_accuracy: 0.8621\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6350 - accuracy: 0.8591 - val_loss: 0.6274 - val_accuracy: 0.8615\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6291 - accuracy: 0.8616 - val_loss: 0.6223 - val_accuracy: 0.8625\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6259 - accuracy: 0.8607 - val_loss: 0.6207 - val_accuracy: 0.8624\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6243 - accuracy: 0.8616 - val_loss: 0.6200 - val_accuracy: 0.8625\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6238 - accuracy: 0.8625 - val_loss: 0.6197 - val_accuracy: 0.8630\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6239 - accuracy: 0.8617 - val_loss: 0.6196 - val_accuracy: 0.8624\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6232 - accuracy: 0.8617 - val_loss: 0.6196 - val_accuracy: 0.8627\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6226 - accuracy: 0.8622 - val_loss: 0.6197 - val_accuracy: 0.8627\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:53.654444\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.0693 - accuracy: 0.5631 - val_loss: 5.7387 - val_accuracy: 0.7370\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9967 - accuracy: 0.7489 - val_loss: 4.2249 - val_accuracy: 0.7937\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7070 - accuracy: 0.7921 - val_loss: 3.1350 - val_accuracy: 0.8172\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.7147 - accuracy: 0.8131 - val_loss: 2.2707 - val_accuracy: 0.8255\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9532 - accuracy: 0.8238 - val_loss: 1.6087 - val_accuracy: 0.8392\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4182 - accuracy: 0.8317 - val_loss: 1.1958 - val_accuracy: 0.8357\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0929 - accuracy: 0.8328 - val_loss: 0.9776 - val_accuracy: 0.8296\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9094 - accuracy: 0.8345 - val_loss: 0.8508 - val_accuracy: 0.8352\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:34.302304\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5025 - accuracy: 0.8378 - val_loss: 1.3626 - val_accuracy: 0.8466\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3427 - accuracy: 0.8427 - val_loss: 1.2626 - val_accuracy: 0.8508\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2674 - accuracy: 0.8469 - val_loss: 1.2095 - val_accuracy: 0.8531\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2309 - accuracy: 0.8470 - val_loss: 1.1829 - val_accuracy: 0.8561\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2135 - accuracy: 0.8470 - val_loss: 1.1722 - val_accuracy: 0.8555\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2066 - accuracy: 0.8491 - val_loss: 1.1675 - val_accuracy: 0.8567\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2009 - accuracy: 0.8490 - val_loss: 1.1655 - val_accuracy: 0.8562\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2019 - accuracy: 0.8490 - val_loss: 1.1652 - val_accuracy: 0.8561\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2018 - accuracy: 0.8488 - val_loss: 1.1648 - val_accuracy: 0.8562\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:00.714357\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.9026 - accuracy: 0.5794 - val_loss: 5.6498 - val_accuracy: 0.7366\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9459 - accuracy: 0.7484 - val_loss: 4.2016 - val_accuracy: 0.7952\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6812 - accuracy: 0.7919 - val_loss: 3.1055 - val_accuracy: 0.8212\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6985 - accuracy: 0.8110 - val_loss: 2.2724 - val_accuracy: 0.8232\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9488 - accuracy: 0.8204 - val_loss: 1.6319 - val_accuracy: 0.8279\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4295 - accuracy: 0.8243 - val_loss: 1.2442 - val_accuracy: 0.8251\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1194 - accuracy: 0.8253 - val_loss: 1.0128 - val_accuracy: 0.8235\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9572 - accuracy: 0.8238 - val_loss: 0.9029 - val_accuracy: 0.8248\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:38.553602\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5039 - accuracy: 0.8326 - val_loss: 1.3776 - val_accuracy: 0.8438\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3470 - accuracy: 0.8376 - val_loss: 1.2821 - val_accuracy: 0.8443\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2726 - accuracy: 0.8399 - val_loss: 1.2291 - val_accuracy: 0.8478\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2345 - accuracy: 0.8419 - val_loss: 1.2056 - val_accuracy: 0.8498\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2179 - accuracy: 0.8437 - val_loss: 1.1955 - val_accuracy: 0.8499\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2100 - accuracy: 0.8436 - val_loss: 1.1907 - val_accuracy: 0.8498\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2084 - accuracy: 0.8432 - val_loss: 1.1887 - val_accuracy: 0.8495\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2056 - accuracy: 0.8441 - val_loss: 1.1878 - val_accuracy: 0.8494\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:38.266614\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.8814 - accuracy: 0.5802 - val_loss: 5.6512 - val_accuracy: 0.7346\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9515 - accuracy: 0.7450 - val_loss: 4.2213 - val_accuracy: 0.7881\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6928 - accuracy: 0.7873 - val_loss: 3.1263 - val_accuracy: 0.8084\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.7141 - accuracy: 0.8064 - val_loss: 2.2736 - val_accuracy: 0.8213\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9609 - accuracy: 0.8173 - val_loss: 1.6511 - val_accuracy: 0.8243\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4412 - accuracy: 0.8209 - val_loss: 1.2319 - val_accuracy: 0.8345\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1295 - accuracy: 0.8235 - val_loss: 1.0409 - val_accuracy: 0.8183\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9657 - accuracy: 0.8227 - val_loss: 0.9183 - val_accuracy: 0.8219\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8812 - accuracy: 0.8235 - val_loss: 0.8383 - val_accuracy: 0.8240\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:04.402622\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1441 - accuracy: 0.8342 - val_loss: 1.0608 - val_accuracy: 0.8419\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0373 - accuracy: 0.8394 - val_loss: 0.9979 - val_accuracy: 0.8393\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9865 - accuracy: 0.8416 - val_loss: 0.9531 - val_accuracy: 0.8460\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9619 - accuracy: 0.8443 - val_loss: 0.9339 - val_accuracy: 0.8489\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9497 - accuracy: 0.8443 - val_loss: 0.9250 - val_accuracy: 0.8504\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9439 - accuracy: 0.8451 - val_loss: 0.9217 - val_accuracy: 0.8508\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9408 - accuracy: 0.8453 - val_loss: 0.9202 - val_accuracy: 0.8506\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9404 - accuracy: 0.8458 - val_loss: 0.9192 - val_accuracy: 0.8506\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9397 - accuracy: 0.8457 - val_loss: 0.9192 - val_accuracy: 0.8503\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:03.953675\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.8998 - accuracy: 0.5774 - val_loss: 5.6617 - val_accuracy: 0.7292\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9665 - accuracy: 0.7424 - val_loss: 4.2094 - val_accuracy: 0.7938\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7028 - accuracy: 0.7864 - val_loss: 3.1406 - val_accuracy: 0.8086\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.7206 - accuracy: 0.8052 - val_loss: 2.2748 - val_accuracy: 0.8194\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9725 - accuracy: 0.8126 - val_loss: 1.6379 - val_accuracy: 0.8294\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4467 - accuracy: 0.8210 - val_loss: 1.2273 - val_accuracy: 0.8299\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1391 - accuracy: 0.8202 - val_loss: 1.0143 - val_accuracy: 0.8244\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9704 - accuracy: 0.8231 - val_loss: 0.9104 - val_accuracy: 0.8233\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8831 - accuracy: 0.8228 - val_loss: 0.8296 - val_accuracy: 0.8299\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:03.443978\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1467 - accuracy: 0.8361 - val_loss: 1.0593 - val_accuracy: 0.8413\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0414 - accuracy: 0.8401 - val_loss: 0.9934 - val_accuracy: 0.8420\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9896 - accuracy: 0.8418 - val_loss: 0.9501 - val_accuracy: 0.8470\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9650 - accuracy: 0.8424 - val_loss: 0.9320 - val_accuracy: 0.8485\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9517 - accuracy: 0.8439 - val_loss: 0.9241 - val_accuracy: 0.8499\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9467 - accuracy: 0.8440 - val_loss: 0.9204 - val_accuracy: 0.8500\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9435 - accuracy: 0.8441 - val_loss: 0.9190 - val_accuracy: 0.8500\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9447 - accuracy: 0.8441 - val_loss: 0.9181 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9426 - accuracy: 0.8447 - val_loss: 0.9179 - val_accuracy: 0.8500\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:07.350337\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.8695 - accuracy: 0.5852 - val_loss: 5.6173 - val_accuracy: 0.7453\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9314 - accuracy: 0.7519 - val_loss: 4.2018 - val_accuracy: 0.8005\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6807 - accuracy: 0.7900 - val_loss: 3.1175 - val_accuracy: 0.8135\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.6982 - accuracy: 0.8111 - val_loss: 2.2648 - val_accuracy: 0.8216\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9456 - accuracy: 0.8204 - val_loss: 1.6281 - val_accuracy: 0.8283\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4265 - accuracy: 0.8247 - val_loss: 1.2442 - val_accuracy: 0.8213\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1179 - accuracy: 0.8256 - val_loss: 1.0059 - val_accuracy: 0.8293\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9520 - accuracy: 0.8253 - val_loss: 0.8860 - val_accuracy: 0.8338\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8680 - accuracy: 0.8255 - val_loss: 0.8260 - val_accuracy: 0.8296\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8144 - accuracy: 0.8283 - val_loss: 0.7806 - val_accuracy: 0.8359\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7823 - accuracy: 0.8288 - val_loss: 0.7563 - val_accuracy: 0.8320\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7555 - accuracy: 0.8301 - val_loss: 0.7374 - val_accuracy: 0.8384\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7356 - accuracy: 0.8326 - val_loss: 0.7159 - val_accuracy: 0.8402\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7172 - accuracy: 0.8343 - val_loss: 0.7141 - val_accuracy: 0.8309\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6993 - accuracy: 0.8384 - val_loss: 0.6935 - val_accuracy: 0.8377\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6847 - accuracy: 0.8390 - val_loss: 0.6689 - val_accuracy: 0.8458\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6720 - accuracy: 0.8407 - val_loss: 0.6782 - val_accuracy: 0.8391\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6587 - accuracy: 0.8437 - val_loss: 0.6661 - val_accuracy: 0.8371\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6513 - accuracy: 0.8444 - val_loss: 0.6505 - val_accuracy: 0.8436\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:35.082542\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6325 - accuracy: 0.8492 - val_loss: 0.6247 - val_accuracy: 0.8504\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6078 - accuracy: 0.8547 - val_loss: 0.6032 - val_accuracy: 0.8556\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5935 - accuracy: 0.8567 - val_loss: 0.5934 - val_accuracy: 0.8562\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5870 - accuracy: 0.8590 - val_loss: 0.5884 - val_accuracy: 0.8577\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5844 - accuracy: 0.8582 - val_loss: 0.5860 - val_accuracy: 0.8577\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5822 - accuracy: 0.8586 - val_loss: 0.5853 - val_accuracy: 0.8573\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5797 - accuracy: 0.8590 - val_loss: 0.5851 - val_accuracy: 0.8576\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5796 - accuracy: 0.8593 - val_loss: 0.5849 - val_accuracy: 0.8578\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5809 - accuracy: 0.8588 - val_loss: 0.5849 - val_accuracy: 0.8579\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5796 - accuracy: 0.8600 - val_loss: 0.5849 - val_accuracy: 0.8575\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5801 - accuracy: 0.8597 - val_loss: 0.5848 - val_accuracy: 0.8576\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5797 - accuracy: 0.8595 - val_loss: 0.5851 - val_accuracy: 0.8582\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5804 - accuracy: 0.8594 - val_loss: 0.5846 - val_accuracy: 0.8579\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5801 - accuracy: 0.8606 - val_loss: 0.5848 - val_accuracy: 0.8582\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5797 - accuracy: 0.8588 - val_loss: 0.5848 - val_accuracy: 0.8582\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:06:42.677666\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.8400 - accuracy: 0.5948 - val_loss: 5.6096 - val_accuracy: 0.7456\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9162 - accuracy: 0.7553 - val_loss: 4.1769 - val_accuracy: 0.8008\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6707 - accuracy: 0.7931 - val_loss: 3.1066 - val_accuracy: 0.8148\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6957 - accuracy: 0.8112 - val_loss: 2.2512 - val_accuracy: 0.8276\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9433 - accuracy: 0.8220 - val_loss: 1.6353 - val_accuracy: 0.8161\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4261 - accuracy: 0.8257 - val_loss: 1.2395 - val_accuracy: 0.8250\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1238 - accuracy: 0.8253 - val_loss: 1.0386 - val_accuracy: 0.8205\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:10.805449\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.1052 - accuracy: 0.8251 - val_loss: 1.9302 - val_accuracy: 0.8355\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8753 - accuracy: 0.8320 - val_loss: 1.7786 - val_accuracy: 0.8390\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7668 - accuracy: 0.8341 - val_loss: 1.7085 - val_accuracy: 0.8414\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7165 - accuracy: 0.8361 - val_loss: 1.6737 - val_accuracy: 0.8430\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6948 - accuracy: 0.8361 - val_loss: 1.6598 - val_accuracy: 0.8428\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6823 - accuracy: 0.8372 - val_loss: 1.6531 - val_accuracy: 0.8430\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6768 - accuracy: 0.8378 - val_loss: 1.6502 - val_accuracy: 0.8430\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:09.774661\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9063 - accuracy: 0.5894 - val_loss: 5.6530 - val_accuracy: 0.7390\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.9347 - accuracy: 0.7552 - val_loss: 4.2333 - val_accuracy: 0.7910\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6790 - accuracy: 0.7969 - val_loss: 3.1285 - val_accuracy: 0.8144\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.7021 - accuracy: 0.8156 - val_loss: 2.2777 - val_accuracy: 0.8274\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9494 - accuracy: 0.8247 - val_loss: 1.6393 - val_accuracy: 0.8269\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4265 - accuracy: 0.8290 - val_loss: 1.2344 - val_accuracy: 0.8323\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1103 - accuracy: 0.8319 - val_loss: 0.9918 - val_accuracy: 0.8359\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9345 - accuracy: 0.8322 - val_loss: 0.8852 - val_accuracy: 0.8269\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8409 - accuracy: 0.8331 - val_loss: 0.8190 - val_accuracy: 0.8287\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7883 - accuracy: 0.8333 - val_loss: 0.7749 - val_accuracy: 0.8369\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7495 - accuracy: 0.8374 - val_loss: 0.7285 - val_accuracy: 0.8344\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7244 - accuracy: 0.8390 - val_loss: 0.7181 - val_accuracy: 0.8367\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7021 - accuracy: 0.8409 - val_loss: 0.6878 - val_accuracy: 0.8451\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6814 - accuracy: 0.8444 - val_loss: 0.6760 - val_accuracy: 0.8478\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6669 - accuracy: 0.8450 - val_loss: 0.6601 - val_accuracy: 0.8460\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6526 - accuracy: 0.8471 - val_loss: 0.6449 - val_accuracy: 0.8512\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6398 - accuracy: 0.8496 - val_loss: 0.6431 - val_accuracy: 0.8473\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6303 - accuracy: 0.8489 - val_loss: 0.6214 - val_accuracy: 0.8532\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6189 - accuracy: 0.8520 - val_loss: 0.6153 - val_accuracy: 0.8516\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6098 - accuracy: 0.8535 - val_loss: 0.6128 - val_accuracy: 0.8492\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:21.405115\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5762 - accuracy: 0.8605 - val_loss: 0.5687 - val_accuracy: 0.8636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5559 - accuracy: 0.8642 - val_loss: 0.5505 - val_accuracy: 0.8686\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5440 - accuracy: 0.8674 - val_loss: 0.5417 - val_accuracy: 0.8695\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5369 - accuracy: 0.8680 - val_loss: 0.5370 - val_accuracy: 0.8696\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5339 - accuracy: 0.8681 - val_loss: 0.5354 - val_accuracy: 0.8699\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5319 - accuracy: 0.8698 - val_loss: 0.5344 - val_accuracy: 0.8708\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5312 - accuracy: 0.8695 - val_loss: 0.5339 - val_accuracy: 0.8704\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5309 - accuracy: 0.8682 - val_loss: 0.5339 - val_accuracy: 0.8706\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5298 - accuracy: 0.8697 - val_loss: 0.5341 - val_accuracy: 0.8706\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:11.394507\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9145 - accuracy: 0.5844 - val_loss: 5.6499 - val_accuracy: 0.7387\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.9289 - accuracy: 0.7585 - val_loss: 4.2057 - val_accuracy: 0.7977\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6782 - accuracy: 0.7987 - val_loss: 3.1205 - val_accuracy: 0.8132\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.7067 - accuracy: 0.8149 - val_loss: 2.2662 - val_accuracy: 0.8287\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9527 - accuracy: 0.8238 - val_loss: 1.6410 - val_accuracy: 0.8271\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4292 - accuracy: 0.8281 - val_loss: 1.2336 - val_accuracy: 0.8307\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1128 - accuracy: 0.8301 - val_loss: 1.0235 - val_accuracy: 0.8238\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9373 - accuracy: 0.8308 - val_loss: 0.8784 - val_accuracy: 0.8290\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8456 - accuracy: 0.8323 - val_loss: 0.7965 - val_accuracy: 0.8383\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7933 - accuracy: 0.8335 - val_loss: 0.7664 - val_accuracy: 0.8353\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7579 - accuracy: 0.8351 - val_loss: 0.7318 - val_accuracy: 0.8354\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7275 - accuracy: 0.8407 - val_loss: 0.7240 - val_accuracy: 0.8340\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:37.428215\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7412 - accuracy: 0.8468 - val_loss: 0.7106 - val_accuracy: 0.8487\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6980 - accuracy: 0.8510 - val_loss: 0.6783 - val_accuracy: 0.8532\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6746 - accuracy: 0.8547 - val_loss: 0.6576 - val_accuracy: 0.8540\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6610 - accuracy: 0.8570 - val_loss: 0.6480 - val_accuracy: 0.8569\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6562 - accuracy: 0.8580 - val_loss: 0.6422 - val_accuracy: 0.8575\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6515 - accuracy: 0.8571 - val_loss: 0.6403 - val_accuracy: 0.8586\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6501 - accuracy: 0.8583 - val_loss: 0.6393 - val_accuracy: 0.8583\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6491 - accuracy: 0.8585 - val_loss: 0.6392 - val_accuracy: 0.8584\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6502 - accuracy: 0.8572 - val_loss: 0.6391 - val_accuracy: 0.8581\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:13.938409\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9270 - accuracy: 0.5815 - val_loss: 5.6800 - val_accuracy: 0.7346\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.9414 - accuracy: 0.7551 - val_loss: 4.2291 - val_accuracy: 0.7903\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6853 - accuracy: 0.7956 - val_loss: 3.1398 - val_accuracy: 0.8110\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.7061 - accuracy: 0.8161 - val_loss: 2.2889 - val_accuracy: 0.8168\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9540 - accuracy: 0.8232 - val_loss: 1.6604 - val_accuracy: 0.8266\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4293 - accuracy: 0.8288 - val_loss: 1.2397 - val_accuracy: 0.8281\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1129 - accuracy: 0.8304 - val_loss: 1.0204 - val_accuracy: 0.8233\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9357 - accuracy: 0.8325 - val_loss: 0.8810 - val_accuracy: 0.8265\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8430 - accuracy: 0.8331 - val_loss: 0.8297 - val_accuracy: 0.8276\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:13.127457\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.1289 - accuracy: 0.8410 - val_loss: 1.0533 - val_accuracy: 0.8434\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0194 - accuracy: 0.8465 - val_loss: 0.9755 - val_accuracy: 0.8490\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9668 - accuracy: 0.8491 - val_loss: 0.9410 - val_accuracy: 0.8507\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9422 - accuracy: 0.8509 - val_loss: 0.9220 - val_accuracy: 0.8528\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9290 - accuracy: 0.8526 - val_loss: 0.9144 - val_accuracy: 0.8531\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9227 - accuracy: 0.8528 - val_loss: 0.9102 - val_accuracy: 0.8528\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9213 - accuracy: 0.8534 - val_loss: 0.9088 - val_accuracy: 0.8528\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9197 - accuracy: 0.8525 - val_loss: 0.9081 - val_accuracy: 0.8528\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:47.519743\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.8940 - accuracy: 0.5900 - val_loss: 5.6235 - val_accuracy: 0.7457\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.9234 - accuracy: 0.7586 - val_loss: 4.2150 - val_accuracy: 0.7930\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6765 - accuracy: 0.7978 - val_loss: 3.1036 - val_accuracy: 0.8244\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.7011 - accuracy: 0.8152 - val_loss: 2.2691 - val_accuracy: 0.8206\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9463 - accuracy: 0.8246 - val_loss: 1.6023 - val_accuracy: 0.8361\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4198 - accuracy: 0.8297 - val_loss: 1.2143 - val_accuracy: 0.8354\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1037 - accuracy: 0.8302 - val_loss: 0.9637 - val_accuracy: 0.8436\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9269 - accuracy: 0.8319 - val_loss: 0.8546 - val_accuracy: 0.8376\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8359 - accuracy: 0.8326 - val_loss: 0.7928 - val_accuracy: 0.8328\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7812 - accuracy: 0.8348 - val_loss: 0.7485 - val_accuracy: 0.8376\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:44.143826\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.9081 - accuracy: 0.8419 - val_loss: 0.8431 - val_accuracy: 0.8480\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8341 - accuracy: 0.8471 - val_loss: 0.7920 - val_accuracy: 0.8543\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7989 - accuracy: 0.8517 - val_loss: 0.7638 - val_accuracy: 0.8578\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7815 - accuracy: 0.8518 - val_loss: 0.7490 - val_accuracy: 0.8595\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7722 - accuracy: 0.8530 - val_loss: 0.7430 - val_accuracy: 0.8592\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7668 - accuracy: 0.8538 - val_loss: 0.7403 - val_accuracy: 0.8595\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7656 - accuracy: 0.8536 - val_loss: 0.7392 - val_accuracy: 0.8589\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:18.324331\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 6.8734 - accuracy: 0.5922 - val_loss: 5.6354 - val_accuracy: 0.7441\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.9325 - accuracy: 0.7505 - val_loss: 4.1926 - val_accuracy: 0.7969\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6848 - accuracy: 0.7913 - val_loss: 3.1214 - val_accuracy: 0.8115\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 2.7124 - accuracy: 0.8081 - val_loss: 2.2560 - val_accuracy: 0.8302\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.9601 - accuracy: 0.8209 - val_loss: 1.6387 - val_accuracy: 0.8259\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4360 - accuracy: 0.8251 - val_loss: 1.2395 - val_accuracy: 0.8264\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1233 - accuracy: 0.8263 - val_loss: 1.0335 - val_accuracy: 0.8243\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:27.733115\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.1161 - accuracy: 0.8250 - val_loss: 1.9299 - val_accuracy: 0.8385\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.8887 - accuracy: 0.8299 - val_loss: 1.7818 - val_accuracy: 0.8426\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7775 - accuracy: 0.8348 - val_loss: 1.7114 - val_accuracy: 0.8448\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7261 - accuracy: 0.8362 - val_loss: 1.6715 - val_accuracy: 0.8481\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7033 - accuracy: 0.8362 - val_loss: 1.6566 - val_accuracy: 0.8488\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6912 - accuracy: 0.8374 - val_loss: 1.6503 - val_accuracy: 0.8494\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6865 - accuracy: 0.8376 - val_loss: 1.6479 - val_accuracy: 0.8490\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6851 - accuracy: 0.8378 - val_loss: 1.6469 - val_accuracy: 0.8492\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6829 - accuracy: 0.8376 - val_loss: 1.6466 - val_accuracy: 0.8497\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6836 - accuracy: 0.8380 - val_loss: 1.6465 - val_accuracy: 0.8492\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6829 - accuracy: 0.8377 - val_loss: 1.6465 - val_accuracy: 0.8491\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6849 - accuracy: 0.8366 - val_loss: 1.6465 - val_accuracy: 0.8488\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:51.597990\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.9499 - accuracy: 0.5635 - val_loss: 1.2925 - val_accuracy: 0.7291\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1776 - accuracy: 0.7388 - val_loss: 0.9829 - val_accuracy: 0.7869\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9672 - accuracy: 0.7846 - val_loss: 0.8600 - val_accuracy: 0.8102\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8645 - accuracy: 0.8060 - val_loss: 0.7961 - val_accuracy: 0.8207\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8013 - accuracy: 0.8186 - val_loss: 0.7318 - val_accuracy: 0.8349\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7566 - accuracy: 0.8282 - val_loss: 0.7202 - val_accuracy: 0.8367\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7228 - accuracy: 0.8348 - val_loss: 0.6976 - val_accuracy: 0.8391\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7002 - accuracy: 0.8385 - val_loss: 0.6689 - val_accuracy: 0.8468\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6782 - accuracy: 0.8443 - val_loss: 0.6536 - val_accuracy: 0.8490\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6613 - accuracy: 0.8484 - val_loss: 0.6443 - val_accuracy: 0.8515\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6477 - accuracy: 0.8513 - val_loss: 0.6321 - val_accuracy: 0.8528\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6348 - accuracy: 0.8544 - val_loss: 0.6221 - val_accuracy: 0.8543\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6259 - accuracy: 0.8560 - val_loss: 0.6146 - val_accuracy: 0.8567\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6168 - accuracy: 0.8576 - val_loss: 0.6098 - val_accuracy: 0.8578\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6088 - accuracy: 0.8590 - val_loss: 0.6000 - val_accuracy: 0.8581\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6010 - accuracy: 0.8600 - val_loss: 0.5959 - val_accuracy: 0.8606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5945 - accuracy: 0.8625 - val_loss: 0.5915 - val_accuracy: 0.8618\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5906 - accuracy: 0.8633 - val_loss: 0.5909 - val_accuracy: 0.8605\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5836 - accuracy: 0.8645 - val_loss: 0.5833 - val_accuracy: 0.8631\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5788 - accuracy: 0.8671 - val_loss: 0.5814 - val_accuracy: 0.8624\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:12.312989\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5738 - accuracy: 0.8667 - val_loss: 0.5775 - val_accuracy: 0.8635\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5712 - accuracy: 0.8678 - val_loss: 0.5757 - val_accuracy: 0.8644\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5696 - accuracy: 0.8686 - val_loss: 0.5751 - val_accuracy: 0.8650\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5681 - accuracy: 0.8695 - val_loss: 0.5748 - val_accuracy: 0.8650\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5671 - accuracy: 0.8691 - val_loss: 0.5748 - val_accuracy: 0.8651\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5691 - accuracy: 0.8679 - val_loss: 0.5747 - val_accuracy: 0.8653\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5689 - accuracy: 0.8689 - val_loss: 0.5746 - val_accuracy: 0.8649\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5702 - accuracy: 0.8686 - val_loss: 0.5746 - val_accuracy: 0.8651\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5684 - accuracy: 0.8692 - val_loss: 0.5746 - val_accuracy: 0.8654\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5708 - accuracy: 0.8681 - val_loss: 0.5746 - val_accuracy: 0.8648\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5681 - accuracy: 0.8692 - val_loss: 0.5747 - val_accuracy: 0.8648\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5687 - accuracy: 0.8688 - val_loss: 0.5746 - val_accuracy: 0.8653\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:26.642758\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9075 - accuracy: 0.5719 - val_loss: 1.2530 - val_accuracy: 0.7372\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1524 - accuracy: 0.7458 - val_loss: 0.9584 - val_accuracy: 0.7885\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9524 - accuracy: 0.7882 - val_loss: 0.8282 - val_accuracy: 0.8170\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8548 - accuracy: 0.8078 - val_loss: 0.7668 - val_accuracy: 0.8302\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7931 - accuracy: 0.8221 - val_loss: 0.7299 - val_accuracy: 0.8357\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7501 - accuracy: 0.8309 - val_loss: 0.6970 - val_accuracy: 0.8453\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7179 - accuracy: 0.8362 - val_loss: 0.6713 - val_accuracy: 0.8476\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6920 - accuracy: 0.8428 - val_loss: 0.6544 - val_accuracy: 0.8512\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6732 - accuracy: 0.8464 - val_loss: 0.6372 - val_accuracy: 0.8565\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6560 - accuracy: 0.8494 - val_loss: 0.6272 - val_accuracy: 0.8569\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6417 - accuracy: 0.8528 - val_loss: 0.6131 - val_accuracy: 0.8602\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6307 - accuracy: 0.8556 - val_loss: 0.6046 - val_accuracy: 0.8614\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6204 - accuracy: 0.8580 - val_loss: 0.5933 - val_accuracy: 0.8643\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6086 - accuracy: 0.8603 - val_loss: 0.5877 - val_accuracy: 0.8656\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6014 - accuracy: 0.8611 - val_loss: 0.5818 - val_accuracy: 0.8659\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5940 - accuracy: 0.8634 - val_loss: 0.5774 - val_accuracy: 0.8664\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5882 - accuracy: 0.8640 - val_loss: 0.5741 - val_accuracy: 0.8671\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5835 - accuracy: 0.8652 - val_loss: 0.5708 - val_accuracy: 0.8673\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5793 - accuracy: 0.8660 - val_loss: 0.5673 - val_accuracy: 0.8687\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5739 - accuracy: 0.8682 - val_loss: 0.5641 - val_accuracy: 0.8695\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:03.309552\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5686 - accuracy: 0.8686 - val_loss: 0.5602 - val_accuracy: 0.8698\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5669 - accuracy: 0.8698 - val_loss: 0.5593 - val_accuracy: 0.8707\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5638 - accuracy: 0.8710 - val_loss: 0.5584 - val_accuracy: 0.8708\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5655 - accuracy: 0.8695 - val_loss: 0.5581 - val_accuracy: 0.8712\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5606 - accuracy: 0.8721 - val_loss: 0.5582 - val_accuracy: 0.8706\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5636 - accuracy: 0.8709 - val_loss: 0.5581 - val_accuracy: 0.8709\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5635 - accuracy: 0.8702 - val_loss: 0.5581 - val_accuracy: 0.8707\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:10.364439\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8863 - accuracy: 0.5761 - val_loss: 1.2540 - val_accuracy: 0.7368\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1415 - accuracy: 0.7472 - val_loss: 0.9497 - val_accuracy: 0.7929\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9467 - accuracy: 0.7873 - val_loss: 0.8459 - val_accuracy: 0.8071\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8497 - accuracy: 0.8094 - val_loss: 0.7822 - val_accuracy: 0.8246\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7877 - accuracy: 0.8225 - val_loss: 0.7314 - val_accuracy: 0.8343\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7453 - accuracy: 0.8310 - val_loss: 0.6998 - val_accuracy: 0.8422\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7140 - accuracy: 0.8366 - val_loss: 0.6853 - val_accuracy: 0.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6889 - accuracy: 0.8415 - val_loss: 0.6662 - val_accuracy: 0.8478\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6707 - accuracy: 0.8478 - val_loss: 0.6465 - val_accuracy: 0.8511\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6534 - accuracy: 0.8500 - val_loss: 0.6387 - val_accuracy: 0.8529\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6394 - accuracy: 0.8529 - val_loss: 0.6244 - val_accuracy: 0.8556\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6277 - accuracy: 0.8560 - val_loss: 0.6133 - val_accuracy: 0.8602\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6169 - accuracy: 0.8584 - val_loss: 0.6072 - val_accuracy: 0.8609\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6094 - accuracy: 0.8586 - val_loss: 0.5997 - val_accuracy: 0.8613\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6011 - accuracy: 0.8604 - val_loss: 0.5973 - val_accuracy: 0.8612\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5932 - accuracy: 0.8634 - val_loss: 0.5919 - val_accuracy: 0.8628\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5873 - accuracy: 0.8634 - val_loss: 0.5860 - val_accuracy: 0.8627\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5812 - accuracy: 0.8657 - val_loss: 0.5815 - val_accuracy: 0.8637\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5751 - accuracy: 0.8669 - val_loss: 0.5807 - val_accuracy: 0.8637\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5710 - accuracy: 0.8686 - val_loss: 0.5748 - val_accuracy: 0.8662\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:02.506920\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5645 - accuracy: 0.8688 - val_loss: 0.5727 - val_accuracy: 0.8669\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5632 - accuracy: 0.8697 - val_loss: 0.5714 - val_accuracy: 0.8658\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5619 - accuracy: 0.8705 - val_loss: 0.5707 - val_accuracy: 0.8665\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5620 - accuracy: 0.8701 - val_loss: 0.5704 - val_accuracy: 0.8661\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:01:48.594798\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8884 - accuracy: 0.5731 - val_loss: 1.2376 - val_accuracy: 0.7333\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1271 - accuracy: 0.7465 - val_loss: 0.9319 - val_accuracy: 0.7940\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9376 - accuracy: 0.7884 - val_loss: 0.8238 - val_accuracy: 0.8181\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8466 - accuracy: 0.8092 - val_loss: 0.7586 - val_accuracy: 0.8281\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7857 - accuracy: 0.8206 - val_loss: 0.7254 - val_accuracy: 0.8363\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7443 - accuracy: 0.8306 - val_loss: 0.6894 - val_accuracy: 0.8433\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7146 - accuracy: 0.8362 - val_loss: 0.6714 - val_accuracy: 0.8410\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6890 - accuracy: 0.8427 - val_loss: 0.6527 - val_accuracy: 0.8477\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6690 - accuracy: 0.8483 - val_loss: 0.6344 - val_accuracy: 0.8521\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6527 - accuracy: 0.8515 - val_loss: 0.6233 - val_accuracy: 0.8537\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6372 - accuracy: 0.8546 - val_loss: 0.6106 - val_accuracy: 0.8558\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6288 - accuracy: 0.8547 - val_loss: 0.6027 - val_accuracy: 0.8587\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6174 - accuracy: 0.8587 - val_loss: 0.5956 - val_accuracy: 0.8589\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6080 - accuracy: 0.8597 - val_loss: 0.5880 - val_accuracy: 0.8622\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6001 - accuracy: 0.8610 - val_loss: 0.5803 - val_accuracy: 0.8639\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5932 - accuracy: 0.8640 - val_loss: 0.5807 - val_accuracy: 0.8609\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5862 - accuracy: 0.8651 - val_loss: 0.5739 - val_accuracy: 0.8634\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5824 - accuracy: 0.8651 - val_loss: 0.5703 - val_accuracy: 0.8637\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:06.340671\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5903 - accuracy: 0.8642 - val_loss: 0.5776 - val_accuracy: 0.8629\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5867 - accuracy: 0.8655 - val_loss: 0.5756 - val_accuracy: 0.8642\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5844 - accuracy: 0.8648 - val_loss: 0.5739 - val_accuracy: 0.8638\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5832 - accuracy: 0.8667 - val_loss: 0.5738 - val_accuracy: 0.8637\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5842 - accuracy: 0.8665 - val_loss: 0.5733 - val_accuracy: 0.8639\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:15.101506\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9020 - accuracy: 0.5698 - val_loss: 1.2492 - val_accuracy: 0.7363\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1450 - accuracy: 0.7455 - val_loss: 0.9455 - val_accuracy: 0.7945\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9503 - accuracy: 0.7859 - val_loss: 0.8352 - val_accuracy: 0.8170\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8533 - accuracy: 0.8073 - val_loss: 0.7747 - val_accuracy: 0.8280\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7882 - accuracy: 0.8218 - val_loss: 0.7329 - val_accuracy: 0.8285\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7465 - accuracy: 0.8302 - val_loss: 0.6933 - val_accuracy: 0.8455\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7175 - accuracy: 0.8365 - val_loss: 0.6792 - val_accuracy: 0.8445\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6918 - accuracy: 0.8414 - val_loss: 0.6546 - val_accuracy: 0.8528\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6713 - accuracy: 0.8449 - val_loss: 0.6372 - val_accuracy: 0.8559\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6545 - accuracy: 0.8506 - val_loss: 0.6262 - val_accuracy: 0.8575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6420 - accuracy: 0.8529 - val_loss: 0.6211 - val_accuracy: 0.8593\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6300 - accuracy: 0.8543 - val_loss: 0.6091 - val_accuracy: 0.8609\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6213 - accuracy: 0.8561 - val_loss: 0.6018 - val_accuracy: 0.8611\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6111 - accuracy: 0.8600 - val_loss: 0.5978 - val_accuracy: 0.8625\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6035 - accuracy: 0.8604 - val_loss: 0.5915 - val_accuracy: 0.8621\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5976 - accuracy: 0.8613 - val_loss: 0.5864 - val_accuracy: 0.8636\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5889 - accuracy: 0.8636 - val_loss: 0.5821 - val_accuracy: 0.8641\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5847 - accuracy: 0.8646 - val_loss: 0.5782 - val_accuracy: 0.8660\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5809 - accuracy: 0.8657 - val_loss: 0.5754 - val_accuracy: 0.8673\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5755 - accuracy: 0.8671 - val_loss: 0.5714 - val_accuracy: 0.8671\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:59.269522\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5715 - accuracy: 0.8674 - val_loss: 0.5690 - val_accuracy: 0.8674\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5690 - accuracy: 0.8672 - val_loss: 0.5679 - val_accuracy: 0.8670\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5681 - accuracy: 0.8678 - val_loss: 0.5670 - val_accuracy: 0.8676\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5659 - accuracy: 0.8693 - val_loss: 0.5669 - val_accuracy: 0.8673\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5668 - accuracy: 0.8688 - val_loss: 0.5667 - val_accuracy: 0.8672\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5645 - accuracy: 0.8695 - val_loss: 0.5668 - val_accuracy: 0.8674\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:42.052968\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7664 - accuracy: 0.5880 - val_loss: 1.1535 - val_accuracy: 0.7493\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0997 - accuracy: 0.7490 - val_loss: 0.9205 - val_accuracy: 0.7977\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9391 - accuracy: 0.7867 - val_loss: 0.8288 - val_accuracy: 0.8132\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8579 - accuracy: 0.8033 - val_loss: 0.7751 - val_accuracy: 0.8285\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8060 - accuracy: 0.8158 - val_loss: 0.7433 - val_accuracy: 0.8330\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7672 - accuracy: 0.8240 - val_loss: 0.7106 - val_accuracy: 0.8396\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7369 - accuracy: 0.8310 - val_loss: 0.6895 - val_accuracy: 0.8449\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7178 - accuracy: 0.8333 - val_loss: 0.6856 - val_accuracy: 0.8436\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6982 - accuracy: 0.8380 - val_loss: 0.6702 - val_accuracy: 0.8473\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6852 - accuracy: 0.8410 - val_loss: 0.6516 - val_accuracy: 0.8516\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6702 - accuracy: 0.8458 - val_loss: 0.6485 - val_accuracy: 0.8523\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6583 - accuracy: 0.8471 - val_loss: 0.6382 - val_accuracy: 0.8531\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6496 - accuracy: 0.8486 - val_loss: 0.6323 - val_accuracy: 0.8552\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6415 - accuracy: 0.8493 - val_loss: 0.6236 - val_accuracy: 0.8558\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6341 - accuracy: 0.8528 - val_loss: 0.6196 - val_accuracy: 0.8565\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6287 - accuracy: 0.8521 - val_loss: 0.6143 - val_accuracy: 0.8560\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6221 - accuracy: 0.8539 - val_loss: 0.6090 - val_accuracy: 0.8578\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6180 - accuracy: 0.8552 - val_loss: 0.6064 - val_accuracy: 0.8593\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6132 - accuracy: 0.8566 - val_loss: 0.6029 - val_accuracy: 0.8607\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6073 - accuracy: 0.8571 - val_loss: 0.6001 - val_accuracy: 0.8597\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:08.698222\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6014 - accuracy: 0.8597 - val_loss: 0.5984 - val_accuracy: 0.8603\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5993 - accuracy: 0.8589 - val_loss: 0.5978 - val_accuracy: 0.8598\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6001 - accuracy: 0.8601 - val_loss: 0.5967 - val_accuracy: 0.8614\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6000 - accuracy: 0.8597 - val_loss: 0.5967 - val_accuracy: 0.8614\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5969 - accuracy: 0.8598 - val_loss: 0.5967 - val_accuracy: 0.8610\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5982 - accuracy: 0.8598 - val_loss: 0.5965 - val_accuracy: 0.8614\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:45.445416\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8016 - accuracy: 0.5755 - val_loss: 1.2364 - val_accuracy: 0.7246\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1374 - accuracy: 0.7391 - val_loss: 0.9554 - val_accuracy: 0.7904\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9561 - accuracy: 0.7802 - val_loss: 0.8519 - val_accuracy: 0.8092\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8652 - accuracy: 0.8014 - val_loss: 0.7858 - val_accuracy: 0.8215\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8100 - accuracy: 0.8147 - val_loss: 0.7489 - val_accuracy: 0.8289\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7679 - accuracy: 0.8227 - val_loss: 0.7259 - val_accuracy: 0.8338\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7387 - accuracy: 0.8307 - val_loss: 0.7016 - val_accuracy: 0.8407\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7187 - accuracy: 0.8333 - val_loss: 0.6813 - val_accuracy: 0.8456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6986 - accuracy: 0.8379 - val_loss: 0.6719 - val_accuracy: 0.8449\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6807 - accuracy: 0.8415 - val_loss: 0.6662 - val_accuracy: 0.8484\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6709 - accuracy: 0.8436 - val_loss: 0.6508 - val_accuracy: 0.8515\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6575 - accuracy: 0.8465 - val_loss: 0.6435 - val_accuracy: 0.8512\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6491 - accuracy: 0.8479 - val_loss: 0.6351 - val_accuracy: 0.8527\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6415 - accuracy: 0.8504 - val_loss: 0.6323 - val_accuracy: 0.8535\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6336 - accuracy: 0.8520 - val_loss: 0.6228 - val_accuracy: 0.8553\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6243 - accuracy: 0.8538 - val_loss: 0.6179 - val_accuracy: 0.8577\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6200 - accuracy: 0.8548 - val_loss: 0.6180 - val_accuracy: 0.8561\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6142 - accuracy: 0.8562 - val_loss: 0.6123 - val_accuracy: 0.8570\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6123 - accuracy: 0.8558 - val_loss: 0.6087 - val_accuracy: 0.8568\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:39.639637\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6170 - accuracy: 0.8570 - val_loss: 0.6139 - val_accuracy: 0.8581\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6169 - accuracy: 0.8562 - val_loss: 0.6129 - val_accuracy: 0.8587\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6138 - accuracy: 0.8557 - val_loss: 0.6124 - val_accuracy: 0.8588\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6130 - accuracy: 0.8565 - val_loss: 0.6117 - val_accuracy: 0.8589\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6139 - accuracy: 0.8565 - val_loss: 0.6120 - val_accuracy: 0.8586\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6115 - accuracy: 0.8569 - val_loss: 0.6119 - val_accuracy: 0.8591\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6147 - accuracy: 0.8556 - val_loss: 0.6120 - val_accuracy: 0.8591\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6117 - accuracy: 0.8568 - val_loss: 0.6118 - val_accuracy: 0.8591\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6128 - accuracy: 0.8562 - val_loss: 0.6117 - val_accuracy: 0.8588\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6117 - accuracy: 0.8579 - val_loss: 0.6116 - val_accuracy: 0.8586\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:33.967259\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8013 - accuracy: 0.5766 - val_loss: 1.2249 - val_accuracy: 0.7298\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1221 - accuracy: 0.7441 - val_loss: 0.9448 - val_accuracy: 0.7882\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9484 - accuracy: 0.7835 - val_loss: 0.8500 - val_accuracy: 0.8096\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8623 - accuracy: 0.8038 - val_loss: 0.7960 - val_accuracy: 0.8198\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8065 - accuracy: 0.8153 - val_loss: 0.7705 - val_accuracy: 0.8262\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7651 - accuracy: 0.8246 - val_loss: 0.7275 - val_accuracy: 0.8325\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7347 - accuracy: 0.8309 - val_loss: 0.7241 - val_accuracy: 0.8326\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7141 - accuracy: 0.8357 - val_loss: 0.6975 - val_accuracy: 0.8380\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6917 - accuracy: 0.8417 - val_loss: 0.6829 - val_accuracy: 0.8392\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6782 - accuracy: 0.8442 - val_loss: 0.6708 - val_accuracy: 0.8452\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6640 - accuracy: 0.8459 - val_loss: 0.6594 - val_accuracy: 0.8442\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6521 - accuracy: 0.8491 - val_loss: 0.6506 - val_accuracy: 0.8474\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6461 - accuracy: 0.8501 - val_loss: 0.6420 - val_accuracy: 0.8487\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6353 - accuracy: 0.8525 - val_loss: 0.6401 - val_accuracy: 0.8480\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6298 - accuracy: 0.8528 - val_loss: 0.6337 - val_accuracy: 0.8497\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6212 - accuracy: 0.8557 - val_loss: 0.6273 - val_accuracy: 0.8506\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6152 - accuracy: 0.8558 - val_loss: 0.6266 - val_accuracy: 0.8495\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6106 - accuracy: 0.8570 - val_loss: 0.6199 - val_accuracy: 0.8513\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6050 - accuracy: 0.8588 - val_loss: 0.6162 - val_accuracy: 0.8528\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6009 - accuracy: 0.8605 - val_loss: 0.6150 - val_accuracy: 0.8528\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:06.119997\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5951 - accuracy: 0.8609 - val_loss: 0.6101 - val_accuracy: 0.8547\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5933 - accuracy: 0.8613 - val_loss: 0.6089 - val_accuracy: 0.8539\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5912 - accuracy: 0.8625 - val_loss: 0.6081 - val_accuracy: 0.8544\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5896 - accuracy: 0.8627 - val_loss: 0.6081 - val_accuracy: 0.8546\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:49.282375\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7890 - accuracy: 0.5803 - val_loss: 1.1856 - val_accuracy: 0.7400\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1236 - accuracy: 0.7431 - val_loss: 0.9386 - val_accuracy: 0.7909\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9544 - accuracy: 0.7822 - val_loss: 0.8542 - val_accuracy: 0.8105\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8698 - accuracy: 0.8002 - val_loss: 0.7886 - val_accuracy: 0.8228\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8152 - accuracy: 0.8131 - val_loss: 0.7511 - val_accuracy: 0.8289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7743 - accuracy: 0.8214 - val_loss: 0.7262 - val_accuracy: 0.8335\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7450 - accuracy: 0.8280 - val_loss: 0.7070 - val_accuracy: 0.8379\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7202 - accuracy: 0.8345 - val_loss: 0.6905 - val_accuracy: 0.8414\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7008 - accuracy: 0.8386 - val_loss: 0.6855 - val_accuracy: 0.8397\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6875 - accuracy: 0.8405 - val_loss: 0.6647 - val_accuracy: 0.8470\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6723 - accuracy: 0.8442 - val_loss: 0.6552 - val_accuracy: 0.8477\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6616 - accuracy: 0.8460 - val_loss: 0.6514 - val_accuracy: 0.8495\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6507 - accuracy: 0.8483 - val_loss: 0.6417 - val_accuracy: 0.8501\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6420 - accuracy: 0.8498 - val_loss: 0.6359 - val_accuracy: 0.8514\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6352 - accuracy: 0.8513 - val_loss: 0.6308 - val_accuracy: 0.8527\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6286 - accuracy: 0.8524 - val_loss: 0.6245 - val_accuracy: 0.8531\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6228 - accuracy: 0.8544 - val_loss: 0.6202 - val_accuracy: 0.8531\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6164 - accuracy: 0.8553 - val_loss: 0.6151 - val_accuracy: 0.8555\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6116 - accuracy: 0.8561 - val_loss: 0.6129 - val_accuracy: 0.8564\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6079 - accuracy: 0.8583 - val_loss: 0.6114 - val_accuracy: 0.8549\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:05.196252\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6043 - accuracy: 0.8583 - val_loss: 0.6084 - val_accuracy: 0.8553\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6009 - accuracy: 0.8594 - val_loss: 0.6069 - val_accuracy: 0.8562\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5986 - accuracy: 0.8603 - val_loss: 0.6058 - val_accuracy: 0.8566\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5976 - accuracy: 0.8603 - val_loss: 0.6056 - val_accuracy: 0.8569\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5994 - accuracy: 0.8601 - val_loss: 0.6056 - val_accuracy: 0.8567\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5965 - accuracy: 0.8603 - val_loss: 0.6055 - val_accuracy: 0.8569\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5975 - accuracy: 0.8598 - val_loss: 0.6054 - val_accuracy: 0.8567\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:10.485223\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8284 - accuracy: 0.5734 - val_loss: 1.2199 - val_accuracy: 0.7346\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1350 - accuracy: 0.7415 - val_loss: 0.9385 - val_accuracy: 0.7921\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9537 - accuracy: 0.7832 - val_loss: 0.8325 - val_accuracy: 0.8116\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8626 - accuracy: 0.8052 - val_loss: 0.7806 - val_accuracy: 0.8248\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8063 - accuracy: 0.8166 - val_loss: 0.7459 - val_accuracy: 0.8295\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7645 - accuracy: 0.8257 - val_loss: 0.7151 - val_accuracy: 0.8372\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7358 - accuracy: 0.8301 - val_loss: 0.6933 - val_accuracy: 0.8395\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7160 - accuracy: 0.8343 - val_loss: 0.6763 - val_accuracy: 0.8456\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6934 - accuracy: 0.8405 - val_loss: 0.6649 - val_accuracy: 0.8479\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6782 - accuracy: 0.8432 - val_loss: 0.6474 - val_accuracy: 0.8513\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6651 - accuracy: 0.8457 - val_loss: 0.6375 - val_accuracy: 0.8512\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6550 - accuracy: 0.8487 - val_loss: 0.6327 - val_accuracy: 0.8521\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6435 - accuracy: 0.8505 - val_loss: 0.6243 - val_accuracy: 0.8546\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6352 - accuracy: 0.8529 - val_loss: 0.6168 - val_accuracy: 0.8547\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6272 - accuracy: 0.8551 - val_loss: 0.6139 - val_accuracy: 0.8565\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6218 - accuracy: 0.8557 - val_loss: 0.6113 - val_accuracy: 0.8558\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6169 - accuracy: 0.8557 - val_loss: 0.6051 - val_accuracy: 0.8576\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6110 - accuracy: 0.8578 - val_loss: 0.6011 - val_accuracy: 0.8586\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6073 - accuracy: 0.8576 - val_loss: 0.5990 - val_accuracy: 0.8595\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6014 - accuracy: 0.8596 - val_loss: 0.5952 - val_accuracy: 0.8599\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:04.410132\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.5982 - accuracy: 0.8604 - val_loss: 0.5922 - val_accuracy: 0.8604\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5942 - accuracy: 0.8617 - val_loss: 0.5891 - val_accuracy: 0.8608\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5925 - accuracy: 0.8614 - val_loss: 0.5889 - val_accuracy: 0.8606\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5916 - accuracy: 0.8623 - val_loss: 0.5884 - val_accuracy: 0.8609\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5889 - accuracy: 0.8624 - val_loss: 0.5886 - val_accuracy: 0.8613\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5913 - accuracy: 0.8627 - val_loss: 0.5885 - val_accuracy: 0.8606\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5904 - accuracy: 0.8619 - val_loss: 0.5885 - val_accuracy: 0.8609\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5907 - accuracy: 0.8617 - val_loss: 0.5884 - val_accuracy: 0.8609\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:39.940215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7937 - accuracy: 0.5851 - val_loss: 1.1690 - val_accuracy: 0.7436\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0919 - accuracy: 0.7527 - val_loss: 0.9093 - val_accuracy: 0.8020\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9228 - accuracy: 0.7919 - val_loss: 0.8042 - val_accuracy: 0.8229\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8346 - accuracy: 0.8116 - val_loss: 0.7489 - val_accuracy: 0.8349\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7826 - accuracy: 0.8219 - val_loss: 0.7079 - val_accuracy: 0.8432\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7420 - accuracy: 0.8305 - val_loss: 0.6839 - val_accuracy: 0.8480\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7150 - accuracy: 0.8358 - val_loss: 0.6661 - val_accuracy: 0.8488\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6901 - accuracy: 0.8420 - val_loss: 0.6490 - val_accuracy: 0.8519\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6723 - accuracy: 0.8461 - val_loss: 0.6353 - val_accuracy: 0.8571\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6551 - accuracy: 0.8491 - val_loss: 0.6210 - val_accuracy: 0.8594\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6424 - accuracy: 0.8524 - val_loss: 0.6116 - val_accuracy: 0.8610\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6307 - accuracy: 0.8552 - val_loss: 0.6079 - val_accuracy: 0.8604\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6225 - accuracy: 0.8564 - val_loss: 0.5961 - val_accuracy: 0.8629\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6138 - accuracy: 0.8590 - val_loss: 0.5923 - val_accuracy: 0.8633\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6041 - accuracy: 0.8600 - val_loss: 0.5856 - val_accuracy: 0.8650\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6001 - accuracy: 0.8603 - val_loss: 0.5839 - val_accuracy: 0.8652\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5949 - accuracy: 0.8614 - val_loss: 0.5792 - val_accuracy: 0.8660\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5874 - accuracy: 0.8640 - val_loss: 0.5746 - val_accuracy: 0.8672\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5818 - accuracy: 0.8654 - val_loss: 0.5712 - val_accuracy: 0.8670\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5780 - accuracy: 0.8653 - val_loss: 0.5677 - val_accuracy: 0.8682\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:22.230751\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5744 - accuracy: 0.8666 - val_loss: 0.5643 - val_accuracy: 0.8689\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5709 - accuracy: 0.8687 - val_loss: 0.5639 - val_accuracy: 0.8690\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5703 - accuracy: 0.8672 - val_loss: 0.5628 - val_accuracy: 0.8689\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5692 - accuracy: 0.8669 - val_loss: 0.5623 - val_accuracy: 0.8698\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5683 - accuracy: 0.8683 - val_loss: 0.5626 - val_accuracy: 0.8692\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5697 - accuracy: 0.8681 - val_loss: 0.5624 - val_accuracy: 0.8691\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5676 - accuracy: 0.8676 - val_loss: 0.5625 - val_accuracy: 0.8695\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:18.874217\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8312 - accuracy: 0.5766 - val_loss: 1.2154 - val_accuracy: 0.7393\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1279 - accuracy: 0.7424 - val_loss: 0.9526 - val_accuracy: 0.7856\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9456 - accuracy: 0.7847 - val_loss: 0.8503 - val_accuracy: 0.8105\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8507 - accuracy: 0.8060 - val_loss: 0.7834 - val_accuracy: 0.8274\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7914 - accuracy: 0.8181 - val_loss: 0.7531 - val_accuracy: 0.8302\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7493 - accuracy: 0.8277 - val_loss: 0.7178 - val_accuracy: 0.8356\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7186 - accuracy: 0.8347 - val_loss: 0.6871 - val_accuracy: 0.8450\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6957 - accuracy: 0.8387 - val_loss: 0.6712 - val_accuracy: 0.8468\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6753 - accuracy: 0.8441 - val_loss: 0.6530 - val_accuracy: 0.8505\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6606 - accuracy: 0.8460 - val_loss: 0.6398 - val_accuracy: 0.8529\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6456 - accuracy: 0.8511 - val_loss: 0.6287 - val_accuracy: 0.8570\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6332 - accuracy: 0.8539 - val_loss: 0.6252 - val_accuracy: 0.8556\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6236 - accuracy: 0.8546 - val_loss: 0.6142 - val_accuracy: 0.8582\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6153 - accuracy: 0.8569 - val_loss: 0.6080 - val_accuracy: 0.8598\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6070 - accuracy: 0.8589 - val_loss: 0.6039 - val_accuracy: 0.8617\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6012 - accuracy: 0.8601 - val_loss: 0.5992 - val_accuracy: 0.8608\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5952 - accuracy: 0.8615 - val_loss: 0.5945 - val_accuracy: 0.8605\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5902 - accuracy: 0.8616 - val_loss: 0.5895 - val_accuracy: 0.8634\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5847 - accuracy: 0.8636 - val_loss: 0.5868 - val_accuracy: 0.8643\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5803 - accuracy: 0.8641 - val_loss: 0.5869 - val_accuracy: 0.8626\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:28.975330\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5753 - accuracy: 0.8659 - val_loss: 0.5814 - val_accuracy: 0.8658\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5727 - accuracy: 0.8667 - val_loss: 0.5797 - val_accuracy: 0.8653\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5703 - accuracy: 0.8671 - val_loss: 0.5791 - val_accuracy: 0.8660\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5689 - accuracy: 0.8676 - val_loss: 0.5788 - val_accuracy: 0.8661\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5712 - accuracy: 0.8667 - val_loss: 0.5787 - val_accuracy: 0.8657\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5707 - accuracy: 0.8678 - val_loss: 0.5788 - val_accuracy: 0.8655\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5710 - accuracy: 0.8664 - val_loss: 0.5786 - val_accuracy: 0.8659\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:19.502940\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8183 - accuracy: 0.5817 - val_loss: 1.1895 - val_accuracy: 0.7376\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0985 - accuracy: 0.7504 - val_loss: 0.9260 - val_accuracy: 0.7951\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9301 - accuracy: 0.7887 - val_loss: 0.8196 - val_accuracy: 0.8216\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8474 - accuracy: 0.8060 - val_loss: 0.7720 - val_accuracy: 0.8337\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7923 - accuracy: 0.8195 - val_loss: 0.7255 - val_accuracy: 0.8430\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7530 - accuracy: 0.8274 - val_loss: 0.6946 - val_accuracy: 0.8478\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7235 - accuracy: 0.8332 - val_loss: 0.6732 - val_accuracy: 0.8491\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7000 - accuracy: 0.8398 - val_loss: 0.6535 - val_accuracy: 0.8548\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6795 - accuracy: 0.8435 - val_loss: 0.6437 - val_accuracy: 0.8571\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6659 - accuracy: 0.8453 - val_loss: 0.6328 - val_accuracy: 0.8578\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6532 - accuracy: 0.8481 - val_loss: 0.6241 - val_accuracy: 0.8580\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6407 - accuracy: 0.8510 - val_loss: 0.6124 - val_accuracy: 0.8614\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6291 - accuracy: 0.8533 - val_loss: 0.6044 - val_accuracy: 0.8626\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6207 - accuracy: 0.8554 - val_loss: 0.5996 - val_accuracy: 0.8637\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6144 - accuracy: 0.8571 - val_loss: 0.5943 - val_accuracy: 0.8650\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6049 - accuracy: 0.8594 - val_loss: 0.5905 - val_accuracy: 0.8665\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6013 - accuracy: 0.8601 - val_loss: 0.5845 - val_accuracy: 0.8676\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5951 - accuracy: 0.8609 - val_loss: 0.5821 - val_accuracy: 0.8685\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5906 - accuracy: 0.8623 - val_loss: 0.5785 - val_accuracy: 0.8691\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5853 - accuracy: 0.8637 - val_loss: 0.5745 - val_accuracy: 0.8676\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:43.798674\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5814 - accuracy: 0.8641 - val_loss: 0.5717 - val_accuracy: 0.8694\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5787 - accuracy: 0.8654 - val_loss: 0.5711 - val_accuracy: 0.8689\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5763 - accuracy: 0.8667 - val_loss: 0.5701 - val_accuracy: 0.8690\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5760 - accuracy: 0.8663 - val_loss: 0.5701 - val_accuracy: 0.8696\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5749 - accuracy: 0.8662 - val_loss: 0.5700 - val_accuracy: 0.8693\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5749 - accuracy: 0.8662 - val_loss: 0.5698 - val_accuracy: 0.8692\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5760 - accuracy: 0.8651 - val_loss: 0.5699 - val_accuracy: 0.8692\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:23.928024\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8910 - accuracy: 0.5596 - val_loss: 1.2549 - val_accuracy: 0.7295\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1455 - accuracy: 0.7387 - val_loss: 0.9567 - val_accuracy: 0.7910\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9438 - accuracy: 0.7865 - val_loss: 0.8323 - val_accuracy: 0.8118\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8484 - accuracy: 0.8091 - val_loss: 0.7705 - val_accuracy: 0.8281\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7911 - accuracy: 0.8203 - val_loss: 0.7280 - val_accuracy: 0.8387\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7507 - accuracy: 0.8299 - val_loss: 0.7046 - val_accuracy: 0.8411\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7192 - accuracy: 0.8370 - val_loss: 0.6804 - val_accuracy: 0.8448\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.6950 - accuracy: 0.8419 - val_loss: 0.6589 - val_accuracy: 0.8488\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6765 - accuracy: 0.8462 - val_loss: 0.6504 - val_accuracy: 0.8504\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6620 - accuracy: 0.8497 - val_loss: 0.6432 - val_accuracy: 0.8507\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6484 - accuracy: 0.8520 - val_loss: 0.6287 - val_accuracy: 0.8531\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6361 - accuracy: 0.8537 - val_loss: 0.6219 - val_accuracy: 0.8557\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6260 - accuracy: 0.8571 - val_loss: 0.6119 - val_accuracy: 0.8562\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6189 - accuracy: 0.8582 - val_loss: 0.6058 - val_accuracy: 0.8591\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6100 - accuracy: 0.8604 - val_loss: 0.6026 - val_accuracy: 0.8590\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6027 - accuracy: 0.8606 - val_loss: 0.5955 - val_accuracy: 0.8616\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5966 - accuracy: 0.8623 - val_loss: 0.5930 - val_accuracy: 0.8610\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5936 - accuracy: 0.8633 - val_loss: 0.5897 - val_accuracy: 0.8600\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5880 - accuracy: 0.8647 - val_loss: 0.5875 - val_accuracy: 0.8617\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5833 - accuracy: 0.8648 - val_loss: 0.5820 - val_accuracy: 0.8629\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:43.562020\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5781 - accuracy: 0.8663 - val_loss: 0.5796 - val_accuracy: 0.8625\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5765 - accuracy: 0.8670 - val_loss: 0.5784 - val_accuracy: 0.8627\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5747 - accuracy: 0.8682 - val_loss: 0.5776 - val_accuracy: 0.8632\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5733 - accuracy: 0.8677 - val_loss: 0.5774 - val_accuracy: 0.8628\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5732 - accuracy: 0.8682 - val_loss: 0.5774 - val_accuracy: 0.8628\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5717 - accuracy: 0.8687 - val_loss: 0.5773 - val_accuracy: 0.8629\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:54.224979\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8027 - accuracy: 0.5848 - val_loss: 1.2227 - val_accuracy: 0.7316\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1052 - accuracy: 0.7495 - val_loss: 0.9503 - val_accuracy: 0.7881\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9256 - accuracy: 0.7928 - val_loss: 0.8277 - val_accuracy: 0.8152\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8399 - accuracy: 0.8109 - val_loss: 0.7727 - val_accuracy: 0.8262\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7850 - accuracy: 0.8231 - val_loss: 0.7352 - val_accuracy: 0.8311\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7434 - accuracy: 0.8321 - val_loss: 0.7052 - val_accuracy: 0.8415\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7166 - accuracy: 0.8373 - val_loss: 0.6879 - val_accuracy: 0.8425\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6917 - accuracy: 0.8427 - val_loss: 0.6692 - val_accuracy: 0.8446\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6742 - accuracy: 0.8455 - val_loss: 0.6498 - val_accuracy: 0.8502\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6590 - accuracy: 0.8496 - val_loss: 0.6530 - val_accuracy: 0.8473\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6452 - accuracy: 0.8532 - val_loss: 0.6334 - val_accuracy: 0.8520\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6346 - accuracy: 0.8545 - val_loss: 0.6256 - val_accuracy: 0.8543\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6240 - accuracy: 0.8564 - val_loss: 0.6183 - val_accuracy: 0.8573\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6163 - accuracy: 0.8589 - val_loss: 0.6098 - val_accuracy: 0.8572\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6077 - accuracy: 0.8603 - val_loss: 0.6046 - val_accuracy: 0.8586\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6021 - accuracy: 0.8616 - val_loss: 0.6045 - val_accuracy: 0.8577\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5942 - accuracy: 0.8637 - val_loss: 0.5965 - val_accuracy: 0.8599\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5909 - accuracy: 0.8641 - val_loss: 0.5922 - val_accuracy: 0.8599\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5836 - accuracy: 0.8660 - val_loss: 0.5924 - val_accuracy: 0.8588\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5793 - accuracy: 0.8666 - val_loss: 0.5864 - val_accuracy: 0.8621\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:34.110770\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5767 - accuracy: 0.8676 - val_loss: 0.5847 - val_accuracy: 0.8628\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.5734 - accuracy: 0.8671 - val_loss: 0.5816 - val_accuracy: 0.8632\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5716 - accuracy: 0.8675 - val_loss: 0.5815 - val_accuracy: 0.8631\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5716 - accuracy: 0.8686 - val_loss: 0.5813 - val_accuracy: 0.8627\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5710 - accuracy: 0.8687 - val_loss: 0.5811 - val_accuracy: 0.8629\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:22.892369\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6622 - accuracy: 0.5995 - val_loss: 1.0730 - val_accuracy: 0.7243\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.8799 - accuracy: 0.7679 - val_loss: 0.7630 - val_accuracy: 0.7824\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6807 - accuracy: 0.8069 - val_loss: 0.6424 - val_accuracy: 0.8066\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5862 - accuracy: 0.8271 - val_loss: 0.5749 - val_accuracy: 0.8211\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5312 - accuracy: 0.8392 - val_loss: 0.5421 - val_accuracy: 0.8284\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4939 - accuracy: 0.8466 - val_loss: 0.5006 - val_accuracy: 0.8406\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4675 - accuracy: 0.8538 - val_loss: 0.4809 - val_accuracy: 0.8418\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4490 - accuracy: 0.8577 - val_loss: 0.4740 - val_accuracy: 0.8445\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4329 - accuracy: 0.8624 - val_loss: 0.4544 - val_accuracy: 0.8502\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4207 - accuracy: 0.8655 - val_loss: 0.4461 - val_accuracy: 0.8523\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4104 - accuracy: 0.8683 - val_loss: 0.4399 - val_accuracy: 0.8542\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4017 - accuracy: 0.8702 - val_loss: 0.4339 - val_accuracy: 0.8559\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3944 - accuracy: 0.8719 - val_loss: 0.4283 - val_accuracy: 0.8575\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3886 - accuracy: 0.8741 - val_loss: 0.4325 - val_accuracy: 0.8554\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3830 - accuracy: 0.8757 - val_loss: 0.4242 - val_accuracy: 0.8577\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3782 - accuracy: 0.8770 - val_loss: 0.4174 - val_accuracy: 0.8603\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3740 - accuracy: 0.8780 - val_loss: 0.4170 - val_accuracy: 0.8606\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3700 - accuracy: 0.8793 - val_loss: 0.4129 - val_accuracy: 0.8618\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.3665 - accuracy: 0.8806 - val_loss: 0.4125 - val_accuracy: 0.8609\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3631 - accuracy: 0.8821 - val_loss: 0.4096 - val_accuracy: 0.8611\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:51.116453\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3597 - accuracy: 0.8822 - val_loss: 0.4082 - val_accuracy: 0.8622\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3578 - accuracy: 0.8830 - val_loss: 0.4066 - val_accuracy: 0.8628\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3564 - accuracy: 0.8840 - val_loss: 0.4062 - val_accuracy: 0.8630\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.3554 - accuracy: 0.8839 - val_loss: 0.4059 - val_accuracy: 0.8634\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3557 - accuracy: 0.8833 - val_loss: 0.4060 - val_accuracy: 0.8632\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3550 - accuracy: 0.8845 - val_loss: 0.4059 - val_accuracy: 0.8628\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3547 - accuracy: 0.8846 - val_loss: 0.4059 - val_accuracy: 0.8633\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:05.786596\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6095 - accuracy: 0.6071 - val_loss: 1.0430 - val_accuracy: 0.7285\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8436 - accuracy: 0.7730 - val_loss: 0.7405 - val_accuracy: 0.7911\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6586 - accuracy: 0.8117 - val_loss: 0.6157 - val_accuracy: 0.8191\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5709 - accuracy: 0.8306 - val_loss: 0.5563 - val_accuracy: 0.8322\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5194 - accuracy: 0.8401 - val_loss: 0.5215 - val_accuracy: 0.8409\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4846 - accuracy: 0.8487 - val_loss: 0.4943 - val_accuracy: 0.8427\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4590 - accuracy: 0.8557 - val_loss: 0.4797 - val_accuracy: 0.8469\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4408 - accuracy: 0.8595 - val_loss: 0.4584 - val_accuracy: 0.8522\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4257 - accuracy: 0.8635 - val_loss: 0.4537 - val_accuracy: 0.8551\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4136 - accuracy: 0.8671 - val_loss: 0.4425 - val_accuracy: 0.8582\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4043 - accuracy: 0.8693 - val_loss: 0.4344 - val_accuracy: 0.8614\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3960 - accuracy: 0.8712 - val_loss: 0.4281 - val_accuracy: 0.8614\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3891 - accuracy: 0.8735 - val_loss: 0.4286 - val_accuracy: 0.8599\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3823 - accuracy: 0.8761 - val_loss: 0.4211 - val_accuracy: 0.8628\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3776 - accuracy: 0.8764 - val_loss: 0.4158 - val_accuracy: 0.8666\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3722 - accuracy: 0.8783 - val_loss: 0.4113 - val_accuracy: 0.8652\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3681 - accuracy: 0.8797 - val_loss: 0.4071 - val_accuracy: 0.8662\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3647 - accuracy: 0.8802 - val_loss: 0.4055 - val_accuracy: 0.8655\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:00.767088\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3695 - accuracy: 0.8799 - val_loss: 0.4099 - val_accuracy: 0.8672\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3675 - accuracy: 0.8806 - val_loss: 0.4081 - val_accuracy: 0.8676\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3663 - accuracy: 0.8809 - val_loss: 0.4077 - val_accuracy: 0.8670\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3646 - accuracy: 0.8810 - val_loss: 0.4076 - val_accuracy: 0.8676\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3645 - accuracy: 0.8815 - val_loss: 0.4076 - val_accuracy: 0.8680\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3642 - accuracy: 0.8814 - val_loss: 0.4074 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3648 - accuracy: 0.8816 - val_loss: 0.4075 - val_accuracy: 0.8678\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3642 - accuracy: 0.8816 - val_loss: 0.4076 - val_accuracy: 0.8676\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:33.792169\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5943 - accuracy: 0.6089 - val_loss: 1.0591 - val_accuracy: 0.7239\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.8576 - accuracy: 0.7682 - val_loss: 0.7304 - val_accuracy: 0.7916\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6683 - accuracy: 0.8078 - val_loss: 0.6380 - val_accuracy: 0.8110\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5802 - accuracy: 0.8277 - val_loss: 0.5656 - val_accuracy: 0.8285\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5272 - accuracy: 0.8389 - val_loss: 0.5305 - val_accuracy: 0.8354\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4908 - accuracy: 0.8472 - val_loss: 0.5040 - val_accuracy: 0.8409\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4668 - accuracy: 0.8525 - val_loss: 0.4879 - val_accuracy: 0.8448\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4471 - accuracy: 0.8577 - val_loss: 0.4753 - val_accuracy: 0.8476\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4324 - accuracy: 0.8624 - val_loss: 0.4686 - val_accuracy: 0.8469\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4197 - accuracy: 0.8649 - val_loss: 0.4587 - val_accuracy: 0.8501\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4100 - accuracy: 0.8663 - val_loss: 0.4453 - val_accuracy: 0.8540\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4026 - accuracy: 0.8688 - val_loss: 0.4441 - val_accuracy: 0.8562\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3945 - accuracy: 0.8712 - val_loss: 0.4360 - val_accuracy: 0.8554\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3890 - accuracy: 0.8730 - val_loss: 0.4390 - val_accuracy: 0.8538\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3831 - accuracy: 0.8748 - val_loss: 0.4286 - val_accuracy: 0.8576\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3786 - accuracy: 0.8759 - val_loss: 0.4239 - val_accuracy: 0.8609\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3737 - accuracy: 0.8772 - val_loss: 0.4199 - val_accuracy: 0.8608\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3707 - accuracy: 0.8785 - val_loss: 0.4195 - val_accuracy: 0.8631\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3673 - accuracy: 0.8792 - val_loss: 0.4154 - val_accuracy: 0.8621\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3643 - accuracy: 0.8798 - val_loss: 0.4164 - val_accuracy: 0.8638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:55.853919\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3605 - accuracy: 0.8819 - val_loss: 0.4124 - val_accuracy: 0.8641\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3576 - accuracy: 0.8829 - val_loss: 0.4110 - val_accuracy: 0.8643\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3565 - accuracy: 0.8829 - val_loss: 0.4106 - val_accuracy: 0.8648\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3562 - accuracy: 0.8832 - val_loss: 0.4103 - val_accuracy: 0.8647\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3561 - accuracy: 0.8830 - val_loss: 0.4104 - val_accuracy: 0.8648\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3557 - accuracy: 0.8828 - val_loss: 0.4104 - val_accuracy: 0.8647\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:40.078002\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6011 - accuracy: 0.6044 - val_loss: 1.0493 - val_accuracy: 0.7271\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8466 - accuracy: 0.7714 - val_loss: 0.7239 - val_accuracy: 0.7939\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6578 - accuracy: 0.8100 - val_loss: 0.6091 - val_accuracy: 0.8215\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5720 - accuracy: 0.8289 - val_loss: 0.5696 - val_accuracy: 0.8255\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5197 - accuracy: 0.8396 - val_loss: 0.5225 - val_accuracy: 0.8373\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4834 - accuracy: 0.8489 - val_loss: 0.4836 - val_accuracy: 0.8473\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4586 - accuracy: 0.8543 - val_loss: 0.4765 - val_accuracy: 0.8485\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4397 - accuracy: 0.8582 - val_loss: 0.4565 - val_accuracy: 0.8547\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4252 - accuracy: 0.8631 - val_loss: 0.4468 - val_accuracy: 0.8578\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4132 - accuracy: 0.8659 - val_loss: 0.4336 - val_accuracy: 0.8589\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4050 - accuracy: 0.8684 - val_loss: 0.4318 - val_accuracy: 0.8615\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3958 - accuracy: 0.8703 - val_loss: 0.4228 - val_accuracy: 0.8590\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3885 - accuracy: 0.8723 - val_loss: 0.4192 - val_accuracy: 0.8621\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3818 - accuracy: 0.8748 - val_loss: 0.4181 - val_accuracy: 0.8624\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3766 - accuracy: 0.8756 - val_loss: 0.4134 - val_accuracy: 0.8637\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3714 - accuracy: 0.8780 - val_loss: 0.4070 - val_accuracy: 0.8660\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3686 - accuracy: 0.8780 - val_loss: 0.4047 - val_accuracy: 0.8666\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3644 - accuracy: 0.8801 - val_loss: 0.4047 - val_accuracy: 0.8660\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3610 - accuracy: 0.8803 - val_loss: 0.4022 - val_accuracy: 0.8684\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3583 - accuracy: 0.8811 - val_loss: 0.4002 - val_accuracy: 0.8670\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:57.971180\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3545 - accuracy: 0.8826 - val_loss: 0.3971 - val_accuracy: 0.8681\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3520 - accuracy: 0.8831 - val_loss: 0.3961 - val_accuracy: 0.8694\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3506 - accuracy: 0.8844 - val_loss: 0.3957 - val_accuracy: 0.8690\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3506 - accuracy: 0.8847 - val_loss: 0.3957 - val_accuracy: 0.8692\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3495 - accuracy: 0.8847 - val_loss: 0.3955 - val_accuracy: 0.8687\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:15.035331\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5761 - accuracy: 0.6134 - val_loss: 1.0204 - val_accuracy: 0.7348\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8297 - accuracy: 0.7764 - val_loss: 0.7132 - val_accuracy: 0.7951\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6486 - accuracy: 0.8130 - val_loss: 0.6140 - val_accuracy: 0.8132\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5660 - accuracy: 0.8301 - val_loss: 0.5538 - val_accuracy: 0.8304\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5180 - accuracy: 0.8413 - val_loss: 0.5152 - val_accuracy: 0.8375\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4829 - accuracy: 0.8493 - val_loss: 0.4948 - val_accuracy: 0.8432\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4589 - accuracy: 0.8558 - val_loss: 0.4736 - val_accuracy: 0.8456\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4410 - accuracy: 0.8598 - val_loss: 0.4687 - val_accuracy: 0.8469\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4268 - accuracy: 0.8636 - val_loss: 0.4524 - val_accuracy: 0.8519\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4156 - accuracy: 0.8667 - val_loss: 0.4497 - val_accuracy: 0.8515\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4053 - accuracy: 0.8702 - val_loss: 0.4408 - val_accuracy: 0.8546\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3971 - accuracy: 0.8717 - val_loss: 0.4346 - val_accuracy: 0.8565\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3900 - accuracy: 0.8741 - val_loss: 0.4262 - val_accuracy: 0.8593\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3838 - accuracy: 0.8756 - val_loss: 0.4305 - val_accuracy: 0.8555\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3788 - accuracy: 0.8766 - val_loss: 0.4181 - val_accuracy: 0.8613\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3744 - accuracy: 0.8781 - val_loss: 0.4159 - val_accuracy: 0.8619\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3698 - accuracy: 0.8792 - val_loss: 0.4135 - val_accuracy: 0.8621\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3658 - accuracy: 0.8806 - val_loss: 0.4133 - val_accuracy: 0.8615\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3631 - accuracy: 0.8813 - val_loss: 0.4093 - val_accuracy: 0.8620\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3602 - accuracy: 0.8820 - val_loss: 0.4105 - val_accuracy: 0.8639\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:55.870694\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3560 - accuracy: 0.8836 - val_loss: 0.4059 - val_accuracy: 0.8651\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3540 - accuracy: 0.8842 - val_loss: 0.4047 - val_accuracy: 0.8644\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3530 - accuracy: 0.8843 - val_loss: 0.4048 - val_accuracy: 0.8652\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3520 - accuracy: 0.8852 - val_loss: 0.4044 - val_accuracy: 0.8654\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3514 - accuracy: 0.8851 - val_loss: 0.4045 - val_accuracy: 0.8653\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3520 - accuracy: 0.8847 - val_loss: 0.4045 - val_accuracy: 0.8651\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.3516 - accuracy: 0.8856 - val_loss: 0.4044 - val_accuracy: 0.8650\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:06.324252\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4467 - accuracy: 0.6239 - val_loss: 0.9885 - val_accuracy: 0.7325\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8261 - accuracy: 0.7706 - val_loss: 0.7355 - val_accuracy: 0.7897\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6618 - accuracy: 0.8080 - val_loss: 0.6439 - val_accuracy: 0.8102\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5848 - accuracy: 0.8254 - val_loss: 0.5763 - val_accuracy: 0.8262\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5391 - accuracy: 0.8353 - val_loss: 0.5535 - val_accuracy: 0.8268\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5065 - accuracy: 0.8432 - val_loss: 0.5241 - val_accuracy: 0.8359\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4841 - accuracy: 0.8493 - val_loss: 0.5064 - val_accuracy: 0.8412\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4664 - accuracy: 0.8531 - val_loss: 0.4969 - val_accuracy: 0.8434\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4532 - accuracy: 0.8563 - val_loss: 0.4875 - val_accuracy: 0.8437\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4424 - accuracy: 0.8590 - val_loss: 0.4814 - val_accuracy: 0.8466\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4334 - accuracy: 0.8612 - val_loss: 0.4708 - val_accuracy: 0.8484\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4259 - accuracy: 0.8639 - val_loss: 0.4724 - val_accuracy: 0.8496\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4196 - accuracy: 0.8655 - val_loss: 0.4625 - val_accuracy: 0.8532\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4130 - accuracy: 0.8673 - val_loss: 0.4578 - val_accuracy: 0.8512\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4080 - accuracy: 0.8690 - val_loss: 0.4586 - val_accuracy: 0.8516\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4037 - accuracy: 0.8698 - val_loss: 0.4514 - val_accuracy: 0.8546\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3998 - accuracy: 0.8707 - val_loss: 0.4483 - val_accuracy: 0.8560\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3968 - accuracy: 0.8716 - val_loss: 0.4481 - val_accuracy: 0.8556\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3934 - accuracy: 0.8723 - val_loss: 0.4456 - val_accuracy: 0.8563\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3912 - accuracy: 0.8729 - val_loss: 0.4447 - val_accuracy: 0.8577\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:00.176255\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3877 - accuracy: 0.8746 - val_loss: 0.4424 - val_accuracy: 0.8579\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3848 - accuracy: 0.8754 - val_loss: 0.4417 - val_accuracy: 0.8571\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3839 - accuracy: 0.8762 - val_loss: 0.4413 - val_accuracy: 0.8578\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3834 - accuracy: 0.8761 - val_loss: 0.4410 - val_accuracy: 0.8575\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:48.557399\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4438 - accuracy: 0.6249 - val_loss: 0.9486 - val_accuracy: 0.7454\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8154 - accuracy: 0.7712 - val_loss: 0.7287 - val_accuracy: 0.7882\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6647 - accuracy: 0.8064 - val_loss: 0.6191 - val_accuracy: 0.8155\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5915 - accuracy: 0.8232 - val_loss: 0.5719 - val_accuracy: 0.8248\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5464 - accuracy: 0.8338 - val_loss: 0.5323 - val_accuracy: 0.8360\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5156 - accuracy: 0.8416 - val_loss: 0.5162 - val_accuracy: 0.8393\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4930 - accuracy: 0.8468 - val_loss: 0.5016 - val_accuracy: 0.8402\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4751 - accuracy: 0.8510 - val_loss: 0.4870 - val_accuracy: 0.8448\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4616 - accuracy: 0.8536 - val_loss: 0.4750 - val_accuracy: 0.8484\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4508 - accuracy: 0.8563 - val_loss: 0.4635 - val_accuracy: 0.8525\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4420 - accuracy: 0.8588 - val_loss: 0.4628 - val_accuracy: 0.8513\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4344 - accuracy: 0.8610 - val_loss: 0.4557 - val_accuracy: 0.8543\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4271 - accuracy: 0.8636 - val_loss: 0.4500 - val_accuracy: 0.8553\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4215 - accuracy: 0.8657 - val_loss: 0.4471 - val_accuracy: 0.8540\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4165 - accuracy: 0.8669 - val_loss: 0.4472 - val_accuracy: 0.8577\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4123 - accuracy: 0.8680 - val_loss: 0.4398 - val_accuracy: 0.8591\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4078 - accuracy: 0.8688 - val_loss: 0.4370 - val_accuracy: 0.8590\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4050 - accuracy: 0.8698 - val_loss: 0.4360 - val_accuracy: 0.8604\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4017 - accuracy: 0.8704 - val_loss: 0.4346 - val_accuracy: 0.8614\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3990 - accuracy: 0.8715 - val_loss: 0.4302 - val_accuracy: 0.8622\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:01.247736\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3951 - accuracy: 0.8727 - val_loss: 0.4291 - val_accuracy: 0.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3937 - accuracy: 0.8733 - val_loss: 0.4287 - val_accuracy: 0.8624\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3923 - accuracy: 0.8742 - val_loss: 0.4278 - val_accuracy: 0.8627\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3913 - accuracy: 0.8744 - val_loss: 0.4280 - val_accuracy: 0.8629\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:47.249446\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4349 - accuracy: 0.6312 - val_loss: 0.9594 - val_accuracy: 0.7361\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8140 - accuracy: 0.7723 - val_loss: 0.7234 - val_accuracy: 0.7926\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6603 - accuracy: 0.8077 - val_loss: 0.6253 - val_accuracy: 0.8135\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5854 - accuracy: 0.8242 - val_loss: 0.5705 - val_accuracy: 0.8261\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5396 - accuracy: 0.8361 - val_loss: 0.5462 - val_accuracy: 0.8281\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5072 - accuracy: 0.8430 - val_loss: 0.5213 - val_accuracy: 0.8384\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4852 - accuracy: 0.8484 - val_loss: 0.5022 - val_accuracy: 0.8409\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4672 - accuracy: 0.8533 - val_loss: 0.4873 - val_accuracy: 0.8457\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4532 - accuracy: 0.8567 - val_loss: 0.4776 - val_accuracy: 0.8469\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4427 - accuracy: 0.8597 - val_loss: 0.4700 - val_accuracy: 0.8481\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4337 - accuracy: 0.8620 - val_loss: 0.4672 - val_accuracy: 0.8480\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4256 - accuracy: 0.8645 - val_loss: 0.4606 - val_accuracy: 0.8527\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4190 - accuracy: 0.8656 - val_loss: 0.4629 - val_accuracy: 0.8514\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4132 - accuracy: 0.8675 - val_loss: 0.4532 - val_accuracy: 0.8530\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4083 - accuracy: 0.8685 - val_loss: 0.4498 - val_accuracy: 0.8527\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4042 - accuracy: 0.8691 - val_loss: 0.4455 - val_accuracy: 0.8559\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3988 - accuracy: 0.8715 - val_loss: 0.4429 - val_accuracy: 0.8551\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3957 - accuracy: 0.8724 - val_loss: 0.4413 - val_accuracy: 0.8557\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3930 - accuracy: 0.8728 - val_loss: 0.4422 - val_accuracy: 0.8565\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3899 - accuracy: 0.8738 - val_loss: 0.4393 - val_accuracy: 0.8573\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:58.850899\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3854 - accuracy: 0.8757 - val_loss: 0.4364 - val_accuracy: 0.8578\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.3846 - accuracy: 0.8764 - val_loss: 0.4358 - val_accuracy: 0.8590\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3833 - accuracy: 0.8766 - val_loss: 0.4353 - val_accuracy: 0.8587\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3828 - accuracy: 0.8757 - val_loss: 0.4352 - val_accuracy: 0.8590\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3819 - accuracy: 0.8767 - val_loss: 0.4352 - val_accuracy: 0.8588\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:18.642654\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4337 - accuracy: 0.6289 - val_loss: 0.9510 - val_accuracy: 0.7418\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8012 - accuracy: 0.7770 - val_loss: 0.7094 - val_accuracy: 0.7927\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6484 - accuracy: 0.8121 - val_loss: 0.6148 - val_accuracy: 0.8150\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5775 - accuracy: 0.8274 - val_loss: 0.5760 - val_accuracy: 0.8251\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5338 - accuracy: 0.8373 - val_loss: 0.5390 - val_accuracy: 0.8339\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5036 - accuracy: 0.8440 - val_loss: 0.5184 - val_accuracy: 0.8383\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4821 - accuracy: 0.8492 - val_loss: 0.5034 - val_accuracy: 0.8407\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4659 - accuracy: 0.8537 - val_loss: 0.4935 - val_accuracy: 0.8419\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4524 - accuracy: 0.8572 - val_loss: 0.4858 - val_accuracy: 0.8447\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4426 - accuracy: 0.8587 - val_loss: 0.4725 - val_accuracy: 0.8500\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4330 - accuracy: 0.8612 - val_loss: 0.4656 - val_accuracy: 0.8502\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4266 - accuracy: 0.8626 - val_loss: 0.4649 - val_accuracy: 0.8511\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4199 - accuracy: 0.8652 - val_loss: 0.4574 - val_accuracy: 0.8513\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4145 - accuracy: 0.8666 - val_loss: 0.4555 - val_accuracy: 0.8531\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4096 - accuracy: 0.8681 - val_loss: 0.4497 - val_accuracy: 0.8533\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4055 - accuracy: 0.8698 - val_loss: 0.4473 - val_accuracy: 0.8538\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4017 - accuracy: 0.8704 - val_loss: 0.4470 - val_accuracy: 0.8543\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3981 - accuracy: 0.8714 - val_loss: 0.4434 - val_accuracy: 0.8556\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3949 - accuracy: 0.8728 - val_loss: 0.4422 - val_accuracy: 0.8563\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3923 - accuracy: 0.8741 - val_loss: 0.4401 - val_accuracy: 0.8553\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:54.912242\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3887 - accuracy: 0.8745 - val_loss: 0.4384 - val_accuracy: 0.8562\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3869 - accuracy: 0.8756 - val_loss: 0.4381 - val_accuracy: 0.8562\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3845 - accuracy: 0.8758 - val_loss: 0.4371 - val_accuracy: 0.8571\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3851 - accuracy: 0.8752 - val_loss: 0.4370 - val_accuracy: 0.8573\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.3850 - accuracy: 0.8761 - val_loss: 0.4372 - val_accuracy: 0.8572\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3849 - accuracy: 0.8751 - val_loss: 0.4371 - val_accuracy: 0.8574\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3850 - accuracy: 0.8766 - val_loss: 0.4370 - val_accuracy: 0.8570\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3849 - accuracy: 0.8759 - val_loss: 0.4369 - val_accuracy: 0.8572\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3851 - accuracy: 0.8759 - val_loss: 0.4370 - val_accuracy: 0.8573\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:02.448528\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4535 - accuracy: 0.6221 - val_loss: 0.9760 - val_accuracy: 0.7357\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8250 - accuracy: 0.7706 - val_loss: 0.7308 - val_accuracy: 0.7828\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6663 - accuracy: 0.8066 - val_loss: 0.6342 - val_accuracy: 0.8049\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5887 - accuracy: 0.8248 - val_loss: 0.5748 - val_accuracy: 0.8211\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5417 - accuracy: 0.8364 - val_loss: 0.5463 - val_accuracy: 0.8265\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5089 - accuracy: 0.8432 - val_loss: 0.5186 - val_accuracy: 0.8331\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4857 - accuracy: 0.8483 - val_loss: 0.5040 - val_accuracy: 0.8387\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4677 - accuracy: 0.8541 - val_loss: 0.4908 - val_accuracy: 0.8407\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4543 - accuracy: 0.8566 - val_loss: 0.4802 - val_accuracy: 0.8425\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4425 - accuracy: 0.8604 - val_loss: 0.4731 - val_accuracy: 0.8441\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4333 - accuracy: 0.8629 - val_loss: 0.4693 - val_accuracy: 0.8447\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4254 - accuracy: 0.8653 - val_loss: 0.4674 - val_accuracy: 0.8440\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4187 - accuracy: 0.8660 - val_loss: 0.4612 - val_accuracy: 0.8484\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4132 - accuracy: 0.8685 - val_loss: 0.4564 - val_accuracy: 0.8508\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4083 - accuracy: 0.8693 - val_loss: 0.4510 - val_accuracy: 0.8487\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4033 - accuracy: 0.8712 - val_loss: 0.4499 - val_accuracy: 0.8503\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4002 - accuracy: 0.8711 - val_loss: 0.4493 - val_accuracy: 0.8504\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:07:34.065804\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4050 - accuracy: 0.8706 - val_loss: 0.4507 - val_accuracy: 0.8501\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4024 - accuracy: 0.8714 - val_loss: 0.4495 - val_accuracy: 0.8488\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4004 - accuracy: 0.8730 - val_loss: 0.4496 - val_accuracy: 0.8495\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4004 - accuracy: 0.8719 - val_loss: 0.4492 - val_accuracy: 0.8491\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:52.531963\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5127 - accuracy: 0.6158 - val_loss: 1.0221 - val_accuracy: 0.7263\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8292 - accuracy: 0.7695 - val_loss: 0.7374 - val_accuracy: 0.7812\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6508 - accuracy: 0.8106 - val_loss: 0.6213 - val_accuracy: 0.8100\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5689 - accuracy: 0.8297 - val_loss: 0.5635 - val_accuracy: 0.8221\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5200 - accuracy: 0.8398 - val_loss: 0.5284 - val_accuracy: 0.8321\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4871 - accuracy: 0.8478 - val_loss: 0.5006 - val_accuracy: 0.8378\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4635 - accuracy: 0.8540 - val_loss: 0.4877 - val_accuracy: 0.8377\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4456 - accuracy: 0.8595 - val_loss: 0.4693 - val_accuracy: 0.8477\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4318 - accuracy: 0.8616 - val_loss: 0.4582 - val_accuracy: 0.8471\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4207 - accuracy: 0.8646 - val_loss: 0.4526 - val_accuracy: 0.8497\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4119 - accuracy: 0.8672 - val_loss: 0.4460 - val_accuracy: 0.8507\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4038 - accuracy: 0.8694 - val_loss: 0.4439 - val_accuracy: 0.8523\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3974 - accuracy: 0.8710 - val_loss: 0.4353 - val_accuracy: 0.8554\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3908 - accuracy: 0.8735 - val_loss: 0.4340 - val_accuracy: 0.8519\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3864 - accuracy: 0.8751 - val_loss: 0.4298 - val_accuracy: 0.8551\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3820 - accuracy: 0.8766 - val_loss: 0.4274 - val_accuracy: 0.8555\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3768 - accuracy: 0.8774 - val_loss: 0.4227 - val_accuracy: 0.8598\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3740 - accuracy: 0.8776 - val_loss: 0.4214 - val_accuracy: 0.8574\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3708 - accuracy: 0.8795 - val_loss: 0.4178 - val_accuracy: 0.8596\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3686 - accuracy: 0.8795 - val_loss: 0.4171 - val_accuracy: 0.8604\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:07.041343\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3637 - accuracy: 0.8819 - val_loss: 0.4139 - val_accuracy: 0.8602\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3622 - accuracy: 0.8824 - val_loss: 0.4125 - val_accuracy: 0.8609\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3611 - accuracy: 0.8822 - val_loss: 0.4125 - val_accuracy: 0.8609\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.3607 - accuracy: 0.8827 - val_loss: 0.4122 - val_accuracy: 0.8611\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3606 - accuracy: 0.8836 - val_loss: 0.4122 - val_accuracy: 0.8613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3603 - accuracy: 0.8826 - val_loss: 0.4122 - val_accuracy: 0.8613\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3599 - accuracy: 0.8826 - val_loss: 0.4121 - val_accuracy: 0.8614\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3601 - accuracy: 0.8828 - val_loss: 0.4122 - val_accuracy: 0.8608\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3598 - accuracy: 0.8836 - val_loss: 0.4120 - val_accuracy: 0.8610\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3601 - accuracy: 0.8826 - val_loss: 0.4122 - val_accuracy: 0.8610\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:33.244891\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4645 - accuracy: 0.6267 - val_loss: 0.9561 - val_accuracy: 0.7484\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7890 - accuracy: 0.7806 - val_loss: 0.6800 - val_accuracy: 0.8055\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6298 - accuracy: 0.8153 - val_loss: 0.5887 - val_accuracy: 0.8201\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5553 - accuracy: 0.8318 - val_loss: 0.5313 - val_accuracy: 0.8351\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5118 - accuracy: 0.8422 - val_loss: 0.5075 - val_accuracy: 0.8393\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4799 - accuracy: 0.8508 - val_loss: 0.4847 - val_accuracy: 0.8449\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4587 - accuracy: 0.8556 - val_loss: 0.4616 - val_accuracy: 0.8513\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4415 - accuracy: 0.8601 - val_loss: 0.4597 - val_accuracy: 0.8505\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4286 - accuracy: 0.8629 - val_loss: 0.4475 - val_accuracy: 0.8503\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4179 - accuracy: 0.8656 - val_loss: 0.4382 - val_accuracy: 0.8551\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4089 - accuracy: 0.8684 - val_loss: 0.4342 - val_accuracy: 0.8560\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4019 - accuracy: 0.8696 - val_loss: 0.4277 - val_accuracy: 0.8583\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3949 - accuracy: 0.8723 - val_loss: 0.4247 - val_accuracy: 0.8568\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3893 - accuracy: 0.8735 - val_loss: 0.4194 - val_accuracy: 0.8603\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3842 - accuracy: 0.8750 - val_loss: 0.4152 - val_accuracy: 0.8600\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3798 - accuracy: 0.8766 - val_loss: 0.4137 - val_accuracy: 0.8620\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3755 - accuracy: 0.8777 - val_loss: 0.4132 - val_accuracy: 0.8617\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3720 - accuracy: 0.8790 - val_loss: 0.4085 - val_accuracy: 0.8640\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3694 - accuracy: 0.8801 - val_loss: 0.4055 - val_accuracy: 0.8642\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3661 - accuracy: 0.8801 - val_loss: 0.4051 - val_accuracy: 0.8652\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:22.246204\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3630 - accuracy: 0.8817 - val_loss: 0.4029 - val_accuracy: 0.8648\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3606 - accuracy: 0.8830 - val_loss: 0.4016 - val_accuracy: 0.8652\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3596 - accuracy: 0.8830 - val_loss: 0.4010 - val_accuracy: 0.8651\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3593 - accuracy: 0.8828 - val_loss: 0.4012 - val_accuracy: 0.8658\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3587 - accuracy: 0.8831 - val_loss: 0.4011 - val_accuracy: 0.8652\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3587 - accuracy: 0.8832 - val_loss: 0.4009 - val_accuracy: 0.8648\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3586 - accuracy: 0.8834 - val_loss: 0.4011 - val_accuracy: 0.8650\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:15.961234\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4923 - accuracy: 0.6206 - val_loss: 0.9809 - val_accuracy: 0.7379\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8081 - accuracy: 0.7751 - val_loss: 0.7112 - val_accuracy: 0.7930\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6453 - accuracy: 0.8107 - val_loss: 0.6067 - val_accuracy: 0.8187\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5675 - accuracy: 0.8295 - val_loss: 0.5645 - val_accuracy: 0.8259\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5208 - accuracy: 0.8389 - val_loss: 0.5355 - val_accuracy: 0.8320\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4887 - accuracy: 0.8473 - val_loss: 0.5138 - val_accuracy: 0.8349\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4650 - accuracy: 0.8549 - val_loss: 0.4893 - val_accuracy: 0.8419\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4476 - accuracy: 0.8578 - val_loss: 0.4804 - val_accuracy: 0.8475\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4332 - accuracy: 0.8617 - val_loss: 0.4663 - val_accuracy: 0.8502\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4232 - accuracy: 0.8646 - val_loss: 0.4620 - val_accuracy: 0.8491\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4135 - accuracy: 0.8674 - val_loss: 0.4486 - val_accuracy: 0.8541\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4052 - accuracy: 0.8694 - val_loss: 0.4493 - val_accuracy: 0.8547\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3981 - accuracy: 0.8712 - val_loss: 0.4389 - val_accuracy: 0.8552\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3922 - accuracy: 0.8732 - val_loss: 0.4358 - val_accuracy: 0.8585\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3877 - accuracy: 0.8744 - val_loss: 0.4313 - val_accuracy: 0.8590\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3831 - accuracy: 0.8760 - val_loss: 0.4289 - val_accuracy: 0.8601\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3780 - accuracy: 0.8771 - val_loss: 0.4274 - val_accuracy: 0.8609\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3754 - accuracy: 0.8777 - val_loss: 0.4243 - val_accuracy: 0.8612\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3718 - accuracy: 0.8791 - val_loss: 0.4234 - val_accuracy: 0.8617\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3696 - accuracy: 0.8798 - val_loss: 0.4216 - val_accuracy: 0.8600\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:20.687999\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3661 - accuracy: 0.8805 - val_loss: 0.4175 - val_accuracy: 0.8635\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3640 - accuracy: 0.8820 - val_loss: 0.4165 - val_accuracy: 0.8637\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3621 - accuracy: 0.8819 - val_loss: 0.4161 - val_accuracy: 0.8638\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3621 - accuracy: 0.8828 - val_loss: 0.4161 - val_accuracy: 0.8637\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3617 - accuracy: 0.8832 - val_loss: 0.4159 - val_accuracy: 0.8629\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3614 - accuracy: 0.8825 - val_loss: 0.4160 - val_accuracy: 0.8637\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:47.398047\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4874 - accuracy: 0.6198 - val_loss: 0.9811 - val_accuracy: 0.7397\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8048 - accuracy: 0.7746 - val_loss: 0.6962 - val_accuracy: 0.7949\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6410 - accuracy: 0.8125 - val_loss: 0.6070 - val_accuracy: 0.8172\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5658 - accuracy: 0.8298 - val_loss: 0.5498 - val_accuracy: 0.8291\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5200 - accuracy: 0.8408 - val_loss: 0.5153 - val_accuracy: 0.8369\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4884 - accuracy: 0.8486 - val_loss: 0.5045 - val_accuracy: 0.8400\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4668 - accuracy: 0.8526 - val_loss: 0.4734 - val_accuracy: 0.8486\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4487 - accuracy: 0.8578 - val_loss: 0.4629 - val_accuracy: 0.8490\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4346 - accuracy: 0.8616 - val_loss: 0.4534 - val_accuracy: 0.8496\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4251 - accuracy: 0.8633 - val_loss: 0.4455 - val_accuracy: 0.8543\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4156 - accuracy: 0.8666 - val_loss: 0.4378 - val_accuracy: 0.8565\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4076 - accuracy: 0.8685 - val_loss: 0.4350 - val_accuracy: 0.8578\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4015 - accuracy: 0.8699 - val_loss: 0.4294 - val_accuracy: 0.8579\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3956 - accuracy: 0.8716 - val_loss: 0.4231 - val_accuracy: 0.8597\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3905 - accuracy: 0.8728 - val_loss: 0.4211 - val_accuracy: 0.8617\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3860 - accuracy: 0.8748 - val_loss: 0.4198 - val_accuracy: 0.8609\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3822 - accuracy: 0.8756 - val_loss: 0.4157 - val_accuracy: 0.8614\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3786 - accuracy: 0.8768 - val_loss: 0.4144 - val_accuracy: 0.8620\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3756 - accuracy: 0.8779 - val_loss: 0.4120 - val_accuracy: 0.8621\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3725 - accuracy: 0.8782 - val_loss: 0.4106 - val_accuracy: 0.8630\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:11.662660\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3689 - accuracy: 0.8803 - val_loss: 0.4079 - val_accuracy: 0.8649\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3668 - accuracy: 0.8801 - val_loss: 0.4067 - val_accuracy: 0.8635\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3657 - accuracy: 0.8813 - val_loss: 0.4064 - val_accuracy: 0.8645\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3648 - accuracy: 0.8814 - val_loss: 0.4065 - val_accuracy: 0.8645\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:01:50.952205\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4609 - accuracy: 0.6286 - val_loss: 0.9442 - val_accuracy: 0.7481\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7839 - accuracy: 0.7806 - val_loss: 0.6995 - val_accuracy: 0.7949\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6320 - accuracy: 0.8162 - val_loss: 0.6092 - val_accuracy: 0.8169\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5592 - accuracy: 0.8302 - val_loss: 0.5578 - val_accuracy: 0.8254\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5137 - accuracy: 0.8412 - val_loss: 0.5258 - val_accuracy: 0.8383\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4821 - accuracy: 0.8488 - val_loss: 0.4980 - val_accuracy: 0.8414\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4582 - accuracy: 0.8548 - val_loss: 0.4865 - val_accuracy: 0.8461\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4421 - accuracy: 0.8588 - val_loss: 0.4798 - val_accuracy: 0.8440\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4281 - accuracy: 0.8617 - val_loss: 0.4575 - val_accuracy: 0.8506\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4167 - accuracy: 0.8656 - val_loss: 0.4493 - val_accuracy: 0.8560\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4072 - accuracy: 0.8675 - val_loss: 0.4410 - val_accuracy: 0.8571\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3993 - accuracy: 0.8702 - val_loss: 0.4376 - val_accuracy: 0.8580\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3923 - accuracy: 0.8726 - val_loss: 0.4293 - val_accuracy: 0.8591\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3865 - accuracy: 0.8737 - val_loss: 0.4296 - val_accuracy: 0.8584\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.3815 - accuracy: 0.8755 - val_loss: 0.4265 - val_accuracy: 0.8596\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3767 - accuracy: 0.8766 - val_loss: 0.4206 - val_accuracy: 0.8630\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3729 - accuracy: 0.8778 - val_loss: 0.4201 - val_accuracy: 0.8616\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3691 - accuracy: 0.8784 - val_loss: 0.4176 - val_accuracy: 0.8626\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3658 - accuracy: 0.8801 - val_loss: 0.4158 - val_accuracy: 0.8615\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:08:49.800448\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3708 - accuracy: 0.8791 - val_loss: 0.4169 - val_accuracy: 0.8626\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3682 - accuracy: 0.8795 - val_loss: 0.4165 - val_accuracy: 0.8625\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3667 - accuracy: 0.8808 - val_loss: 0.4160 - val_accuracy: 0.8626\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3656 - accuracy: 0.8806 - val_loss: 0.4159 - val_accuracy: 0.8626\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:01:50.525000\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 6.9247 - accuracy: 0.6142 - val_loss: 5.7251 - val_accuracy: 0.7308\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.9010 - accuracy: 0.7795 - val_loss: 4.2331 - val_accuracy: 0.7933\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.6286 - accuracy: 0.8166 - val_loss: 3.1310 - val_accuracy: 0.8171\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.6461 - accuracy: 0.8347 - val_loss: 2.2606 - val_accuracy: 0.8313\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.8906 - accuracy: 0.8428 - val_loss: 1.6450 - val_accuracy: 0.8266\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3576 - accuracy: 0.8476 - val_loss: 1.2315 - val_accuracy: 0.8282\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0327 - accuracy: 0.8480 - val_loss: 1.0163 - val_accuracy: 0.8161\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:04.049223\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.0533 - accuracy: 0.8472 - val_loss: 1.9318 - val_accuracy: 0.8421\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.8237 - accuracy: 0.8547 - val_loss: 1.7798 - val_accuracy: 0.8472\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.7158 - accuracy: 0.8571 - val_loss: 1.7074 - val_accuracy: 0.8494\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6640 - accuracy: 0.8599 - val_loss: 1.6748 - val_accuracy: 0.8492\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6405 - accuracy: 0.8607 - val_loss: 1.6599 - val_accuracy: 0.8503\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6296 - accuracy: 0.8599 - val_loss: 1.6535 - val_accuracy: 0.8510\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6245 - accuracy: 0.8610 - val_loss: 1.6510 - val_accuracy: 0.8512\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6226 - accuracy: 0.8611 - val_loss: 1.6499 - val_accuracy: 0.8510\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6223 - accuracy: 0.8613 - val_loss: 1.6499 - val_accuracy: 0.8512\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6214 - accuracy: 0.8613 - val_loss: 1.6497 - val_accuracy: 0.8514\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6220 - accuracy: 0.8608 - val_loss: 1.6498 - val_accuracy: 0.8511\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6216 - accuracy: 0.8610 - val_loss: 1.6497 - val_accuracy: 0.8513\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6219 - accuracy: 0.8610 - val_loss: 1.6496 - val_accuracy: 0.8511\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:42.777961\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 7.0082 - accuracy: 0.6009 - val_loss: 5.7956 - val_accuracy: 0.7164\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.9458 - accuracy: 0.7729 - val_loss: 4.2796 - val_accuracy: 0.7844\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.6556 - accuracy: 0.8149 - val_loss: 3.1714 - val_accuracy: 0.8066\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.6647 - accuracy: 0.8327 - val_loss: 2.3038 - val_accuracy: 0.8174\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.9021 - accuracy: 0.8426 - val_loss: 1.6399 - val_accuracy: 0.8246\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3665 - accuracy: 0.8458 - val_loss: 1.2352 - val_accuracy: 0.8227\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0373 - accuracy: 0.8481 - val_loss: 1.0069 - val_accuracy: 0.8195\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8503 - accuracy: 0.8487 - val_loss: 0.8557 - val_accuracy: 0.8283\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7503 - accuracy: 0.8498 - val_loss: 0.8118 - val_accuracy: 0.8223\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6993 - accuracy: 0.8521 - val_loss: 0.7586 - val_accuracy: 0.8255\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6660 - accuracy: 0.8556 - val_loss: 0.7296 - val_accuracy: 0.8322\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6424 - accuracy: 0.8571 - val_loss: 0.6995 - val_accuracy: 0.8343\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6235 - accuracy: 0.8594 - val_loss: 0.6823 - val_accuracy: 0.8383\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6052 - accuracy: 0.8615 - val_loss: 0.6637 - val_accuracy: 0.8431\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5900 - accuracy: 0.8650 - val_loss: 0.6467 - val_accuracy: 0.8424\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5780 - accuracy: 0.8656 - val_loss: 0.6535 - val_accuracy: 0.8399\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5665 - accuracy: 0.8665 - val_loss: 0.6180 - val_accuracy: 0.8497\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5547 - accuracy: 0.8692 - val_loss: 0.6113 - val_accuracy: 0.8449\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5452 - accuracy: 0.8706 - val_loss: 0.5988 - val_accuracy: 0.8471\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5373 - accuracy: 0.8712 - val_loss: 0.5897 - val_accuracy: 0.8496\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:46.195364\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5234 - accuracy: 0.8783 - val_loss: 0.5643 - val_accuracy: 0.8584\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5037 - accuracy: 0.8818 - val_loss: 0.5534 - val_accuracy: 0.8612\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4937 - accuracy: 0.8849 - val_loss: 0.5440 - val_accuracy: 0.8617\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4884 - accuracy: 0.8854 - val_loss: 0.5399 - val_accuracy: 0.8617\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4858 - accuracy: 0.8863 - val_loss: 0.5384 - val_accuracy: 0.8625\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4845 - accuracy: 0.8865 - val_loss: 0.5381 - val_accuracy: 0.8624\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4836 - accuracy: 0.8870 - val_loss: 0.5378 - val_accuracy: 0.8623\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4831 - accuracy: 0.8866 - val_loss: 0.5375 - val_accuracy: 0.8619\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:30.552600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 6.9308 - accuracy: 0.6115 - val_loss: 5.7040 - val_accuracy: 0.7352\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.9082 - accuracy: 0.7776 - val_loss: 4.2199 - val_accuracy: 0.7963\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.6398 - accuracy: 0.8152 - val_loss: 3.1320 - val_accuracy: 0.8134\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.6562 - accuracy: 0.8317 - val_loss: 2.2695 - val_accuracy: 0.8207\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.9009 - accuracy: 0.8373 - val_loss: 1.6174 - val_accuracy: 0.8307\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3678 - accuracy: 0.8453 - val_loss: 1.2177 - val_accuracy: 0.8306\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0448 - accuracy: 0.8461 - val_loss: 0.9980 - val_accuracy: 0.8203\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8625 - accuracy: 0.8463 - val_loss: 0.8613 - val_accuracy: 0.8220\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:29.169215\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.4517 - accuracy: 0.8530 - val_loss: 1.3701 - val_accuracy: 0.8476\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2931 - accuracy: 0.8586 - val_loss: 1.2557 - val_accuracy: 0.8560\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2178 - accuracy: 0.8623 - val_loss: 1.2056 - val_accuracy: 0.8578\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1811 - accuracy: 0.8643 - val_loss: 1.1797 - val_accuracy: 0.8598\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1645 - accuracy: 0.8640 - val_loss: 1.1698 - val_accuracy: 0.8597\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1569 - accuracy: 0.8654 - val_loss: 1.1645 - val_accuracy: 0.8601\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1535 - accuracy: 0.8651 - val_loss: 1.1626 - val_accuracy: 0.8603\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1520 - accuracy: 0.8654 - val_loss: 1.1620 - val_accuracy: 0.8604\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1513 - accuracy: 0.8663 - val_loss: 1.1618 - val_accuracy: 0.8603\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1517 - accuracy: 0.8655 - val_loss: 1.1616 - val_accuracy: 0.8603\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1512 - accuracy: 0.8655 - val_loss: 1.1614 - val_accuracy: 0.8606\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1507 - accuracy: 0.8661 - val_loss: 1.1617 - val_accuracy: 0.8603\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1512 - accuracy: 0.8657 - val_loss: 1.1618 - val_accuracy: 0.8603\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1510 - accuracy: 0.8659 - val_loss: 1.1618 - val_accuracy: 0.8601\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:06:05.274186\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 6.9643 - accuracy: 0.6091 - val_loss: 5.7406 - val_accuracy: 0.7242\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.9124 - accuracy: 0.7799 - val_loss: 4.2361 - val_accuracy: 0.7951\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.6376 - accuracy: 0.8169 - val_loss: 3.1370 - val_accuracy: 0.8186\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.6524 - accuracy: 0.8347 - val_loss: 2.2958 - val_accuracy: 0.8194\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.8957 - accuracy: 0.8418 - val_loss: 1.6271 - val_accuracy: 0.8335\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3629 - accuracy: 0.8463 - val_loss: 1.2192 - val_accuracy: 0.8312\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0367 - accuracy: 0.8479 - val_loss: 0.9748 - val_accuracy: 0.8315\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8538 - accuracy: 0.8488 - val_loss: 0.8432 - val_accuracy: 0.8313\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:29.317894\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.4466 - accuracy: 0.8549 - val_loss: 1.3834 - val_accuracy: 0.8425\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2873 - accuracy: 0.8614 - val_loss: 1.2724 - val_accuracy: 0.8483\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2131 - accuracy: 0.8644 - val_loss: 1.2221 - val_accuracy: 0.8512\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1769 - accuracy: 0.8657 - val_loss: 1.1982 - val_accuracy: 0.8515\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1599 - accuracy: 0.8671 - val_loss: 1.1869 - val_accuracy: 0.8520\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1520 - accuracy: 0.8669 - val_loss: 1.1826 - val_accuracy: 0.8529\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1490 - accuracy: 0.8669 - val_loss: 1.1808 - val_accuracy: 0.8528\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1478 - accuracy: 0.8672 - val_loss: 1.1802 - val_accuracy: 0.8524\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1466 - accuracy: 0.8678 - val_loss: 1.1800 - val_accuracy: 0.8527\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:55.450195\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 6.9796 - accuracy: 0.6028 - val_loss: 5.7581 - val_accuracy: 0.7287\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.9446 - accuracy: 0.7701 - val_loss: 4.2476 - val_accuracy: 0.7992\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.6591 - accuracy: 0.8120 - val_loss: 3.1387 - val_accuracy: 0.8205\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.6689 - accuracy: 0.8298 - val_loss: 2.2739 - val_accuracy: 0.8332\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.9066 - accuracy: 0.8374 - val_loss: 1.6313 - val_accuracy: 0.8250\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3719 - accuracy: 0.8434 - val_loss: 1.2028 - val_accuracy: 0.8371\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0487 - accuracy: 0.8448 - val_loss: 1.0339 - val_accuracy: 0.8115\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8657 - accuracy: 0.8434 - val_loss: 0.8260 - val_accuracy: 0.8406\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7650 - accuracy: 0.8466 - val_loss: 0.7779 - val_accuracy: 0.8369\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7136 - accuracy: 0.8482 - val_loss: 0.7271 - val_accuracy: 0.8425\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6797 - accuracy: 0.8506 - val_loss: 0.7008 - val_accuracy: 0.8410\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6545 - accuracy: 0.8535 - val_loss: 0.6905 - val_accuracy: 0.8384\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6332 - accuracy: 0.8566 - val_loss: 0.6652 - val_accuracy: 0.8434\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6157 - accuracy: 0.8587 - val_loss: 0.6329 - val_accuracy: 0.8538\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6007 - accuracy: 0.8610 - val_loss: 0.6377 - val_accuracy: 0.8508\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5873 - accuracy: 0.8619 - val_loss: 0.6157 - val_accuracy: 0.8543\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5764 - accuracy: 0.8641 - val_loss: 0.6083 - val_accuracy: 0.8551\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5648 - accuracy: 0.8673 - val_loss: 0.5967 - val_accuracy: 0.8558\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5555 - accuracy: 0.8670 - val_loss: 0.5868 - val_accuracy: 0.8582\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5469 - accuracy: 0.8681 - val_loss: 0.5769 - val_accuracy: 0.8569\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:42.514575\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5175 - accuracy: 0.8760 - val_loss: 0.5397 - val_accuracy: 0.8689\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4993 - accuracy: 0.8807 - val_loss: 0.5295 - val_accuracy: 0.8690\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4887 - accuracy: 0.8837 - val_loss: 0.5185 - val_accuracy: 0.8733\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4834 - accuracy: 0.8852 - val_loss: 0.5161 - val_accuracy: 0.8727\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4803 - accuracy: 0.8854 - val_loss: 0.5137 - val_accuracy: 0.8731\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4787 - accuracy: 0.8857 - val_loss: 0.5130 - val_accuracy: 0.8727\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:36.967674\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.7443 - accuracy: 0.6378 - val_loss: 5.5940 - val_accuracy: 0.7468\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.8312 - accuracy: 0.7882 - val_loss: 4.1971 - val_accuracy: 0.7976\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6072 - accuracy: 0.8167 - val_loss: 3.1040 - val_accuracy: 0.8189\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6379 - accuracy: 0.8301 - val_loss: 2.2456 - val_accuracy: 0.8248\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8857 - accuracy: 0.8377 - val_loss: 1.6235 - val_accuracy: 0.8228\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3618 - accuracy: 0.8406 - val_loss: 1.2071 - val_accuracy: 0.8266\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0517 - accuracy: 0.8411 - val_loss: 0.9846 - val_accuracy: 0.8251\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8882 - accuracy: 0.8388 - val_loss: 0.9115 - val_accuracy: 0.8195\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8060 - accuracy: 0.8388 - val_loss: 0.7958 - val_accuracy: 0.8345\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7576 - accuracy: 0.8403 - val_loss: 0.7701 - val_accuracy: 0.8275\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7263 - accuracy: 0.8394 - val_loss: 0.7455 - val_accuracy: 0.8331\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7005 - accuracy: 0.8437 - val_loss: 0.7136 - val_accuracy: 0.8342\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:21.598373\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7078 - accuracy: 0.8538 - val_loss: 0.7235 - val_accuracy: 0.8384\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6682 - accuracy: 0.8586 - val_loss: 0.6863 - val_accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6483 - accuracy: 0.8621 - val_loss: 0.6679 - val_accuracy: 0.8517\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6366 - accuracy: 0.8639 - val_loss: 0.6610 - val_accuracy: 0.8539\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6310 - accuracy: 0.8649 - val_loss: 0.6562 - val_accuracy: 0.8537\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6290 - accuracy: 0.8650 - val_loss: 0.6546 - val_accuracy: 0.8538\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6268 - accuracy: 0.8652 - val_loss: 0.6540 - val_accuracy: 0.8535\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:08.024441\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.7799 - accuracy: 0.6232 - val_loss: 5.6632 - val_accuracy: 0.7309\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.8789 - accuracy: 0.7722 - val_loss: 4.2110 - val_accuracy: 0.7920\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6240 - accuracy: 0.8104 - val_loss: 3.1148 - val_accuracy: 0.8109\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6472 - accuracy: 0.8273 - val_loss: 2.2446 - val_accuracy: 0.8310\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8959 - accuracy: 0.8351 - val_loss: 1.6232 - val_accuracy: 0.8290\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3735 - accuracy: 0.8398 - val_loss: 1.2230 - val_accuracy: 0.8261\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0671 - accuracy: 0.8386 - val_loss: 0.9942 - val_accuracy: 0.8361\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9038 - accuracy: 0.8381 - val_loss: 0.8616 - val_accuracy: 0.8356\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.8147 - accuracy: 0.8376 - val_loss: 0.8239 - val_accuracy: 0.8254\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7651 - accuracy: 0.8385 - val_loss: 0.7633 - val_accuracy: 0.8333\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:26.637044\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8763 - accuracy: 0.8524 - val_loss: 0.8762 - val_accuracy: 0.8416\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8090 - accuracy: 0.8581 - val_loss: 0.8232 - val_accuracy: 0.8425\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7757 - accuracy: 0.8611 - val_loss: 0.7872 - val_accuracy: 0.8516\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7582 - accuracy: 0.8632 - val_loss: 0.7743 - val_accuracy: 0.8537\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7493 - accuracy: 0.8645 - val_loss: 0.7686 - val_accuracy: 0.8546\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7455 - accuracy: 0.8653 - val_loss: 0.7660 - val_accuracy: 0.8553\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7434 - accuracy: 0.8649 - val_loss: 0.7650 - val_accuracy: 0.8548\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7427 - accuracy: 0.8656 - val_loss: 0.7645 - val_accuracy: 0.8546\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7427 - accuracy: 0.8655 - val_loss: 0.7645 - val_accuracy: 0.8548\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:01.877293\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.7590 - accuracy: 0.6342 - val_loss: 5.6208 - val_accuracy: 0.7462\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.8491 - accuracy: 0.7828 - val_loss: 4.1836 - val_accuracy: 0.7992\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6111 - accuracy: 0.8162 - val_loss: 3.1097 - val_accuracy: 0.8179\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6392 - accuracy: 0.8299 - val_loss: 2.2624 - val_accuracy: 0.8261\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8888 - accuracy: 0.8371 - val_loss: 1.6150 - val_accuracy: 0.8310\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3670 - accuracy: 0.8383 - val_loss: 1.2081 - val_accuracy: 0.8286\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0593 - accuracy: 0.8390 - val_loss: 0.9997 - val_accuracy: 0.8240\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8969 - accuracy: 0.8376 - val_loss: 0.8846 - val_accuracy: 0.8257\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:34.635498\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.4459 - accuracy: 0.8491 - val_loss: 1.3754 - val_accuracy: 0.8425\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2903 - accuracy: 0.8550 - val_loss: 1.2674 - val_accuracy: 0.8487\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2171 - accuracy: 0.8585 - val_loss: 1.2182 - val_accuracy: 0.8480\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.1820 - accuracy: 0.8595 - val_loss: 1.1938 - val_accuracy: 0.8505\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1663 - accuracy: 0.8604 - val_loss: 1.1836 - val_accuracy: 0.8513\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1582 - accuracy: 0.8607 - val_loss: 1.1792 - val_accuracy: 0.8521\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1548 - accuracy: 0.8610 - val_loss: 1.1778 - val_accuracy: 0.8521\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1533 - accuracy: 0.8615 - val_loss: 1.1768 - val_accuracy: 0.8519\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.1532 - accuracy: 0.8615 - val_loss: 1.1767 - val_accuracy: 0.8518\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:00.193690\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 6.7893 - accuracy: 0.6269 - val_loss: 5.6361 - val_accuracy: 0.7405\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.8626 - accuracy: 0.7801 - val_loss: 4.2093 - val_accuracy: 0.7917\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6149 - accuracy: 0.8157 - val_loss: 3.1114 - val_accuracy: 0.8165\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6396 - accuracy: 0.8307 - val_loss: 2.2606 - val_accuracy: 0.8231\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8881 - accuracy: 0.8376 - val_loss: 1.6182 - val_accuracy: 0.8276\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3661 - accuracy: 0.8402 - val_loss: 1.2259 - val_accuracy: 0.8195\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0577 - accuracy: 0.8396 - val_loss: 1.0049 - val_accuracy: 0.8213\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8926 - accuracy: 0.8397 - val_loss: 0.8736 - val_accuracy: 0.8274\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:33.293286\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4451 - accuracy: 0.8505 - val_loss: 1.3851 - val_accuracy: 0.8373\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2897 - accuracy: 0.8558 - val_loss: 1.2725 - val_accuracy: 0.8448\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2169 - accuracy: 0.8588 - val_loss: 1.2224 - val_accuracy: 0.8466\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1816 - accuracy: 0.8610 - val_loss: 1.2000 - val_accuracy: 0.8470\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1652 - accuracy: 0.8616 - val_loss: 1.1894 - val_accuracy: 0.8473\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.1576 - accuracy: 0.8622 - val_loss: 1.1850 - val_accuracy: 0.8480\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1546 - accuracy: 0.8623 - val_loss: 1.1831 - val_accuracy: 0.8476\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1538 - accuracy: 0.8620 - val_loss: 1.1828 - val_accuracy: 0.8477\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1519 - accuracy: 0.8625 - val_loss: 1.1823 - val_accuracy: 0.8473\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:00.877652\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.7480 - accuracy: 0.6326 - val_loss: 5.6097 - val_accuracy: 0.7519\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.8381 - accuracy: 0.7835 - val_loss: 4.1983 - val_accuracy: 0.7960\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6083 - accuracy: 0.8145 - val_loss: 3.1199 - val_accuracy: 0.8138\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6359 - accuracy: 0.8296 - val_loss: 2.2845 - val_accuracy: 0.8071\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8825 - accuracy: 0.8372 - val_loss: 1.6243 - val_accuracy: 0.8247\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3608 - accuracy: 0.8407 - val_loss: 1.2332 - val_accuracy: 0.8244\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0520 - accuracy: 0.8416 - val_loss: 0.9910 - val_accuracy: 0.8288\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8896 - accuracy: 0.8375 - val_loss: 0.8991 - val_accuracy: 0.8199\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8078 - accuracy: 0.8392 - val_loss: 0.8150 - val_accuracy: 0.8254\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7594 - accuracy: 0.8403 - val_loss: 0.7972 - val_accuracy: 0.8238\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:28.460733\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.8652 - accuracy: 0.8541 - val_loss: 0.8670 - val_accuracy: 0.8389\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.8005 - accuracy: 0.8567 - val_loss: 0.8246 - val_accuracy: 0.8418\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7672 - accuracy: 0.8610 - val_loss: 0.7993 - val_accuracy: 0.8445\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7510 - accuracy: 0.8627 - val_loss: 0.7858 - val_accuracy: 0.8459\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7432 - accuracy: 0.8637 - val_loss: 0.7805 - val_accuracy: 0.8471\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7389 - accuracy: 0.8649 - val_loss: 0.7774 - val_accuracy: 0.8477\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7374 - accuracy: 0.8647 - val_loss: 0.7763 - val_accuracy: 0.8474\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7370 - accuracy: 0.8654 - val_loss: 0.7759 - val_accuracy: 0.8480\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7364 - accuracy: 0.8648 - val_loss: 0.7762 - val_accuracy: 0.8479\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7357 - accuracy: 0.8649 - val_loss: 0.7761 - val_accuracy: 0.8477\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7359 - accuracy: 0.8648 - val_loss: 0.7760 - val_accuracy: 0.8480\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:05.122984\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 6.8401 - accuracy: 0.6173 - val_loss: 5.7161 - val_accuracy: 0.7323\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8922 - accuracy: 0.7735 - val_loss: 4.2265 - val_accuracy: 0.7956\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6326 - accuracy: 0.8138 - val_loss: 3.1612 - val_accuracy: 0.8082\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.6503 - accuracy: 0.8318 - val_loss: 2.2828 - val_accuracy: 0.8276\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8978 - accuracy: 0.8388 - val_loss: 1.6251 - val_accuracy: 0.8350\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3716 - accuracy: 0.8413 - val_loss: 1.2743 - val_accuracy: 0.8105\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0537 - accuracy: 0.8433 - val_loss: 1.0037 - val_accuracy: 0.8285\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8812 - accuracy: 0.8430 - val_loss: 0.8874 - val_accuracy: 0.8251\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:48.106915\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4504 - accuracy: 0.8528 - val_loss: 1.3907 - val_accuracy: 0.8440\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2935 - accuracy: 0.8579 - val_loss: 1.2781 - val_accuracy: 0.8476\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2198 - accuracy: 0.8604 - val_loss: 1.2288 - val_accuracy: 0.8520\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1828 - accuracy: 0.8633 - val_loss: 1.2040 - val_accuracy: 0.8515\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1660 - accuracy: 0.8642 - val_loss: 1.1935 - val_accuracy: 0.8518\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1586 - accuracy: 0.8649 - val_loss: 1.1886 - val_accuracy: 0.8518\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:50.115149\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.8584 - accuracy: 0.6164 - val_loss: 5.7009 - val_accuracy: 0.7293\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8882 - accuracy: 0.7771 - val_loss: 4.2499 - val_accuracy: 0.7833\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6305 - accuracy: 0.8162 - val_loss: 3.1328 - val_accuracy: 0.8160\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.6529 - accuracy: 0.8327 - val_loss: 2.2957 - val_accuracy: 0.8172\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9009 - accuracy: 0.8408 - val_loss: 1.6332 - val_accuracy: 0.8289\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3741 - accuracy: 0.8439 - val_loss: 1.2441 - val_accuracy: 0.8255\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0566 - accuracy: 0.8446 - val_loss: 1.0161 - val_accuracy: 0.8242\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8810 - accuracy: 0.8447 - val_loss: 0.8989 - val_accuracy: 0.8203\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:47.543215\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4568 - accuracy: 0.8534 - val_loss: 1.3964 - val_accuracy: 0.8395\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3004 - accuracy: 0.8588 - val_loss: 1.2864 - val_accuracy: 0.8436\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.2261 - accuracy: 0.8613 - val_loss: 1.2352 - val_accuracy: 0.8455\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.1903 - accuracy: 0.8638 - val_loss: 1.2116 - val_accuracy: 0.8491\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1737 - accuracy: 0.8648 - val_loss: 1.1991 - val_accuracy: 0.8497\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1656 - accuracy: 0.8649 - val_loss: 1.1944 - val_accuracy: 0.8501\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1623 - accuracy: 0.8660 - val_loss: 1.1930 - val_accuracy: 0.8493\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1612 - accuracy: 0.8661 - val_loss: 1.1921 - val_accuracy: 0.8497\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1610 - accuracy: 0.8658 - val_loss: 1.1919 - val_accuracy: 0.8495\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:16.318262\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.8197 - accuracy: 0.6310 - val_loss: 5.6365 - val_accuracy: 0.7500\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8505 - accuracy: 0.7879 - val_loss: 4.1997 - val_accuracy: 0.8034\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 40ms/step - loss: 3.6106 - accuracy: 0.8225 - val_loss: 3.1205 - val_accuracy: 0.8187\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.6405 - accuracy: 0.8349 - val_loss: 2.2674 - val_accuracy: 0.8238\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8869 - accuracy: 0.8429 - val_loss: 1.6098 - val_accuracy: 0.8381\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3582 - accuracy: 0.8470 - val_loss: 1.2453 - val_accuracy: 0.8198\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0379 - accuracy: 0.8472 - val_loss: 1.0023 - val_accuracy: 0.8194\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8590 - accuracy: 0.8469 - val_loss: 0.8638 - val_accuracy: 0.8279\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:47.522764\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4441 - accuracy: 0.8553 - val_loss: 1.3707 - val_accuracy: 0.8510\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2878 - accuracy: 0.8602 - val_loss: 1.2663 - val_accuracy: 0.8532\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2146 - accuracy: 0.8621 - val_loss: 1.2178 - val_accuracy: 0.8563\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1787 - accuracy: 0.8650 - val_loss: 1.1937 - val_accuracy: 0.8575\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1632 - accuracy: 0.8651 - val_loss: 1.1844 - val_accuracy: 0.8582\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1548 - accuracy: 0.8660 - val_loss: 1.1796 - val_accuracy: 0.8589\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1518 - accuracy: 0.8653 - val_loss: 1.1776 - val_accuracy: 0.8590\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1506 - accuracy: 0.8659 - val_loss: 1.1772 - val_accuracy: 0.8589\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1499 - accuracy: 0.8657 - val_loss: 1.1769 - val_accuracy: 0.8588\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1497 - accuracy: 0.8657 - val_loss: 1.1769 - val_accuracy: 0.8586\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:39.662076\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.8104 - accuracy: 0.6343 - val_loss: 5.6488 - val_accuracy: 0.7454\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8655 - accuracy: 0.7860 - val_loss: 4.2242 - val_accuracy: 0.7846\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6259 - accuracy: 0.8177 - val_loss: 3.1341 - val_accuracy: 0.8126\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.6531 - accuracy: 0.8323 - val_loss: 2.2595 - val_accuracy: 0.8310\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8990 - accuracy: 0.8404 - val_loss: 1.6174 - val_accuracy: 0.8270\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3688 - accuracy: 0.8433 - val_loss: 1.2341 - val_accuracy: 0.8261\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0493 - accuracy: 0.8449 - val_loss: 1.0013 - val_accuracy: 0.8266\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:16.085938\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.0610 - accuracy: 0.8463 - val_loss: 1.9354 - val_accuracy: 0.8362\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8326 - accuracy: 0.8529 - val_loss: 1.7747 - val_accuracy: 0.8434\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7253 - accuracy: 0.8553 - val_loss: 1.7058 - val_accuracy: 0.8467\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6736 - accuracy: 0.8581 - val_loss: 1.6695 - val_accuracy: 0.8483\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6495 - accuracy: 0.8581 - val_loss: 1.6541 - val_accuracy: 0.8485\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6387 - accuracy: 0.8592 - val_loss: 1.6477 - val_accuracy: 0.8492\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6350 - accuracy: 0.8592 - val_loss: 1.6452 - val_accuracy: 0.8488\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6332 - accuracy: 0.8588 - val_loss: 1.6438 - val_accuracy: 0.8490\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6316 - accuracy: 0.8598 - val_loss: 1.6438 - val_accuracy: 0.8493\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6316 - accuracy: 0.8589 - val_loss: 1.6437 - val_accuracy: 0.8488\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6309 - accuracy: 0.8593 - val_loss: 1.6437 - val_accuracy: 0.8489\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6321 - accuracy: 0.8591 - val_loss: 1.6437 - val_accuracy: 0.8489\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:34.619002\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.8117 - accuracy: 0.6281 - val_loss: 5.6406 - val_accuracy: 0.7419\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.8620 - accuracy: 0.7828 - val_loss: 4.1991 - val_accuracy: 0.8030\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6147 - accuracy: 0.8193 - val_loss: 3.1200 - val_accuracy: 0.8165\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.6421 - accuracy: 0.8341 - val_loss: 2.2736 - val_accuracy: 0.8201\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8926 - accuracy: 0.8401 - val_loss: 1.6353 - val_accuracy: 0.8242\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3671 - accuracy: 0.8439 - val_loss: 1.2556 - val_accuracy: 0.8180\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0473 - accuracy: 0.8448 - val_loss: 1.0009 - val_accuracy: 0.8255\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8731 - accuracy: 0.8453 - val_loss: 0.8510 - val_accuracy: 0.8320\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7801 - accuracy: 0.8443 - val_loss: 0.8173 - val_accuracy: 0.8217\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7289 - accuracy: 0.8452 - val_loss: 0.7499 - val_accuracy: 0.8308\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6946 - accuracy: 0.8496 - val_loss: 0.7290 - val_accuracy: 0.8306\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:06.283077\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7398 - accuracy: 0.8581 - val_loss: 0.7398 - val_accuracy: 0.8500\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6883 - accuracy: 0.8642 - val_loss: 0.7074 - val_accuracy: 0.8539\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6636 - accuracy: 0.8674 - val_loss: 0.6868 - val_accuracy: 0.8550\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6498 - accuracy: 0.8696 - val_loss: 0.6717 - val_accuracy: 0.8580\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6421 - accuracy: 0.8708 - val_loss: 0.6668 - val_accuracy: 0.8590\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6387 - accuracy: 0.8715 - val_loss: 0.6648 - val_accuracy: 0.8594\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6373 - accuracy: 0.8725 - val_loss: 0.6639 - val_accuracy: 0.8583\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6373 - accuracy: 0.8718 - val_loss: 0.6635 - val_accuracy: 0.8589\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6362 - accuracy: 0.8724 - val_loss: 0.6635 - val_accuracy: 0.8589\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:12.727406\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.7699 - accuracy: 0.6231 - val_loss: 1.2266 - val_accuracy: 0.7476\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0443 - accuracy: 0.7803 - val_loss: 0.9471 - val_accuracy: 0.7947\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8652 - accuracy: 0.8150 - val_loss: 0.8258 - val_accuracy: 0.8223\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7784 - accuracy: 0.8334 - val_loss: 0.7761 - val_accuracy: 0.8301\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7241 - accuracy: 0.8436 - val_loss: 0.7369 - val_accuracy: 0.8319\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6844 - accuracy: 0.8512 - val_loss: 0.7004 - val_accuracy: 0.8402\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6552 - accuracy: 0.8573 - val_loss: 0.6762 - val_accuracy: 0.8449\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6332 - accuracy: 0.8621 - val_loss: 0.6637 - val_accuracy: 0.8480\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6147 - accuracy: 0.8656 - val_loss: 0.6443 - val_accuracy: 0.8539\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5997 - accuracy: 0.8684 - val_loss: 0.6344 - val_accuracy: 0.8543\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5861 - accuracy: 0.8710 - val_loss: 0.6254 - val_accuracy: 0.8543\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5746 - accuracy: 0.8735 - val_loss: 0.6154 - val_accuracy: 0.8582\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5652 - accuracy: 0.8752 - val_loss: 0.6060 - val_accuracy: 0.8598\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5562 - accuracy: 0.8776 - val_loss: 0.5992 - val_accuracy: 0.8624\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5488 - accuracy: 0.8785 - val_loss: 0.5974 - val_accuracy: 0.8634\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5419 - accuracy: 0.8803 - val_loss: 0.5907 - val_accuracy: 0.8647\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5358 - accuracy: 0.8830 - val_loss: 0.5887 - val_accuracy: 0.8641\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5309 - accuracy: 0.8825 - val_loss: 0.5827 - val_accuracy: 0.8650\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5260 - accuracy: 0.8842 - val_loss: 0.5804 - val_accuracy: 0.8647\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5219 - accuracy: 0.8847 - val_loss: 0.5749 - val_accuracy: 0.8657\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:41.651024\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5168 - accuracy: 0.8866 - val_loss: 0.5731 - val_accuracy: 0.8664\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5138 - accuracy: 0.8877 - val_loss: 0.5714 - val_accuracy: 0.8666\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5122 - accuracy: 0.8877 - val_loss: 0.5710 - val_accuracy: 0.8671\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5115 - accuracy: 0.8877 - val_loss: 0.5705 - val_accuracy: 0.8675\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5111 - accuracy: 0.8885 - val_loss: 0.5704 - val_accuracy: 0.8675\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5112 - accuracy: 0.8887 - val_loss: 0.5703 - val_accuracy: 0.8673\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5105 - accuracy: 0.8884 - val_loss: 0.5703 - val_accuracy: 0.8674\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:02.991131\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.8274 - accuracy: 0.6080 - val_loss: 1.2481 - val_accuracy: 0.7343\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0640 - accuracy: 0.7731 - val_loss: 0.9582 - val_accuracy: 0.7971\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8750 - accuracy: 0.8134 - val_loss: 0.8270 - val_accuracy: 0.8191\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7840 - accuracy: 0.8309 - val_loss: 0.7751 - val_accuracy: 0.8289\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7283 - accuracy: 0.8425 - val_loss: 0.7265 - val_accuracy: 0.8417\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6885 - accuracy: 0.8501 - val_loss: 0.6943 - val_accuracy: 0.8460\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6592 - accuracy: 0.8574 - val_loss: 0.6754 - val_accuracy: 0.8487\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6362 - accuracy: 0.8611 - val_loss: 0.6521 - val_accuracy: 0.8535\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6173 - accuracy: 0.8647 - val_loss: 0.6431 - val_accuracy: 0.8550\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6018 - accuracy: 0.8681 - val_loss: 0.6299 - val_accuracy: 0.8560\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5888 - accuracy: 0.8709 - val_loss: 0.6223 - val_accuracy: 0.8568\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5774 - accuracy: 0.8736 - val_loss: 0.6075 - val_accuracy: 0.8603\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5674 - accuracy: 0.8754 - val_loss: 0.6034 - val_accuracy: 0.8619\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5590 - accuracy: 0.8773 - val_loss: 0.6023 - val_accuracy: 0.8597\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5508 - accuracy: 0.8795 - val_loss: 0.5931 - val_accuracy: 0.8633\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5444 - accuracy: 0.8807 - val_loss: 0.5906 - val_accuracy: 0.8633\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5385 - accuracy: 0.8825 - val_loss: 0.5816 - val_accuracy: 0.8651\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5338 - accuracy: 0.8824 - val_loss: 0.5778 - val_accuracy: 0.8669\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5278 - accuracy: 0.8846 - val_loss: 0.5781 - val_accuracy: 0.8668\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5238 - accuracy: 0.8847 - val_loss: 0.5717 - val_accuracy: 0.8672\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:44.523492\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5185 - accuracy: 0.8868 - val_loss: 0.5690 - val_accuracy: 0.8677\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5160 - accuracy: 0.8880 - val_loss: 0.5666 - val_accuracy: 0.8680\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5140 - accuracy: 0.8881 - val_loss: 0.5660 - val_accuracy: 0.8679\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5130 - accuracy: 0.8892 - val_loss: 0.5660 - val_accuracy: 0.8680\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5128 - accuracy: 0.8886 - val_loss: 0.5661 - val_accuracy: 0.8683\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5130 - accuracy: 0.8890 - val_loss: 0.5660 - val_accuracy: 0.8683\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5123 - accuracy: 0.8890 - val_loss: 0.5660 - val_accuracy: 0.8683\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5127 - accuracy: 0.8893 - val_loss: 0.5659 - val_accuracy: 0.8681\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:28.575961\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.7716 - accuracy: 0.6170 - val_loss: 1.2248 - val_accuracy: 0.7438\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0366 - accuracy: 0.7802 - val_loss: 0.9379 - val_accuracy: 0.7966\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8612 - accuracy: 0.8170 - val_loss: 0.8371 - val_accuracy: 0.8193\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7742 - accuracy: 0.8346 - val_loss: 0.7703 - val_accuracy: 0.8301\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7201 - accuracy: 0.8449 - val_loss: 0.7338 - val_accuracy: 0.8375\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6807 - accuracy: 0.8522 - val_loss: 0.7060 - val_accuracy: 0.8436\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6520 - accuracy: 0.8580 - val_loss: 0.6789 - val_accuracy: 0.8491\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6292 - accuracy: 0.8626 - val_loss: 0.6568 - val_accuracy: 0.8520\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6105 - accuracy: 0.8658 - val_loss: 0.6462 - val_accuracy: 0.8566\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5958 - accuracy: 0.8695 - val_loss: 0.6352 - val_accuracy: 0.8585\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5831 - accuracy: 0.8721 - val_loss: 0.6314 - val_accuracy: 0.8565\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5716 - accuracy: 0.8736 - val_loss: 0.6180 - val_accuracy: 0.8607\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5623 - accuracy: 0.8761 - val_loss: 0.6100 - val_accuracy: 0.8598\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5539 - accuracy: 0.8781 - val_loss: 0.6051 - val_accuracy: 0.8611\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5468 - accuracy: 0.8802 - val_loss: 0.5994 - val_accuracy: 0.8637\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5398 - accuracy: 0.8812 - val_loss: 0.5954 - val_accuracy: 0.8642\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5337 - accuracy: 0.8814 - val_loss: 0.5875 - val_accuracy: 0.8643\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5288 - accuracy: 0.8836 - val_loss: 0.5885 - val_accuracy: 0.8662\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5236 - accuracy: 0.8845 - val_loss: 0.5830 - val_accuracy: 0.8653\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5196 - accuracy: 0.8857 - val_loss: 0.5807 - val_accuracy: 0.8659\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:41.362708\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5148 - accuracy: 0.8867 - val_loss: 0.5758 - val_accuracy: 0.8670\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5115 - accuracy: 0.8881 - val_loss: 0.5758 - val_accuracy: 0.8671\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5103 - accuracy: 0.8886 - val_loss: 0.5747 - val_accuracy: 0.8675\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5092 - accuracy: 0.8885 - val_loss: 0.5749 - val_accuracy: 0.8675\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5083 - accuracy: 0.8893 - val_loss: 0.5745 - val_accuracy: 0.8673\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5088 - accuracy: 0.8893 - val_loss: 0.5746 - val_accuracy: 0.8674\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:38.519247\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.8570 - accuracy: 0.5980 - val_loss: 1.3270 - val_accuracy: 0.7161\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1225 - accuracy: 0.7602 - val_loss: 0.9988 - val_accuracy: 0.7735\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9125 - accuracy: 0.8042 - val_loss: 0.8698 - val_accuracy: 0.8081\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8093 - accuracy: 0.8239 - val_loss: 0.7884 - val_accuracy: 0.8198\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7474 - accuracy: 0.8364 - val_loss: 0.7425 - val_accuracy: 0.8341\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7041 - accuracy: 0.8452 - val_loss: 0.7144 - val_accuracy: 0.8401\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6717 - accuracy: 0.8522 - val_loss: 0.6853 - val_accuracy: 0.8480\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6490 - accuracy: 0.8580 - val_loss: 0.6656 - val_accuracy: 0.8466\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6286 - accuracy: 0.8616 - val_loss: 0.6512 - val_accuracy: 0.8521\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6132 - accuracy: 0.8655 - val_loss: 0.6489 - val_accuracy: 0.8496\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5989 - accuracy: 0.8689 - val_loss: 0.6349 - val_accuracy: 0.8514\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5874 - accuracy: 0.8701 - val_loss: 0.6166 - val_accuracy: 0.8557\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5776 - accuracy: 0.8724 - val_loss: 0.6112 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5693 - accuracy: 0.8748 - val_loss: 0.6054 - val_accuracy: 0.8599\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5609 - accuracy: 0.8759 - val_loss: 0.6011 - val_accuracy: 0.8609\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5544 - accuracy: 0.8777 - val_loss: 0.5924 - val_accuracy: 0.8618\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5486 - accuracy: 0.8785 - val_loss: 0.5890 - val_accuracy: 0.8630\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5429 - accuracy: 0.8795 - val_loss: 0.5847 - val_accuracy: 0.8629\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5389 - accuracy: 0.8804 - val_loss: 0.5795 - val_accuracy: 0.8620\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5340 - accuracy: 0.8825 - val_loss: 0.5791 - val_accuracy: 0.8629\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:42.073543\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5411 - accuracy: 0.8812 - val_loss: 0.5831 - val_accuracy: 0.8630\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5369 - accuracy: 0.8817 - val_loss: 0.5807 - val_accuracy: 0.8643\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5354 - accuracy: 0.8833 - val_loss: 0.5801 - val_accuracy: 0.8630\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5352 - accuracy: 0.8832 - val_loss: 0.5796 - val_accuracy: 0.8635\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5342 - accuracy: 0.8834 - val_loss: 0.5798 - val_accuracy: 0.8636\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:12.130634\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.8104 - accuracy: 0.6118 - val_loss: 1.2723 - val_accuracy: 0.7304\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0648 - accuracy: 0.7755 - val_loss: 0.9479 - val_accuracy: 0.7980\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8743 - accuracy: 0.8139 - val_loss: 0.8335 - val_accuracy: 0.8168\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7836 - accuracy: 0.8328 - val_loss: 0.7772 - val_accuracy: 0.8274\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7276 - accuracy: 0.8429 - val_loss: 0.7274 - val_accuracy: 0.8344\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6874 - accuracy: 0.8509 - val_loss: 0.6983 - val_accuracy: 0.8422\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6570 - accuracy: 0.8573 - val_loss: 0.6729 - val_accuracy: 0.8470\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6341 - accuracy: 0.8625 - val_loss: 0.6632 - val_accuracy: 0.8513\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6163 - accuracy: 0.8649 - val_loss: 0.6496 - val_accuracy: 0.8520\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6006 - accuracy: 0.8680 - val_loss: 0.6415 - val_accuracy: 0.8514\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5875 - accuracy: 0.8711 - val_loss: 0.6253 - val_accuracy: 0.8579\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5763 - accuracy: 0.8740 - val_loss: 0.6179 - val_accuracy: 0.8554\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5658 - accuracy: 0.8759 - val_loss: 0.6062 - val_accuracy: 0.8595\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5581 - accuracy: 0.8776 - val_loss: 0.6028 - val_accuracy: 0.8597\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5499 - accuracy: 0.8795 - val_loss: 0.5959 - val_accuracy: 0.8616\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5442 - accuracy: 0.8810 - val_loss: 0.5907 - val_accuracy: 0.8628\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5372 - accuracy: 0.8822 - val_loss: 0.5894 - val_accuracy: 0.8634\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5321 - accuracy: 0.8837 - val_loss: 0.5851 - val_accuracy: 0.8636\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5279 - accuracy: 0.8843 - val_loss: 0.5798 - val_accuracy: 0.8629\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5227 - accuracy: 0.8858 - val_loss: 0.5768 - val_accuracy: 0.8639\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:41.261559\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5176 - accuracy: 0.8873 - val_loss: 0.5731 - val_accuracy: 0.8663\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5152 - accuracy: 0.8877 - val_loss: 0.5721 - val_accuracy: 0.8664\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5144 - accuracy: 0.8884 - val_loss: 0.5716 - val_accuracy: 0.8660\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5130 - accuracy: 0.8888 - val_loss: 0.5715 - val_accuracy: 0.8665\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5129 - accuracy: 0.8883 - val_loss: 0.5713 - val_accuracy: 0.8664\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5120 - accuracy: 0.8894 - val_loss: 0.5712 - val_accuracy: 0.8665\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5124 - accuracy: 0.8891 - val_loss: 0.5713 - val_accuracy: 0.8664\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:05.078662\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6713 - accuracy: 0.6288 - val_loss: 1.1939 - val_accuracy: 0.7351\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0416 - accuracy: 0.7741 - val_loss: 0.9583 - val_accuracy: 0.7875\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.8855 - accuracy: 0.8084 - val_loss: 0.8527 - val_accuracy: 0.8058\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8049 - accuracy: 0.8249 - val_loss: 0.7941 - val_accuracy: 0.8230\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7555 - accuracy: 0.8340 - val_loss: 0.7543 - val_accuracy: 0.8311\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7178 - accuracy: 0.8426 - val_loss: 0.7288 - val_accuracy: 0.8338\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6894 - accuracy: 0.8486 - val_loss: 0.7063 - val_accuracy: 0.8385\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6676 - accuracy: 0.8534 - val_loss: 0.6924 - val_accuracy: 0.8426\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6500 - accuracy: 0.8577 - val_loss: 0.6789 - val_accuracy: 0.8423\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.6357 - accuracy: 0.8590 - val_loss: 0.6655 - val_accuracy: 0.8469\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6228 - accuracy: 0.8621 - val_loss: 0.6595 - val_accuracy: 0.8498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6121 - accuracy: 0.8648 - val_loss: 0.6465 - val_accuracy: 0.8493\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.6030 - accuracy: 0.8664 - val_loss: 0.6404 - val_accuracy: 0.8505\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5944 - accuracy: 0.8679 - val_loss: 0.6385 - val_accuracy: 0.8517\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5873 - accuracy: 0.8700 - val_loss: 0.6278 - val_accuracy: 0.8525\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5807 - accuracy: 0.8713 - val_loss: 0.6240 - val_accuracy: 0.8543\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5748 - accuracy: 0.8722 - val_loss: 0.6213 - val_accuracy: 0.8545\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5703 - accuracy: 0.8734 - val_loss: 0.6179 - val_accuracy: 0.8556\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5652 - accuracy: 0.8740 - val_loss: 0.6147 - val_accuracy: 0.8546\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5612 - accuracy: 0.8751 - val_loss: 0.6117 - val_accuracy: 0.8553\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:55.329447\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5567 - accuracy: 0.8762 - val_loss: 0.6083 - val_accuracy: 0.8565\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5545 - accuracy: 0.8771 - val_loss: 0.6069 - val_accuracy: 0.8579\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5526 - accuracy: 0.8776 - val_loss: 0.6063 - val_accuracy: 0.8573\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5511 - accuracy: 0.8782 - val_loss: 0.6063 - val_accuracy: 0.8574\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5517 - accuracy: 0.8775 - val_loss: 0.6062 - val_accuracy: 0.8576\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:18.418728\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6998 - accuracy: 0.6234 - val_loss: 1.2030 - val_accuracy: 0.7365\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0405 - accuracy: 0.7725 - val_loss: 0.9284 - val_accuracy: 0.7997\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8781 - accuracy: 0.8089 - val_loss: 0.8308 - val_accuracy: 0.8184\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7977 - accuracy: 0.8255 - val_loss: 0.7826 - val_accuracy: 0.8272\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7479 - accuracy: 0.8364 - val_loss: 0.7415 - val_accuracy: 0.8367\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7101 - accuracy: 0.8440 - val_loss: 0.7187 - val_accuracy: 0.8380\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6836 - accuracy: 0.8495 - val_loss: 0.6934 - val_accuracy: 0.8433\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6618 - accuracy: 0.8541 - val_loss: 0.6831 - val_accuracy: 0.8448\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6447 - accuracy: 0.8571 - val_loss: 0.6639 - val_accuracy: 0.8490\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6301 - accuracy: 0.8607 - val_loss: 0.6564 - val_accuracy: 0.8496\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6174 - accuracy: 0.8632 - val_loss: 0.6464 - val_accuracy: 0.8504\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6074 - accuracy: 0.8650 - val_loss: 0.6394 - val_accuracy: 0.8532\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5971 - accuracy: 0.8673 - val_loss: 0.6295 - val_accuracy: 0.8548\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5899 - accuracy: 0.8688 - val_loss: 0.6251 - val_accuracy: 0.8565\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5826 - accuracy: 0.8703 - val_loss: 0.6202 - val_accuracy: 0.8562\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5766 - accuracy: 0.8715 - val_loss: 0.6170 - val_accuracy: 0.8563\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5710 - accuracy: 0.8729 - val_loss: 0.6117 - val_accuracy: 0.8586\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5657 - accuracy: 0.8744 - val_loss: 0.6086 - val_accuracy: 0.8579\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5612 - accuracy: 0.8751 - val_loss: 0.6043 - val_accuracy: 0.8592\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5574 - accuracy: 0.8753 - val_loss: 0.6031 - val_accuracy: 0.8575\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:54.637066\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5517 - accuracy: 0.8780 - val_loss: 0.5983 - val_accuracy: 0.8601\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5493 - accuracy: 0.8785 - val_loss: 0.5976 - val_accuracy: 0.8596\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5482 - accuracy: 0.8790 - val_loss: 0.5977 - val_accuracy: 0.8607\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5471 - accuracy: 0.8787 - val_loss: 0.5969 - val_accuracy: 0.8603\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5473 - accuracy: 0.8794 - val_loss: 0.5968 - val_accuracy: 0.8601\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5469 - accuracy: 0.8800 - val_loss: 0.5968 - val_accuracy: 0.8602\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:42.848431\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6532 - accuracy: 0.6324 - val_loss: 1.1774 - val_accuracy: 0.7414\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0204 - accuracy: 0.7787 - val_loss: 0.9242 - val_accuracy: 0.8002\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8678 - accuracy: 0.8111 - val_loss: 0.8488 - val_accuracy: 0.8137\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7913 - accuracy: 0.8281 - val_loss: 0.7792 - val_accuracy: 0.8293\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7419 - accuracy: 0.8391 - val_loss: 0.7503 - val_accuracy: 0.8329\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7066 - accuracy: 0.8458 - val_loss: 0.7126 - val_accuracy: 0.8417\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6801 - accuracy: 0.8503 - val_loss: 0.6956 - val_accuracy: 0.8441\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6584 - accuracy: 0.8550 - val_loss: 0.6788 - val_accuracy: 0.8453\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6416 - accuracy: 0.8597 - val_loss: 0.6666 - val_accuracy: 0.8476\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6268 - accuracy: 0.8609 - val_loss: 0.6532 - val_accuracy: 0.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6156 - accuracy: 0.8636 - val_loss: 0.6473 - val_accuracy: 0.8506\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6044 - accuracy: 0.8658 - val_loss: 0.6422 - val_accuracy: 0.8512\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5961 - accuracy: 0.8671 - val_loss: 0.6342 - val_accuracy: 0.8513\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5869 - accuracy: 0.8690 - val_loss: 0.6269 - val_accuracy: 0.8535\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5814 - accuracy: 0.8704 - val_loss: 0.6247 - val_accuracy: 0.8534\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5748 - accuracy: 0.8723 - val_loss: 0.6189 - val_accuracy: 0.8543\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5689 - accuracy: 0.8732 - val_loss: 0.6147 - val_accuracy: 0.8551\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5635 - accuracy: 0.8742 - val_loss: 0.6104 - val_accuracy: 0.8555\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5594 - accuracy: 0.8749 - val_loss: 0.6082 - val_accuracy: 0.8573\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5556 - accuracy: 0.8754 - val_loss: 0.6054 - val_accuracy: 0.8558\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:59.065288\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5508 - accuracy: 0.8775 - val_loss: 0.6027 - val_accuracy: 0.8574\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5479 - accuracy: 0.8783 - val_loss: 0.6015 - val_accuracy: 0.8567\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5462 - accuracy: 0.8791 - val_loss: 0.6009 - val_accuracy: 0.8576\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5458 - accuracy: 0.8792 - val_loss: 0.6005 - val_accuracy: 0.8579\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5453 - accuracy: 0.8790 - val_loss: 0.6004 - val_accuracy: 0.8580\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5449 - accuracy: 0.8795 - val_loss: 0.6003 - val_accuracy: 0.8578\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5449 - accuracy: 0.8794 - val_loss: 0.6004 - val_accuracy: 0.8582\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5448 - accuracy: 0.8794 - val_loss: 0.6004 - val_accuracy: 0.8583\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5452 - accuracy: 0.8794 - val_loss: 0.6006 - val_accuracy: 0.8580\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5442 - accuracy: 0.8796 - val_loss: 0.6006 - val_accuracy: 0.8585\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5448 - accuracy: 0.8800 - val_loss: 0.6004 - val_accuracy: 0.8578\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5449 - accuracy: 0.8792 - val_loss: 0.6004 - val_accuracy: 0.8579\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5451 - accuracy: 0.8798 - val_loss: 0.6005 - val_accuracy: 0.8581\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:55.822534\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6939 - accuracy: 0.6209 - val_loss: 1.2089 - val_accuracy: 0.7317\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0523 - accuracy: 0.7698 - val_loss: 0.9456 - val_accuracy: 0.7896\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8864 - accuracy: 0.8061 - val_loss: 0.8505 - val_accuracy: 0.8119\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8042 - accuracy: 0.8231 - val_loss: 0.8037 - val_accuracy: 0.8174\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7506 - accuracy: 0.8350 - val_loss: 0.7499 - val_accuracy: 0.8298\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7131 - accuracy: 0.8426 - val_loss: 0.7189 - val_accuracy: 0.8371\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6848 - accuracy: 0.8494 - val_loss: 0.7021 - val_accuracy: 0.8381\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6633 - accuracy: 0.8542 - val_loss: 0.6817 - val_accuracy: 0.8450\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6460 - accuracy: 0.8563 - val_loss: 0.6707 - val_accuracy: 0.8470\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6310 - accuracy: 0.8602 - val_loss: 0.6606 - val_accuracy: 0.8449\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6184 - accuracy: 0.8621 - val_loss: 0.6542 - val_accuracy: 0.8492\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6071 - accuracy: 0.8647 - val_loss: 0.6418 - val_accuracy: 0.8491\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5982 - accuracy: 0.8663 - val_loss: 0.6378 - val_accuracy: 0.8499\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5907 - accuracy: 0.8683 - val_loss: 0.6286 - val_accuracy: 0.8514\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5836 - accuracy: 0.8697 - val_loss: 0.6239 - val_accuracy: 0.8539\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5767 - accuracy: 0.8700 - val_loss: 0.6167 - val_accuracy: 0.8547\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5709 - accuracy: 0.8726 - val_loss: 0.6158 - val_accuracy: 0.8527\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5660 - accuracy: 0.8732 - val_loss: 0.6113 - val_accuracy: 0.8571\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5611 - accuracy: 0.8742 - val_loss: 0.6066 - val_accuracy: 0.8565\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5569 - accuracy: 0.8753 - val_loss: 0.6070 - val_accuracy: 0.8537\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:00.129461\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5517 - accuracy: 0.8769 - val_loss: 0.6016 - val_accuracy: 0.8579\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5491 - accuracy: 0.8784 - val_loss: 0.6001 - val_accuracy: 0.8574\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5472 - accuracy: 0.8780 - val_loss: 0.5995 - val_accuracy: 0.8573\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5468 - accuracy: 0.8785 - val_loss: 0.5992 - val_accuracy: 0.8577\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:47.271576\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6573 - accuracy: 0.6305 - val_loss: 1.1742 - val_accuracy: 0.7442\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0180 - accuracy: 0.7787 - val_loss: 0.9259 - val_accuracy: 0.7973\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8668 - accuracy: 0.8116 - val_loss: 0.8297 - val_accuracy: 0.8218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7912 - accuracy: 0.8272 - val_loss: 0.7773 - val_accuracy: 0.8315\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7423 - accuracy: 0.8369 - val_loss: 0.7395 - val_accuracy: 0.8357\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7070 - accuracy: 0.8442 - val_loss: 0.7183 - val_accuracy: 0.8397\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6810 - accuracy: 0.8492 - val_loss: 0.6920 - val_accuracy: 0.8452\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6578 - accuracy: 0.8542 - val_loss: 0.6776 - val_accuracy: 0.8482\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6414 - accuracy: 0.8584 - val_loss: 0.6701 - val_accuracy: 0.8489\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6273 - accuracy: 0.8601 - val_loss: 0.6601 - val_accuracy: 0.8498\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6146 - accuracy: 0.8632 - val_loss: 0.6509 - val_accuracy: 0.8508\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6044 - accuracy: 0.8647 - val_loss: 0.6407 - val_accuracy: 0.8535\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5945 - accuracy: 0.8678 - val_loss: 0.6363 - val_accuracy: 0.8540\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5861 - accuracy: 0.8693 - val_loss: 0.6316 - val_accuracy: 0.8525\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5790 - accuracy: 0.8711 - val_loss: 0.6253 - val_accuracy: 0.8539\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5733 - accuracy: 0.8712 - val_loss: 0.6199 - val_accuracy: 0.8565\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5679 - accuracy: 0.8732 - val_loss: 0.6170 - val_accuracy: 0.8571\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5614 - accuracy: 0.8741 - val_loss: 0.6145 - val_accuracy: 0.8568\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.5575 - accuracy: 0.8752 - val_loss: 0.6123 - val_accuracy: 0.8563\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5533 - accuracy: 0.8763 - val_loss: 0.6083 - val_accuracy: 0.8566\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:08.766882\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5604 - accuracy: 0.8749 - val_loss: 0.6134 - val_accuracy: 0.8579\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.5574 - accuracy: 0.8763 - val_loss: 0.6128 - val_accuracy: 0.8581\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5557 - accuracy: 0.8769 - val_loss: 0.6114 - val_accuracy: 0.8590\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5544 - accuracy: 0.8773 - val_loss: 0.6110 - val_accuracy: 0.8589\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5546 - accuracy: 0.8768 - val_loss: 0.6114 - val_accuracy: 0.8589\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5548 - accuracy: 0.8765 - val_loss: 0.6111 - val_accuracy: 0.8591\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5549 - accuracy: 0.8766 - val_loss: 0.6110 - val_accuracy: 0.8588\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5550 - accuracy: 0.8769 - val_loss: 0.6112 - val_accuracy: 0.8590\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5542 - accuracy: 0.8774 - val_loss: 0.6111 - val_accuracy: 0.8591\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5545 - accuracy: 0.8768 - val_loss: 0.6110 - val_accuracy: 0.8590\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5545 - accuracy: 0.8770 - val_loss: 0.6112 - val_accuracy: 0.8592\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 33s 47ms/step - loss: 0.5545 - accuracy: 0.8766 - val_loss: 0.6112 - val_accuracy: 0.8588\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5541 - accuracy: 0.8765 - val_loss: 0.6111 - val_accuracy: 0.8590\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5543 - accuracy: 0.8769 - val_loss: 0.6110 - val_accuracy: 0.8593\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5548 - accuracy: 0.8772 - val_loss: 0.6111 - val_accuracy: 0.8587\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5544 - accuracy: 0.8764 - val_loss: 0.6111 - val_accuracy: 0.8590\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5541 - accuracy: 0.8771 - val_loss: 0.6112 - val_accuracy: 0.8589\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:07:58.534541\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7403 - accuracy: 0.6111 - val_loss: 1.2218 - val_accuracy: 0.7403\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0391 - accuracy: 0.7753 - val_loss: 0.9485 - val_accuracy: 0.7950\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8685 - accuracy: 0.8117 - val_loss: 0.8295 - val_accuracy: 0.8184\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7849 - accuracy: 0.8298 - val_loss: 0.7795 - val_accuracy: 0.8249\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7325 - accuracy: 0.8404 - val_loss: 0.7420 - val_accuracy: 0.8324\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6957 - accuracy: 0.8476 - val_loss: 0.7060 - val_accuracy: 0.8410\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6670 - accuracy: 0.8539 - val_loss: 0.6890 - val_accuracy: 0.8417\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6452 - accuracy: 0.8580 - val_loss: 0.6664 - val_accuracy: 0.8492\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6264 - accuracy: 0.8634 - val_loss: 0.6592 - val_accuracy: 0.8472\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6122 - accuracy: 0.8657 - val_loss: 0.6455 - val_accuracy: 0.8529\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5999 - accuracy: 0.8675 - val_loss: 0.6304 - val_accuracy: 0.8546\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5877 - accuracy: 0.8713 - val_loss: 0.6269 - val_accuracy: 0.8544\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5787 - accuracy: 0.8730 - val_loss: 0.6214 - val_accuracy: 0.8526\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5706 - accuracy: 0.8745 - val_loss: 0.6137 - val_accuracy: 0.8569\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5637 - accuracy: 0.8760 - val_loss: 0.6099 - val_accuracy: 0.8556\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5567 - accuracy: 0.8773 - val_loss: 0.6014 - val_accuracy: 0.8597\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5512 - accuracy: 0.8782 - val_loss: 0.5970 - val_accuracy: 0.8602\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5454 - accuracy: 0.8802 - val_loss: 0.5963 - val_accuracy: 0.8621\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5405 - accuracy: 0.8813 - val_loss: 0.5913 - val_accuracy: 0.8605\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5369 - accuracy: 0.8816 - val_loss: 0.5887 - val_accuracy: 0.8613\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:31.032277\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5316 - accuracy: 0.8827 - val_loss: 0.5852 - val_accuracy: 0.8623\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5287 - accuracy: 0.8842 - val_loss: 0.5837 - val_accuracy: 0.8631\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5272 - accuracy: 0.8848 - val_loss: 0.5836 - val_accuracy: 0.8626\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5273 - accuracy: 0.8850 - val_loss: 0.5833 - val_accuracy: 0.8629\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5260 - accuracy: 0.8850 - val_loss: 0.5832 - val_accuracy: 0.8626\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:21.507492\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6648 - accuracy: 0.6341 - val_loss: 1.1153 - val_accuracy: 0.7610\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9886 - accuracy: 0.7860 - val_loss: 0.8824 - val_accuracy: 0.8052\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8424 - accuracy: 0.8180 - val_loss: 0.7916 - val_accuracy: 0.8254\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7676 - accuracy: 0.8334 - val_loss: 0.7489 - val_accuracy: 0.8324\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7199 - accuracy: 0.8425 - val_loss: 0.7110 - val_accuracy: 0.8387\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6843 - accuracy: 0.8508 - val_loss: 0.6805 - val_accuracy: 0.8461\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6571 - accuracy: 0.8561 - val_loss: 0.6704 - val_accuracy: 0.8473\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6364 - accuracy: 0.8604 - val_loss: 0.6485 - val_accuracy: 0.8516\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6189 - accuracy: 0.8639 - val_loss: 0.6385 - val_accuracy: 0.8535\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6040 - accuracy: 0.8667 - val_loss: 0.6268 - val_accuracy: 0.8549\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5920 - accuracy: 0.8692 - val_loss: 0.6095 - val_accuracy: 0.8593\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5815 - accuracy: 0.8712 - val_loss: 0.6040 - val_accuracy: 0.8582\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5716 - accuracy: 0.8734 - val_loss: 0.5977 - val_accuracy: 0.8598\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5641 - accuracy: 0.8754 - val_loss: 0.5964 - val_accuracy: 0.8594\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5567 - accuracy: 0.8771 - val_loss: 0.5866 - val_accuracy: 0.8629\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5503 - accuracy: 0.8782 - val_loss: 0.5820 - val_accuracy: 0.8638\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5448 - accuracy: 0.8797 - val_loss: 0.5819 - val_accuracy: 0.8628\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5398 - accuracy: 0.8809 - val_loss: 0.5765 - val_accuracy: 0.8637\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5354 - accuracy: 0.8815 - val_loss: 0.5738 - val_accuracy: 0.8658\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5309 - accuracy: 0.8818 - val_loss: 0.5713 - val_accuracy: 0.8640\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:26.543559\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5266 - accuracy: 0.8837 - val_loss: 0.5669 - val_accuracy: 0.8657\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5231 - accuracy: 0.8852 - val_loss: 0.5657 - val_accuracy: 0.8668\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5222 - accuracy: 0.8851 - val_loss: 0.5651 - val_accuracy: 0.8672\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5211 - accuracy: 0.8854 - val_loss: 0.5650 - val_accuracy: 0.8670\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5210 - accuracy: 0.8856 - val_loss: 0.5648 - val_accuracy: 0.8674\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5206 - accuracy: 0.8864 - val_loss: 0.5650 - val_accuracy: 0.8671\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5203 - accuracy: 0.8866 - val_loss: 0.5649 - val_accuracy: 0.8673\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5203 - accuracy: 0.8864 - val_loss: 0.5648 - val_accuracy: 0.8671\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:46.567959\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6999 - accuracy: 0.6279 - val_loss: 1.2057 - val_accuracy: 0.7414\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0267 - accuracy: 0.7790 - val_loss: 0.9217 - val_accuracy: 0.7983\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8611 - accuracy: 0.8154 - val_loss: 0.8227 - val_accuracy: 0.8210\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7804 - accuracy: 0.8309 - val_loss: 0.7712 - val_accuracy: 0.8294\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7311 - accuracy: 0.8404 - val_loss: 0.7455 - val_accuracy: 0.8327\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6933 - accuracy: 0.8477 - val_loss: 0.7131 - val_accuracy: 0.8395\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6664 - accuracy: 0.8529 - val_loss: 0.6803 - val_accuracy: 0.8487\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6448 - accuracy: 0.8577 - val_loss: 0.6652 - val_accuracy: 0.8505\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6268 - accuracy: 0.8624 - val_loss: 0.6565 - val_accuracy: 0.8522\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6109 - accuracy: 0.8658 - val_loss: 0.6382 - val_accuracy: 0.8549\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5988 - accuracy: 0.8682 - val_loss: 0.6275 - val_accuracy: 0.8586\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5883 - accuracy: 0.8708 - val_loss: 0.6245 - val_accuracy: 0.8574\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5788 - accuracy: 0.8721 - val_loss: 0.6153 - val_accuracy: 0.8602\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5695 - accuracy: 0.8749 - val_loss: 0.6059 - val_accuracy: 0.8611\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5621 - accuracy: 0.8765 - val_loss: 0.5988 - val_accuracy: 0.8631\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5549 - accuracy: 0.8776 - val_loss: 0.5956 - val_accuracy: 0.8618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5492 - accuracy: 0.8786 - val_loss: 0.5908 - val_accuracy: 0.8637\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5437 - accuracy: 0.8806 - val_loss: 0.5868 - val_accuracy: 0.8643\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5399 - accuracy: 0.8818 - val_loss: 0.5836 - val_accuracy: 0.8648\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5356 - accuracy: 0.8825 - val_loss: 0.5809 - val_accuracy: 0.8650\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:23.774775\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5307 - accuracy: 0.8833 - val_loss: 0.5788 - val_accuracy: 0.8652\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5278 - accuracy: 0.8845 - val_loss: 0.5766 - val_accuracy: 0.8670\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5255 - accuracy: 0.8849 - val_loss: 0.5763 - val_accuracy: 0.8668\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5253 - accuracy: 0.8854 - val_loss: 0.5759 - val_accuracy: 0.8669\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5243 - accuracy: 0.8858 - val_loss: 0.5759 - val_accuracy: 0.8665\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:21.330393\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7304 - accuracy: 0.6190 - val_loss: 1.2195 - val_accuracy: 0.7348\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0386 - accuracy: 0.7755 - val_loss: 0.9479 - val_accuracy: 0.7883\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8661 - accuracy: 0.8136 - val_loss: 0.8403 - val_accuracy: 0.8095\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7832 - accuracy: 0.8295 - val_loss: 0.7745 - val_accuracy: 0.8286\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7296 - accuracy: 0.8410 - val_loss: 0.7284 - val_accuracy: 0.8383\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6917 - accuracy: 0.8495 - val_loss: 0.7066 - val_accuracy: 0.8412\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6639 - accuracy: 0.8541 - val_loss: 0.6855 - val_accuracy: 0.8425\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6414 - accuracy: 0.8595 - val_loss: 0.6701 - val_accuracy: 0.8488\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6232 - accuracy: 0.8636 - val_loss: 0.6516 - val_accuracy: 0.8515\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6080 - accuracy: 0.8672 - val_loss: 0.6459 - val_accuracy: 0.8505\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5961 - accuracy: 0.8687 - val_loss: 0.6315 - val_accuracy: 0.8556\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5855 - accuracy: 0.8719 - val_loss: 0.6218 - val_accuracy: 0.8569\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5755 - accuracy: 0.8734 - val_loss: 0.6176 - val_accuracy: 0.8574\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5674 - accuracy: 0.8749 - val_loss: 0.6087 - val_accuracy: 0.8589\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5596 - accuracy: 0.8767 - val_loss: 0.6039 - val_accuracy: 0.8598\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5528 - accuracy: 0.8787 - val_loss: 0.6002 - val_accuracy: 0.8609\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5472 - accuracy: 0.8807 - val_loss: 0.5963 - val_accuracy: 0.8602\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5420 - accuracy: 0.8810 - val_loss: 0.5926 - val_accuracy: 0.8607\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5375 - accuracy: 0.8820 - val_loss: 0.5882 - val_accuracy: 0.8626\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5329 - accuracy: 0.8829 - val_loss: 0.5868 - val_accuracy: 0.8621\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:24.825474\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5282 - accuracy: 0.8844 - val_loss: 0.5826 - val_accuracy: 0.8639\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5245 - accuracy: 0.8855 - val_loss: 0.5809 - val_accuracy: 0.8643\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5240 - accuracy: 0.8861 - val_loss: 0.5806 - val_accuracy: 0.8645\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5228 - accuracy: 0.8860 - val_loss: 0.5805 - val_accuracy: 0.8647\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5224 - accuracy: 0.8861 - val_loss: 0.5805 - val_accuracy: 0.8648\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5225 - accuracy: 0.8862 - val_loss: 0.5803 - val_accuracy: 0.8654\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5223 - accuracy: 0.8864 - val_loss: 0.5803 - val_accuracy: 0.8653\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5219 - accuracy: 0.8868 - val_loss: 0.5802 - val_accuracy: 0.8649\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5225 - accuracy: 0.8864 - val_loss: 0.5803 - val_accuracy: 0.8648\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:13.840259\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7559 - accuracy: 0.6086 - val_loss: 1.2608 - val_accuracy: 0.7220\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0590 - accuracy: 0.7706 - val_loss: 0.9560 - val_accuracy: 0.7877\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8762 - accuracy: 0.8096 - val_loss: 0.8482 - val_accuracy: 0.8123\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7882 - accuracy: 0.8287 - val_loss: 0.7974 - val_accuracy: 0.8230\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7337 - accuracy: 0.8404 - val_loss: 0.7439 - val_accuracy: 0.8343\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6946 - accuracy: 0.8483 - val_loss: 0.7263 - val_accuracy: 0.8334\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6672 - accuracy: 0.8549 - val_loss: 0.6907 - val_accuracy: 0.8442\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6448 - accuracy: 0.8578 - val_loss: 0.6826 - val_accuracy: 0.8434\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6268 - accuracy: 0.8626 - val_loss: 0.6621 - val_accuracy: 0.8483\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6117 - accuracy: 0.8653 - val_loss: 0.6506 - val_accuracy: 0.8510\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5988 - accuracy: 0.8681 - val_loss: 0.6351 - val_accuracy: 0.8556\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5884 - accuracy: 0.8709 - val_loss: 0.6359 - val_accuracy: 0.8547\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5790 - accuracy: 0.8727 - val_loss: 0.6277 - val_accuracy: 0.8543\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5704 - accuracy: 0.8745 - val_loss: 0.6210 - val_accuracy: 0.8549\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:35.387243\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5859 - accuracy: 0.8724 - val_loss: 0.6301 - val_accuracy: 0.8570\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5800 - accuracy: 0.8745 - val_loss: 0.6255 - val_accuracy: 0.8587\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5769 - accuracy: 0.8751 - val_loss: 0.6235 - val_accuracy: 0.8594\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5751 - accuracy: 0.8760 - val_loss: 0.6232 - val_accuracy: 0.8599\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5751 - accuracy: 0.8760 - val_loss: 0.6232 - val_accuracy: 0.8596\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5748 - accuracy: 0.8757 - val_loss: 0.6232 - val_accuracy: 0.8595\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5747 - accuracy: 0.8757 - val_loss: 0.6230 - val_accuracy: 0.8594\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:17.559541\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.1123 - accuracy: 0.1944 - val_loss: 1.6636 - val_accuracy: 0.5462\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.5948 - accuracy: 0.5377 - val_loss: 1.1626 - val_accuracy: 0.6633\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2474 - accuracy: 0.6296 - val_loss: 0.9508 - val_accuracy: 0.7142\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0489 - accuracy: 0.6826 - val_loss: 0.8156 - val_accuracy: 0.7476\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9162 - accuracy: 0.7153 - val_loss: 0.7101 - val_accuracy: 0.7771\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8249 - accuracy: 0.7422 - val_loss: 0.6565 - val_accuracy: 0.7919\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7645 - accuracy: 0.7576 - val_loss: 0.6200 - val_accuracy: 0.8002\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7198 - accuracy: 0.7707 - val_loss: 0.5902 - val_accuracy: 0.8100\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6862 - accuracy: 0.7803 - val_loss: 0.5678 - val_accuracy: 0.8157\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6602 - accuracy: 0.7882 - val_loss: 0.5502 - val_accuracy: 0.8203\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6392 - accuracy: 0.7947 - val_loss: 0.5369 - val_accuracy: 0.8237\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6242 - accuracy: 0.7991 - val_loss: 0.5288 - val_accuracy: 0.8240\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6100 - accuracy: 0.8027 - val_loss: 0.5184 - val_accuracy: 0.8300\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5966 - accuracy: 0.8061 - val_loss: 0.5100 - val_accuracy: 0.8310\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5887 - accuracy: 0.8086 - val_loss: 0.5028 - val_accuracy: 0.8336\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5806 - accuracy: 0.8123 - val_loss: 0.5030 - val_accuracy: 0.8336\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5743 - accuracy: 0.8127 - val_loss: 0.4962 - val_accuracy: 0.8360\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5662 - accuracy: 0.8149 - val_loss: 0.4934 - val_accuracy: 0.8365\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5624 - accuracy: 0.8167 - val_loss: 0.4890 - val_accuracy: 0.8365\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5566 - accuracy: 0.8180 - val_loss: 0.4864 - val_accuracy: 0.8373\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:41.634530\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5491 - accuracy: 0.8190 - val_loss: 0.4820 - val_accuracy: 0.8402\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5444 - accuracy: 0.8228 - val_loss: 0.4810 - val_accuracy: 0.8401\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5436 - accuracy: 0.8220 - val_loss: 0.4801 - val_accuracy: 0.8409\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5447 - accuracy: 0.8214 - val_loss: 0.4801 - val_accuracy: 0.8410\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5436 - accuracy: 0.8221 - val_loss: 0.4799 - val_accuracy: 0.8410\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5435 - accuracy: 0.8228 - val_loss: 0.4798 - val_accuracy: 0.8412\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5408 - accuracy: 0.8231 - val_loss: 0.4798 - val_accuracy: 0.8411\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5428 - accuracy: 0.8221 - val_loss: 0.4798 - val_accuracy: 0.8411\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5418 - accuracy: 0.8222 - val_loss: 0.4798 - val_accuracy: 0.8411\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:56.909999\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.3964 - accuracy: 0.1447 - val_loss: 1.9943 - val_accuracy: 0.4770\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 1.7148 - accuracy: 0.5110 - val_loss: 1.2012 - val_accuracy: 0.6555\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 1.2749 - accuracy: 0.6242 - val_loss: 0.9819 - val_accuracy: 0.7118\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0572 - accuracy: 0.6821 - val_loss: 0.8261 - val_accuracy: 0.7483\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9201 - accuracy: 0.7184 - val_loss: 0.7320 - val_accuracy: 0.7739\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8224 - accuracy: 0.7443 - val_loss: 0.6593 - val_accuracy: 0.7963\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7590 - accuracy: 0.7617 - val_loss: 0.6239 - val_accuracy: 0.8039\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7160 - accuracy: 0.7731 - val_loss: 0.5969 - val_accuracy: 0.8101\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6878 - accuracy: 0.7810 - val_loss: 0.5757 - val_accuracy: 0.8136\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6616 - accuracy: 0.7876 - val_loss: 0.5547 - val_accuracy: 0.8207\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6428 - accuracy: 0.7931 - val_loss: 0.5446 - val_accuracy: 0.8236\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6254 - accuracy: 0.7986 - val_loss: 0.5326 - val_accuracy: 0.8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6122 - accuracy: 0.8017 - val_loss: 0.5246 - val_accuracy: 0.8277\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5985 - accuracy: 0.8050 - val_loss: 0.5167 - val_accuracy: 0.8286\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5888 - accuracy: 0.8089 - val_loss: 0.5086 - val_accuracy: 0.8335\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5819 - accuracy: 0.8085 - val_loss: 0.5017 - val_accuracy: 0.8332\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5772 - accuracy: 0.8116 - val_loss: 0.4983 - val_accuracy: 0.8365\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5688 - accuracy: 0.8147 - val_loss: 0.4936 - val_accuracy: 0.8368\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5617 - accuracy: 0.8156 - val_loss: 0.4920 - val_accuracy: 0.8381\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5588 - accuracy: 0.8162 - val_loss: 0.4869 - val_accuracy: 0.8389\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:37.634873\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5529 - accuracy: 0.8201 - val_loss: 0.4850 - val_accuracy: 0.8394\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5493 - accuracy: 0.8207 - val_loss: 0.4840 - val_accuracy: 0.8402\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5437 - accuracy: 0.8210 - val_loss: 0.4830 - val_accuracy: 0.8405\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5468 - accuracy: 0.8225 - val_loss: 0.4828 - val_accuracy: 0.8405\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5453 - accuracy: 0.8210 - val_loss: 0.4826 - val_accuracy: 0.8406\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5470 - accuracy: 0.8209 - val_loss: 0.4825 - val_accuracy: 0.8403\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5461 - accuracy: 0.8203 - val_loss: 0.4825 - val_accuracy: 0.8404\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5454 - accuracy: 0.8208 - val_loss: 0.4825 - val_accuracy: 0.8403\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:27.405365\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.4143 - accuracy: 0.1327 - val_loss: 1.9672 - val_accuracy: 0.4961\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.7261 - accuracy: 0.5064 - val_loss: 1.2375 - val_accuracy: 0.6455\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2969 - accuracy: 0.6189 - val_loss: 1.0036 - val_accuracy: 0.7052\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0862 - accuracy: 0.6719 - val_loss: 0.8631 - val_accuracy: 0.7398\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9390 - accuracy: 0.7121 - val_loss: 0.7431 - val_accuracy: 0.7693\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8348 - accuracy: 0.7401 - val_loss: 0.6760 - val_accuracy: 0.7872\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7687 - accuracy: 0.7566 - val_loss: 0.6357 - val_accuracy: 0.7977\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7190 - accuracy: 0.7730 - val_loss: 0.6050 - val_accuracy: 0.8046\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6860 - accuracy: 0.7801 - val_loss: 0.5857 - val_accuracy: 0.8109\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6601 - accuracy: 0.7877 - val_loss: 0.5665 - val_accuracy: 0.8189\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6425 - accuracy: 0.7947 - val_loss: 0.5534 - val_accuracy: 0.8196\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6247 - accuracy: 0.7981 - val_loss: 0.5395 - val_accuracy: 0.8237\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6111 - accuracy: 0.8022 - val_loss: 0.5327 - val_accuracy: 0.8254\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5956 - accuracy: 0.8066 - val_loss: 0.5259 - val_accuracy: 0.8277\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5896 - accuracy: 0.8080 - val_loss: 0.5184 - val_accuracy: 0.8325\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5795 - accuracy: 0.8122 - val_loss: 0.5159 - val_accuracy: 0.8316\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5711 - accuracy: 0.8141 - val_loss: 0.5073 - val_accuracy: 0.8331\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5696 - accuracy: 0.8132 - val_loss: 0.5044 - val_accuracy: 0.8350\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5600 - accuracy: 0.8177 - val_loss: 0.4999 - val_accuracy: 0.8361\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5555 - accuracy: 0.8186 - val_loss: 0.4972 - val_accuracy: 0.8366\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:39.318690\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5496 - accuracy: 0.8203 - val_loss: 0.4949 - val_accuracy: 0.8382\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5458 - accuracy: 0.8210 - val_loss: 0.4934 - val_accuracy: 0.8385\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5442 - accuracy: 0.8229 - val_loss: 0.4924 - val_accuracy: 0.8389\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5427 - accuracy: 0.8220 - val_loss: 0.4921 - val_accuracy: 0.8384\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5402 - accuracy: 0.8228 - val_loss: 0.4919 - val_accuracy: 0.8389\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5429 - accuracy: 0.8222 - val_loss: 0.4919 - val_accuracy: 0.8387\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:36.094706\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.3604 - accuracy: 0.1567 - val_loss: 1.9867 - val_accuracy: 0.4726\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6957 - accuracy: 0.5153 - val_loss: 1.2350 - val_accuracy: 0.6466\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2711 - accuracy: 0.6241 - val_loss: 0.9997 - val_accuracy: 0.7056\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 1.0598 - accuracy: 0.6810 - val_loss: 0.8389 - val_accuracy: 0.7453\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9265 - accuracy: 0.7153 - val_loss: 0.7574 - val_accuracy: 0.7644\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8294 - accuracy: 0.7427 - val_loss: 0.7008 - val_accuracy: 0.7754\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7685 - accuracy: 0.7590 - val_loss: 0.6531 - val_accuracy: 0.7952\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7209 - accuracy: 0.7717 - val_loss: 0.6235 - val_accuracy: 0.8022\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6897 - accuracy: 0.7798 - val_loss: 0.5876 - val_accuracy: 0.8094\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6655 - accuracy: 0.7870 - val_loss: 0.5753 - val_accuracy: 0.8139\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6461 - accuracy: 0.7916 - val_loss: 0.5624 - val_accuracy: 0.8195\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6262 - accuracy: 0.7982 - val_loss: 0.5481 - val_accuracy: 0.8213\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6144 - accuracy: 0.8017 - val_loss: 0.5386 - val_accuracy: 0.8247\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6032 - accuracy: 0.8041 - val_loss: 0.5320 - val_accuracy: 0.8264\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5943 - accuracy: 0.8065 - val_loss: 0.5280 - val_accuracy: 0.8274\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5856 - accuracy: 0.8089 - val_loss: 0.5190 - val_accuracy: 0.8282\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5783 - accuracy: 0.8112 - val_loss: 0.5176 - val_accuracy: 0.8304\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5749 - accuracy: 0.8132 - val_loss: 0.5152 - val_accuracy: 0.8311\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5684 - accuracy: 0.8150 - val_loss: 0.5098 - val_accuracy: 0.8317\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5622 - accuracy: 0.8154 - val_loss: 0.5036 - val_accuracy: 0.8339\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:38.472272\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5565 - accuracy: 0.8181 - val_loss: 0.5019 - val_accuracy: 0.8354\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5502 - accuracy: 0.8194 - val_loss: 0.5007 - val_accuracy: 0.8355\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5505 - accuracy: 0.8199 - val_loss: 0.4999 - val_accuracy: 0.8353\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5485 - accuracy: 0.8208 - val_loss: 0.4997 - val_accuracy: 0.8359\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5467 - accuracy: 0.8207 - val_loss: 0.4995 - val_accuracy: 0.8355\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5502 - accuracy: 0.8196 - val_loss: 0.4994 - val_accuracy: 0.8355\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5475 - accuracy: 0.8194 - val_loss: 0.4994 - val_accuracy: 0.8355\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:01.309405\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.1895 - accuracy: 0.1842 - val_loss: 1.7536 - val_accuracy: 0.5330\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6240 - accuracy: 0.5326 - val_loss: 1.1975 - val_accuracy: 0.6542\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 1.2621 - accuracy: 0.6291 - val_loss: 0.9736 - val_accuracy: 0.7119\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0654 - accuracy: 0.6783 - val_loss: 0.8470 - val_accuracy: 0.7445\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.9323 - accuracy: 0.7142 - val_loss: 0.7457 - val_accuracy: 0.7646\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8391 - accuracy: 0.7395 - val_loss: 0.6792 - val_accuracy: 0.7877\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7735 - accuracy: 0.7573 - val_loss: 0.6395 - val_accuracy: 0.7947\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.7281 - accuracy: 0.7701 - val_loss: 0.6140 - val_accuracy: 0.8029\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6987 - accuracy: 0.7785 - val_loss: 0.5955 - val_accuracy: 0.8105\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.6708 - accuracy: 0.7861 - val_loss: 0.5716 - val_accuracy: 0.8180\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.6490 - accuracy: 0.7933 - val_loss: 0.5587 - val_accuracy: 0.8197\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6314 - accuracy: 0.7979 - val_loss: 0.5492 - val_accuracy: 0.8227\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6182 - accuracy: 0.8005 - val_loss: 0.5409 - val_accuracy: 0.8256\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.6056 - accuracy: 0.8045 - val_loss: 0.5272 - val_accuracy: 0.8296\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5971 - accuracy: 0.8077 - val_loss: 0.5248 - val_accuracy: 0.8309\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5857 - accuracy: 0.8110 - val_loss: 0.5185 - val_accuracy: 0.8325\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5840 - accuracy: 0.8107 - val_loss: 0.5141 - val_accuracy: 0.8333\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5748 - accuracy: 0.8138 - val_loss: 0.5115 - val_accuracy: 0.8327\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5692 - accuracy: 0.8132 - val_loss: 0.5064 - val_accuracy: 0.8348\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5622 - accuracy: 0.8171 - val_loss: 0.5025 - val_accuracy: 0.8372\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:36.188103\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5564 - accuracy: 0.8202 - val_loss: 0.4999 - val_accuracy: 0.8376\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5529 - accuracy: 0.8198 - val_loss: 0.4977 - val_accuracy: 0.8398\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5523 - accuracy: 0.8199 - val_loss: 0.4972 - val_accuracy: 0.8394\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5523 - accuracy: 0.8204 - val_loss: 0.4967 - val_accuracy: 0.8387\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 36ms/step - loss: 0.5505 - accuracy: 0.8215 - val_loss: 0.4964 - val_accuracy: 0.8391\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:10.551795\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 2.6891 - accuracy: 0.3106 - val_loss: 1.4420 - val_accuracy: 0.6033\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3888 - accuracy: 0.5983 - val_loss: 1.0656 - val_accuracy: 0.6899\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1051 - accuracy: 0.6720 - val_loss: 0.8784 - val_accuracy: 0.7379\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9378 - accuracy: 0.7148 - val_loss: 0.7591 - val_accuracy: 0.7676\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8226 - accuracy: 0.7450 - val_loss: 0.6753 - val_accuracy: 0.7863\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7451 - accuracy: 0.7651 - val_loss: 0.6242 - val_accuracy: 0.8001\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6918 - accuracy: 0.7794 - val_loss: 0.5896 - val_accuracy: 0.8102\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6516 - accuracy: 0.7905 - val_loss: 0.5629 - val_accuracy: 0.8201\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6243 - accuracy: 0.7982 - val_loss: 0.5430 - val_accuracy: 0.8239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6016 - accuracy: 0.8052 - val_loss: 0.5269 - val_accuracy: 0.8280\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5869 - accuracy: 0.8086 - val_loss: 0.5176 - val_accuracy: 0.8309\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5676 - accuracy: 0.8142 - val_loss: 0.5048 - val_accuracy: 0.8355\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5586 - accuracy: 0.8175 - val_loss: 0.5010 - val_accuracy: 0.8355\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5466 - accuracy: 0.8213 - val_loss: 0.4910 - val_accuracy: 0.8384\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5389 - accuracy: 0.8233 - val_loss: 0.4872 - val_accuracy: 0.8394\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5336 - accuracy: 0.8247 - val_loss: 0.4808 - val_accuracy: 0.8412\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5282 - accuracy: 0.8255 - val_loss: 0.4766 - val_accuracy: 0.8430\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5184 - accuracy: 0.8301 - val_loss: 0.4714 - val_accuracy: 0.8458\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5129 - accuracy: 0.8303 - val_loss: 0.4699 - val_accuracy: 0.8434\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5108 - accuracy: 0.8306 - val_loss: 0.4675 - val_accuracy: 0.8452\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:46.780652\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5041 - accuracy: 0.8333 - val_loss: 0.4639 - val_accuracy: 0.8453\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5011 - accuracy: 0.8348 - val_loss: 0.4616 - val_accuracy: 0.8465\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5001 - accuracy: 0.8336 - val_loss: 0.4610 - val_accuracy: 0.8469\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4989 - accuracy: 0.8337 - val_loss: 0.4609 - val_accuracy: 0.8469\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4991 - accuracy: 0.8356 - val_loss: 0.4608 - val_accuracy: 0.8469\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4976 - accuracy: 0.8346 - val_loss: 0.4608 - val_accuracy: 0.8468\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:42.845855\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.8756 - accuracy: 0.2613 - val_loss: 1.5258 - val_accuracy: 0.5852\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4455 - accuracy: 0.5817 - val_loss: 1.1187 - val_accuracy: 0.6770\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1452 - accuracy: 0.6585 - val_loss: 0.8995 - val_accuracy: 0.7315\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9609 - accuracy: 0.7069 - val_loss: 0.7684 - val_accuracy: 0.7663\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8346 - accuracy: 0.7420 - val_loss: 0.6813 - val_accuracy: 0.7894\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7484 - accuracy: 0.7652 - val_loss: 0.6266 - val_accuracy: 0.8050\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6925 - accuracy: 0.7793 - val_loss: 0.5833 - val_accuracy: 0.8162\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6551 - accuracy: 0.7900 - val_loss: 0.5621 - val_accuracy: 0.8210\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6254 - accuracy: 0.7976 - val_loss: 0.5455 - val_accuracy: 0.8254\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6024 - accuracy: 0.8031 - val_loss: 0.5296 - val_accuracy: 0.8293\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5844 - accuracy: 0.8086 - val_loss: 0.5191 - val_accuracy: 0.8331\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5705 - accuracy: 0.8123 - val_loss: 0.5097 - val_accuracy: 0.8363\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5561 - accuracy: 0.8176 - val_loss: 0.4985 - val_accuracy: 0.8359\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5470 - accuracy: 0.8206 - val_loss: 0.4938 - val_accuracy: 0.8383\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5389 - accuracy: 0.8226 - val_loss: 0.4897 - val_accuracy: 0.8391\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5327 - accuracy: 0.8245 - val_loss: 0.4842 - val_accuracy: 0.8418\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5250 - accuracy: 0.8271 - val_loss: 0.4777 - val_accuracy: 0.8428\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5189 - accuracy: 0.8288 - val_loss: 0.4757 - val_accuracy: 0.8424\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5138 - accuracy: 0.8301 - val_loss: 0.4720 - val_accuracy: 0.8446\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5128 - accuracy: 0.8290 - val_loss: 0.4700 - val_accuracy: 0.8450\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:47.976797\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5055 - accuracy: 0.8326 - val_loss: 0.4667 - val_accuracy: 0.8463\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5016 - accuracy: 0.8339 - val_loss: 0.4659 - val_accuracy: 0.8463\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5025 - accuracy: 0.8340 - val_loss: 0.4650 - val_accuracy: 0.8472\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4985 - accuracy: 0.8333 - val_loss: 0.4648 - val_accuracy: 0.8475\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5006 - accuracy: 0.8337 - val_loss: 0.4647 - val_accuracy: 0.8472\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5011 - accuracy: 0.8338 - val_loss: 0.4647 - val_accuracy: 0.8475\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.4979 - accuracy: 0.8331 - val_loss: 0.4647 - val_accuracy: 0.8474\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4987 - accuracy: 0.8347 - val_loss: 0.4647 - val_accuracy: 0.8474\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5004 - accuracy: 0.8341 - val_loss: 0.4647 - val_accuracy: 0.8474\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:59.655406\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.7686 - accuracy: 0.2899 - val_loss: 1.4797 - val_accuracy: 0.5934\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3921 - accuracy: 0.5966 - val_loss: 1.0864 - val_accuracy: 0.6866\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1106 - accuracy: 0.6694 - val_loss: 0.8920 - val_accuracy: 0.7306\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9320 - accuracy: 0.7180 - val_loss: 0.7731 - val_accuracy: 0.7620\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8184 - accuracy: 0.7475 - val_loss: 0.6850 - val_accuracy: 0.7840\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7377 - accuracy: 0.7690 - val_loss: 0.6376 - val_accuracy: 0.7952\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.6854 - accuracy: 0.7827 - val_loss: 0.6023 - val_accuracy: 0.8049\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.6485 - accuracy: 0.7922 - val_loss: 0.5736 - val_accuracy: 0.8148\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6203 - accuracy: 0.8007 - val_loss: 0.5545 - val_accuracy: 0.8188\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5983 - accuracy: 0.8073 - val_loss: 0.5409 - val_accuracy: 0.8236\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5819 - accuracy: 0.8114 - val_loss: 0.5243 - val_accuracy: 0.8267\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5663 - accuracy: 0.8165 - val_loss: 0.5170 - val_accuracy: 0.8301\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5544 - accuracy: 0.8199 - val_loss: 0.5076 - val_accuracy: 0.8323\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5444 - accuracy: 0.8215 - val_loss: 0.5015 - val_accuracy: 0.8332\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5344 - accuracy: 0.8254 - val_loss: 0.4930 - val_accuracy: 0.8364\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5269 - accuracy: 0.8276 - val_loss: 0.4901 - val_accuracy: 0.8378\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5232 - accuracy: 0.8293 - val_loss: 0.4868 - val_accuracy: 0.8391\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5140 - accuracy: 0.8303 - val_loss: 0.4818 - val_accuracy: 0.8385\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5104 - accuracy: 0.8306 - val_loss: 0.4778 - val_accuracy: 0.8409\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5052 - accuracy: 0.8332 - val_loss: 0.4758 - val_accuracy: 0.8412\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:52.943647\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.5015 - accuracy: 0.8339 - val_loss: 0.4726 - val_accuracy: 0.8424\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.4977 - accuracy: 0.8362 - val_loss: 0.4708 - val_accuracy: 0.8418\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4964 - accuracy: 0.8358 - val_loss: 0.4702 - val_accuracy: 0.8430\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4945 - accuracy: 0.8369 - val_loss: 0.4699 - val_accuracy: 0.8428\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4945 - accuracy: 0.8368 - val_loss: 0.4699 - val_accuracy: 0.8427\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4941 - accuracy: 0.8367 - val_loss: 0.4698 - val_accuracy: 0.8428\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:44.926050\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 2.6550 - accuracy: 0.3138 - val_loss: 1.4218 - val_accuracy: 0.6096\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3636 - accuracy: 0.6019 - val_loss: 1.0535 - val_accuracy: 0.6957\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0798 - accuracy: 0.6764 - val_loss: 0.8622 - val_accuracy: 0.7417\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9076 - accuracy: 0.7226 - val_loss: 0.7347 - val_accuracy: 0.7766\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7977 - accuracy: 0.7506 - val_loss: 0.6608 - val_accuracy: 0.7940\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7280 - accuracy: 0.7693 - val_loss: 0.6072 - val_accuracy: 0.8086\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6755 - accuracy: 0.7844 - val_loss: 0.5801 - val_accuracy: 0.8126\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6429 - accuracy: 0.7929 - val_loss: 0.5559 - val_accuracy: 0.8227\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6173 - accuracy: 0.8010 - val_loss: 0.5393 - val_accuracy: 0.8261\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5955 - accuracy: 0.8067 - val_loss: 0.5322 - val_accuracy: 0.8264\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5799 - accuracy: 0.8102 - val_loss: 0.5125 - val_accuracy: 0.8338\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5680 - accuracy: 0.8146 - val_loss: 0.5054 - val_accuracy: 0.8355\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5545 - accuracy: 0.8202 - val_loss: 0.5010 - val_accuracy: 0.8359\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5440 - accuracy: 0.8220 - val_loss: 0.4916 - val_accuracy: 0.8386\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5334 - accuracy: 0.8250 - val_loss: 0.4862 - val_accuracy: 0.8414\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5285 - accuracy: 0.8259 - val_loss: 0.4851 - val_accuracy: 0.8416\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5256 - accuracy: 0.8258 - val_loss: 0.4777 - val_accuracy: 0.8437\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5185 - accuracy: 0.8295 - val_loss: 0.4748 - val_accuracy: 0.8461\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5123 - accuracy: 0.8325 - val_loss: 0.4721 - val_accuracy: 0.8446\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5063 - accuracy: 0.8310 - val_loss: 0.4681 - val_accuracy: 0.8474\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:49.550837\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5025 - accuracy: 0.8338 - val_loss: 0.4667 - val_accuracy: 0.8485\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5001 - accuracy: 0.8332 - val_loss: 0.4657 - val_accuracy: 0.8476\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4972 - accuracy: 0.8359 - val_loss: 0.4646 - val_accuracy: 0.8478\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4985 - accuracy: 0.8357 - val_loss: 0.4642 - val_accuracy: 0.8485\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:47.307553\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.8477 - accuracy: 0.2808 - val_loss: 1.4921 - val_accuracy: 0.5957\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3843 - accuracy: 0.5966 - val_loss: 1.0897 - val_accuracy: 0.6862\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0895 - accuracy: 0.6747 - val_loss: 0.8874 - val_accuracy: 0.7348\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9144 - accuracy: 0.7198 - val_loss: 0.7590 - val_accuracy: 0.7702\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7976 - accuracy: 0.7509 - val_loss: 0.6773 - val_accuracy: 0.7905\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7211 - accuracy: 0.7717 - val_loss: 0.6293 - val_accuracy: 0.8035\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6701 - accuracy: 0.7858 - val_loss: 0.5934 - val_accuracy: 0.8131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6349 - accuracy: 0.7957 - val_loss: 0.5682 - val_accuracy: 0.8209\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6082 - accuracy: 0.8028 - val_loss: 0.5532 - val_accuracy: 0.8238\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5860 - accuracy: 0.8097 - val_loss: 0.5306 - val_accuracy: 0.8324\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5693 - accuracy: 0.8135 - val_loss: 0.5233 - val_accuracy: 0.8342\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5560 - accuracy: 0.8175 - val_loss: 0.5129 - val_accuracy: 0.8367\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.5429 - accuracy: 0.8208 - val_loss: 0.5072 - val_accuracy: 0.8379\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5342 - accuracy: 0.8238 - val_loss: 0.4970 - val_accuracy: 0.8406\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5252 - accuracy: 0.8264 - val_loss: 0.4922 - val_accuracy: 0.8418\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5180 - accuracy: 0.8287 - val_loss: 0.4869 - val_accuracy: 0.8434\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5143 - accuracy: 0.8299 - val_loss: 0.4836 - val_accuracy: 0.8457\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5069 - accuracy: 0.8323 - val_loss: 0.4806 - val_accuracy: 0.8454\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5007 - accuracy: 0.8334 - val_loss: 0.4761 - val_accuracy: 0.8461\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4965 - accuracy: 0.8343 - val_loss: 0.4732 - val_accuracy: 0.8468\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:48.649552\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4904 - accuracy: 0.8377 - val_loss: 0.4714 - val_accuracy: 0.8478\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4884 - accuracy: 0.8386 - val_loss: 0.4704 - val_accuracy: 0.8491\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4883 - accuracy: 0.8367 - val_loss: 0.4693 - val_accuracy: 0.8490\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4873 - accuracy: 0.8387 - val_loss: 0.4689 - val_accuracy: 0.8492\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4867 - accuracy: 0.8379 - val_loss: 0.4688 - val_accuracy: 0.8492\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4864 - accuracy: 0.8382 - val_loss: 0.4688 - val_accuracy: 0.8491\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4856 - accuracy: 0.8385 - val_loss: 0.4687 - val_accuracy: 0.8491\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:06.432615\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.2422 - accuracy: 0.1693 - val_loss: 1.7349 - val_accuracy: 0.5434\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5666 - accuracy: 0.5469 - val_loss: 1.1641 - val_accuracy: 0.6698\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1975 - accuracy: 0.6445 - val_loss: 0.9510 - val_accuracy: 0.7204\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0082 - accuracy: 0.6965 - val_loss: 0.8070 - val_accuracy: 0.7610\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8720 - accuracy: 0.7311 - val_loss: 0.7190 - val_accuracy: 0.7823\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7894 - accuracy: 0.7533 - val_loss: 0.6686 - val_accuracy: 0.7962\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7331 - accuracy: 0.7684 - val_loss: 0.6304 - val_accuracy: 0.8036\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6910 - accuracy: 0.7801 - val_loss: 0.5967 - val_accuracy: 0.8129\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6615 - accuracy: 0.7883 - val_loss: 0.5728 - val_accuracy: 0.8205\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6357 - accuracy: 0.7964 - val_loss: 0.5610 - val_accuracy: 0.8216\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6191 - accuracy: 0.8013 - val_loss: 0.5484 - val_accuracy: 0.8261\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6020 - accuracy: 0.8050 - val_loss: 0.5379 - val_accuracy: 0.8288\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5926 - accuracy: 0.8082 - val_loss: 0.5349 - val_accuracy: 0.8279\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5778 - accuracy: 0.8117 - val_loss: 0.5185 - val_accuracy: 0.8336\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5714 - accuracy: 0.8142 - val_loss: 0.5166 - val_accuracy: 0.8326\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5610 - accuracy: 0.8166 - val_loss: 0.5099 - val_accuracy: 0.8355\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5555 - accuracy: 0.8175 - val_loss: 0.5041 - val_accuracy: 0.8383\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5509 - accuracy: 0.8187 - val_loss: 0.5007 - val_accuracy: 0.8372\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5440 - accuracy: 0.8235 - val_loss: 0.4973 - val_accuracy: 0.8387\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5403 - accuracy: 0.8222 - val_loss: 0.4950 - val_accuracy: 0.8411\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:12.001049\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5374 - accuracy: 0.8257 - val_loss: 0.4910 - val_accuracy: 0.8414\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5294 - accuracy: 0.8264 - val_loss: 0.4901 - val_accuracy: 0.8418\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5306 - accuracy: 0.8263 - val_loss: 0.4890 - val_accuracy: 0.8418\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5296 - accuracy: 0.8269 - val_loss: 0.4891 - val_accuracy: 0.8414\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5289 - accuracy: 0.8264 - val_loss: 0.4888 - val_accuracy: 0.8418\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5281 - accuracy: 0.8276 - val_loss: 0.4887 - val_accuracy: 0.8416\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:47.396795\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3626 - accuracy: 0.1502 - val_loss: 1.8767 - val_accuracy: 0.5114\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6443 - accuracy: 0.5327 - val_loss: 1.2091 - val_accuracy: 0.6548\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2415 - accuracy: 0.6346 - val_loss: 0.9579 - val_accuracy: 0.7158\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0247 - accuracy: 0.6905 - val_loss: 0.8216 - val_accuracy: 0.7508\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8851 - accuracy: 0.7276 - val_loss: 0.7219 - val_accuracy: 0.7758\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7879 - accuracy: 0.7547 - val_loss: 0.6508 - val_accuracy: 0.7987\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7296 - accuracy: 0.7701 - val_loss: 0.6180 - val_accuracy: 0.8037\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6838 - accuracy: 0.7847 - val_loss: 0.5874 - val_accuracy: 0.8135\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6547 - accuracy: 0.7922 - val_loss: 0.5676 - val_accuracy: 0.8218\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6282 - accuracy: 0.7987 - val_loss: 0.5540 - val_accuracy: 0.8213\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6103 - accuracy: 0.8041 - val_loss: 0.5388 - val_accuracy: 0.8270\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5947 - accuracy: 0.8079 - val_loss: 0.5287 - val_accuracy: 0.8298\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5822 - accuracy: 0.8107 - val_loss: 0.5175 - val_accuracy: 0.8325\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5716 - accuracy: 0.8150 - val_loss: 0.5113 - val_accuracy: 0.8351\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5640 - accuracy: 0.8170 - val_loss: 0.5040 - val_accuracy: 0.8364\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5510 - accuracy: 0.8215 - val_loss: 0.4985 - val_accuracy: 0.8390\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5472 - accuracy: 0.8219 - val_loss: 0.4960 - val_accuracy: 0.8395\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5427 - accuracy: 0.8224 - val_loss: 0.4903 - val_accuracy: 0.8414\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5364 - accuracy: 0.8243 - val_loss: 0.4868 - val_accuracy: 0.8430\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5307 - accuracy: 0.8262 - val_loss: 0.4858 - val_accuracy: 0.8427\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:13.688485\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5271 - accuracy: 0.8283 - val_loss: 0.4814 - val_accuracy: 0.8443\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5212 - accuracy: 0.8301 - val_loss: 0.4812 - val_accuracy: 0.8437\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5218 - accuracy: 0.8275 - val_loss: 0.4801 - val_accuracy: 0.8438\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5203 - accuracy: 0.8304 - val_loss: 0.4801 - val_accuracy: 0.8447\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5178 - accuracy: 0.8302 - val_loss: 0.4799 - val_accuracy: 0.8443\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5178 - accuracy: 0.8300 - val_loss: 0.4799 - val_accuracy: 0.8442\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5199 - accuracy: 0.8294 - val_loss: 0.4799 - val_accuracy: 0.8443\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:17.061676\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 3.1562 - accuracy: 0.1944 - val_loss: 1.7185 - val_accuracy: 0.5304\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5823 - accuracy: 0.5441 - val_loss: 1.2438 - val_accuracy: 0.6431\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2498 - accuracy: 0.6334 - val_loss: 1.0165 - val_accuracy: 0.6954\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0590 - accuracy: 0.6824 - val_loss: 0.8535 - val_accuracy: 0.7468\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9188 - accuracy: 0.7194 - val_loss: 0.7664 - val_accuracy: 0.7633\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8206 - accuracy: 0.7456 - val_loss: 0.6905 - val_accuracy: 0.7845\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7507 - accuracy: 0.7649 - val_loss: 0.6456 - val_accuracy: 0.7997\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7038 - accuracy: 0.7769 - val_loss: 0.6115 - val_accuracy: 0.8080\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6667 - accuracy: 0.7891 - val_loss: 0.5857 - val_accuracy: 0.8121\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6419 - accuracy: 0.7945 - val_loss: 0.5703 - val_accuracy: 0.8155\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6224 - accuracy: 0.7997 - val_loss: 0.5555 - val_accuracy: 0.8219\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6037 - accuracy: 0.8054 - val_loss: 0.5407 - val_accuracy: 0.8249\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5894 - accuracy: 0.8084 - val_loss: 0.5316 - val_accuracy: 0.8292\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5786 - accuracy: 0.8122 - val_loss: 0.5263 - val_accuracy: 0.8303\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5668 - accuracy: 0.8149 - val_loss: 0.5195 - val_accuracy: 0.8343\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5606 - accuracy: 0.8168 - val_loss: 0.5120 - val_accuracy: 0.8345\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5520 - accuracy: 0.8191 - val_loss: 0.5072 - val_accuracy: 0.8371\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5479 - accuracy: 0.8217 - val_loss: 0.5031 - val_accuracy: 0.8395\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5410 - accuracy: 0.8228 - val_loss: 0.4994 - val_accuracy: 0.8379\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5359 - accuracy: 0.8248 - val_loss: 0.4987 - val_accuracy: 0.8378\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:23.849912\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5292 - accuracy: 0.8280 - val_loss: 0.4934 - val_accuracy: 0.8402\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5259 - accuracy: 0.8269 - val_loss: 0.4924 - val_accuracy: 0.8402\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5270 - accuracy: 0.8281 - val_loss: 0.4918 - val_accuracy: 0.8414\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5222 - accuracy: 0.8288 - val_loss: 0.4914 - val_accuracy: 0.8417\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5244 - accuracy: 0.8276 - val_loss: 0.4913 - val_accuracy: 0.8416\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5238 - accuracy: 0.8282 - val_loss: 0.4913 - val_accuracy: 0.8414\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5248 - accuracy: 0.8296 - val_loss: 0.4913 - val_accuracy: 0.8414\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:16.113780\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.1841 - accuracy: 0.1892 - val_loss: 1.7304 - val_accuracy: 0.5340\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5725 - accuracy: 0.5488 - val_loss: 1.1610 - val_accuracy: 0.6671\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2261 - accuracy: 0.6379 - val_loss: 0.9656 - val_accuracy: 0.7135\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0335 - accuracy: 0.6900 - val_loss: 0.8182 - val_accuracy: 0.7517\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9052 - accuracy: 0.7235 - val_loss: 0.7299 - val_accuracy: 0.7758\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8107 - accuracy: 0.7455 - val_loss: 0.6703 - val_accuracy: 0.7927\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7485 - accuracy: 0.7644 - val_loss: 0.6330 - val_accuracy: 0.7997\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7016 - accuracy: 0.7776 - val_loss: 0.5996 - val_accuracy: 0.8085\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6704 - accuracy: 0.7852 - val_loss: 0.5711 - val_accuracy: 0.8173\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6420 - accuracy: 0.7939 - val_loss: 0.5561 - val_accuracy: 0.8192\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6239 - accuracy: 0.7994 - val_loss: 0.5420 - val_accuracy: 0.8231\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6064 - accuracy: 0.8041 - val_loss: 0.5311 - val_accuracy: 0.8259\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5951 - accuracy: 0.8067 - val_loss: 0.5220 - val_accuracy: 0.8290\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5792 - accuracy: 0.8121 - val_loss: 0.5123 - val_accuracy: 0.8315\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5716 - accuracy: 0.8130 - val_loss: 0.5063 - val_accuracy: 0.8307\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5639 - accuracy: 0.8164 - val_loss: 0.5031 - val_accuracy: 0.8348\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5568 - accuracy: 0.8187 - val_loss: 0.4975 - val_accuracy: 0.8361\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5515 - accuracy: 0.8197 - val_loss: 0.4939 - val_accuracy: 0.8377\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5455 - accuracy: 0.8230 - val_loss: 0.4895 - val_accuracy: 0.8384\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5418 - accuracy: 0.8226 - val_loss: 0.4875 - val_accuracy: 0.8387\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:22.727834\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5362 - accuracy: 0.8251 - val_loss: 0.4832 - val_accuracy: 0.8400\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5345 - accuracy: 0.8244 - val_loss: 0.4815 - val_accuracy: 0.8405\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5308 - accuracy: 0.8261 - val_loss: 0.4813 - val_accuracy: 0.8406\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5299 - accuracy: 0.8267 - val_loss: 0.4807 - val_accuracy: 0.8408\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5286 - accuracy: 0.8276 - val_loss: 0.4806 - val_accuracy: 0.8409\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5276 - accuracy: 0.8256 - val_loss: 0.4805 - val_accuracy: 0.8408\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5296 - accuracy: 0.8265 - val_loss: 0.4805 - val_accuracy: 0.8408\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5279 - accuracy: 0.8277 - val_loss: 0.4805 - val_accuracy: 0.8408\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:41.223244\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3338 - accuracy: 0.1637 - val_loss: 1.8442 - val_accuracy: 0.5153\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6305 - accuracy: 0.5317 - val_loss: 1.2110 - val_accuracy: 0.6524\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2379 - accuracy: 0.6358 - val_loss: 0.9803 - val_accuracy: 0.7125\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0296 - accuracy: 0.6908 - val_loss: 0.8304 - val_accuracy: 0.7487\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8882 - accuracy: 0.7283 - val_loss: 0.7410 - val_accuracy: 0.7748\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7964 - accuracy: 0.7520 - val_loss: 0.6662 - val_accuracy: 0.7923\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7365 - accuracy: 0.7669 - val_loss: 0.6204 - val_accuracy: 0.8034\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6919 - accuracy: 0.7790 - val_loss: 0.5986 - val_accuracy: 0.8077\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6610 - accuracy: 0.7893 - val_loss: 0.5729 - val_accuracy: 0.8151\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6372 - accuracy: 0.7953 - val_loss: 0.5612 - val_accuracy: 0.8219\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6182 - accuracy: 0.8007 - val_loss: 0.5450 - val_accuracy: 0.8236\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6025 - accuracy: 0.8057 - val_loss: 0.5309 - val_accuracy: 0.8281\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5916 - accuracy: 0.8071 - val_loss: 0.5214 - val_accuracy: 0.8297\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5778 - accuracy: 0.8112 - val_loss: 0.5170 - val_accuracy: 0.8327\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5684 - accuracy: 0.8150 - val_loss: 0.5109 - val_accuracy: 0.8316\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5619 - accuracy: 0.8174 - val_loss: 0.5044 - val_accuracy: 0.8359\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5548 - accuracy: 0.8183 - val_loss: 0.4996 - val_accuracy: 0.8361\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5472 - accuracy: 0.8223 - val_loss: 0.4976 - val_accuracy: 0.8344\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5444 - accuracy: 0.8210 - val_loss: 0.4930 - val_accuracy: 0.8382\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5397 - accuracy: 0.8223 - val_loss: 0.4910 - val_accuracy: 0.8388\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:13.559136\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5319 - accuracy: 0.8260 - val_loss: 0.4874 - val_accuracy: 0.8395\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5326 - accuracy: 0.8253 - val_loss: 0.4856 - val_accuracy: 0.8398\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5304 - accuracy: 0.8271 - val_loss: 0.4847 - val_accuracy: 0.8401\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5279 - accuracy: 0.8255 - val_loss: 0.4846 - val_accuracy: 0.8399\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5284 - accuracy: 0.8274 - val_loss: 0.4844 - val_accuracy: 0.8402\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5285 - accuracy: 0.8267 - val_loss: 0.4844 - val_accuracy: 0.8401\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5287 - accuracy: 0.8268 - val_loss: 0.4844 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5294 - accuracy: 0.8251 - val_loss: 0.4843 - val_accuracy: 0.8400\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:41.689024\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 8.9089 - accuracy: 0.1086 - val_loss: 6.9766 - val_accuracy: 0.4187\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 5.9522 - accuracy: 0.4810 - val_loss: 4.8387 - val_accuracy: 0.6387\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.4372 - accuracy: 0.6011 - val_loss: 3.6743 - val_accuracy: 0.6863\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.3574 - accuracy: 0.6576 - val_loss: 2.7628 - val_accuracy: 0.7255\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.5369 - accuracy: 0.6914 - val_loss: 2.0764 - val_accuracy: 0.7445\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.9546 - accuracy: 0.7167 - val_loss: 1.6061 - val_accuracy: 0.7713\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.5875 - accuracy: 0.7328 - val_loss: 1.3262 - val_accuracy: 0.7782\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3551 - accuracy: 0.7443 - val_loss: 1.1531 - val_accuracy: 0.7882\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2177 - accuracy: 0.7533 - val_loss: 1.0495 - val_accuracy: 0.7911\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1320 - accuracy: 0.7603 - val_loss: 0.9916 - val_accuracy: 0.7989\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0774 - accuracy: 0.7656 - val_loss: 0.9571 - val_accuracy: 0.8013\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0352 - accuracy: 0.7707 - val_loss: 0.9238 - val_accuracy: 0.8023\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0012 - accuracy: 0.7749 - val_loss: 0.8939 - val_accuracy: 0.8059\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9723 - accuracy: 0.7786 - val_loss: 0.8641 - val_accuracy: 0.8112\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9497 - accuracy: 0.7820 - val_loss: 0.8331 - val_accuracy: 0.8147\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9308 - accuracy: 0.7849 - val_loss: 0.8329 - val_accuracy: 0.8133\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9110 - accuracy: 0.7875 - val_loss: 0.8142 - val_accuracy: 0.8141\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8978 - accuracy: 0.7892 - val_loss: 0.7988 - val_accuracy: 0.8200\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8804 - accuracy: 0.7933 - val_loss: 0.7934 - val_accuracy: 0.8202\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8701 - accuracy: 0.7959 - val_loss: 0.7859 - val_accuracy: 0.8211\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:46.863896\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8465 - accuracy: 0.8008 - val_loss: 0.7620 - val_accuracy: 0.8250\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8325 - accuracy: 0.8036 - val_loss: 0.7545 - val_accuracy: 0.8254\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8270 - accuracy: 0.8045 - val_loss: 0.7485 - val_accuracy: 0.8267\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8233 - accuracy: 0.8054 - val_loss: 0.7469 - val_accuracy: 0.8279\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8224 - accuracy: 0.8054 - val_loss: 0.7454 - val_accuracy: 0.8275\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8204 - accuracy: 0.8055 - val_loss: 0.7446 - val_accuracy: 0.8276\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8201 - accuracy: 0.8053 - val_loss: 0.7445 - val_accuracy: 0.8277\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:04.093122\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 8.6603 - accuracy: 0.1664 - val_loss: 6.5823 - val_accuracy: 0.4937\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 5.8284 - accuracy: 0.5170 - val_loss: 4.8359 - val_accuracy: 0.6481\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.4023 - accuracy: 0.6142 - val_loss: 3.6521 - val_accuracy: 0.6941\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.3350 - accuracy: 0.6661 - val_loss: 2.7408 - val_accuracy: 0.7328\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.5186 - accuracy: 0.6989 - val_loss: 2.0651 - val_accuracy: 0.7508\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.9420 - accuracy: 0.7192 - val_loss: 1.6338 - val_accuracy: 0.7560\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.5752 - accuracy: 0.7343 - val_loss: 1.3443 - val_accuracy: 0.7692\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3470 - accuracy: 0.7442 - val_loss: 1.1680 - val_accuracy: 0.7785\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2106 - accuracy: 0.7534 - val_loss: 1.0656 - val_accuracy: 0.7853\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1344 - accuracy: 0.7590 - val_loss: 1.0124 - val_accuracy: 0.7945\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0844 - accuracy: 0.7627 - val_loss: 0.9495 - val_accuracy: 0.7995\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0413 - accuracy: 0.7688 - val_loss: 0.9220 - val_accuracy: 0.8026\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0091 - accuracy: 0.7738 - val_loss: 0.9183 - val_accuracy: 0.8003\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9848 - accuracy: 0.7757 - val_loss: 0.8950 - val_accuracy: 0.8023\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9613 - accuracy: 0.7805 - val_loss: 0.8579 - val_accuracy: 0.8104\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9353 - accuracy: 0.7846 - val_loss: 0.8503 - val_accuracy: 0.8112\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9229 - accuracy: 0.7864 - val_loss: 0.8353 - val_accuracy: 0.8088\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9066 - accuracy: 0.7904 - val_loss: 0.8245 - val_accuracy: 0.8137\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8949 - accuracy: 0.7905 - val_loss: 0.8170 - val_accuracy: 0.8111\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8813 - accuracy: 0.7926 - val_loss: 0.7955 - val_accuracy: 0.8174\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:45.127688\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8535 - accuracy: 0.7999 - val_loss: 0.7745 - val_accuracy: 0.8194\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8403 - accuracy: 0.8033 - val_loss: 0.7663 - val_accuracy: 0.8207\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8336 - accuracy: 0.8040 - val_loss: 0.7598 - val_accuracy: 0.8233\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8312 - accuracy: 0.8049 - val_loss: 0.7575 - val_accuracy: 0.8229\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8287 - accuracy: 0.8046 - val_loss: 0.7567 - val_accuracy: 0.8237\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8255 - accuracy: 0.8059 - val_loss: 0.7562 - val_accuracy: 0.8234\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8261 - accuracy: 0.8059 - val_loss: 0.7560 - val_accuracy: 0.8232\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8246 - accuracy: 0.8058 - val_loss: 0.7558 - val_accuracy: 0.8231\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:29.824826\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.5851 - accuracy: 0.1774 - val_loss: 6.4989 - val_accuracy: 0.5254\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 5.8150 - accuracy: 0.5164 - val_loss: 4.8135 - val_accuracy: 0.6460\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.4024 - accuracy: 0.6113 - val_loss: 3.6131 - val_accuracy: 0.7106\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.3405 - accuracy: 0.6617 - val_loss: 2.7257 - val_accuracy: 0.7348\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.5256 - accuracy: 0.6936 - val_loss: 2.0609 - val_accuracy: 0.7525\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.9399 - accuracy: 0.7187 - val_loss: 1.5648 - val_accuracy: 0.7816\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.5703 - accuracy: 0.7325 - val_loss: 1.3214 - val_accuracy: 0.7675\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3436 - accuracy: 0.7425 - val_loss: 1.1398 - val_accuracy: 0.7884\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2080 - accuracy: 0.7499 - val_loss: 1.0374 - val_accuracy: 0.7934\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.1281 - accuracy: 0.7566 - val_loss: 1.0078 - val_accuracy: 0.7903\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0751 - accuracy: 0.7631 - val_loss: 0.9440 - val_accuracy: 0.8042\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0370 - accuracy: 0.7673 - val_loss: 0.9243 - val_accuracy: 0.7996\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0065 - accuracy: 0.7714 - val_loss: 0.8828 - val_accuracy: 0.8093\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9781 - accuracy: 0.7744 - val_loss: 0.8700 - val_accuracy: 0.8061\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9563 - accuracy: 0.7770 - val_loss: 0.8468 - val_accuracy: 0.8118\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9395 - accuracy: 0.7794 - val_loss: 0.8243 - val_accuracy: 0.8184\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9196 - accuracy: 0.7839 - val_loss: 0.8124 - val_accuracy: 0.8170\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9075 - accuracy: 0.7862 - val_loss: 0.8064 - val_accuracy: 0.8180\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8936 - accuracy: 0.7897 - val_loss: 0.7952 - val_accuracy: 0.8201\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8808 - accuracy: 0.7907 - val_loss: 0.7928 - val_accuracy: 0.8197\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:47.647551\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8594 - accuracy: 0.7950 - val_loss: 0.7682 - val_accuracy: 0.8241\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8436 - accuracy: 0.7987 - val_loss: 0.7561 - val_accuracy: 0.8269\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8388 - accuracy: 0.7996 - val_loss: 0.7525 - val_accuracy: 0.8294\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8339 - accuracy: 0.7992 - val_loss: 0.7506 - val_accuracy: 0.8296\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8309 - accuracy: 0.8013 - val_loss: 0.7491 - val_accuracy: 0.8292\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8298 - accuracy: 0.8011 - val_loss: 0.7488 - val_accuracy: 0.8293\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8323 - accuracy: 0.8014 - val_loss: 0.7487 - val_accuracy: 0.8296\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:04.135757\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.7870 - accuracy: 0.1355 - val_loss: 6.7265 - val_accuracy: 0.4842\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 5.8880 - accuracy: 0.4998 - val_loss: 4.8256 - val_accuracy: 0.6425\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.4140 - accuracy: 0.6054 - val_loss: 3.6621 - val_accuracy: 0.6872\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.3350 - accuracy: 0.6624 - val_loss: 2.7486 - val_accuracy: 0.7244\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.5130 - accuracy: 0.6988 - val_loss: 2.0576 - val_accuracy: 0.7506\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.9327 - accuracy: 0.7234 - val_loss: 1.6386 - val_accuracy: 0.7563\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.5647 - accuracy: 0.7369 - val_loss: 1.3403 - val_accuracy: 0.7765\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3374 - accuracy: 0.7465 - val_loss: 1.1516 - val_accuracy: 0.7838\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2001 - accuracy: 0.7553 - val_loss: 1.0661 - val_accuracy: 0.7794\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1160 - accuracy: 0.7633 - val_loss: 1.0058 - val_accuracy: 0.7925\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0580 - accuracy: 0.7693 - val_loss: 0.9540 - val_accuracy: 0.7959\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0183 - accuracy: 0.7731 - val_loss: 0.9187 - val_accuracy: 0.8012\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9863 - accuracy: 0.7776 - val_loss: 0.8889 - val_accuracy: 0.8060\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9580 - accuracy: 0.7825 - val_loss: 0.8753 - val_accuracy: 0.8061\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9358 - accuracy: 0.7859 - val_loss: 0.8582 - val_accuracy: 0.8058\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9159 - accuracy: 0.7869 - val_loss: 0.8280 - val_accuracy: 0.8151\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8990 - accuracy: 0.7916 - val_loss: 0.8134 - val_accuracy: 0.8177\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8861 - accuracy: 0.7937 - val_loss: 0.8096 - val_accuracy: 0.8182\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8703 - accuracy: 0.7960 - val_loss: 0.7989 - val_accuracy: 0.8193\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8613 - accuracy: 0.7972 - val_loss: 0.7828 - val_accuracy: 0.8203\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:46.534193\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8397 - accuracy: 0.8031 - val_loss: 0.7701 - val_accuracy: 0.8236\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8245 - accuracy: 0.8059 - val_loss: 0.7597 - val_accuracy: 0.8254\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8190 - accuracy: 0.8085 - val_loss: 0.7553 - val_accuracy: 0.8257\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8153 - accuracy: 0.8073 - val_loss: 0.7532 - val_accuracy: 0.8253\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8130 - accuracy: 0.8081 - val_loss: 0.7521 - val_accuracy: 0.8260\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8130 - accuracy: 0.8076 - val_loss: 0.7514 - val_accuracy: 0.8262\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8116 - accuracy: 0.8085 - val_loss: 0.7512 - val_accuracy: 0.8260\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8135 - accuracy: 0.8074 - val_loss: 0.7512 - val_accuracy: 0.8259\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8113 - accuracy: 0.8082 - val_loss: 0.7512 - val_accuracy: 0.8259\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:56.932866\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 8.5140 - accuracy: 0.1849 - val_loss: 6.4830 - val_accuracy: 0.5254\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 5.7859 - accuracy: 0.5253 - val_loss: 4.7909 - val_accuracy: 0.6496\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.3943 - accuracy: 0.6160 - val_loss: 3.6375 - val_accuracy: 0.6981\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 3.3422 - accuracy: 0.6614 - val_loss: 2.7328 - val_accuracy: 0.7326\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.5289 - accuracy: 0.6946 - val_loss: 2.0532 - val_accuracy: 0.7529\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.9533 - accuracy: 0.7153 - val_loss: 1.6430 - val_accuracy: 0.7527\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.5799 - accuracy: 0.7320 - val_loss: 1.3144 - val_accuracy: 0.7781\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3483 - accuracy: 0.7422 - val_loss: 1.1700 - val_accuracy: 0.7757\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2095 - accuracy: 0.7520 - val_loss: 1.0470 - val_accuracy: 0.7918\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1284 - accuracy: 0.7570 - val_loss: 0.9864 - val_accuracy: 0.7972\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0766 - accuracy: 0.7629 - val_loss: 0.9464 - val_accuracy: 0.8004\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0330 - accuracy: 0.7691 - val_loss: 0.9127 - val_accuracy: 0.8040\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9978 - accuracy: 0.7743 - val_loss: 0.8875 - val_accuracy: 0.8057\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9704 - accuracy: 0.7764 - val_loss: 0.8679 - val_accuracy: 0.8050\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9507 - accuracy: 0.7798 - val_loss: 0.8485 - val_accuracy: 0.8088\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9287 - accuracy: 0.7833 - val_loss: 0.8309 - val_accuracy: 0.8135\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9103 - accuracy: 0.7877 - val_loss: 0.8207 - val_accuracy: 0.8125\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.8971 - accuracy: 0.7886 - val_loss: 0.8057 - val_accuracy: 0.8150\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8834 - accuracy: 0.7914 - val_loss: 0.7895 - val_accuracy: 0.8159\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8733 - accuracy: 0.7928 - val_loss: 0.7887 - val_accuracy: 0.8184\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:47.375886\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8493 - accuracy: 0.7969 - val_loss: 0.7678 - val_accuracy: 0.8225\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.8330 - accuracy: 0.8013 - val_loss: 0.7559 - val_accuracy: 0.8250\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8276 - accuracy: 0.8022 - val_loss: 0.7531 - val_accuracy: 0.8250\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8237 - accuracy: 0.8027 - val_loss: 0.7502 - val_accuracy: 0.8258\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8229 - accuracy: 0.8036 - val_loss: 0.7490 - val_accuracy: 0.8259\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8205 - accuracy: 0.8035 - val_loss: 0.7487 - val_accuracy: 0.8258\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8243 - accuracy: 0.8018 - val_loss: 0.7487 - val_accuracy: 0.8256\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8231 - accuracy: 0.8034 - val_loss: 0.7486 - val_accuracy: 0.8257\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:31.787973\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.2249 - accuracy: 0.2728 - val_loss: 6.2788 - val_accuracy: 0.5786\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5780 - accuracy: 0.5902 - val_loss: 4.7256 - val_accuracy: 0.6739\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2347 - accuracy: 0.6632 - val_loss: 3.5898 - val_accuracy: 0.7156\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1882 - accuracy: 0.7084 - val_loss: 2.6584 - val_accuracy: 0.7560\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3957 - accuracy: 0.7376 - val_loss: 1.9845 - val_accuracy: 0.7754\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8398 - accuracy: 0.7535 - val_loss: 1.5778 - val_accuracy: 0.7769\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4905 - accuracy: 0.7633 - val_loss: 1.3138 - val_accuracy: 0.7895\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2832 - accuracy: 0.7703 - val_loss: 1.1680 - val_accuracy: 0.7837\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1587 - accuracy: 0.7751 - val_loss: 1.0706 - val_accuracy: 0.7917\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0808 - accuracy: 0.7788 - val_loss: 0.9848 - val_accuracy: 0.8039\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0270 - accuracy: 0.7823 - val_loss: 0.9571 - val_accuracy: 0.7971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9844 - accuracy: 0.7864 - val_loss: 0.9070 - val_accuracy: 0.8068\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9527 - accuracy: 0.7920 - val_loss: 0.8948 - val_accuracy: 0.8023\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9247 - accuracy: 0.7951 - val_loss: 0.8602 - val_accuracy: 0.8138\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9066 - accuracy: 0.7962 - val_loss: 0.8436 - val_accuracy: 0.8145\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8867 - accuracy: 0.7992 - val_loss: 0.8277 - val_accuracy: 0.8162\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8714 - accuracy: 0.8017 - val_loss: 0.8203 - val_accuracy: 0.8160\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8566 - accuracy: 0.8046 - val_loss: 0.8038 - val_accuracy: 0.8186\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8423 - accuracy: 0.8064 - val_loss: 0.7964 - val_accuracy: 0.8181\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8328 - accuracy: 0.8068 - val_loss: 0.7788 - val_accuracy: 0.8249\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:57.152393\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8105 - accuracy: 0.8119 - val_loss: 0.7630 - val_accuracy: 0.8242\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7979 - accuracy: 0.8151 - val_loss: 0.7544 - val_accuracy: 0.8262\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7903 - accuracy: 0.8167 - val_loss: 0.7499 - val_accuracy: 0.8270\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7855 - accuracy: 0.8176 - val_loss: 0.7473 - val_accuracy: 0.8271\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7836 - accuracy: 0.8171 - val_loss: 0.7463 - val_accuracy: 0.8267\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7844 - accuracy: 0.8174 - val_loss: 0.7458 - val_accuracy: 0.8270\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7840 - accuracy: 0.8172 - val_loss: 0.7457 - val_accuracy: 0.8270\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:08.590586\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.3066 - accuracy: 0.2559 - val_loss: 6.2675 - val_accuracy: 0.5850\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.5977 - accuracy: 0.5830 - val_loss: 4.7130 - val_accuracy: 0.6747\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2445 - accuracy: 0.6601 - val_loss: 3.5586 - val_accuracy: 0.7241\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1960 - accuracy: 0.7046 - val_loss: 2.6433 - val_accuracy: 0.7594\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3980 - accuracy: 0.7333 - val_loss: 1.9716 - val_accuracy: 0.7768\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8452 - accuracy: 0.7490 - val_loss: 1.5532 - val_accuracy: 0.7861\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5037 - accuracy: 0.7599 - val_loss: 1.3004 - val_accuracy: 0.7922\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3006 - accuracy: 0.7659 - val_loss: 1.1493 - val_accuracy: 0.7939\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1748 - accuracy: 0.7706 - val_loss: 1.0628 - val_accuracy: 0.7955\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0960 - accuracy: 0.7753 - val_loss: 0.9992 - val_accuracy: 0.7972\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0409 - accuracy: 0.7813 - val_loss: 0.9547 - val_accuracy: 0.8059\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9974 - accuracy: 0.7853 - val_loss: 0.9093 - val_accuracy: 0.8075\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9626 - accuracy: 0.7890 - val_loss: 0.8807 - val_accuracy: 0.8098\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9363 - accuracy: 0.7915 - val_loss: 0.8502 - val_accuracy: 0.8180\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9146 - accuracy: 0.7947 - val_loss: 0.8439 - val_accuracy: 0.8110\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8939 - accuracy: 0.7974 - val_loss: 0.8172 - val_accuracy: 0.8187\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8782 - accuracy: 0.7995 - val_loss: 0.8030 - val_accuracy: 0.8213\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8631 - accuracy: 0.8021 - val_loss: 0.7955 - val_accuracy: 0.8203\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8494 - accuracy: 0.8027 - val_loss: 0.7834 - val_accuracy: 0.8223\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8379 - accuracy: 0.8057 - val_loss: 0.7718 - val_accuracy: 0.8264\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:04.635846\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8145 - accuracy: 0.8099 - val_loss: 0.7552 - val_accuracy: 0.8277\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8009 - accuracy: 0.8131 - val_loss: 0.7453 - val_accuracy: 0.8293\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7947 - accuracy: 0.8143 - val_loss: 0.7419 - val_accuracy: 0.8291\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7917 - accuracy: 0.8150 - val_loss: 0.7395 - val_accuracy: 0.8293\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7891 - accuracy: 0.8160 - val_loss: 0.7379 - val_accuracy: 0.8303\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7880 - accuracy: 0.8162 - val_loss: 0.7370 - val_accuracy: 0.8302\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7852 - accuracy: 0.8161 - val_loss: 0.7368 - val_accuracy: 0.8305\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7865 - accuracy: 0.8156 - val_loss: 0.7368 - val_accuracy: 0.8306\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7858 - accuracy: 0.8165 - val_loss: 0.7367 - val_accuracy: 0.8307\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7860 - accuracy: 0.8168 - val_loss: 0.7367 - val_accuracy: 0.8306\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7884 - accuracy: 0.8160 - val_loss: 0.7367 - val_accuracy: 0.8306\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7870 - accuracy: 0.8165 - val_loss: 0.7367 - val_accuracy: 0.8306\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:20.307148\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.0728 - accuracy: 0.3050 - val_loss: 6.1949 - val_accuracy: 0.5955\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5473 - accuracy: 0.5923 - val_loss: 4.6882 - val_accuracy: 0.6782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2041 - accuracy: 0.6665 - val_loss: 3.5190 - val_accuracy: 0.7320\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1632 - accuracy: 0.7114 - val_loss: 2.6306 - val_accuracy: 0.7555\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3717 - accuracy: 0.7380 - val_loss: 1.9725 - val_accuracy: 0.7767\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8234 - accuracy: 0.7551 - val_loss: 1.5512 - val_accuracy: 0.7853\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4861 - accuracy: 0.7616 - val_loss: 1.2887 - val_accuracy: 0.7887\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2794 - accuracy: 0.7693 - val_loss: 1.1470 - val_accuracy: 0.7937\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1566 - accuracy: 0.7733 - val_loss: 1.0561 - val_accuracy: 0.7917\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0785 - accuracy: 0.7777 - val_loss: 0.9788 - val_accuracy: 0.8025\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0281 - accuracy: 0.7801 - val_loss: 0.9381 - val_accuracy: 0.8069\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9862 - accuracy: 0.7852 - val_loss: 0.9172 - val_accuracy: 0.8050\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9555 - accuracy: 0.7889 - val_loss: 0.8818 - val_accuracy: 0.8076\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9256 - accuracy: 0.7904 - val_loss: 0.8609 - val_accuracy: 0.8118\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9047 - accuracy: 0.7966 - val_loss: 0.8516 - val_accuracy: 0.8101\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8873 - accuracy: 0.7976 - val_loss: 0.8221 - val_accuracy: 0.8157\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8721 - accuracy: 0.7989 - val_loss: 0.8183 - val_accuracy: 0.8134\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8534 - accuracy: 0.8026 - val_loss: 0.8035 - val_accuracy: 0.8187\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8453 - accuracy: 0.8038 - val_loss: 0.7957 - val_accuracy: 0.8160\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8349 - accuracy: 0.8040 - val_loss: 0.7772 - val_accuracy: 0.8208\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:56.373719\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8088 - accuracy: 0.8114 - val_loss: 0.7644 - val_accuracy: 0.8231\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7987 - accuracy: 0.8128 - val_loss: 0.7523 - val_accuracy: 0.8298\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7897 - accuracy: 0.8146 - val_loss: 0.7461 - val_accuracy: 0.8292\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7841 - accuracy: 0.8162 - val_loss: 0.7435 - val_accuracy: 0.8303\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7835 - accuracy: 0.8166 - val_loss: 0.7423 - val_accuracy: 0.8299\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7828 - accuracy: 0.8165 - val_loss: 0.7416 - val_accuracy: 0.8303\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7829 - accuracy: 0.8157 - val_loss: 0.7415 - val_accuracy: 0.8305\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7844 - accuracy: 0.8155 - val_loss: 0.7414 - val_accuracy: 0.8303\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7839 - accuracy: 0.8152 - val_loss: 0.7414 - val_accuracy: 0.8304\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7828 - accuracy: 0.8167 - val_loss: 0.7413 - val_accuracy: 0.8304\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:26.831118\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.0399 - accuracy: 0.3160 - val_loss: 6.1795 - val_accuracy: 0.6090\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5421 - accuracy: 0.5978 - val_loss: 4.7032 - val_accuracy: 0.6814\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2228 - accuracy: 0.6652 - val_loss: 3.5497 - val_accuracy: 0.7325\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1828 - accuracy: 0.7092 - val_loss: 2.6437 - val_accuracy: 0.7628\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3939 - accuracy: 0.7350 - val_loss: 1.9865 - val_accuracy: 0.7793\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8382 - accuracy: 0.7516 - val_loss: 1.5695 - val_accuracy: 0.7790\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4952 - accuracy: 0.7595 - val_loss: 1.2997 - val_accuracy: 0.7922\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2894 - accuracy: 0.7660 - val_loss: 1.1603 - val_accuracy: 0.7889\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1602 - accuracy: 0.7729 - val_loss: 1.0547 - val_accuracy: 0.7987\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0810 - accuracy: 0.7787 - val_loss: 0.9920 - val_accuracy: 0.8023\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0271 - accuracy: 0.7818 - val_loss: 0.9603 - val_accuracy: 0.8039\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9825 - accuracy: 0.7864 - val_loss: 0.9114 - val_accuracy: 0.8079\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9503 - accuracy: 0.7898 - val_loss: 0.8918 - val_accuracy: 0.8088\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9253 - accuracy: 0.7919 - val_loss: 0.8638 - val_accuracy: 0.8117\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9029 - accuracy: 0.7969 - val_loss: 0.8448 - val_accuracy: 0.8146\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8836 - accuracy: 0.7983 - val_loss: 0.8282 - val_accuracy: 0.8155\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8679 - accuracy: 0.7993 - val_loss: 0.8082 - val_accuracy: 0.8198\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8518 - accuracy: 0.8024 - val_loss: 0.7997 - val_accuracy: 0.8194\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8406 - accuracy: 0.8048 - val_loss: 0.7895 - val_accuracy: 0.8218\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8295 - accuracy: 0.8066 - val_loss: 0.7779 - val_accuracy: 0.8232\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:54.169632\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8082 - accuracy: 0.8114 - val_loss: 0.7617 - val_accuracy: 0.8263\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7932 - accuracy: 0.8141 - val_loss: 0.7525 - val_accuracy: 0.8281\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7884 - accuracy: 0.8140 - val_loss: 0.7500 - val_accuracy: 0.8282\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7842 - accuracy: 0.8153 - val_loss: 0.7461 - val_accuracy: 0.8295\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7813 - accuracy: 0.8166 - val_loss: 0.7454 - val_accuracy: 0.8300\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7799 - accuracy: 0.8162 - val_loss: 0.7448 - val_accuracy: 0.8299\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7799 - accuracy: 0.8160 - val_loss: 0.7446 - val_accuracy: 0.8303\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7809 - accuracy: 0.8160 - val_loss: 0.7446 - val_accuracy: 0.8302\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7803 - accuracy: 0.8155 - val_loss: 0.7445 - val_accuracy: 0.8302\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7791 - accuracy: 0.8185 - val_loss: 0.7445 - val_accuracy: 0.8302\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:28.522643\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.0131 - accuracy: 0.3171 - val_loss: 6.1972 - val_accuracy: 0.5875\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5413 - accuracy: 0.5963 - val_loss: 4.7033 - val_accuracy: 0.6788\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2150 - accuracy: 0.6661 - val_loss: 3.5348 - val_accuracy: 0.7301\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1779 - accuracy: 0.7107 - val_loss: 2.6444 - val_accuracy: 0.7568\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.3906 - accuracy: 0.7371 - val_loss: 1.9796 - val_accuracy: 0.7745\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8419 - accuracy: 0.7513 - val_loss: 1.5647 - val_accuracy: 0.7815\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5003 - accuracy: 0.7627 - val_loss: 1.3337 - val_accuracy: 0.7763\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2957 - accuracy: 0.7682 - val_loss: 1.1660 - val_accuracy: 0.7902\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1714 - accuracy: 0.7729 - val_loss: 1.0493 - val_accuracy: 0.8008\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0917 - accuracy: 0.7781 - val_loss: 1.0020 - val_accuracy: 0.7966\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0363 - accuracy: 0.7822 - val_loss: 0.9455 - val_accuracy: 0.8048\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9920 - accuracy: 0.7873 - val_loss: 0.9043 - val_accuracy: 0.8106\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9610 - accuracy: 0.7900 - val_loss: 0.8908 - val_accuracy: 0.8128\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9313 - accuracy: 0.7950 - val_loss: 0.8640 - val_accuracy: 0.8146\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9101 - accuracy: 0.7963 - val_loss: 0.8450 - val_accuracy: 0.8170\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8895 - accuracy: 0.7996 - val_loss: 0.8386 - val_accuracy: 0.8113\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8746 - accuracy: 0.8005 - val_loss: 0.8204 - val_accuracy: 0.8159\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8594 - accuracy: 0.8028 - val_loss: 0.7950 - val_accuracy: 0.8219\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8476 - accuracy: 0.8048 - val_loss: 0.7905 - val_accuracy: 0.8216\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8347 - accuracy: 0.8077 - val_loss: 0.7747 - val_accuracy: 0.8255\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:59.994744\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8120 - accuracy: 0.8124 - val_loss: 0.7559 - val_accuracy: 0.8300\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7977 - accuracy: 0.8157 - val_loss: 0.7501 - val_accuracy: 0.8282\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7903 - accuracy: 0.8175 - val_loss: 0.7449 - val_accuracy: 0.8292\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7882 - accuracy: 0.8178 - val_loss: 0.7419 - val_accuracy: 0.8305\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7853 - accuracy: 0.8181 - val_loss: 0.7407 - val_accuracy: 0.8305\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7831 - accuracy: 0.8178 - val_loss: 0.7401 - val_accuracy: 0.8299\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7830 - accuracy: 0.8188 - val_loss: 0.7399 - val_accuracy: 0.8301\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:09.804014\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.6614 - accuracy: 0.1655 - val_loss: 6.5614 - val_accuracy: 0.4992\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7720 - accuracy: 0.5292 - val_loss: 4.8142 - val_accuracy: 0.6470\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3607 - accuracy: 0.6251 - val_loss: 3.6353 - val_accuracy: 0.7029\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3017 - accuracy: 0.6754 - val_loss: 2.7692 - val_accuracy: 0.7210\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.4899 - accuracy: 0.7089 - val_loss: 2.0474 - val_accuracy: 0.7591\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9147 - accuracy: 0.7325 - val_loss: 1.6054 - val_accuracy: 0.7675\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5603 - accuracy: 0.7448 - val_loss: 1.3413 - val_accuracy: 0.7770\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3417 - accuracy: 0.7526 - val_loss: 1.1977 - val_accuracy: 0.7774\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2135 - accuracy: 0.7593 - val_loss: 1.0844 - val_accuracy: 0.7916\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1268 - accuracy: 0.7672 - val_loss: 1.0032 - val_accuracy: 0.7998\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0738 - accuracy: 0.7714 - val_loss: 0.9884 - val_accuracy: 0.7902\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0314 - accuracy: 0.7755 - val_loss: 0.9330 - val_accuracy: 0.8025\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9997 - accuracy: 0.7796 - val_loss: 0.9154 - val_accuracy: 0.8031\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9714 - accuracy: 0.7819 - val_loss: 0.8929 - val_accuracy: 0.8041\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9493 - accuracy: 0.7864 - val_loss: 0.8571 - val_accuracy: 0.8159\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9269 - accuracy: 0.7891 - val_loss: 0.8458 - val_accuracy: 0.8131\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9116 - accuracy: 0.7903 - val_loss: 0.8368 - val_accuracy: 0.8128\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8961 - accuracy: 0.7937 - val_loss: 0.8367 - val_accuracy: 0.8100\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:08:26.197397\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.9021 - accuracy: 0.7957 - val_loss: 0.8314 - val_accuracy: 0.8157\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 0.8848 - accuracy: 0.7989 - val_loss: 0.8182 - val_accuracy: 0.8176\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.8764 - accuracy: 0.8013 - val_loss: 0.8116 - val_accuracy: 0.8214\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.8698 - accuracy: 0.8027 - val_loss: 0.8081 - val_accuracy: 0.8215\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 33s 47ms/step - loss: 0.8674 - accuracy: 0.8025 - val_loss: 0.8067 - val_accuracy: 0.8215\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 0.8660 - accuracy: 0.8018 - val_loss: 0.8061 - val_accuracy: 0.8215\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8666 - accuracy: 0.8007 - val_loss: 0.8058 - val_accuracy: 0.8216\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8684 - accuracy: 0.8022 - val_loss: 0.8057 - val_accuracy: 0.8217\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8676 - accuracy: 0.8027 - val_loss: 0.8057 - val_accuracy: 0.8217\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8670 - accuracy: 0.8024 - val_loss: 0.8057 - val_accuracy: 0.8217\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8661 - accuracy: 0.8024 - val_loss: 0.8057 - val_accuracy: 0.8217\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:28.174180\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.8177 - accuracy: 0.1296 - val_loss: 6.7066 - val_accuracy: 0.4875\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8425 - accuracy: 0.5174 - val_loss: 4.8413 - val_accuracy: 0.6449\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4009 - accuracy: 0.6179 - val_loss: 3.6832 - val_accuracy: 0.6903\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3435 - accuracy: 0.6658 - val_loss: 2.7852 - val_accuracy: 0.7215\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.5274 - accuracy: 0.6996 - val_loss: 2.0721 - val_accuracy: 0.7588\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9488 - accuracy: 0.7256 - val_loss: 1.6288 - val_accuracy: 0.7674\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5881 - accuracy: 0.7397 - val_loss: 1.3424 - val_accuracy: 0.7867\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3674 - accuracy: 0.7492 - val_loss: 1.1945 - val_accuracy: 0.7865\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2341 - accuracy: 0.7571 - val_loss: 1.0812 - val_accuracy: 0.7973\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1492 - accuracy: 0.7630 - val_loss: 1.0564 - val_accuracy: 0.7866\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0944 - accuracy: 0.7685 - val_loss: 0.9763 - val_accuracy: 0.8011\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0509 - accuracy: 0.7743 - val_loss: 0.9582 - val_accuracy: 0.8029\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0141 - accuracy: 0.7789 - val_loss: 0.8984 - val_accuracy: 0.8151\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9856 - accuracy: 0.7835 - val_loss: 0.8750 - val_accuracy: 0.8171\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9624 - accuracy: 0.7848 - val_loss: 0.8742 - val_accuracy: 0.8149\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9394 - accuracy: 0.7890 - val_loss: 0.8469 - val_accuracy: 0.8171\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9217 - accuracy: 0.7917 - val_loss: 0.8379 - val_accuracy: 0.8178\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9063 - accuracy: 0.7944 - val_loss: 0.8195 - val_accuracy: 0.8219\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8912 - accuracy: 0.7970 - val_loss: 0.8072 - val_accuracy: 0.8234\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8798 - accuracy: 0.7974 - val_loss: 0.7936 - val_accuracy: 0.8234\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:21.974253\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8530 - accuracy: 0.8046 - val_loss: 0.7745 - val_accuracy: 0.8270\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8384 - accuracy: 0.8059 - val_loss: 0.7650 - val_accuracy: 0.8293\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8332 - accuracy: 0.8081 - val_loss: 0.7587 - val_accuracy: 0.8303\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8285 - accuracy: 0.8095 - val_loss: 0.7557 - val_accuracy: 0.8321\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8277 - accuracy: 0.8071 - val_loss: 0.7550 - val_accuracy: 0.8310\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8257 - accuracy: 0.8100 - val_loss: 0.7547 - val_accuracy: 0.8314\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8242 - accuracy: 0.8089 - val_loss: 0.7545 - val_accuracy: 0.8316\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:17.468453\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.7491 - accuracy: 0.1445 - val_loss: 6.6904 - val_accuracy: 0.4916\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.8313 - accuracy: 0.5159 - val_loss: 4.8565 - val_accuracy: 0.6377\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4103 - accuracy: 0.6111 - val_loss: 3.7040 - val_accuracy: 0.6829\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3528 - accuracy: 0.6610 - val_loss: 2.7888 - val_accuracy: 0.7211\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.5438 - accuracy: 0.6918 - val_loss: 2.0863 - val_accuracy: 0.7547\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.9703 - accuracy: 0.7185 - val_loss: 1.6718 - val_accuracy: 0.7587\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6096 - accuracy: 0.7330 - val_loss: 1.3940 - val_accuracy: 0.7711\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3897 - accuracy: 0.7431 - val_loss: 1.2251 - val_accuracy: 0.7772\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2550 - accuracy: 0.7526 - val_loss: 1.1054 - val_accuracy: 0.7866\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1683 - accuracy: 0.7595 - val_loss: 1.0656 - val_accuracy: 0.7836\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1084 - accuracy: 0.7659 - val_loss: 1.0245 - val_accuracy: 0.7868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0598 - accuracy: 0.7713 - val_loss: 0.9800 - val_accuracy: 0.7926\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0277 - accuracy: 0.7745 - val_loss: 0.9378 - val_accuracy: 0.8025\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9981 - accuracy: 0.7782 - val_loss: 0.9205 - val_accuracy: 0.8021\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9701 - accuracy: 0.7818 - val_loss: 0.8890 - val_accuracy: 0.8084\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9490 - accuracy: 0.7859 - val_loss: 0.8710 - val_accuracy: 0.8112\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9310 - accuracy: 0.7872 - val_loss: 0.8552 - val_accuracy: 0.8115\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9115 - accuracy: 0.7919 - val_loss: 0.8413 - val_accuracy: 0.8146\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9004 - accuracy: 0.7925 - val_loss: 0.8342 - val_accuracy: 0.8147\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8870 - accuracy: 0.7957 - val_loss: 0.8330 - val_accuracy: 0.8139\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:16.953978\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8611 - accuracy: 0.8013 - val_loss: 0.7993 - val_accuracy: 0.8206\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8469 - accuracy: 0.8035 - val_loss: 0.7923 - val_accuracy: 0.8219\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8393 - accuracy: 0.8054 - val_loss: 0.7862 - val_accuracy: 0.8208\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8366 - accuracy: 0.8058 - val_loss: 0.7837 - val_accuracy: 0.8227\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8335 - accuracy: 0.8059 - val_loss: 0.7819 - val_accuracy: 0.8221\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8348 - accuracy: 0.8063 - val_loss: 0.7815 - val_accuracy: 0.8219\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8323 - accuracy: 0.8063 - val_loss: 0.7812 - val_accuracy: 0.8221\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:15.794886\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.8080 - accuracy: 0.1348 - val_loss: 6.7590 - val_accuracy: 0.4761\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8552 - accuracy: 0.5088 - val_loss: 4.8449 - val_accuracy: 0.6447\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.4152 - accuracy: 0.6079 - val_loss: 3.6972 - val_accuracy: 0.6844\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3576 - accuracy: 0.6588 - val_loss: 2.8302 - val_accuracy: 0.7067\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.5475 - accuracy: 0.6931 - val_loss: 2.1010 - val_accuracy: 0.7382\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.9770 - accuracy: 0.7149 - val_loss: 1.6527 - val_accuracy: 0.7590\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6118 - accuracy: 0.7328 - val_loss: 1.3701 - val_accuracy: 0.7750\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3883 - accuracy: 0.7440 - val_loss: 1.2161 - val_accuracy: 0.7790\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2572 - accuracy: 0.7505 - val_loss: 1.1385 - val_accuracy: 0.7770\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1722 - accuracy: 0.7565 - val_loss: 1.0626 - val_accuracy: 0.7819\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1131 - accuracy: 0.7635 - val_loss: 0.9990 - val_accuracy: 0.7924\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0639 - accuracy: 0.7693 - val_loss: 0.9765 - val_accuracy: 0.7965\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0295 - accuracy: 0.7718 - val_loss: 0.9354 - val_accuracy: 0.8014\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9968 - accuracy: 0.7781 - val_loss: 0.9325 - val_accuracy: 0.7995\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9718 - accuracy: 0.7825 - val_loss: 0.8964 - val_accuracy: 0.8024\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9504 - accuracy: 0.7838 - val_loss: 0.8839 - val_accuracy: 0.8064\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9293 - accuracy: 0.7876 - val_loss: 0.8542 - val_accuracy: 0.8112\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9162 - accuracy: 0.7894 - val_loss: 0.8476 - val_accuracy: 0.8122\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9002 - accuracy: 0.7925 - val_loss: 0.8324 - val_accuracy: 0.8136\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8893 - accuracy: 0.7934 - val_loss: 0.8255 - val_accuracy: 0.8112\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:17.435785\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8625 - accuracy: 0.7982 - val_loss: 0.8031 - val_accuracy: 0.8179\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8487 - accuracy: 0.8017 - val_loss: 0.7894 - val_accuracy: 0.8205\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8428 - accuracy: 0.8036 - val_loss: 0.7844 - val_accuracy: 0.8216\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8385 - accuracy: 0.8033 - val_loss: 0.7820 - val_accuracy: 0.8222\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8345 - accuracy: 0.8052 - val_loss: 0.7811 - val_accuracy: 0.8219\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8323 - accuracy: 0.8054 - val_loss: 0.7805 - val_accuracy: 0.8219\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8330 - accuracy: 0.8044 - val_loss: 0.7803 - val_accuracy: 0.8216\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:15.511202\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.3978 - accuracy: 0.2208 - val_loss: 6.3952 - val_accuracy: 0.5497\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7004 - accuracy: 0.5508 - val_loss: 4.7895 - val_accuracy: 0.6609\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3354 - accuracy: 0.6337 - val_loss: 3.6550 - val_accuracy: 0.7000\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2835 - accuracy: 0.6822 - val_loss: 2.7335 - val_accuracy: 0.7374\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.4794 - accuracy: 0.7146 - val_loss: 2.0594 - val_accuracy: 0.7599\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9120 - accuracy: 0.7342 - val_loss: 1.6075 - val_accuracy: 0.7715\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5557 - accuracy: 0.7440 - val_loss: 1.3612 - val_accuracy: 0.7668\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3409 - accuracy: 0.7519 - val_loss: 1.1853 - val_accuracy: 0.7822\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2076 - accuracy: 0.7590 - val_loss: 1.0903 - val_accuracy: 0.7828\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1275 - accuracy: 0.7655 - val_loss: 1.0366 - val_accuracy: 0.7832\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0765 - accuracy: 0.7700 - val_loss: 0.9731 - val_accuracy: 0.7953\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0345 - accuracy: 0.7758 - val_loss: 0.9361 - val_accuracy: 0.8020\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0020 - accuracy: 0.7789 - val_loss: 0.9265 - val_accuracy: 0.7982\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9764 - accuracy: 0.7827 - val_loss: 0.8883 - val_accuracy: 0.8071\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9521 - accuracy: 0.7843 - val_loss: 0.8876 - val_accuracy: 0.8016\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9326 - accuracy: 0.7898 - val_loss: 0.8596 - val_accuracy: 0.8064\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9171 - accuracy: 0.7909 - val_loss: 0.8439 - val_accuracy: 0.8080\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9004 - accuracy: 0.7943 - val_loss: 0.8412 - val_accuracy: 0.8102\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8865 - accuracy: 0.7951 - val_loss: 0.8326 - val_accuracy: 0.8099\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8734 - accuracy: 0.7982 - val_loss: 0.8157 - val_accuracy: 0.8128\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:22.085559\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.8508 - accuracy: 0.8029 - val_loss: 0.7976 - val_accuracy: 0.8173\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.8361 - accuracy: 0.8055 - val_loss: 0.7849 - val_accuracy: 0.8193\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8300 - accuracy: 0.8062 - val_loss: 0.7807 - val_accuracy: 0.8197\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8260 - accuracy: 0.8067 - val_loss: 0.7780 - val_accuracy: 0.8195\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8224 - accuracy: 0.8090 - val_loss: 0.7769 - val_accuracy: 0.8195\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8219 - accuracy: 0.8087 - val_loss: 0.7763 - val_accuracy: 0.8199\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8237 - accuracy: 0.8078 - val_loss: 0.7762 - val_accuracy: 0.8195\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8218 - accuracy: 0.8090 - val_loss: 0.7761 - val_accuracy: 0.8198\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8222 - accuracy: 0.8071 - val_loss: 0.7761 - val_accuracy: 0.8199\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:18.299710\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4715 - accuracy: 0.1753 - val_loss: 1.9821 - val_accuracy: 0.5362\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8244 - accuracy: 0.5386 - val_loss: 1.3671 - val_accuracy: 0.6656\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4289 - accuracy: 0.6411 - val_loss: 1.1447 - val_accuracy: 0.7273\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.2291 - accuracy: 0.6934 - val_loss: 1.0172 - val_accuracy: 0.7539\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0969 - accuracy: 0.7279 - val_loss: 0.9298 - val_accuracy: 0.7764\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.0085 - accuracy: 0.7518 - val_loss: 0.8655 - val_accuracy: 0.7924\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9474 - accuracy: 0.7667 - val_loss: 0.8298 - val_accuracy: 0.8013\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9045 - accuracy: 0.7787 - val_loss: 0.7992 - val_accuracy: 0.8071\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8720 - accuracy: 0.7860 - val_loss: 0.7806 - val_accuracy: 0.8104\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8470 - accuracy: 0.7938 - val_loss: 0.7639 - val_accuracy: 0.8139\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8245 - accuracy: 0.7986 - val_loss: 0.7453 - val_accuracy: 0.8212\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8079 - accuracy: 0.8023 - val_loss: 0.7276 - val_accuracy: 0.8252\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7940 - accuracy: 0.8064 - val_loss: 0.7198 - val_accuracy: 0.8274\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7780 - accuracy: 0.8120 - val_loss: 0.7157 - val_accuracy: 0.8279\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7724 - accuracy: 0.8101 - val_loss: 0.7028 - val_accuracy: 0.8315\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7589 - accuracy: 0.8144 - val_loss: 0.6953 - val_accuracy: 0.8342\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7500 - accuracy: 0.8180 - val_loss: 0.6909 - val_accuracy: 0.8347\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7423 - accuracy: 0.8186 - val_loss: 0.6877 - val_accuracy: 0.8341\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7361 - accuracy: 0.8211 - val_loss: 0.6826 - val_accuracy: 0.8366\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7287 - accuracy: 0.8231 - val_loss: 0.6799 - val_accuracy: 0.8371\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:53.723812\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7232 - accuracy: 0.8249 - val_loss: 0.6750 - val_accuracy: 0.8376\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7199 - accuracy: 0.8245 - val_loss: 0.6732 - val_accuracy: 0.8381\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7156 - accuracy: 0.8270 - val_loss: 0.6718 - val_accuracy: 0.8396\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7175 - accuracy: 0.8251 - val_loss: 0.6710 - val_accuracy: 0.8395\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7159 - accuracy: 0.8257 - val_loss: 0.6710 - val_accuracy: 0.8396\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7148 - accuracy: 0.8250 - val_loss: 0.6709 - val_accuracy: 0.8395\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:42.158216\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.4729 - accuracy: 0.1687 - val_loss: 2.0015 - val_accuracy: 0.5221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8372 - accuracy: 0.5372 - val_loss: 1.3973 - val_accuracy: 0.6598\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4528 - accuracy: 0.6329 - val_loss: 1.1614 - val_accuracy: 0.7162\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2491 - accuracy: 0.6869 - val_loss: 1.0280 - val_accuracy: 0.7502\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1190 - accuracy: 0.7226 - val_loss: 0.9372 - val_accuracy: 0.7731\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0254 - accuracy: 0.7470 - val_loss: 0.8703 - val_accuracy: 0.7928\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9625 - accuracy: 0.7641 - val_loss: 0.8258 - val_accuracy: 0.8022\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9172 - accuracy: 0.7742 - val_loss: 0.7907 - val_accuracy: 0.8114\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8838 - accuracy: 0.7852 - val_loss: 0.7680 - val_accuracy: 0.8151\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8595 - accuracy: 0.7886 - val_loss: 0.7493 - val_accuracy: 0.8201\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8364 - accuracy: 0.7957 - val_loss: 0.7322 - val_accuracy: 0.8275\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8192 - accuracy: 0.7992 - val_loss: 0.7198 - val_accuracy: 0.8304\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8013 - accuracy: 0.8042 - val_loss: 0.7107 - val_accuracy: 0.8326\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7904 - accuracy: 0.8076 - val_loss: 0.6991 - val_accuracy: 0.8348\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7768 - accuracy: 0.8103 - val_loss: 0.6936 - val_accuracy: 0.8352\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7676 - accuracy: 0.8134 - val_loss: 0.6858 - val_accuracy: 0.8366\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7614 - accuracy: 0.8141 - val_loss: 0.6825 - val_accuracy: 0.8381\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7556 - accuracy: 0.8166 - val_loss: 0.6752 - val_accuracy: 0.8406\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7481 - accuracy: 0.8171 - val_loss: 0.6702 - val_accuracy: 0.8410\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7387 - accuracy: 0.8195 - val_loss: 0.6675 - val_accuracy: 0.8414\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:04.060503\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7315 - accuracy: 0.8213 - val_loss: 0.6637 - val_accuracy: 0.8434\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7303 - accuracy: 0.8224 - val_loss: 0.6626 - val_accuracy: 0.8430\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7249 - accuracy: 0.8253 - val_loss: 0.6607 - val_accuracy: 0.8441\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7278 - accuracy: 0.8238 - val_loss: 0.6605 - val_accuracy: 0.8443\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7261 - accuracy: 0.8227 - val_loss: 0.6601 - val_accuracy: 0.8436\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7256 - accuracy: 0.8244 - val_loss: 0.6600 - val_accuracy: 0.8436\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7258 - accuracy: 0.8233 - val_loss: 0.6600 - val_accuracy: 0.8439\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:09.781243\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6230 - accuracy: 0.1441 - val_loss: 2.1663 - val_accuracy: 0.4947\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9056 - accuracy: 0.5197 - val_loss: 1.4561 - val_accuracy: 0.6500\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4721 - accuracy: 0.6295 - val_loss: 1.1934 - val_accuracy: 0.7147\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2531 - accuracy: 0.6865 - val_loss: 1.0557 - val_accuracy: 0.7493\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1100 - accuracy: 0.7233 - val_loss: 0.9620 - val_accuracy: 0.7711\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0189 - accuracy: 0.7473 - val_loss: 0.8907 - val_accuracy: 0.7869\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9537 - accuracy: 0.7637 - val_loss: 0.8426 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9057 - accuracy: 0.7764 - val_loss: 0.8154 - val_accuracy: 0.8062\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8721 - accuracy: 0.7862 - val_loss: 0.7933 - val_accuracy: 0.8119\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8455 - accuracy: 0.7926 - val_loss: 0.7766 - val_accuracy: 0.8166\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8232 - accuracy: 0.7976 - val_loss: 0.7592 - val_accuracy: 0.8199\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8060 - accuracy: 0.8028 - val_loss: 0.7485 - val_accuracy: 0.8232\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7886 - accuracy: 0.8068 - val_loss: 0.7376 - val_accuracy: 0.8239\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7782 - accuracy: 0.8091 - val_loss: 0.7289 - val_accuracy: 0.8268\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7667 - accuracy: 0.8121 - val_loss: 0.7183 - val_accuracy: 0.8308\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7570 - accuracy: 0.8142 - val_loss: 0.7131 - val_accuracy: 0.8309\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7468 - accuracy: 0.8167 - val_loss: 0.7067 - val_accuracy: 0.8321\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7418 - accuracy: 0.8179 - val_loss: 0.7017 - val_accuracy: 0.8340\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7326 - accuracy: 0.8209 - val_loss: 0.6985 - val_accuracy: 0.8336\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7268 - accuracy: 0.8211 - val_loss: 0.6943 - val_accuracy: 0.8349\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:04.514373\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7212 - accuracy: 0.8239 - val_loss: 0.6893 - val_accuracy: 0.8371\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7181 - accuracy: 0.8247 - val_loss: 0.6890 - val_accuracy: 0.8374\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7136 - accuracy: 0.8258 - val_loss: 0.6870 - val_accuracy: 0.8378\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7132 - accuracy: 0.8262 - val_loss: 0.6874 - val_accuracy: 0.8386\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7128 - accuracy: 0.8270 - val_loss: 0.6871 - val_accuracy: 0.8383\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7116 - accuracy: 0.8270 - val_loss: 0.6870 - val_accuracy: 0.8383\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7127 - accuracy: 0.8260 - val_loss: 0.6869 - val_accuracy: 0.8383\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:10.354554\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.4374 - accuracy: 0.1705 - val_loss: 1.9763 - val_accuracy: 0.5325\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8609 - accuracy: 0.5282 - val_loss: 1.4120 - val_accuracy: 0.6525\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4810 - accuracy: 0.6282 - val_loss: 1.1512 - val_accuracy: 0.7215\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2681 - accuracy: 0.6816 - val_loss: 1.0100 - val_accuracy: 0.7617\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1278 - accuracy: 0.7187 - val_loss: 0.9195 - val_accuracy: 0.7822\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0339 - accuracy: 0.7448 - val_loss: 0.8556 - val_accuracy: 0.7987\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9711 - accuracy: 0.7607 - val_loss: 0.8061 - val_accuracy: 0.8113\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9209 - accuracy: 0.7746 - val_loss: 0.7790 - val_accuracy: 0.8164\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8895 - accuracy: 0.7824 - val_loss: 0.7571 - val_accuracy: 0.8219\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8606 - accuracy: 0.7883 - val_loss: 0.7341 - val_accuracy: 0.8295\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8403 - accuracy: 0.7947 - val_loss: 0.7239 - val_accuracy: 0.8275\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8200 - accuracy: 0.7991 - val_loss: 0.7071 - val_accuracy: 0.8323\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8038 - accuracy: 0.8028 - val_loss: 0.6995 - val_accuracy: 0.8351\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7906 - accuracy: 0.8064 - val_loss: 0.6888 - val_accuracy: 0.8369\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7788 - accuracy: 0.8091 - val_loss: 0.6813 - val_accuracy: 0.8383\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7722 - accuracy: 0.8124 - val_loss: 0.6762 - val_accuracy: 0.8395\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7628 - accuracy: 0.8140 - val_loss: 0.6694 - val_accuracy: 0.8411\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7523 - accuracy: 0.8174 - val_loss: 0.6659 - val_accuracy: 0.8431\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7450 - accuracy: 0.8184 - val_loss: 0.6602 - val_accuracy: 0.8436\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7396 - accuracy: 0.8187 - val_loss: 0.6553 - val_accuracy: 0.8443\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:03.155863\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7314 - accuracy: 0.8230 - val_loss: 0.6536 - val_accuracy: 0.8427\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7281 - accuracy: 0.8232 - val_loss: 0.6506 - val_accuracy: 0.8442\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7240 - accuracy: 0.8241 - val_loss: 0.6500 - val_accuracy: 0.8450\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7239 - accuracy: 0.8237 - val_loss: 0.6495 - val_accuracy: 0.8451\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7283 - accuracy: 0.8225 - val_loss: 0.6494 - val_accuracy: 0.8449\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7267 - accuracy: 0.8227 - val_loss: 0.6493 - val_accuracy: 0.8451\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7240 - accuracy: 0.8237 - val_loss: 0.6493 - val_accuracy: 0.8450\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:09.709404\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6100 - accuracy: 0.1548 - val_loss: 2.1596 - val_accuracy: 0.4911\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9087 - accuracy: 0.5154 - val_loss: 1.4357 - val_accuracy: 0.6521\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4876 - accuracy: 0.6281 - val_loss: 1.1835 - val_accuracy: 0.7148\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2788 - accuracy: 0.6812 - val_loss: 1.0408 - val_accuracy: 0.7527\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1363 - accuracy: 0.7187 - val_loss: 0.9455 - val_accuracy: 0.7728\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0396 - accuracy: 0.7436 - val_loss: 0.8945 - val_accuracy: 0.7857\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9743 - accuracy: 0.7613 - val_loss: 0.8377 - val_accuracy: 0.8037\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9290 - accuracy: 0.7723 - val_loss: 0.8100 - val_accuracy: 0.8094\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8935 - accuracy: 0.7803 - val_loss: 0.7885 - val_accuracy: 0.8137\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8647 - accuracy: 0.7866 - val_loss: 0.7698 - val_accuracy: 0.8181\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8429 - accuracy: 0.7937 - val_loss: 0.7494 - val_accuracy: 0.8224\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8224 - accuracy: 0.7990 - val_loss: 0.7349 - val_accuracy: 0.8264\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8097 - accuracy: 0.8019 - val_loss: 0.7260 - val_accuracy: 0.8262\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7920 - accuracy: 0.8079 - val_loss: 0.7151 - val_accuracy: 0.8293\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7832 - accuracy: 0.8082 - val_loss: 0.7069 - val_accuracy: 0.8323\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7703 - accuracy: 0.8123 - val_loss: 0.6996 - val_accuracy: 0.8337\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7602 - accuracy: 0.8144 - val_loss: 0.6921 - val_accuracy: 0.8360\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7566 - accuracy: 0.8157 - val_loss: 0.6909 - val_accuracy: 0.8359\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7469 - accuracy: 0.8190 - val_loss: 0.6830 - val_accuracy: 0.8362\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7414 - accuracy: 0.8199 - val_loss: 0.6791 - val_accuracy: 0.8391\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:03.254934\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7321 - accuracy: 0.8228 - val_loss: 0.6746 - val_accuracy: 0.8395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7291 - accuracy: 0.8227 - val_loss: 0.6726 - val_accuracy: 0.8400\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7268 - accuracy: 0.8245 - val_loss: 0.6725 - val_accuracy: 0.8402\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7258 - accuracy: 0.8240 - val_loss: 0.6716 - val_accuracy: 0.8408\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7253 - accuracy: 0.8238 - val_loss: 0.6714 - val_accuracy: 0.8404\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7233 - accuracy: 0.8252 - val_loss: 0.6713 - val_accuracy: 0.8405\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7258 - accuracy: 0.8230 - val_loss: 0.6714 - val_accuracy: 0.8408\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:07.037613\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.9868 - accuracy: 0.2918 - val_loss: 1.7198 - val_accuracy: 0.5922\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6385 - accuracy: 0.5928 - val_loss: 1.3194 - val_accuracy: 0.6887\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3453 - accuracy: 0.6680 - val_loss: 1.1201 - val_accuracy: 0.7362\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1538 - accuracy: 0.7161 - val_loss: 0.9828 - val_accuracy: 0.7706\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0275 - accuracy: 0.7508 - val_loss: 0.8882 - val_accuracy: 0.7902\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9431 - accuracy: 0.7701 - val_loss: 0.8270 - val_accuracy: 0.8078\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8834 - accuracy: 0.7851 - val_loss: 0.7897 - val_accuracy: 0.8121\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8434 - accuracy: 0.7961 - val_loss: 0.7632 - val_accuracy: 0.8190\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8132 - accuracy: 0.8039 - val_loss: 0.7453 - val_accuracy: 0.8239\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7879 - accuracy: 0.8114 - val_loss: 0.7226 - val_accuracy: 0.8300\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7689 - accuracy: 0.8143 - val_loss: 0.7087 - val_accuracy: 0.8324\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7533 - accuracy: 0.8181 - val_loss: 0.6994 - val_accuracy: 0.8369\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7377 - accuracy: 0.8219 - val_loss: 0.6919 - val_accuracy: 0.8375\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7244 - accuracy: 0.8269 - val_loss: 0.6811 - val_accuracy: 0.8400\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7158 - accuracy: 0.8266 - val_loss: 0.6730 - val_accuracy: 0.8416\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7064 - accuracy: 0.8299 - val_loss: 0.6676 - val_accuracy: 0.8436\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7008 - accuracy: 0.8322 - val_loss: 0.6611 - val_accuracy: 0.8460\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6938 - accuracy: 0.8326 - val_loss: 0.6537 - val_accuracy: 0.8466\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6859 - accuracy: 0.8354 - val_loss: 0.6529 - val_accuracy: 0.8475\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6846 - accuracy: 0.8352 - val_loss: 0.6476 - val_accuracy: 0.8464\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:04.630622\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6771 - accuracy: 0.8361 - val_loss: 0.6443 - val_accuracy: 0.8480\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6718 - accuracy: 0.8375 - val_loss: 0.6428 - val_accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6703 - accuracy: 0.8393 - val_loss: 0.6419 - val_accuracy: 0.8494\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6693 - accuracy: 0.8393 - val_loss: 0.6416 - val_accuracy: 0.8496\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6672 - accuracy: 0.8395 - val_loss: 0.6414 - val_accuracy: 0.8496\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6711 - accuracy: 0.8401 - val_loss: 0.6414 - val_accuracy: 0.8497\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6674 - accuracy: 0.8393 - val_loss: 0.6413 - val_accuracy: 0.8498\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6693 - accuracy: 0.8403 - val_loss: 0.6413 - val_accuracy: 0.8499\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6696 - accuracy: 0.8394 - val_loss: 0.6413 - val_accuracy: 0.8499\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6671 - accuracy: 0.8388 - val_loss: 0.6413 - val_accuracy: 0.8499\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6691 - accuracy: 0.8399 - val_loss: 0.6413 - val_accuracy: 0.8499\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:58.829982\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1381 - accuracy: 0.2618 - val_loss: 1.7493 - val_accuracy: 0.5845\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6516 - accuracy: 0.5915 - val_loss: 1.3251 - val_accuracy: 0.6894\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3497 - accuracy: 0.6699 - val_loss: 1.1321 - val_accuracy: 0.7329\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1646 - accuracy: 0.7156 - val_loss: 0.9970 - val_accuracy: 0.7655\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0423 - accuracy: 0.7465 - val_loss: 0.8928 - val_accuracy: 0.7907\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9563 - accuracy: 0.7679 - val_loss: 0.8466 - val_accuracy: 0.7999\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8982 - accuracy: 0.7830 - val_loss: 0.8001 - val_accuracy: 0.8108\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8541 - accuracy: 0.7941 - val_loss: 0.7688 - val_accuracy: 0.8213\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8240 - accuracy: 0.8013 - val_loss: 0.7498 - val_accuracy: 0.8231\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7965 - accuracy: 0.8074 - val_loss: 0.7318 - val_accuracy: 0.8293\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7765 - accuracy: 0.8128 - val_loss: 0.7144 - val_accuracy: 0.8345\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7574 - accuracy: 0.8174 - val_loss: 0.6993 - val_accuracy: 0.8367\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7460 - accuracy: 0.8199 - val_loss: 0.6934 - val_accuracy: 0.8391\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7319 - accuracy: 0.8236 - val_loss: 0.6847 - val_accuracy: 0.8389\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7204 - accuracy: 0.8253 - val_loss: 0.6771 - val_accuracy: 0.8426\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7133 - accuracy: 0.8274 - val_loss: 0.6692 - val_accuracy: 0.8435\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7045 - accuracy: 0.8289 - val_loss: 0.6666 - val_accuracy: 0.8461\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6963 - accuracy: 0.8310 - val_loss: 0.6621 - val_accuracy: 0.8438\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6914 - accuracy: 0.8334 - val_loss: 0.6535 - val_accuracy: 0.8467\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6838 - accuracy: 0.8348 - val_loss: 0.6499 - val_accuracy: 0.8487\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:02.955678\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6789 - accuracy: 0.8351 - val_loss: 0.6464 - val_accuracy: 0.8487\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6746 - accuracy: 0.8380 - val_loss: 0.6448 - val_accuracy: 0.8496\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6723 - accuracy: 0.8381 - val_loss: 0.6445 - val_accuracy: 0.8488\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6740 - accuracy: 0.8373 - val_loss: 0.6440 - val_accuracy: 0.8493\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6726 - accuracy: 0.8386 - val_loss: 0.6439 - val_accuracy: 0.8497\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6720 - accuracy: 0.8387 - val_loss: 0.6438 - val_accuracy: 0.8498\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6720 - accuracy: 0.8373 - val_loss: 0.6438 - val_accuracy: 0.8497\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6722 - accuracy: 0.8380 - val_loss: 0.6438 - val_accuracy: 0.8497\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6736 - accuracy: 0.8369 - val_loss: 0.6438 - val_accuracy: 0.8497\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:03.887035\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.0142 - accuracy: 0.2853 - val_loss: 1.7364 - val_accuracy: 0.5865\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6383 - accuracy: 0.5936 - val_loss: 1.3525 - val_accuracy: 0.6744\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3574 - accuracy: 0.6633 - val_loss: 1.1601 - val_accuracy: 0.7191\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1812 - accuracy: 0.7104 - val_loss: 1.0253 - val_accuracy: 0.7588\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0619 - accuracy: 0.7407 - val_loss: 0.9393 - val_accuracy: 0.7774\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9743 - accuracy: 0.7627 - val_loss: 0.8679 - val_accuracy: 0.7960\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9152 - accuracy: 0.7781 - val_loss: 0.8307 - val_accuracy: 0.8051\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8706 - accuracy: 0.7892 - val_loss: 0.7976 - val_accuracy: 0.8116\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8370 - accuracy: 0.7970 - val_loss: 0.7725 - val_accuracy: 0.8196\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8099 - accuracy: 0.8037 - val_loss: 0.7572 - val_accuracy: 0.8219\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7898 - accuracy: 0.8115 - val_loss: 0.7411 - val_accuracy: 0.8252\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7702 - accuracy: 0.8143 - val_loss: 0.7228 - val_accuracy: 0.8297\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7551 - accuracy: 0.8174 - val_loss: 0.7137 - val_accuracy: 0.8327\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7434 - accuracy: 0.8201 - val_loss: 0.7040 - val_accuracy: 0.8350\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7327 - accuracy: 0.8226 - val_loss: 0.6947 - val_accuracy: 0.8363\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7236 - accuracy: 0.8248 - val_loss: 0.6928 - val_accuracy: 0.8361\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7165 - accuracy: 0.8280 - val_loss: 0.6820 - val_accuracy: 0.8391\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7054 - accuracy: 0.8299 - val_loss: 0.6778 - val_accuracy: 0.8402\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6989 - accuracy: 0.8306 - val_loss: 0.6710 - val_accuracy: 0.8426\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6925 - accuracy: 0.8334 - val_loss: 0.6708 - val_accuracy: 0.8413\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:01.913716\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6869 - accuracy: 0.8346 - val_loss: 0.6663 - val_accuracy: 0.8434\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6819 - accuracy: 0.8360 - val_loss: 0.6642 - val_accuracy: 0.8430\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6830 - accuracy: 0.8354 - val_loss: 0.6633 - val_accuracy: 0.8434\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6801 - accuracy: 0.8349 - val_loss: 0.6630 - val_accuracy: 0.8435\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6812 - accuracy: 0.8366 - val_loss: 0.6629 - val_accuracy: 0.8434\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6815 - accuracy: 0.8353 - val_loss: 0.6628 - val_accuracy: 0.8435\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6811 - accuracy: 0.8355 - val_loss: 0.6628 - val_accuracy: 0.8434\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:09.792202\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.0220 - accuracy: 0.2888 - val_loss: 1.7204 - val_accuracy: 0.5912\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6474 - accuracy: 0.5911 - val_loss: 1.3278 - val_accuracy: 0.6788\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3480 - accuracy: 0.6670 - val_loss: 1.1149 - val_accuracy: 0.7334\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1561 - accuracy: 0.7149 - val_loss: 0.9706 - val_accuracy: 0.7685\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0280 - accuracy: 0.7493 - val_loss: 0.8803 - val_accuracy: 0.7877\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9412 - accuracy: 0.7725 - val_loss: 0.8224 - val_accuracy: 0.8031\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8869 - accuracy: 0.7846 - val_loss: 0.7821 - val_accuracy: 0.8141\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8453 - accuracy: 0.7961 - val_loss: 0.7554 - val_accuracy: 0.8205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8152 - accuracy: 0.8030 - val_loss: 0.7293 - val_accuracy: 0.8272\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7920 - accuracy: 0.8097 - val_loss: 0.7202 - val_accuracy: 0.8281\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7719 - accuracy: 0.8137 - val_loss: 0.7048 - val_accuracy: 0.8314\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7566 - accuracy: 0.8161 - val_loss: 0.6928 - val_accuracy: 0.8348\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7426 - accuracy: 0.8216 - val_loss: 0.6849 - val_accuracy: 0.8370\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7312 - accuracy: 0.8229 - val_loss: 0.6736 - val_accuracy: 0.8404\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7200 - accuracy: 0.8252 - val_loss: 0.6677 - val_accuracy: 0.8429\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7120 - accuracy: 0.8289 - val_loss: 0.6629 - val_accuracy: 0.8416\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7022 - accuracy: 0.8310 - val_loss: 0.6566 - val_accuracy: 0.8444\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7005 - accuracy: 0.8308 - val_loss: 0.6501 - val_accuracy: 0.8447\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6910 - accuracy: 0.8332 - val_loss: 0.6461 - val_accuracy: 0.8462\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6846 - accuracy: 0.8356 - val_loss: 0.6436 - val_accuracy: 0.8469\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:02.564248\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6802 - accuracy: 0.8363 - val_loss: 0.6395 - val_accuracy: 0.8479\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6758 - accuracy: 0.8375 - val_loss: 0.6383 - val_accuracy: 0.8482\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6735 - accuracy: 0.8387 - val_loss: 0.6374 - val_accuracy: 0.8489\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6747 - accuracy: 0.8385 - val_loss: 0.6372 - val_accuracy: 0.8481\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6718 - accuracy: 0.8392 - val_loss: 0.6370 - val_accuracy: 0.8483\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6731 - accuracy: 0.8374 - val_loss: 0.6369 - val_accuracy: 0.8482\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:42.622209\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.0163 - accuracy: 0.2943 - val_loss: 1.7329 - val_accuracy: 0.5888\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6179 - accuracy: 0.5992 - val_loss: 1.3098 - val_accuracy: 0.6884\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3045 - accuracy: 0.6804 - val_loss: 1.0943 - val_accuracy: 0.7423\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1168 - accuracy: 0.7271 - val_loss: 0.9520 - val_accuracy: 0.7781\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0014 - accuracy: 0.7576 - val_loss: 0.8761 - val_accuracy: 0.7961\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9212 - accuracy: 0.7765 - val_loss: 0.8161 - val_accuracy: 0.8091\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8716 - accuracy: 0.7887 - val_loss: 0.7838 - val_accuracy: 0.8165\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8337 - accuracy: 0.8002 - val_loss: 0.7560 - val_accuracy: 0.8256\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8028 - accuracy: 0.8070 - val_loss: 0.7341 - val_accuracy: 0.8307\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7834 - accuracy: 0.8121 - val_loss: 0.7179 - val_accuracy: 0.8323\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7604 - accuracy: 0.8172 - val_loss: 0.7004 - val_accuracy: 0.8372\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7468 - accuracy: 0.8205 - val_loss: 0.6909 - val_accuracy: 0.8403\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7324 - accuracy: 0.8240 - val_loss: 0.6834 - val_accuracy: 0.8419\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7207 - accuracy: 0.8271 - val_loss: 0.6731 - val_accuracy: 0.8436\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7112 - accuracy: 0.8294 - val_loss: 0.6665 - val_accuracy: 0.8453\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7044 - accuracy: 0.8318 - val_loss: 0.6594 - val_accuracy: 0.8472\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6959 - accuracy: 0.8318 - val_loss: 0.6565 - val_accuracy: 0.8479\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6877 - accuracy: 0.8341 - val_loss: 0.6504 - val_accuracy: 0.8489\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6830 - accuracy: 0.8351 - val_loss: 0.6461 - val_accuracy: 0.8504\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6792 - accuracy: 0.8361 - val_loss: 0.6434 - val_accuracy: 0.8496\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:06.149945\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6731 - accuracy: 0.8387 - val_loss: 0.6404 - val_accuracy: 0.8512\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6685 - accuracy: 0.8387 - val_loss: 0.6383 - val_accuracy: 0.8515\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6666 - accuracy: 0.8403 - val_loss: 0.6376 - val_accuracy: 0.8519\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6653 - accuracy: 0.8408 - val_loss: 0.6369 - val_accuracy: 0.8514\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6661 - accuracy: 0.8407 - val_loss: 0.6369 - val_accuracy: 0.8512\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6649 - accuracy: 0.8416 - val_loss: 0.6369 - val_accuracy: 0.8513\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:44.767787\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5320 - accuracy: 0.1655 - val_loss: 2.0298 - val_accuracy: 0.5443\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8330 - accuracy: 0.5427 - val_loss: 1.4041 - val_accuracy: 0.6632\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4422 - accuracy: 0.6423 - val_loss: 1.1832 - val_accuracy: 0.7156\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2352 - accuracy: 0.6951 - val_loss: 1.0042 - val_accuracy: 0.7633\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1001 - accuracy: 0.7294 - val_loss: 0.9174 - val_accuracy: 0.7846\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0064 - accuracy: 0.7528 - val_loss: 0.8564 - val_accuracy: 0.7981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9425 - accuracy: 0.7711 - val_loss: 0.8121 - val_accuracy: 0.8085\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8980 - accuracy: 0.7817 - val_loss: 0.7799 - val_accuracy: 0.8170\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8626 - accuracy: 0.7908 - val_loss: 0.7635 - val_accuracy: 0.8181\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8363 - accuracy: 0.7969 - val_loss: 0.7438 - val_accuracy: 0.8247\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8166 - accuracy: 0.8035 - val_loss: 0.7265 - val_accuracy: 0.8305\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7966 - accuracy: 0.8069 - val_loss: 0.7102 - val_accuracy: 0.8351\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7850 - accuracy: 0.8095 - val_loss: 0.7015 - val_accuracy: 0.8373\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7705 - accuracy: 0.8129 - val_loss: 0.6905 - val_accuracy: 0.8373\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7580 - accuracy: 0.8172 - val_loss: 0.6858 - val_accuracy: 0.8379\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7494 - accuracy: 0.8193 - val_loss: 0.6814 - val_accuracy: 0.8385\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7396 - accuracy: 0.8215 - val_loss: 0.6732 - val_accuracy: 0.8413\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7325 - accuracy: 0.8227 - val_loss: 0.6678 - val_accuracy: 0.8431\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7285 - accuracy: 0.8247 - val_loss: 0.6621 - val_accuracy: 0.8437\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7193 - accuracy: 0.8263 - val_loss: 0.6589 - val_accuracy: 0.8441\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:27.888854\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7153 - accuracy: 0.8286 - val_loss: 0.6552 - val_accuracy: 0.8456\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7083 - accuracy: 0.8302 - val_loss: 0.6529 - val_accuracy: 0.8471\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7092 - accuracy: 0.8296 - val_loss: 0.6524 - val_accuracy: 0.8456\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7068 - accuracy: 0.8301 - val_loss: 0.6519 - val_accuracy: 0.8465\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7071 - accuracy: 0.8301 - val_loss: 0.6517 - val_accuracy: 0.8464\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:21.844503\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3173 - accuracy: 0.2154 - val_loss: 1.9170 - val_accuracy: 0.5377\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7654 - accuracy: 0.5577 - val_loss: 1.4122 - val_accuracy: 0.6600\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4217 - accuracy: 0.6484 - val_loss: 1.1800 - val_accuracy: 0.7168\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2286 - accuracy: 0.6954 - val_loss: 1.0314 - val_accuracy: 0.7534\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0923 - accuracy: 0.7314 - val_loss: 0.9408 - val_accuracy: 0.7797\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0020 - accuracy: 0.7550 - val_loss: 0.8837 - val_accuracy: 0.7889\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9375 - accuracy: 0.7705 - val_loss: 0.8350 - val_accuracy: 0.8020\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8955 - accuracy: 0.7826 - val_loss: 0.8015 - val_accuracy: 0.8132\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8611 - accuracy: 0.7900 - val_loss: 0.7818 - val_accuracy: 0.8144\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8308 - accuracy: 0.7992 - val_loss: 0.7625 - val_accuracy: 0.8203\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8135 - accuracy: 0.8020 - val_loss: 0.7434 - val_accuracy: 0.8256\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7938 - accuracy: 0.8070 - val_loss: 0.7383 - val_accuracy: 0.8270\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7787 - accuracy: 0.8115 - val_loss: 0.7240 - val_accuracy: 0.8302\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7656 - accuracy: 0.8132 - val_loss: 0.7151 - val_accuracy: 0.8327\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7557 - accuracy: 0.8168 - val_loss: 0.7078 - val_accuracy: 0.8330\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7473 - accuracy: 0.8194 - val_loss: 0.6992 - val_accuracy: 0.8355\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7380 - accuracy: 0.8201 - val_loss: 0.6918 - val_accuracy: 0.8358\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7294 - accuracy: 0.8233 - val_loss: 0.6899 - val_accuracy: 0.8382\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7250 - accuracy: 0.8237 - val_loss: 0.6839 - val_accuracy: 0.8388\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7210 - accuracy: 0.8247 - val_loss: 0.6819 - val_accuracy: 0.8394\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:27.768516\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7126 - accuracy: 0.8271 - val_loss: 0.6769 - val_accuracy: 0.8421\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7072 - accuracy: 0.8275 - val_loss: 0.6753 - val_accuracy: 0.8417\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7068 - accuracy: 0.8279 - val_loss: 0.6745 - val_accuracy: 0.8421\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7057 - accuracy: 0.8290 - val_loss: 0.6740 - val_accuracy: 0.8417\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:01:53.572901\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4108 - accuracy: 0.1890 - val_loss: 1.9373 - val_accuracy: 0.5408\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8003 - accuracy: 0.5474 - val_loss: 1.4092 - val_accuracy: 0.6573\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4522 - accuracy: 0.6397 - val_loss: 1.1960 - val_accuracy: 0.7169\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2534 - accuracy: 0.6891 - val_loss: 1.0541 - val_accuracy: 0.7464\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1150 - accuracy: 0.7252 - val_loss: 0.9388 - val_accuracy: 0.7844\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0130 - accuracy: 0.7515 - val_loss: 0.8720 - val_accuracy: 0.7967\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9490 - accuracy: 0.7678 - val_loss: 0.8316 - val_accuracy: 0.8073\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9013 - accuracy: 0.7794 - val_loss: 0.8060 - val_accuracy: 0.8089\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8667 - accuracy: 0.7904 - val_loss: 0.7781 - val_accuracy: 0.8186\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8363 - accuracy: 0.7964 - val_loss: 0.7535 - val_accuracy: 0.8238\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8163 - accuracy: 0.8021 - val_loss: 0.7413 - val_accuracy: 0.8274\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7980 - accuracy: 0.8075 - val_loss: 0.7252 - val_accuracy: 0.8318\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7828 - accuracy: 0.8102 - val_loss: 0.7162 - val_accuracy: 0.8323\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7697 - accuracy: 0.8129 - val_loss: 0.7096 - val_accuracy: 0.8356\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7579 - accuracy: 0.8171 - val_loss: 0.7014 - val_accuracy: 0.8383\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7506 - accuracy: 0.8177 - val_loss: 0.6962 - val_accuracy: 0.8390\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7411 - accuracy: 0.8209 - val_loss: 0.6876 - val_accuracy: 0.8394\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7321 - accuracy: 0.8217 - val_loss: 0.6817 - val_accuracy: 0.8408\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7270 - accuracy: 0.8227 - val_loss: 0.6753 - val_accuracy: 0.8448\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7217 - accuracy: 0.8254 - val_loss: 0.6725 - val_accuracy: 0.8449\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:25.299256\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7142 - accuracy: 0.8275 - val_loss: 0.6712 - val_accuracy: 0.8450\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7080 - accuracy: 0.8286 - val_loss: 0.6684 - val_accuracy: 0.8458\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7070 - accuracy: 0.8282 - val_loss: 0.6672 - val_accuracy: 0.8461\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7079 - accuracy: 0.8283 - val_loss: 0.6668 - val_accuracy: 0.8460\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7067 - accuracy: 0.8290 - val_loss: 0.6666 - val_accuracy: 0.8463\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7055 - accuracy: 0.8302 - val_loss: 0.6665 - val_accuracy: 0.8463\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7083 - accuracy: 0.8288 - val_loss: 0.6665 - val_accuracy: 0.8465\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7064 - accuracy: 0.8288 - val_loss: 0.6665 - val_accuracy: 0.8465\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7056 - accuracy: 0.8294 - val_loss: 0.6665 - val_accuracy: 0.8465\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7076 - accuracy: 0.8297 - val_loss: 0.6665 - val_accuracy: 0.8465\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:40.622631\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4565 - accuracy: 0.1719 - val_loss: 2.0173 - val_accuracy: 0.5080\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8168 - accuracy: 0.5414 - val_loss: 1.3837 - val_accuracy: 0.6722\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4457 - accuracy: 0.6391 - val_loss: 1.2006 - val_accuracy: 0.7069\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2425 - accuracy: 0.6927 - val_loss: 1.0338 - val_accuracy: 0.7530\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1036 - accuracy: 0.7290 - val_loss: 0.9321 - val_accuracy: 0.7789\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0090 - accuracy: 0.7535 - val_loss: 0.8620 - val_accuracy: 0.7987\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9436 - accuracy: 0.7691 - val_loss: 0.8209 - val_accuracy: 0.8091\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8972 - accuracy: 0.7807 - val_loss: 0.7957 - val_accuracy: 0.8122\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8652 - accuracy: 0.7898 - val_loss: 0.7692 - val_accuracy: 0.8208\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8400 - accuracy: 0.7963 - val_loss: 0.7466 - val_accuracy: 0.8250\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8169 - accuracy: 0.8022 - val_loss: 0.7302 - val_accuracy: 0.8305\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7963 - accuracy: 0.8078 - val_loss: 0.7197 - val_accuracy: 0.8321\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7855 - accuracy: 0.8098 - val_loss: 0.7081 - val_accuracy: 0.8326\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7725 - accuracy: 0.8119 - val_loss: 0.6993 - val_accuracy: 0.8376\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7611 - accuracy: 0.8154 - val_loss: 0.6931 - val_accuracy: 0.8367\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7489 - accuracy: 0.8195 - val_loss: 0.6859 - val_accuracy: 0.8380\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7421 - accuracy: 0.8207 - val_loss: 0.6813 - val_accuracy: 0.8401\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7336 - accuracy: 0.8222 - val_loss: 0.6761 - val_accuracy: 0.8408\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7303 - accuracy: 0.8234 - val_loss: 0.6690 - val_accuracy: 0.8424\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7248 - accuracy: 0.8238 - val_loss: 0.6692 - val_accuracy: 0.8428\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:22.452647\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7164 - accuracy: 0.8284 - val_loss: 0.6626 - val_accuracy: 0.8431\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7127 - accuracy: 0.8288 - val_loss: 0.6605 - val_accuracy: 0.8439\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7120 - accuracy: 0.8289 - val_loss: 0.6598 - val_accuracy: 0.8445\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7112 - accuracy: 0.8288 - val_loss: 0.6593 - val_accuracy: 0.8446\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7093 - accuracy: 0.8288 - val_loss: 0.6589 - val_accuracy: 0.8449\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7108 - accuracy: 0.8292 - val_loss: 0.6589 - val_accuracy: 0.8449\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7101 - accuracy: 0.8285 - val_loss: 0.6589 - val_accuracy: 0.8449\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7097 - accuracy: 0.8294 - val_loss: 0.6589 - val_accuracy: 0.8449\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:44.057409\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4062 - accuracy: 0.1889 - val_loss: 1.9635 - val_accuracy: 0.5308\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7798 - accuracy: 0.5554 - val_loss: 1.4083 - val_accuracy: 0.6618\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4351 - accuracy: 0.6440 - val_loss: 1.2158 - val_accuracy: 0.7044\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2476 - accuracy: 0.6932 - val_loss: 1.0711 - val_accuracy: 0.7420\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1177 - accuracy: 0.7241 - val_loss: 0.9847 - val_accuracy: 0.7621\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0167 - accuracy: 0.7516 - val_loss: 0.9092 - val_accuracy: 0.7811\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9540 - accuracy: 0.7684 - val_loss: 0.8653 - val_accuracy: 0.7914\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9046 - accuracy: 0.7816 - val_loss: 0.8261 - val_accuracy: 0.8013\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8682 - accuracy: 0.7913 - val_loss: 0.7974 - val_accuracy: 0.8064\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8376 - accuracy: 0.7976 - val_loss: 0.7831 - val_accuracy: 0.8098\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8172 - accuracy: 0.8029 - val_loss: 0.7641 - val_accuracy: 0.8155\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7983 - accuracy: 0.8073 - val_loss: 0.7494 - val_accuracy: 0.8188\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7824 - accuracy: 0.8108 - val_loss: 0.7370 - val_accuracy: 0.8220\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7672 - accuracy: 0.8159 - val_loss: 0.7312 - val_accuracy: 0.8225\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7560 - accuracy: 0.8177 - val_loss: 0.7190 - val_accuracy: 0.8270\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7472 - accuracy: 0.8207 - val_loss: 0.7166 - val_accuracy: 0.8264\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7382 - accuracy: 0.8220 - val_loss: 0.7066 - val_accuracy: 0.8294\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7309 - accuracy: 0.8254 - val_loss: 0.7020 - val_accuracy: 0.8300\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7229 - accuracy: 0.8263 - val_loss: 0.6961 - val_accuracy: 0.8306\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7182 - accuracy: 0.8275 - val_loss: 0.6954 - val_accuracy: 0.8312\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:21.033752\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7128 - accuracy: 0.8293 - val_loss: 0.6900 - val_accuracy: 0.8334\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7069 - accuracy: 0.8307 - val_loss: 0.6876 - val_accuracy: 0.8334\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7047 - accuracy: 0.8303 - val_loss: 0.6862 - val_accuracy: 0.8339\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7042 - accuracy: 0.8315 - val_loss: 0.6859 - val_accuracy: 0.8336\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7042 - accuracy: 0.8313 - val_loss: 0.6857 - val_accuracy: 0.8338\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7046 - accuracy: 0.8318 - val_loss: 0.6856 - val_accuracy: 0.8336\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:50.456829\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.1999 - accuracy: 0.2044 - val_loss: 1.7351 - val_accuracy: 0.5085\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3827 - accuracy: 0.6026 - val_loss: 1.2010 - val_accuracy: 0.6483\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0447 - accuracy: 0.6909 - val_loss: 0.9262 - val_accuracy: 0.7207\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8531 - accuracy: 0.7418 - val_loss: 0.7748 - val_accuracy: 0.7623\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7341 - accuracy: 0.7723 - val_loss: 0.6809 - val_accuracy: 0.7875\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6568 - accuracy: 0.7920 - val_loss: 0.6333 - val_accuracy: 0.7990\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6066 - accuracy: 0.8075 - val_loss: 0.5976 - val_accuracy: 0.8067\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5722 - accuracy: 0.8172 - val_loss: 0.5665 - val_accuracy: 0.8173\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5469 - accuracy: 0.8235 - val_loss: 0.5484 - val_accuracy: 0.8231\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5259 - accuracy: 0.8305 - val_loss: 0.5366 - val_accuracy: 0.8264\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5106 - accuracy: 0.8340 - val_loss: 0.5197 - val_accuracy: 0.8310\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4974 - accuracy: 0.8380 - val_loss: 0.5138 - val_accuracy: 0.8318\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4852 - accuracy: 0.8413 - val_loss: 0.5012 - val_accuracy: 0.8357\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4762 - accuracy: 0.8432 - val_loss: 0.4976 - val_accuracy: 0.8366\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4678 - accuracy: 0.8466 - val_loss: 0.4918 - val_accuracy: 0.8381\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4610 - accuracy: 0.8481 - val_loss: 0.4829 - val_accuracy: 0.8431\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4550 - accuracy: 0.8503 - val_loss: 0.4829 - val_accuracy: 0.8421\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4495 - accuracy: 0.8516 - val_loss: 0.4760 - val_accuracy: 0.8418\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4446 - accuracy: 0.8540 - val_loss: 0.4712 - val_accuracy: 0.8452\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4403 - accuracy: 0.8546 - val_loss: 0.4709 - val_accuracy: 0.8457\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:43.023571\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4333 - accuracy: 0.8575 - val_loss: 0.4686 - val_accuracy: 0.8455\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4295 - accuracy: 0.8588 - val_loss: 0.4653 - val_accuracy: 0.8483\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4276 - accuracy: 0.8593 - val_loss: 0.4638 - val_accuracy: 0.8486\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4265 - accuracy: 0.8599 - val_loss: 0.4637 - val_accuracy: 0.8477\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4260 - accuracy: 0.8597 - val_loss: 0.4634 - val_accuracy: 0.8479\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4257 - accuracy: 0.8599 - val_loss: 0.4634 - val_accuracy: 0.8475\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:37.314338\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.1879 - accuracy: 0.1965 - val_loss: 1.7513 - val_accuracy: 0.5015\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3945 - accuracy: 0.5959 - val_loss: 1.1829 - val_accuracy: 0.6528\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0419 - accuracy: 0.6907 - val_loss: 0.9479 - val_accuracy: 0.7137\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8454 - accuracy: 0.7408 - val_loss: 0.7883 - val_accuracy: 0.7573\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7211 - accuracy: 0.7735 - val_loss: 0.6885 - val_accuracy: 0.7798\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6398 - accuracy: 0.7972 - val_loss: 0.6491 - val_accuracy: 0.7893\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5904 - accuracy: 0.8111 - val_loss: 0.5997 - val_accuracy: 0.8069\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5566 - accuracy: 0.8198 - val_loss: 0.5688 - val_accuracy: 0.8156\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5324 - accuracy: 0.8264 - val_loss: 0.5644 - val_accuracy: 0.8169\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5122 - accuracy: 0.8333 - val_loss: 0.5430 - val_accuracy: 0.8216\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4964 - accuracy: 0.8371 - val_loss: 0.5285 - val_accuracy: 0.8277\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4838 - accuracy: 0.8405 - val_loss: 0.5295 - val_accuracy: 0.8280\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4728 - accuracy: 0.8441 - val_loss: 0.5134 - val_accuracy: 0.8317\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4642 - accuracy: 0.8478 - val_loss: 0.5067 - val_accuracy: 0.8327\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4567 - accuracy: 0.8486 - val_loss: 0.5005 - val_accuracy: 0.8371\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4500 - accuracy: 0.8505 - val_loss: 0.4984 - val_accuracy: 0.8355\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4434 - accuracy: 0.8526 - val_loss: 0.4943 - val_accuracy: 0.8363\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4382 - accuracy: 0.8546 - val_loss: 0.4891 - val_accuracy: 0.8370\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:07:52.469152\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4428 - accuracy: 0.8543 - val_loss: 0.4923 - val_accuracy: 0.8382\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4378 - accuracy: 0.8560 - val_loss: 0.4910 - val_accuracy: 0.8385\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4354 - accuracy: 0.8566 - val_loss: 0.4895 - val_accuracy: 0.8393\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4342 - accuracy: 0.8568 - val_loss: 0.4892 - val_accuracy: 0.8395\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4335 - accuracy: 0.8573 - val_loss: 0.4891 - val_accuracy: 0.8391\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4332 - accuracy: 0.8574 - val_loss: 0.4890 - val_accuracy: 0.8392\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4330 - accuracy: 0.8576 - val_loss: 0.4890 - val_accuracy: 0.8392\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:04.590613\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.1298 - accuracy: 0.2105 - val_loss: 1.6202 - val_accuracy: 0.5375\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3718 - accuracy: 0.6011 - val_loss: 1.1733 - val_accuracy: 0.6589\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0497 - accuracy: 0.6872 - val_loss: 0.9819 - val_accuracy: 0.7078\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8617 - accuracy: 0.7377 - val_loss: 0.8130 - val_accuracy: 0.7512\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7413 - accuracy: 0.7691 - val_loss: 0.7153 - val_accuracy: 0.7782\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6596 - accuracy: 0.7914 - val_loss: 0.6624 - val_accuracy: 0.7844\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6093 - accuracy: 0.8037 - val_loss: 0.6204 - val_accuracy: 0.8009\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5741 - accuracy: 0.8140 - val_loss: 0.5957 - val_accuracy: 0.8054\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5472 - accuracy: 0.8220 - val_loss: 0.5710 - val_accuracy: 0.8157\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5262 - accuracy: 0.8271 - val_loss: 0.5605 - val_accuracy: 0.8169\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5097 - accuracy: 0.8324 - val_loss: 0.5443 - val_accuracy: 0.8220\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4963 - accuracy: 0.8367 - val_loss: 0.5366 - val_accuracy: 0.8238\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4846 - accuracy: 0.8402 - val_loss: 0.5278 - val_accuracy: 0.8227\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4754 - accuracy: 0.8437 - val_loss: 0.5170 - val_accuracy: 0.8296\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4668 - accuracy: 0.8459 - val_loss: 0.5102 - val_accuracy: 0.8316\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4597 - accuracy: 0.8482 - val_loss: 0.5077 - val_accuracy: 0.8302\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4536 - accuracy: 0.8497 - val_loss: 0.5024 - val_accuracy: 0.8360\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4481 - accuracy: 0.8507 - val_loss: 0.4949 - val_accuracy: 0.8361\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4429 - accuracy: 0.8528 - val_loss: 0.4931 - val_accuracy: 0.8362\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4388 - accuracy: 0.8546 - val_loss: 0.4902 - val_accuracy: 0.8397\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:45.986064\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4317 - accuracy: 0.8568 - val_loss: 0.4863 - val_accuracy: 0.8386\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4277 - accuracy: 0.8587 - val_loss: 0.4847 - val_accuracy: 0.8394\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4258 - accuracy: 0.8591 - val_loss: 0.4831 - val_accuracy: 0.8415\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4248 - accuracy: 0.8595 - val_loss: 0.4824 - val_accuracy: 0.8426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4242 - accuracy: 0.8601 - val_loss: 0.4825 - val_accuracy: 0.8416\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4239 - accuracy: 0.8600 - val_loss: 0.4824 - val_accuracy: 0.8422\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4238 - accuracy: 0.8601 - val_loss: 0.4824 - val_accuracy: 0.8424\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:04.664527\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.3085 - accuracy: 0.1733 - val_loss: 1.8061 - val_accuracy: 0.4897\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3797 - accuracy: 0.5982 - val_loss: 1.2070 - val_accuracy: 0.6338\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0139 - accuracy: 0.6958 - val_loss: 0.8860 - val_accuracy: 0.7337\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8239 - accuracy: 0.7460 - val_loss: 0.7485 - val_accuracy: 0.7696\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7104 - accuracy: 0.7768 - val_loss: 0.6859 - val_accuracy: 0.7802\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6376 - accuracy: 0.7972 - val_loss: 0.6211 - val_accuracy: 0.8020\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5909 - accuracy: 0.8107 - val_loss: 0.5921 - val_accuracy: 0.8068\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5583 - accuracy: 0.8194 - val_loss: 0.5595 - val_accuracy: 0.8201\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5356 - accuracy: 0.8264 - val_loss: 0.5491 - val_accuracy: 0.8202\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5164 - accuracy: 0.8309 - val_loss: 0.5337 - val_accuracy: 0.8246\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5016 - accuracy: 0.8359 - val_loss: 0.5168 - val_accuracy: 0.8313\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4888 - accuracy: 0.8393 - val_loss: 0.5103 - val_accuracy: 0.8331\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4789 - accuracy: 0.8424 - val_loss: 0.5032 - val_accuracy: 0.8341\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4691 - accuracy: 0.8461 - val_loss: 0.4940 - val_accuracy: 0.8369\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4615 - accuracy: 0.8475 - val_loss: 0.4902 - val_accuracy: 0.8397\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4548 - accuracy: 0.8504 - val_loss: 0.4830 - val_accuracy: 0.8402\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4491 - accuracy: 0.8518 - val_loss: 0.4827 - val_accuracy: 0.8394\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4434 - accuracy: 0.8535 - val_loss: 0.4815 - val_accuracy: 0.8415\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4394 - accuracy: 0.8542 - val_loss: 0.4745 - val_accuracy: 0.8435\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4354 - accuracy: 0.8555 - val_loss: 0.4752 - val_accuracy: 0.8409\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:43.739701\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4286 - accuracy: 0.8586 - val_loss: 0.4698 - val_accuracy: 0.8454\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4248 - accuracy: 0.8596 - val_loss: 0.4675 - val_accuracy: 0.8449\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4230 - accuracy: 0.8605 - val_loss: 0.4663 - val_accuracy: 0.8460\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4220 - accuracy: 0.8609 - val_loss: 0.4653 - val_accuracy: 0.8463\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4214 - accuracy: 0.8611 - val_loss: 0.4652 - val_accuracy: 0.8465\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4212 - accuracy: 0.8611 - val_loss: 0.4652 - val_accuracy: 0.8466\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4210 - accuracy: 0.8610 - val_loss: 0.4651 - val_accuracy: 0.8466\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4210 - accuracy: 0.8610 - val_loss: 0.4651 - val_accuracy: 0.8465\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4210 - accuracy: 0.8611 - val_loss: 0.4651 - val_accuracy: 0.8466\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:56.833209\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.9841 - accuracy: 0.2388 - val_loss: 1.6621 - val_accuracy: 0.5248\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3392 - accuracy: 0.6123 - val_loss: 1.1823 - val_accuracy: 0.6488\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0391 - accuracy: 0.6924 - val_loss: 0.9826 - val_accuracy: 0.7097\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8590 - accuracy: 0.7403 - val_loss: 0.8135 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7411 - accuracy: 0.7704 - val_loss: 0.7107 - val_accuracy: 0.7785\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6636 - accuracy: 0.7900 - val_loss: 0.6707 - val_accuracy: 0.7860\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.6116 - accuracy: 0.8043 - val_loss: 0.6260 - val_accuracy: 0.8010\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5744 - accuracy: 0.8150 - val_loss: 0.6046 - val_accuracy: 0.8042\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5487 - accuracy: 0.8224 - val_loss: 0.5646 - val_accuracy: 0.8187\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5277 - accuracy: 0.8274 - val_loss: 0.5602 - val_accuracy: 0.8164\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.5113 - accuracy: 0.8329 - val_loss: 0.5424 - val_accuracy: 0.8251\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4975 - accuracy: 0.8365 - val_loss: 0.5436 - val_accuracy: 0.8233\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4856 - accuracy: 0.8407 - val_loss: 0.5288 - val_accuracy: 0.8258\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4753 - accuracy: 0.8434 - val_loss: 0.5209 - val_accuracy: 0.8297\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4667 - accuracy: 0.8458 - val_loss: 0.5156 - val_accuracy: 0.8318\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4597 - accuracy: 0.8482 - val_loss: 0.5185 - val_accuracy: 0.8282\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4526 - accuracy: 0.8511 - val_loss: 0.5049 - val_accuracy: 0.8336\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4475 - accuracy: 0.8515 - val_loss: 0.5021 - val_accuracy: 0.8348\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4423 - accuracy: 0.8539 - val_loss: 0.4969 - val_accuracy: 0.8371\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4378 - accuracy: 0.8558 - val_loss: 0.4965 - val_accuracy: 0.8371\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:46.585749\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4305 - accuracy: 0.8578 - val_loss: 0.4925 - val_accuracy: 0.8382\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4268 - accuracy: 0.8603 - val_loss: 0.4894 - val_accuracy: 0.8384\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4249 - accuracy: 0.8605 - val_loss: 0.4883 - val_accuracy: 0.8385\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4239 - accuracy: 0.8603 - val_loss: 0.4883 - val_accuracy: 0.8395\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4233 - accuracy: 0.8608 - val_loss: 0.4882 - val_accuracy: 0.8396\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4231 - accuracy: 0.8610 - val_loss: 0.4881 - val_accuracy: 0.8395\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4229 - accuracy: 0.8610 - val_loss: 0.4881 - val_accuracy: 0.8393\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.4229 - accuracy: 0.8612 - val_loss: 0.4881 - val_accuracy: 0.8393\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:31.244633\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6509 - accuracy: 0.3291 - val_loss: 1.4252 - val_accuracy: 0.5905\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2103 - accuracy: 0.6498 - val_loss: 1.0362 - val_accuracy: 0.6974\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9430 - accuracy: 0.7189 - val_loss: 0.8461 - val_accuracy: 0.7434\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7815 - accuracy: 0.7617 - val_loss: 0.7175 - val_accuracy: 0.7768\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6813 - accuracy: 0.7885 - val_loss: 0.6356 - val_accuracy: 0.8010\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6151 - accuracy: 0.8062 - val_loss: 0.6022 - val_accuracy: 0.8052\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5725 - accuracy: 0.8176 - val_loss: 0.5707 - val_accuracy: 0.8146\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5404 - accuracy: 0.8264 - val_loss: 0.5389 - val_accuracy: 0.8263\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5174 - accuracy: 0.8328 - val_loss: 0.5307 - val_accuracy: 0.8245\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4989 - accuracy: 0.8383 - val_loss: 0.5103 - val_accuracy: 0.8306\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4847 - accuracy: 0.8428 - val_loss: 0.5059 - val_accuracy: 0.8277\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4724 - accuracy: 0.8460 - val_loss: 0.4952 - val_accuracy: 0.8343\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4619 - accuracy: 0.8490 - val_loss: 0.4839 - val_accuracy: 0.8355\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4533 - accuracy: 0.8523 - val_loss: 0.4749 - val_accuracy: 0.8395\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4458 - accuracy: 0.8542 - val_loss: 0.4697 - val_accuracy: 0.8435\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4388 - accuracy: 0.8561 - val_loss: 0.4661 - val_accuracy: 0.8430\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4331 - accuracy: 0.8586 - val_loss: 0.4590 - val_accuracy: 0.8470\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4282 - accuracy: 0.8597 - val_loss: 0.4591 - val_accuracy: 0.8448\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4238 - accuracy: 0.8606 - val_loss: 0.4547 - val_accuracy: 0.8473\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4197 - accuracy: 0.8623 - val_loss: 0.4519 - val_accuracy: 0.8488\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:54.895222\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4133 - accuracy: 0.8646 - val_loss: 0.4487 - val_accuracy: 0.8497\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4099 - accuracy: 0.8654 - val_loss: 0.4471 - val_accuracy: 0.8495\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4081 - accuracy: 0.8667 - val_loss: 0.4459 - val_accuracy: 0.8496\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4071 - accuracy: 0.8667 - val_loss: 0.4456 - val_accuracy: 0.8508\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4067 - accuracy: 0.8674 - val_loss: 0.4456 - val_accuracy: 0.8508\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4064 - accuracy: 0.8672 - val_loss: 0.4455 - val_accuracy: 0.8503\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4063 - accuracy: 0.8672 - val_loss: 0.4455 - val_accuracy: 0.8503\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:09.571378\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.5126 - accuracy: 0.3618 - val_loss: 1.3795 - val_accuracy: 0.6033\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1676 - accuracy: 0.6588 - val_loss: 1.0728 - val_accuracy: 0.6845\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9241 - accuracy: 0.7248 - val_loss: 0.8682 - val_accuracy: 0.7370\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7703 - accuracy: 0.7638 - val_loss: 0.7349 - val_accuracy: 0.7740\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6716 - accuracy: 0.7900 - val_loss: 0.6572 - val_accuracy: 0.7952\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6049 - accuracy: 0.8064 - val_loss: 0.6187 - val_accuracy: 0.8043\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5615 - accuracy: 0.8189 - val_loss: 0.5907 - val_accuracy: 0.8092\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5315 - accuracy: 0.8272 - val_loss: 0.5725 - val_accuracy: 0.8168\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5091 - accuracy: 0.8331 - val_loss: 0.5500 - val_accuracy: 0.8246\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4908 - accuracy: 0.8384 - val_loss: 0.5273 - val_accuracy: 0.8314\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4757 - accuracy: 0.8428 - val_loss: 0.5155 - val_accuracy: 0.8320\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4633 - accuracy: 0.8459 - val_loss: 0.5116 - val_accuracy: 0.8362\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4534 - accuracy: 0.8503 - val_loss: 0.4990 - val_accuracy: 0.8382\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4446 - accuracy: 0.8520 - val_loss: 0.4993 - val_accuracy: 0.8400\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4371 - accuracy: 0.8542 - val_loss: 0.4900 - val_accuracy: 0.8434\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4305 - accuracy: 0.8563 - val_loss: 0.4843 - val_accuracy: 0.8446\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4247 - accuracy: 0.8581 - val_loss: 0.4896 - val_accuracy: 0.8397\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4196 - accuracy: 0.8593 - val_loss: 0.4823 - val_accuracy: 0.8447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4157 - accuracy: 0.8608 - val_loss: 0.4763 - val_accuracy: 0.8447\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4113 - accuracy: 0.8621 - val_loss: 0.4756 - val_accuracy: 0.8446\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:12.416611\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4050 - accuracy: 0.8646 - val_loss: 0.4688 - val_accuracy: 0.8488\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4015 - accuracy: 0.8662 - val_loss: 0.4683 - val_accuracy: 0.8494\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3997 - accuracy: 0.8671 - val_loss: 0.4677 - val_accuracy: 0.8495\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3987 - accuracy: 0.8671 - val_loss: 0.4672 - val_accuracy: 0.8497\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3982 - accuracy: 0.8675 - val_loss: 0.4670 - val_accuracy: 0.8496\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3980 - accuracy: 0.8675 - val_loss: 0.4669 - val_accuracy: 0.8498\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3979 - accuracy: 0.8676 - val_loss: 0.4669 - val_accuracy: 0.8498\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3978 - accuracy: 0.8676 - val_loss: 0.4669 - val_accuracy: 0.8499\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.3978 - accuracy: 0.8676 - val_loss: 0.4669 - val_accuracy: 0.8499\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3978 - accuracy: 0.8675 - val_loss: 0.4669 - val_accuracy: 0.8499\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.3978 - accuracy: 0.8676 - val_loss: 0.4669 - val_accuracy: 0.8499\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:02.673100\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.7760 - accuracy: 0.3119 - val_loss: 1.4440 - val_accuracy: 0.5944\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2365 - accuracy: 0.6435 - val_loss: 1.0502 - val_accuracy: 0.6941\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9593 - accuracy: 0.7152 - val_loss: 0.8840 - val_accuracy: 0.7283\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7869 - accuracy: 0.7616 - val_loss: 0.7333 - val_accuracy: 0.7781\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6821 - accuracy: 0.7877 - val_loss: 0.6641 - val_accuracy: 0.7910\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6124 - accuracy: 0.8053 - val_loss: 0.6128 - val_accuracy: 0.8064\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5675 - accuracy: 0.8182 - val_loss: 0.5622 - val_accuracy: 0.8229\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5361 - accuracy: 0.8274 - val_loss: 0.5441 - val_accuracy: 0.8261\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5125 - accuracy: 0.8333 - val_loss: 0.5330 - val_accuracy: 0.8281\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4944 - accuracy: 0.8380 - val_loss: 0.5209 - val_accuracy: 0.8333\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4795 - accuracy: 0.8434 - val_loss: 0.5109 - val_accuracy: 0.8351\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4672 - accuracy: 0.8464 - val_loss: 0.5009 - val_accuracy: 0.8387\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4566 - accuracy: 0.8493 - val_loss: 0.4899 - val_accuracy: 0.8402\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4477 - accuracy: 0.8523 - val_loss: 0.4898 - val_accuracy: 0.8394\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4404 - accuracy: 0.8541 - val_loss: 0.4801 - val_accuracy: 0.8407\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4339 - accuracy: 0.8566 - val_loss: 0.4735 - val_accuracy: 0.8451\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4280 - accuracy: 0.8583 - val_loss: 0.4738 - val_accuracy: 0.8458\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4229 - accuracy: 0.8595 - val_loss: 0.4682 - val_accuracy: 0.8475\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4183 - accuracy: 0.8606 - val_loss: 0.4627 - val_accuracy: 0.8482\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4143 - accuracy: 0.8626 - val_loss: 0.4665 - val_accuracy: 0.8450\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:08.140298\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4080 - accuracy: 0.8646 - val_loss: 0.4588 - val_accuracy: 0.8494\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4044 - accuracy: 0.8661 - val_loss: 0.4575 - val_accuracy: 0.8498\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4027 - accuracy: 0.8667 - val_loss: 0.4569 - val_accuracy: 0.8498\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4017 - accuracy: 0.8670 - val_loss: 0.4562 - val_accuracy: 0.8501\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4012 - accuracy: 0.8672 - val_loss: 0.4562 - val_accuracy: 0.8500\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4010 - accuracy: 0.8674 - val_loss: 0.4562 - val_accuracy: 0.8499\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4009 - accuracy: 0.8675 - val_loss: 0.4562 - val_accuracy: 0.8498\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:08.211500\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.6767 - accuracy: 0.3276 - val_loss: 1.4218 - val_accuracy: 0.5915\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2453 - accuracy: 0.6390 - val_loss: 1.1193 - val_accuracy: 0.6723\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0086 - accuracy: 0.7022 - val_loss: 0.9414 - val_accuracy: 0.7168\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8428 - accuracy: 0.7463 - val_loss: 0.7947 - val_accuracy: 0.7580\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7223 - accuracy: 0.7758 - val_loss: 0.6868 - val_accuracy: 0.7889\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6401 - accuracy: 0.7989 - val_loss: 0.6440 - val_accuracy: 0.8001\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5860 - accuracy: 0.8138 - val_loss: 0.5877 - val_accuracy: 0.8152\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5495 - accuracy: 0.8239 - val_loss: 0.5714 - val_accuracy: 0.8146\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5228 - accuracy: 0.8312 - val_loss: 0.5504 - val_accuracy: 0.8202\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5018 - accuracy: 0.8363 - val_loss: 0.5314 - val_accuracy: 0.8303\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4857 - accuracy: 0.8418 - val_loss: 0.5175 - val_accuracy: 0.8355\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4722 - accuracy: 0.8457 - val_loss: 0.5091 - val_accuracy: 0.8318\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4612 - accuracy: 0.8484 - val_loss: 0.4986 - val_accuracy: 0.8416\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4521 - accuracy: 0.8501 - val_loss: 0.4938 - val_accuracy: 0.8398\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4441 - accuracy: 0.8534 - val_loss: 0.4883 - val_accuracy: 0.8402\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4373 - accuracy: 0.8552 - val_loss: 0.4819 - val_accuracy: 0.8449\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4311 - accuracy: 0.8574 - val_loss: 0.4812 - val_accuracy: 0.8435\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4257 - accuracy: 0.8593 - val_loss: 0.4769 - val_accuracy: 0.8434\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4214 - accuracy: 0.8600 - val_loss: 0.4756 - val_accuracy: 0.8449\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:32.369156\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4255 - accuracy: 0.8599 - val_loss: 0.4767 - val_accuracy: 0.8459\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4216 - accuracy: 0.8617 - val_loss: 0.4750 - val_accuracy: 0.8461\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4194 - accuracy: 0.8616 - val_loss: 0.4734 - val_accuracy: 0.8469\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4183 - accuracy: 0.8623 - val_loss: 0.4732 - val_accuracy: 0.8465\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4177 - accuracy: 0.8624 - val_loss: 0.4731 - val_accuracy: 0.8469\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4175 - accuracy: 0.8627 - val_loss: 0.4730 - val_accuracy: 0.8470\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4173 - accuracy: 0.8628 - val_loss: 0.4730 - val_accuracy: 0.8469\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4173 - accuracy: 0.8628 - val_loss: 0.4730 - val_accuracy: 0.8469\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4173 - accuracy: 0.8628 - val_loss: 0.4730 - val_accuracy: 0.8469\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:02.861896\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.5404 - accuracy: 0.3558 - val_loss: 1.4102 - val_accuracy: 0.5975\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2094 - accuracy: 0.6503 - val_loss: 1.0854 - val_accuracy: 0.6793\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9542 - accuracy: 0.7155 - val_loss: 0.8740 - val_accuracy: 0.7328\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7951 - accuracy: 0.7576 - val_loss: 0.7429 - val_accuracy: 0.7725\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6933 - accuracy: 0.7840 - val_loss: 0.6659 - val_accuracy: 0.7912\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6233 - accuracy: 0.8032 - val_loss: 0.6215 - val_accuracy: 0.8040\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5764 - accuracy: 0.8152 - val_loss: 0.5824 - val_accuracy: 0.8162\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5433 - accuracy: 0.8246 - val_loss: 0.5600 - val_accuracy: 0.8211\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5199 - accuracy: 0.8324 - val_loss: 0.5448 - val_accuracy: 0.8252\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5003 - accuracy: 0.8360 - val_loss: 0.5336 - val_accuracy: 0.8253\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4854 - accuracy: 0.8410 - val_loss: 0.5164 - val_accuracy: 0.8312\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4725 - accuracy: 0.8447 - val_loss: 0.5075 - val_accuracy: 0.8331\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4615 - accuracy: 0.8479 - val_loss: 0.5024 - val_accuracy: 0.8320\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4526 - accuracy: 0.8502 - val_loss: 0.4924 - val_accuracy: 0.8376\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4452 - accuracy: 0.8520 - val_loss: 0.4892 - val_accuracy: 0.8375\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4376 - accuracy: 0.8559 - val_loss: 0.4860 - val_accuracy: 0.8389\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4329 - accuracy: 0.8563 - val_loss: 0.4776 - val_accuracy: 0.8434\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4279 - accuracy: 0.8577 - val_loss: 0.4735 - val_accuracy: 0.8439\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4232 - accuracy: 0.8596 - val_loss: 0.4728 - val_accuracy: 0.8428\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4187 - accuracy: 0.8606 - val_loss: 0.4717 - val_accuracy: 0.8437\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:02.315687\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4126 - accuracy: 0.8622 - val_loss: 0.4651 - val_accuracy: 0.8483\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4089 - accuracy: 0.8638 - val_loss: 0.4646 - val_accuracy: 0.8460\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.4072 - accuracy: 0.8644 - val_loss: 0.4633 - val_accuracy: 0.8473\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.4061 - accuracy: 0.8652 - val_loss: 0.4634 - val_accuracy: 0.8468\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:48.320099\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.0416 - accuracy: 0.2388 - val_loss: 1.6051 - val_accuracy: 0.5524\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3212 - accuracy: 0.6162 - val_loss: 1.1282 - val_accuracy: 0.6708\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0151 - accuracy: 0.6974 - val_loss: 0.9331 - val_accuracy: 0.7192\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8351 - accuracy: 0.7455 - val_loss: 0.8050 - val_accuracy: 0.7579\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7249 - accuracy: 0.7740 - val_loss: 0.7190 - val_accuracy: 0.7795\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6479 - accuracy: 0.7952 - val_loss: 0.6707 - val_accuracy: 0.7875\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5982 - accuracy: 0.8093 - val_loss: 0.6237 - val_accuracy: 0.8070\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5652 - accuracy: 0.8190 - val_loss: 0.5941 - val_accuracy: 0.8119\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5394 - accuracy: 0.8250 - val_loss: 0.5744 - val_accuracy: 0.8199\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5190 - accuracy: 0.8309 - val_loss: 0.5598 - val_accuracy: 0.8215\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5023 - accuracy: 0.8371 - val_loss: 0.5486 - val_accuracy: 0.8257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4898 - accuracy: 0.8394 - val_loss: 0.5373 - val_accuracy: 0.8290\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4784 - accuracy: 0.8425 - val_loss: 0.5239 - val_accuracy: 0.8319\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4686 - accuracy: 0.8467 - val_loss: 0.5232 - val_accuracy: 0.8320\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4609 - accuracy: 0.8471 - val_loss: 0.5127 - val_accuracy: 0.8354\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4538 - accuracy: 0.8511 - val_loss: 0.5087 - val_accuracy: 0.8376\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4478 - accuracy: 0.8529 - val_loss: 0.5083 - val_accuracy: 0.8354\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4427 - accuracy: 0.8545 - val_loss: 0.5026 - val_accuracy: 0.8386\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4377 - accuracy: 0.8556 - val_loss: 0.4967 - val_accuracy: 0.8401\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4338 - accuracy: 0.8570 - val_loss: 0.4959 - val_accuracy: 0.8402\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:20.012983\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4268 - accuracy: 0.8591 - val_loss: 0.4909 - val_accuracy: 0.8416\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4229 - accuracy: 0.8605 - val_loss: 0.4883 - val_accuracy: 0.8421\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4210 - accuracy: 0.8616 - val_loss: 0.4873 - val_accuracy: 0.8443\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4200 - accuracy: 0.8622 - val_loss: 0.4872 - val_accuracy: 0.8434\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4196 - accuracy: 0.8621 - val_loss: 0.4871 - val_accuracy: 0.8443\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4193 - accuracy: 0.8623 - val_loss: 0.4870 - val_accuracy: 0.8445\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4192 - accuracy: 0.8623 - val_loss: 0.4870 - val_accuracy: 0.8444\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4191 - accuracy: 0.8624 - val_loss: 0.4870 - val_accuracy: 0.8444\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4191 - accuracy: 0.8624 - val_loss: 0.4870 - val_accuracy: 0.8445\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:11.908855\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.9656 - accuracy: 0.2603 - val_loss: 1.5432 - val_accuracy: 0.5466\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3098 - accuracy: 0.6217 - val_loss: 1.0993 - val_accuracy: 0.6728\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0190 - accuracy: 0.6974 - val_loss: 0.9043 - val_accuracy: 0.7236\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8378 - accuracy: 0.7452 - val_loss: 0.7612 - val_accuracy: 0.7628\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7214 - accuracy: 0.7760 - val_loss: 0.6630 - val_accuracy: 0.7881\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6440 - accuracy: 0.7987 - val_loss: 0.6081 - val_accuracy: 0.8028\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5962 - accuracy: 0.8098 - val_loss: 0.5771 - val_accuracy: 0.8078\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5632 - accuracy: 0.8194 - val_loss: 0.5481 - val_accuracy: 0.8207\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5385 - accuracy: 0.8265 - val_loss: 0.5262 - val_accuracy: 0.8258\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5190 - accuracy: 0.8302 - val_loss: 0.5174 - val_accuracy: 0.8246\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5030 - accuracy: 0.8365 - val_loss: 0.5025 - val_accuracy: 0.8313\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4909 - accuracy: 0.8404 - val_loss: 0.4992 - val_accuracy: 0.8335\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4800 - accuracy: 0.8437 - val_loss: 0.4924 - val_accuracy: 0.8329\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4711 - accuracy: 0.8450 - val_loss: 0.4759 - val_accuracy: 0.8417\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4633 - accuracy: 0.8492 - val_loss: 0.4735 - val_accuracy: 0.8398\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4558 - accuracy: 0.8505 - val_loss: 0.4676 - val_accuracy: 0.8387\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4498 - accuracy: 0.8529 - val_loss: 0.4677 - val_accuracy: 0.8425\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4447 - accuracy: 0.8532 - val_loss: 0.4592 - val_accuracy: 0.8457\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4405 - accuracy: 0.8545 - val_loss: 0.4574 - val_accuracy: 0.8433\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4361 - accuracy: 0.8565 - val_loss: 0.4537 - val_accuracy: 0.8468\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:18.676592\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4292 - accuracy: 0.8584 - val_loss: 0.4525 - val_accuracy: 0.8458\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4257 - accuracy: 0.8603 - val_loss: 0.4502 - val_accuracy: 0.8456\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4239 - accuracy: 0.8603 - val_loss: 0.4476 - val_accuracy: 0.8482\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4230 - accuracy: 0.8606 - val_loss: 0.4468 - val_accuracy: 0.8489\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4225 - accuracy: 0.8609 - val_loss: 0.4468 - val_accuracy: 0.8486\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4222 - accuracy: 0.8610 - val_loss: 0.4466 - val_accuracy: 0.8483\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4221 - accuracy: 0.8611 - val_loss: 0.4466 - val_accuracy: 0.8484\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:15.619605\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.8901 - accuracy: 0.2764 - val_loss: 1.4918 - val_accuracy: 0.5781\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2584 - accuracy: 0.6353 - val_loss: 1.1075 - val_accuracy: 0.6764\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9661 - accuracy: 0.7098 - val_loss: 0.8690 - val_accuracy: 0.7433\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7888 - accuracy: 0.7579 - val_loss: 0.7663 - val_accuracy: 0.7687\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6827 - accuracy: 0.7854 - val_loss: 0.6946 - val_accuracy: 0.7883\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6138 - accuracy: 0.8040 - val_loss: 0.6185 - val_accuracy: 0.8061\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5691 - accuracy: 0.8163 - val_loss: 0.5918 - val_accuracy: 0.8101\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5376 - accuracy: 0.8245 - val_loss: 0.5705 - val_accuracy: 0.8182\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5146 - accuracy: 0.8315 - val_loss: 0.5496 - val_accuracy: 0.8224\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4966 - accuracy: 0.8371 - val_loss: 0.5342 - val_accuracy: 0.8292\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4828 - accuracy: 0.8414 - val_loss: 0.5199 - val_accuracy: 0.8310\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4698 - accuracy: 0.8449 - val_loss: 0.5102 - val_accuracy: 0.8348\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4597 - accuracy: 0.8489 - val_loss: 0.5150 - val_accuracy: 0.8315\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4511 - accuracy: 0.8506 - val_loss: 0.5045 - val_accuracy: 0.8344\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4434 - accuracy: 0.8539 - val_loss: 0.4949 - val_accuracy: 0.8378\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4373 - accuracy: 0.8544 - val_loss: 0.4918 - val_accuracy: 0.8380\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4307 - accuracy: 0.8572 - val_loss: 0.4906 - val_accuracy: 0.8400\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4259 - accuracy: 0.8576 - val_loss: 0.4832 - val_accuracy: 0.8419\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4218 - accuracy: 0.8606 - val_loss: 0.4857 - val_accuracy: 0.8384\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4172 - accuracy: 0.8606 - val_loss: 0.4798 - val_accuracy: 0.8406\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:20.963994\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4107 - accuracy: 0.8635 - val_loss: 0.4756 - val_accuracy: 0.8415\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4071 - accuracy: 0.8650 - val_loss: 0.4735 - val_accuracy: 0.8438\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4051 - accuracy: 0.8656 - val_loss: 0.4724 - val_accuracy: 0.8446\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4042 - accuracy: 0.8659 - val_loss: 0.4723 - val_accuracy: 0.8437\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4037 - accuracy: 0.8665 - val_loss: 0.4720 - val_accuracy: 0.8447\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4034 - accuracy: 0.8666 - val_loss: 0.4720 - val_accuracy: 0.8442\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4033 - accuracy: 0.8667 - val_loss: 0.4720 - val_accuracy: 0.8440\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4033 - accuracy: 0.8667 - val_loss: 0.4720 - val_accuracy: 0.8440\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:44.277733\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.9055 - accuracy: 0.2672 - val_loss: 1.6052 - val_accuracy: 0.5361\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3244 - accuracy: 0.6167 - val_loss: 1.1275 - val_accuracy: 0.6715\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0354 - accuracy: 0.6948 - val_loss: 0.9544 - val_accuracy: 0.7097\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8634 - accuracy: 0.7390 - val_loss: 0.8426 - val_accuracy: 0.7402\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7429 - accuracy: 0.7696 - val_loss: 0.7337 - val_accuracy: 0.7690\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6621 - accuracy: 0.7920 - val_loss: 0.6487 - val_accuracy: 0.7982\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6094 - accuracy: 0.8056 - val_loss: 0.6199 - val_accuracy: 0.7976\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5734 - accuracy: 0.8157 - val_loss: 0.5800 - val_accuracy: 0.8137\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5470 - accuracy: 0.8224 - val_loss: 0.5657 - val_accuracy: 0.8176\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5260 - accuracy: 0.8291 - val_loss: 0.5532 - val_accuracy: 0.8216\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5107 - accuracy: 0.8342 - val_loss: 0.5334 - val_accuracy: 0.8254\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4963 - accuracy: 0.8378 - val_loss: 0.5358 - val_accuracy: 0.8269\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4854 - accuracy: 0.8409 - val_loss: 0.5157 - val_accuracy: 0.8330\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4758 - accuracy: 0.8437 - val_loss: 0.5085 - val_accuracy: 0.8376\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4672 - accuracy: 0.8465 - val_loss: 0.5001 - val_accuracy: 0.8379\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4601 - accuracy: 0.8480 - val_loss: 0.4971 - val_accuracy: 0.8383\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4541 - accuracy: 0.8495 - val_loss: 0.4902 - val_accuracy: 0.8400\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4488 - accuracy: 0.8522 - val_loss: 0.4892 - val_accuracy: 0.8392\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4438 - accuracy: 0.8529 - val_loss: 0.4857 - val_accuracy: 0.8429\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4392 - accuracy: 0.8548 - val_loss: 0.4825 - val_accuracy: 0.8449\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:15.305387\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4322 - accuracy: 0.8572 - val_loss: 0.4767 - val_accuracy: 0.8446\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4280 - accuracy: 0.8589 - val_loss: 0.4762 - val_accuracy: 0.8450\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4261 - accuracy: 0.8601 - val_loss: 0.4746 - val_accuracy: 0.8452\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4251 - accuracy: 0.8603 - val_loss: 0.4742 - val_accuracy: 0.8471\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4246 - accuracy: 0.8603 - val_loss: 0.4741 - val_accuracy: 0.8463\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4243 - accuracy: 0.8607 - val_loss: 0.4739 - val_accuracy: 0.8465\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4242 - accuracy: 0.8606 - val_loss: 0.4739 - val_accuracy: 0.8463\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:14.602299\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.7718 - accuracy: 0.2980 - val_loss: 1.4921 - val_accuracy: 0.5777\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2637 - accuracy: 0.6328 - val_loss: 1.1058 - val_accuracy: 0.6793\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9776 - accuracy: 0.7100 - val_loss: 0.8824 - val_accuracy: 0.7320\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8043 - accuracy: 0.7539 - val_loss: 0.7674 - val_accuracy: 0.7577\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7000 - accuracy: 0.7826 - val_loss: 0.6593 - val_accuracy: 0.7948\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6308 - accuracy: 0.8009 - val_loss: 0.6376 - val_accuracy: 0.7942\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5870 - accuracy: 0.8131 - val_loss: 0.5788 - val_accuracy: 0.8152\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5556 - accuracy: 0.8213 - val_loss: 0.5585 - val_accuracy: 0.8188\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5322 - accuracy: 0.8293 - val_loss: 0.5437 - val_accuracy: 0.8235\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5150 - accuracy: 0.8336 - val_loss: 0.5330 - val_accuracy: 0.8264\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4983 - accuracy: 0.8383 - val_loss: 0.5258 - val_accuracy: 0.8285\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4864 - accuracy: 0.8408 - val_loss: 0.5041 - val_accuracy: 0.8373\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4763 - accuracy: 0.8444 - val_loss: 0.5115 - val_accuracy: 0.8335\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4670 - accuracy: 0.8469 - val_loss: 0.4945 - val_accuracy: 0.8404\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4594 - accuracy: 0.8498 - val_loss: 0.4930 - val_accuracy: 0.8357\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4527 - accuracy: 0.8510 - val_loss: 0.4893 - val_accuracy: 0.8386\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4473 - accuracy: 0.8525 - val_loss: 0.4823 - val_accuracy: 0.8417\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4420 - accuracy: 0.8548 - val_loss: 0.4799 - val_accuracy: 0.8430\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4375 - accuracy: 0.8559 - val_loss: 0.4757 - val_accuracy: 0.8454\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4333 - accuracy: 0.8566 - val_loss: 0.4730 - val_accuracy: 0.8458\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:18.782488\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4259 - accuracy: 0.8596 - val_loss: 0.4683 - val_accuracy: 0.8458\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4223 - accuracy: 0.8607 - val_loss: 0.4673 - val_accuracy: 0.8466\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4205 - accuracy: 0.8615 - val_loss: 0.4664 - val_accuracy: 0.8477\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4195 - accuracy: 0.8618 - val_loss: 0.4661 - val_accuracy: 0.8474\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4190 - accuracy: 0.8622 - val_loss: 0.4657 - val_accuracy: 0.8477\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4187 - accuracy: 0.8621 - val_loss: 0.4656 - val_accuracy: 0.8476\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.4186 - accuracy: 0.8623 - val_loss: 0.4656 - val_accuracy: 0.8477\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.4186 - accuracy: 0.8623 - val_loss: 0.4656 - val_accuracy: 0.8477\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:43.339445\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 8.2717 - accuracy: 0.2592 - val_loss: 6.3584 - val_accuracy: 0.5301\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5223 - accuracy: 0.6024 - val_loss: 4.7998 - val_accuracy: 0.6433\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 4.1906 - accuracy: 0.6753 - val_loss: 3.6340 - val_accuracy: 0.7050\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1528 - accuracy: 0.7204 - val_loss: 2.7230 - val_accuracy: 0.7312\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3500 - accuracy: 0.7495 - val_loss: 2.0200 - val_accuracy: 0.7665\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7836 - accuracy: 0.7666 - val_loss: 1.5813 - val_accuracy: 0.7721\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.4192 - accuracy: 0.7791 - val_loss: 1.2965 - val_accuracy: 0.7855\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.1963 - accuracy: 0.7866 - val_loss: 1.1487 - val_accuracy: 0.7828\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0619 - accuracy: 0.7933 - val_loss: 1.0597 - val_accuracy: 0.7765\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9864 - accuracy: 0.7977 - val_loss: 0.9604 - val_accuracy: 0.7974\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9361 - accuracy: 0.8024 - val_loss: 0.9330 - val_accuracy: 0.7997\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8974 - accuracy: 0.8068 - val_loss: 0.9159 - val_accuracy: 0.7962\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8665 - accuracy: 0.8099 - val_loss: 0.8681 - val_accuracy: 0.8048\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8407 - accuracy: 0.8139 - val_loss: 0.8353 - val_accuracy: 0.8158\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8190 - accuracy: 0.8166 - val_loss: 0.8537 - val_accuracy: 0.8024\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7989 - accuracy: 0.8217 - val_loss: 0.8007 - val_accuracy: 0.8186\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7840 - accuracy: 0.8214 - val_loss: 0.7940 - val_accuracy: 0.8185\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7704 - accuracy: 0.8235 - val_loss: 0.7946 - val_accuracy: 0.8139\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7565 - accuracy: 0.8267 - val_loss: 0.7769 - val_accuracy: 0.8174\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:25.519458\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7581 - accuracy: 0.8305 - val_loss: 0.7777 - val_accuracy: 0.8230\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7439 - accuracy: 0.8342 - val_loss: 0.7645 - val_accuracy: 0.8275\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7368 - accuracy: 0.8354 - val_loss: 0.7585 - val_accuracy: 0.8283\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7332 - accuracy: 0.8368 - val_loss: 0.7565 - val_accuracy: 0.8296\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7313 - accuracy: 0.8369 - val_loss: 0.7556 - val_accuracy: 0.8296\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7304 - accuracy: 0.8374 - val_loss: 0.7549 - val_accuracy: 0.8293\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7299 - accuracy: 0.8374 - val_loss: 0.7548 - val_accuracy: 0.8290\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:07.491533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.7708 - accuracy: 0.1576 - val_loss: 6.5789 - val_accuracy: 0.4895\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.6157 - accuracy: 0.5716 - val_loss: 4.8447 - val_accuracy: 0.6329\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1799 - accuracy: 0.6773 - val_loss: 3.6181 - val_accuracy: 0.7003\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1232 - accuracy: 0.7267 - val_loss: 2.6458 - val_accuracy: 0.7563\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3270 - accuracy: 0.7565 - val_loss: 2.0097 - val_accuracy: 0.7612\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7673 - accuracy: 0.7735 - val_loss: 1.5399 - val_accuracy: 0.7850\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4105 - accuracy: 0.7832 - val_loss: 1.2614 - val_accuracy: 0.7939\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1923 - accuracy: 0.7912 - val_loss: 1.1451 - val_accuracy: 0.7844\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0649 - accuracy: 0.7942 - val_loss: 1.0287 - val_accuracy: 0.7934\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9824 - accuracy: 0.8019 - val_loss: 0.9699 - val_accuracy: 0.7996\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9317 - accuracy: 0.8059 - val_loss: 0.9150 - val_accuracy: 0.8070\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8916 - accuracy: 0.8102 - val_loss: 0.8758 - val_accuracy: 0.8083\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8593 - accuracy: 0.8143 - val_loss: 0.8689 - val_accuracy: 0.8082\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8349 - accuracy: 0.8159 - val_loss: 0.8197 - val_accuracy: 0.8204\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8122 - accuracy: 0.8183 - val_loss: 0.7997 - val_accuracy: 0.8162\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7936 - accuracy: 0.8220 - val_loss: 0.7943 - val_accuracy: 0.8176\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7770 - accuracy: 0.8247 - val_loss: 0.7767 - val_accuracy: 0.8222\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7628 - accuracy: 0.8273 - val_loss: 0.7713 - val_accuracy: 0.8227\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7502 - accuracy: 0.8288 - val_loss: 0.7753 - val_accuracy: 0.8168\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7394 - accuracy: 0.8290 - val_loss: 0.7503 - val_accuracy: 0.8256\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:57.317098\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7141 - accuracy: 0.8359 - val_loss: 0.7298 - val_accuracy: 0.8292\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7011 - accuracy: 0.8397 - val_loss: 0.7168 - val_accuracy: 0.8333\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6944 - accuracy: 0.8411 - val_loss: 0.7112 - val_accuracy: 0.8331\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6909 - accuracy: 0.8427 - val_loss: 0.7089 - val_accuracy: 0.8340\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6892 - accuracy: 0.8425 - val_loss: 0.7074 - val_accuracy: 0.8359\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6884 - accuracy: 0.8424 - val_loss: 0.7070 - val_accuracy: 0.8359\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6879 - accuracy: 0.8426 - val_loss: 0.7067 - val_accuracy: 0.8358\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6877 - accuracy: 0.8426 - val_loss: 0.7066 - val_accuracy: 0.8357\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:38.735948\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.5262 - accuracy: 0.2123 - val_loss: 6.4590 - val_accuracy: 0.4941\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5281 - accuracy: 0.5997 - val_loss: 4.7585 - val_accuracy: 0.6547\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 4.1808 - accuracy: 0.6776 - val_loss: 3.6095 - val_accuracy: 0.7075\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1386 - accuracy: 0.7242 - val_loss: 2.6882 - val_accuracy: 0.7420\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3436 - accuracy: 0.7500 - val_loss: 2.0149 - val_accuracy: 0.7618\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7781 - accuracy: 0.7694 - val_loss: 1.5776 - val_accuracy: 0.7743\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4172 - accuracy: 0.7803 - val_loss: 1.2829 - val_accuracy: 0.7900\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1983 - accuracy: 0.7877 - val_loss: 1.1228 - val_accuracy: 0.7862\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0659 - accuracy: 0.7925 - val_loss: 1.0756 - val_accuracy: 0.7793\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9869 - accuracy: 0.7988 - val_loss: 0.9942 - val_accuracy: 0.7903\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9394 - accuracy: 0.8020 - val_loss: 0.9202 - val_accuracy: 0.8078\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8984 - accuracy: 0.8077 - val_loss: 0.9026 - val_accuracy: 0.8011\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8673 - accuracy: 0.8103 - val_loss: 0.8855 - val_accuracy: 0.8057\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8416 - accuracy: 0.8146 - val_loss: 0.8575 - val_accuracy: 0.8067\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:06:15.464017\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8600 - accuracy: 0.8208 - val_loss: 0.8732 - val_accuracy: 0.8161\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8340 - accuracy: 0.8259 - val_loss: 0.8512 - val_accuracy: 0.8203\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8216 - accuracy: 0.8273 - val_loss: 0.8451 - val_accuracy: 0.8197\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8150 - accuracy: 0.8286 - val_loss: 0.8408 - val_accuracy: 0.8208\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8120 - accuracy: 0.8289 - val_loss: 0.8379 - val_accuracy: 0.8223\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8104 - accuracy: 0.8292 - val_loss: 0.8371 - val_accuracy: 0.8227\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8097 - accuracy: 0.8295 - val_loss: 0.8368 - val_accuracy: 0.8225\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8093 - accuracy: 0.8294 - val_loss: 0.8367 - val_accuracy: 0.8222\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8092 - accuracy: 0.8296 - val_loss: 0.8366 - val_accuracy: 0.8225\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:02.696114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.3346 - accuracy: 0.2462 - val_loss: 6.3769 - val_accuracy: 0.5350\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 5.5266 - accuracy: 0.6023 - val_loss: 4.8258 - val_accuracy: 0.6407\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.1978 - accuracy: 0.6740 - val_loss: 3.6374 - val_accuracy: 0.7008\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.1566 - accuracy: 0.7211 - val_loss: 2.7627 - val_accuracy: 0.7221\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 2.3600 - accuracy: 0.7480 - val_loss: 2.0328 - val_accuracy: 0.7623\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.7838 - accuracy: 0.7670 - val_loss: 1.6188 - val_accuracy: 0.7616\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.4170 - accuracy: 0.7792 - val_loss: 1.2827 - val_accuracy: 0.7870\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.1895 - accuracy: 0.7875 - val_loss: 1.1225 - val_accuracy: 0.7913\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0564 - accuracy: 0.7934 - val_loss: 1.0363 - val_accuracy: 0.7904\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9812 - accuracy: 0.7954 - val_loss: 0.9972 - val_accuracy: 0.7877\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9311 - accuracy: 0.8033 - val_loss: 0.9602 - val_accuracy: 0.7910\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:51.509441\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.0278 - accuracy: 0.8099 - val_loss: 1.0246 - val_accuracy: 0.8035\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9755 - accuracy: 0.8150 - val_loss: 0.9912 - val_accuracy: 0.8107\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9512 - accuracy: 0.8184 - val_loss: 0.9729 - val_accuracy: 0.8109\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9395 - accuracy: 0.8199 - val_loss: 0.9656 - val_accuracy: 0.8121\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9339 - accuracy: 0.8209 - val_loss: 0.9618 - val_accuracy: 0.8131\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9313 - accuracy: 0.8210 - val_loss: 0.9604 - val_accuracy: 0.8126\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9301 - accuracy: 0.8211 - val_loss: 0.9597 - val_accuracy: 0.8129\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9296 - accuracy: 0.8212 - val_loss: 0.9594 - val_accuracy: 0.8126\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:38.841489\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.4784 - accuracy: 0.2249 - val_loss: 6.5343 - val_accuracy: 0.4696\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5243 - accuracy: 0.6009 - val_loss: 4.7976 - val_accuracy: 0.6468\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.1704 - accuracy: 0.6827 - val_loss: 3.5991 - val_accuracy: 0.7084\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.1225 - accuracy: 0.7289 - val_loss: 2.7133 - val_accuracy: 0.7342\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.3301 - accuracy: 0.7576 - val_loss: 2.0030 - val_accuracy: 0.7714\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.7675 - accuracy: 0.7754 - val_loss: 1.5733 - val_accuracy: 0.7759\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.4087 - accuracy: 0.7854 - val_loss: 1.3040 - val_accuracy: 0.7829\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1864 - accuracy: 0.7908 - val_loss: 1.0934 - val_accuracy: 0.8016\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0511 - accuracy: 0.7983 - val_loss: 1.0023 - val_accuracy: 0.7954\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9760 - accuracy: 0.8007 - val_loss: 0.9660 - val_accuracy: 0.7945\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.9264 - accuracy: 0.8051 - val_loss: 0.9222 - val_accuracy: 0.7995\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:52.032268\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0235 - accuracy: 0.8142 - val_loss: 1.0132 - val_accuracy: 0.8098\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9713 - accuracy: 0.8190 - val_loss: 0.9815 - val_accuracy: 0.8111\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9469 - accuracy: 0.8230 - val_loss: 0.9622 - val_accuracy: 0.8130\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9353 - accuracy: 0.8237 - val_loss: 0.9530 - val_accuracy: 0.8159\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9296 - accuracy: 0.8249 - val_loss: 0.9498 - val_accuracy: 0.8151\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9270 - accuracy: 0.8248 - val_loss: 0.9476 - val_accuracy: 0.8160\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9257 - accuracy: 0.8253 - val_loss: 0.9471 - val_accuracy: 0.8167\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9251 - accuracy: 0.8254 - val_loss: 0.9469 - val_accuracy: 0.8170\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9249 - accuracy: 0.8254 - val_loss: 0.9468 - val_accuracy: 0.8171\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9249 - accuracy: 0.8254 - val_loss: 0.9468 - val_accuracy: 0.8171\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9248 - accuracy: 0.8254 - val_loss: 0.9468 - val_accuracy: 0.8171\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9248 - accuracy: 0.8254 - val_loss: 0.9468 - val_accuracy: 0.8171\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9248 - accuracy: 0.8254 - val_loss: 0.9468 - val_accuracy: 0.8171\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:47.781391\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.2387 - accuracy: 0.2843 - val_loss: 6.2335 - val_accuracy: 0.5691\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.4209 - accuracy: 0.6290 - val_loss: 4.7257 - val_accuracy: 0.6676\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1106 - accuracy: 0.6969 - val_loss: 3.5925 - val_accuracy: 0.7073\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.0797 - accuracy: 0.7396 - val_loss: 2.6877 - val_accuracy: 0.7432\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3051 - accuracy: 0.7630 - val_loss: 2.0299 - val_accuracy: 0.7611\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7584 - accuracy: 0.7776 - val_loss: 1.6168 - val_accuracy: 0.7625\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4180 - accuracy: 0.7871 - val_loss: 1.3675 - val_accuracy: 0.7625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2128 - accuracy: 0.7934 - val_loss: 1.1725 - val_accuracy: 0.7833\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0917 - accuracy: 0.7963 - val_loss: 1.0821 - val_accuracy: 0.7880\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0135 - accuracy: 0.7999 - val_loss: 1.0097 - val_accuracy: 0.7977\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9545 - accuracy: 0.8054 - val_loss: 0.9807 - val_accuracy: 0.7925\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9131 - accuracy: 0.8085 - val_loss: 0.9684 - val_accuracy: 0.7778\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8798 - accuracy: 0.8119 - val_loss: 0.9243 - val_accuracy: 0.7940\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:52.791683\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9196 - accuracy: 0.8197 - val_loss: 0.9600 - val_accuracy: 0.8021\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8885 - accuracy: 0.8242 - val_loss: 0.9278 - val_accuracy: 0.8116\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8731 - accuracy: 0.8261 - val_loss: 0.9170 - val_accuracy: 0.8121\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8654 - accuracy: 0.8283 - val_loss: 0.9108 - val_accuracy: 0.8138\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8616 - accuracy: 0.8294 - val_loss: 0.9083 - val_accuracy: 0.8136\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8598 - accuracy: 0.8292 - val_loss: 0.9069 - val_accuracy: 0.8141\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8589 - accuracy: 0.8292 - val_loss: 0.9064 - val_accuracy: 0.8144\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8585 - accuracy: 0.8294 - val_loss: 0.9062 - val_accuracy: 0.8144\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8584 - accuracy: 0.8293 - val_loss: 0.9061 - val_accuracy: 0.8145\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8583 - accuracy: 0.8293 - val_loss: 0.9061 - val_accuracy: 0.8145\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8583 - accuracy: 0.8292 - val_loss: 0.9061 - val_accuracy: 0.8144\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8583 - accuracy: 0.8292 - val_loss: 0.9061 - val_accuracy: 0.8144\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:30.951587\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.0108 - accuracy: 0.3466 - val_loss: 6.1536 - val_accuracy: 0.5989\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.3975 - accuracy: 0.6377 - val_loss: 4.6967 - val_accuracy: 0.6800\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1147 - accuracy: 0.6995 - val_loss: 3.5683 - val_accuracy: 0.7205\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1006 - accuracy: 0.7371 - val_loss: 2.6794 - val_accuracy: 0.7520\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3199 - accuracy: 0.7613 - val_loss: 2.0495 - val_accuracy: 0.7595\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7675 - accuracy: 0.7775 - val_loss: 1.5584 - val_accuracy: 0.7851\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4242 - accuracy: 0.7850 - val_loss: 1.3434 - val_accuracy: 0.7760\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2158 - accuracy: 0.7926 - val_loss: 1.1498 - val_accuracy: 0.7926\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.0887 - accuracy: 0.7956 - val_loss: 1.0584 - val_accuracy: 0.7954\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0087 - accuracy: 0.8002 - val_loss: 1.0239 - val_accuracy: 0.7899\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9517 - accuracy: 0.8055 - val_loss: 0.9495 - val_accuracy: 0.8039\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9115 - accuracy: 0.8092 - val_loss: 0.9137 - val_accuracy: 0.8089\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8780 - accuracy: 0.8138 - val_loss: 0.9063 - val_accuracy: 0.8030\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8507 - accuracy: 0.8163 - val_loss: 0.8603 - val_accuracy: 0.8116\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8275 - accuracy: 0.8198 - val_loss: 0.8429 - val_accuracy: 0.8152\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8089 - accuracy: 0.8221 - val_loss: 0.8208 - val_accuracy: 0.8195\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7929 - accuracy: 0.8245 - val_loss: 0.8120 - val_accuracy: 0.8168\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7786 - accuracy: 0.8264 - val_loss: 0.7939 - val_accuracy: 0.8209\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7642 - accuracy: 0.8291 - val_loss: 0.7897 - val_accuracy: 0.8174\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7531 - accuracy: 0.8300 - val_loss: 0.7781 - val_accuracy: 0.8218\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:06.704581\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7278 - accuracy: 0.8366 - val_loss: 0.7583 - val_accuracy: 0.8264\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7145 - accuracy: 0.8412 - val_loss: 0.7460 - val_accuracy: 0.8304\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7077 - accuracy: 0.8429 - val_loss: 0.7400 - val_accuracy: 0.8317\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7042 - accuracy: 0.8441 - val_loss: 0.7382 - val_accuracy: 0.8315\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7025 - accuracy: 0.8438 - val_loss: 0.7371 - val_accuracy: 0.8309\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7016 - accuracy: 0.8447 - val_loss: 0.7367 - val_accuracy: 0.8316\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:42.954216\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.0150 - accuracy: 0.3378 - val_loss: 6.1844 - val_accuracy: 0.5876\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.4006 - accuracy: 0.6410 - val_loss: 4.6964 - val_accuracy: 0.6779\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1013 - accuracy: 0.7050 - val_loss: 3.5405 - val_accuracy: 0.7300\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.0830 - accuracy: 0.7430 - val_loss: 2.6640 - val_accuracy: 0.7514\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3057 - accuracy: 0.7661 - val_loss: 1.9794 - val_accuracy: 0.7789\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7638 - accuracy: 0.7792 - val_loss: 1.5663 - val_accuracy: 0.7813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4268 - accuracy: 0.7885 - val_loss: 1.2944 - val_accuracy: 0.7949\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2232 - accuracy: 0.7934 - val_loss: 1.1796 - val_accuracy: 0.7824\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1029 - accuracy: 0.7962 - val_loss: 1.0669 - val_accuracy: 0.7959\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0222 - accuracy: 0.8007 - val_loss: 0.9828 - val_accuracy: 0.8080\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9669 - accuracy: 0.8044 - val_loss: 0.9797 - val_accuracy: 0.7956\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9237 - accuracy: 0.8093 - val_loss: 0.9225 - val_accuracy: 0.8047\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8898 - accuracy: 0.8118 - val_loss: 0.8899 - val_accuracy: 0.8006\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:55.036510\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9290 - accuracy: 0.8195 - val_loss: 0.9285 - val_accuracy: 0.8164\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8979 - accuracy: 0.8240 - val_loss: 0.9024 - val_accuracy: 0.8206\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8819 - accuracy: 0.8264 - val_loss: 0.8930 - val_accuracy: 0.8218\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8742 - accuracy: 0.8280 - val_loss: 0.8882 - val_accuracy: 0.8211\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8703 - accuracy: 0.8288 - val_loss: 0.8855 - val_accuracy: 0.8222\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8684 - accuracy: 0.8286 - val_loss: 0.8845 - val_accuracy: 0.8226\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8676 - accuracy: 0.8289 - val_loss: 0.8842 - val_accuracy: 0.8228\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8672 - accuracy: 0.8290 - val_loss: 0.8840 - val_accuracy: 0.8221\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8670 - accuracy: 0.8290 - val_loss: 0.8839 - val_accuracy: 0.8221\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8670 - accuracy: 0.8290 - val_loss: 0.8839 - val_accuracy: 0.8221\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:32.316729\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 7.9476 - accuracy: 0.3468 - val_loss: 6.2403 - val_accuracy: 0.5549\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.4150 - accuracy: 0.6354 - val_loss: 4.7369 - val_accuracy: 0.6647\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1273 - accuracy: 0.6963 - val_loss: 3.5921 - val_accuracy: 0.7125\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1029 - accuracy: 0.7361 - val_loss: 2.6883 - val_accuracy: 0.7497\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.3218 - accuracy: 0.7605 - val_loss: 1.9892 - val_accuracy: 0.7768\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7718 - accuracy: 0.7764 - val_loss: 1.5668 - val_accuracy: 0.7834\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4335 - accuracy: 0.7845 - val_loss: 1.3274 - val_accuracy: 0.7848\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2237 - accuracy: 0.7913 - val_loss: 1.1679 - val_accuracy: 0.7905\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0994 - accuracy: 0.7952 - val_loss: 1.0568 - val_accuracy: 0.8000\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0187 - accuracy: 0.8013 - val_loss: 1.0465 - val_accuracy: 0.7833\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9611 - accuracy: 0.8043 - val_loss: 0.9353 - val_accuracy: 0.8102\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9177 - accuracy: 0.8100 - val_loss: 0.9101 - val_accuracy: 0.8094\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8842 - accuracy: 0.8133 - val_loss: 0.8772 - val_accuracy: 0.8126\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8566 - accuracy: 0.8165 - val_loss: 0.8904 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8341 - accuracy: 0.8194 - val_loss: 0.8231 - val_accuracy: 0.8188\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8144 - accuracy: 0.8234 - val_loss: 0.8206 - val_accuracy: 0.8191\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7978 - accuracy: 0.8240 - val_loss: 0.8011 - val_accuracy: 0.8233\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7816 - accuracy: 0.8275 - val_loss: 0.7823 - val_accuracy: 0.8252\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7690 - accuracy: 0.8285 - val_loss: 0.7727 - val_accuracy: 0.8242\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7580 - accuracy: 0.8304 - val_loss: 0.7629 - val_accuracy: 0.8247\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:03.969361\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7311 - accuracy: 0.8376 - val_loss: 0.7440 - val_accuracy: 0.8298\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7180 - accuracy: 0.8402 - val_loss: 0.7340 - val_accuracy: 0.8334\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7112 - accuracy: 0.8421 - val_loss: 0.7277 - val_accuracy: 0.8348\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7075 - accuracy: 0.8426 - val_loss: 0.7267 - val_accuracy: 0.8344\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7058 - accuracy: 0.8431 - val_loss: 0.7248 - val_accuracy: 0.8350\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7048 - accuracy: 0.8433 - val_loss: 0.7243 - val_accuracy: 0.8352\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7044 - accuracy: 0.8435 - val_loss: 0.7241 - val_accuracy: 0.8352\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7042 - accuracy: 0.8437 - val_loss: 0.7240 - val_accuracy: 0.8353\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7041 - accuracy: 0.8436 - val_loss: 0.7240 - val_accuracy: 0.8353\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7041 - accuracy: 0.8437 - val_loss: 0.7240 - val_accuracy: 0.8353\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7041 - accuracy: 0.8438 - val_loss: 0.7240 - val_accuracy: 0.8353\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:59.405733\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 7.9823 - accuracy: 0.3417 - val_loss: 6.1614 - val_accuracy: 0.5808\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.3591 - accuracy: 0.6452 - val_loss: 4.6321 - val_accuracy: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0604 - accuracy: 0.7088 - val_loss: 3.5345 - val_accuracy: 0.7194\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.0448 - accuracy: 0.7485 - val_loss: 2.6131 - val_accuracy: 0.7654\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2776 - accuracy: 0.7676 - val_loss: 1.9930 - val_accuracy: 0.7682\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7377 - accuracy: 0.7819 - val_loss: 1.5797 - val_accuracy: 0.7718\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4030 - accuracy: 0.7872 - val_loss: 1.3280 - val_accuracy: 0.7727\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1996 - accuracy: 0.7935 - val_loss: 1.1350 - val_accuracy: 0.7927\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0773 - accuracy: 0.7965 - val_loss: 1.0451 - val_accuracy: 0.7952\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9984 - accuracy: 0.8016 - val_loss: 0.9611 - val_accuracy: 0.8065\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9437 - accuracy: 0.8058 - val_loss: 0.9330 - val_accuracy: 0.7975\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9021 - accuracy: 0.8098 - val_loss: 0.8842 - val_accuracy: 0.8124\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8681 - accuracy: 0.8134 - val_loss: 0.8780 - val_accuracy: 0.8093\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8431 - accuracy: 0.8151 - val_loss: 0.8343 - val_accuracy: 0.8170\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8215 - accuracy: 0.8173 - val_loss: 0.8175 - val_accuracy: 0.8176\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8022 - accuracy: 0.8210 - val_loss: 0.8123 - val_accuracy: 0.8185\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7859 - accuracy: 0.8235 - val_loss: 0.8096 - val_accuracy: 0.8104\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7718 - accuracy: 0.8255 - val_loss: 0.7757 - val_accuracy: 0.8230\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7596 - accuracy: 0.8270 - val_loss: 0.7693 - val_accuracy: 0.8228\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7475 - accuracy: 0.8293 - val_loss: 0.7660 - val_accuracy: 0.8204\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:01.694027\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7232 - accuracy: 0.8344 - val_loss: 0.7382 - val_accuracy: 0.8277\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7102 - accuracy: 0.8389 - val_loss: 0.7235 - val_accuracy: 0.8349\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7037 - accuracy: 0.8394 - val_loss: 0.7187 - val_accuracy: 0.8358\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7003 - accuracy: 0.8413 - val_loss: 0.7175 - val_accuracy: 0.8363\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6987 - accuracy: 0.8414 - val_loss: 0.7157 - val_accuracy: 0.8364\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6977 - accuracy: 0.8416 - val_loss: 0.7152 - val_accuracy: 0.8365\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6973 - accuracy: 0.8417 - val_loss: 0.7150 - val_accuracy: 0.8365\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6971 - accuracy: 0.8418 - val_loss: 0.7149 - val_accuracy: 0.8365\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6970 - accuracy: 0.8418 - val_loss: 0.7149 - val_accuracy: 0.8364\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:02.780667\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.1781 - accuracy: 0.2938 - val_loss: 6.2678 - val_accuracy: 0.5656\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4708 - accuracy: 0.6196 - val_loss: 4.7203 - val_accuracy: 0.6779\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1456 - accuracy: 0.6921 - val_loss: 3.5895 - val_accuracy: 0.7168\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.1087 - accuracy: 0.7370 - val_loss: 2.6919 - val_accuracy: 0.7474\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3226 - accuracy: 0.7609 - val_loss: 2.0230 - val_accuracy: 0.7665\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7662 - accuracy: 0.7764 - val_loss: 1.5953 - val_accuracy: 0.7764\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4108 - accuracy: 0.7859 - val_loss: 1.3322 - val_accuracy: 0.7730\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1963 - accuracy: 0.7903 - val_loss: 1.1453 - val_accuracy: 0.7860\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0666 - accuracy: 0.7964 - val_loss: 1.0538 - val_accuracy: 0.7901\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9865 - accuracy: 0.8009 - val_loss: 0.9732 - val_accuracy: 0.8057\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9336 - accuracy: 0.8053 - val_loss: 0.9756 - val_accuracy: 0.7826\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8971 - accuracy: 0.8086 - val_loss: 0.9086 - val_accuracy: 0.8062\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8651 - accuracy: 0.8130 - val_loss: 0.8833 - val_accuracy: 0.8051\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8417 - accuracy: 0.8147 - val_loss: 0.8447 - val_accuracy: 0.8153\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8194 - accuracy: 0.8174 - val_loss: 0.8674 - val_accuracy: 0.8014\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8006 - accuracy: 0.8206 - val_loss: 0.8117 - val_accuracy: 0.8218\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7852 - accuracy: 0.8228 - val_loss: 0.8221 - val_accuracy: 0.8125\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7717 - accuracy: 0.8251 - val_loss: 0.8138 - val_accuracy: 0.8098\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7596 - accuracy: 0.8275 - val_loss: 0.7870 - val_accuracy: 0.8231\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7487 - accuracy: 0.8285 - val_loss: 0.7804 - val_accuracy: 0.8214\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:21.041316\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7250 - accuracy: 0.8338 - val_loss: 0.7582 - val_accuracy: 0.8265\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7126 - accuracy: 0.8380 - val_loss: 0.7446 - val_accuracy: 0.8291\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7057 - accuracy: 0.8391 - val_loss: 0.7428 - val_accuracy: 0.8293\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7026 - accuracy: 0.8396 - val_loss: 0.7397 - val_accuracy: 0.8299\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7008 - accuracy: 0.8401 - val_loss: 0.7389 - val_accuracy: 0.8302\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6999 - accuracy: 0.8405 - val_loss: 0.7384 - val_accuracy: 0.8302\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6995 - accuracy: 0.8405 - val_loss: 0.7381 - val_accuracy: 0.8305\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6993 - accuracy: 0.8404 - val_loss: 0.7380 - val_accuracy: 0.8305\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6992 - accuracy: 0.8406 - val_loss: 0.7380 - val_accuracy: 0.8305\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6992 - accuracy: 0.8406 - val_loss: 0.7380 - val_accuracy: 0.8306\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6992 - accuracy: 0.8406 - val_loss: 0.7380 - val_accuracy: 0.8306\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6992 - accuracy: 0.8406 - val_loss: 0.7380 - val_accuracy: 0.8306\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6992 - accuracy: 0.8406 - val_loss: 0.7380 - val_accuracy: 0.8306\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:05.653263\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.4901 - accuracy: 0.2200 - val_loss: 6.4343 - val_accuracy: 0.5083\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.5523 - accuracy: 0.5947 - val_loss: 4.8457 - val_accuracy: 0.6388\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2202 - accuracy: 0.6713 - val_loss: 3.6522 - val_accuracy: 0.6978\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.1779 - accuracy: 0.7148 - val_loss: 2.7260 - val_accuracy: 0.7403\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3747 - accuracy: 0.7454 - val_loss: 2.0594 - val_accuracy: 0.7552\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8010 - accuracy: 0.7669 - val_loss: 1.6106 - val_accuracy: 0.7658\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4375 - accuracy: 0.7787 - val_loss: 1.3143 - val_accuracy: 0.7823\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2146 - accuracy: 0.7872 - val_loss: 1.1337 - val_accuracy: 0.7897\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0818 - accuracy: 0.7926 - val_loss: 1.0517 - val_accuracy: 0.7959\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0040 - accuracy: 0.7974 - val_loss: 1.0099 - val_accuracy: 0.7893\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9510 - accuracy: 0.8031 - val_loss: 0.9678 - val_accuracy: 0.7807\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9111 - accuracy: 0.8069 - val_loss: 0.9055 - val_accuracy: 0.8109\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8810 - accuracy: 0.8100 - val_loss: 0.8949 - val_accuracy: 0.8041\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8543 - accuracy: 0.8134 - val_loss: 0.8610 - val_accuracy: 0.8110\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8336 - accuracy: 0.8168 - val_loss: 0.8670 - val_accuracy: 0.8008\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8149 - accuracy: 0.8203 - val_loss: 0.8515 - val_accuracy: 0.8098\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7991 - accuracy: 0.8225 - val_loss: 0.8222 - val_accuracy: 0.8047\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:07:59.822164\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8035 - accuracy: 0.8284 - val_loss: 0.8268 - val_accuracy: 0.8159\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7863 - accuracy: 0.8306 - val_loss: 0.8136 - val_accuracy: 0.8200\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7778 - accuracy: 0.8328 - val_loss: 0.8082 - val_accuracy: 0.8215\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7732 - accuracy: 0.8335 - val_loss: 0.8042 - val_accuracy: 0.8221\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7710 - accuracy: 0.8336 - val_loss: 0.8030 - val_accuracy: 0.8219\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7698 - accuracy: 0.8342 - val_loss: 0.8022 - val_accuracy: 0.8222\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7693 - accuracy: 0.8345 - val_loss: 0.8019 - val_accuracy: 0.8223\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7691 - accuracy: 0.8343 - val_loss: 0.8018 - val_accuracy: 0.8221\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7690 - accuracy: 0.8343 - val_loss: 0.8018 - val_accuracy: 0.8221\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7690 - accuracy: 0.8343 - val_loss: 0.8018 - val_accuracy: 0.8221\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:43.249786\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.4029 - accuracy: 0.2430 - val_loss: 6.2950 - val_accuracy: 0.5577\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.5253 - accuracy: 0.6058 - val_loss: 4.7703 - val_accuracy: 0.6486\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1858 - accuracy: 0.6837 - val_loss: 3.6568 - val_accuracy: 0.6938\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.1435 - accuracy: 0.7257 - val_loss: 2.6868 - val_accuracy: 0.7478\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3494 - accuracy: 0.7538 - val_loss: 2.0572 - val_accuracy: 0.7488\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7837 - accuracy: 0.7709 - val_loss: 1.5866 - val_accuracy: 0.7712\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4271 - accuracy: 0.7794 - val_loss: 1.2857 - val_accuracy: 0.7798\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2031 - accuracy: 0.7888 - val_loss: 1.1279 - val_accuracy: 0.7861\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0699 - accuracy: 0.7939 - val_loss: 1.0158 - val_accuracy: 0.7964\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9929 - accuracy: 0.7976 - val_loss: 0.9783 - val_accuracy: 0.7945\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9408 - accuracy: 0.8027 - val_loss: 0.9281 - val_accuracy: 0.8023\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8978 - accuracy: 0.8073 - val_loss: 0.8801 - val_accuracy: 0.8085\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8682 - accuracy: 0.8109 - val_loss: 0.8725 - val_accuracy: 0.8039\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.8418 - accuracy: 0.8137 - val_loss: 0.8377 - val_accuracy: 0.8128\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8200 - accuracy: 0.8178 - val_loss: 0.8260 - val_accuracy: 0.8117\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8018 - accuracy: 0.8194 - val_loss: 0.8053 - val_accuracy: 0.8187\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7858 - accuracy: 0.8222 - val_loss: 0.7961 - val_accuracy: 0.8178\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7712 - accuracy: 0.8249 - val_loss: 0.7907 - val_accuracy: 0.8131\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7586 - accuracy: 0.8265 - val_loss: 0.7596 - val_accuracy: 0.8262\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7478 - accuracy: 0.8280 - val_loss: 0.7517 - val_accuracy: 0.8249\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:34.645361\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7254 - accuracy: 0.8342 - val_loss: 0.7353 - val_accuracy: 0.8277\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7136 - accuracy: 0.8368 - val_loss: 0.7263 - val_accuracy: 0.8318\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7075 - accuracy: 0.8386 - val_loss: 0.7187 - val_accuracy: 0.8309\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7041 - accuracy: 0.8401 - val_loss: 0.7172 - val_accuracy: 0.8318\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7024 - accuracy: 0.8406 - val_loss: 0.7160 - val_accuracy: 0.8325\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7016 - accuracy: 0.8409 - val_loss: 0.7155 - val_accuracy: 0.8320\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7012 - accuracy: 0.8408 - val_loss: 0.7154 - val_accuracy: 0.8321\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7010 - accuracy: 0.8408 - val_loss: 0.7153 - val_accuracy: 0.8321\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:47.937525\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 8.1609 - accuracy: 0.2937 - val_loss: 6.2428 - val_accuracy: 0.5609\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4640 - accuracy: 0.6181 - val_loss: 4.7642 - val_accuracy: 0.6554\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 4.1482 - accuracy: 0.6893 - val_loss: 3.5719 - val_accuracy: 0.7160\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.1225 - accuracy: 0.7288 - val_loss: 2.6912 - val_accuracy: 0.7508\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3372 - accuracy: 0.7545 - val_loss: 2.0482 - val_accuracy: 0.7545\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7742 - accuracy: 0.7719 - val_loss: 1.6313 - val_accuracy: 0.7449\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4229 - accuracy: 0.7790 - val_loss: 1.3111 - val_accuracy: 0.7756\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2029 - accuracy: 0.7858 - val_loss: 1.1136 - val_accuracy: 0.7974\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0744 - accuracy: 0.7928 - val_loss: 1.0465 - val_accuracy: 0.7879\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.0022 - accuracy: 0.7945 - val_loss: 0.9914 - val_accuracy: 0.7950\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9503 - accuracy: 0.8001 - val_loss: 0.9302 - val_accuracy: 0.8051\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9143 - accuracy: 0.8030 - val_loss: 0.9244 - val_accuracy: 0.7988\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8838 - accuracy: 0.8069 - val_loss: 0.9075 - val_accuracy: 0.7982\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8596 - accuracy: 0.8111 - val_loss: 0.8697 - val_accuracy: 0.8041\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:06:38.843298\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8780 - accuracy: 0.8167 - val_loss: 0.8795 - val_accuracy: 0.8119\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8526 - accuracy: 0.8198 - val_loss: 0.8612 - val_accuracy: 0.8148\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8399 - accuracy: 0.8223 - val_loss: 0.8541 - val_accuracy: 0.8165\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8335 - accuracy: 0.8238 - val_loss: 0.8488 - val_accuracy: 0.8180\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8304 - accuracy: 0.8243 - val_loss: 0.8473 - val_accuracy: 0.8180\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8289 - accuracy: 0.8248 - val_loss: 0.8459 - val_accuracy: 0.8178\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8281 - accuracy: 0.8249 - val_loss: 0.8454 - val_accuracy: 0.8182\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8278 - accuracy: 0.8248 - val_loss: 0.8453 - val_accuracy: 0.8185\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8277 - accuracy: 0.8250 - val_loss: 0.8452 - val_accuracy: 0.8186\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8276 - accuracy: 0.8250 - val_loss: 0.8452 - val_accuracy: 0.8185\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8276 - accuracy: 0.8250 - val_loss: 0.8452 - val_accuracy: 0.8185\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8276 - accuracy: 0.8250 - val_loss: 0.8452 - val_accuracy: 0.8185\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:41.604494\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.4233 - accuracy: 0.2314 - val_loss: 6.3838 - val_accuracy: 0.5270\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.5259 - accuracy: 0.6061 - val_loss: 4.9328 - val_accuracy: 0.6088\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 4.1879 - accuracy: 0.6813 - val_loss: 3.6029 - val_accuracy: 0.7145\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.1402 - accuracy: 0.7255 - val_loss: 2.6862 - val_accuracy: 0.7588\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.3417 - accuracy: 0.7543 - val_loss: 2.0481 - val_accuracy: 0.7562\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7722 - accuracy: 0.7742 - val_loss: 1.5820 - val_accuracy: 0.7723\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4185 - accuracy: 0.7827 - val_loss: 1.3140 - val_accuracy: 0.7840\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2028 - accuracy: 0.7888 - val_loss: 1.1280 - val_accuracy: 0.7912\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0754 - accuracy: 0.7926 - val_loss: 1.0453 - val_accuracy: 0.7938\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9952 - accuracy: 0.7970 - val_loss: 0.9947 - val_accuracy: 0.7910\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9420 - accuracy: 0.8020 - val_loss: 0.9342 - val_accuracy: 0.8003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9021 - accuracy: 0.8057 - val_loss: 0.9210 - val_accuracy: 0.7993\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8728 - accuracy: 0.8073 - val_loss: 0.8941 - val_accuracy: 0.8042\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8463 - accuracy: 0.8121 - val_loss: 0.8497 - val_accuracy: 0.8119\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8252 - accuracy: 0.8159 - val_loss: 0.8364 - val_accuracy: 0.8129\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8062 - accuracy: 0.8184 - val_loss: 0.8189 - val_accuracy: 0.8152\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7916 - accuracy: 0.8196 - val_loss: 0.8286 - val_accuracy: 0.8095\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7773 - accuracy: 0.8216 - val_loss: 0.8023 - val_accuracy: 0.8127\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7654 - accuracy: 0.8229 - val_loss: 0.7893 - val_accuracy: 0.8174\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7547 - accuracy: 0.8251 - val_loss: 0.7751 - val_accuracy: 0.8194\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:31.858973\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7300 - accuracy: 0.8319 - val_loss: 0.7596 - val_accuracy: 0.8258\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7177 - accuracy: 0.8351 - val_loss: 0.7446 - val_accuracy: 0.8275\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7115 - accuracy: 0.8363 - val_loss: 0.7396 - val_accuracy: 0.8288\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7081 - accuracy: 0.8374 - val_loss: 0.7376 - val_accuracy: 0.8295\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7064 - accuracy: 0.8377 - val_loss: 0.7369 - val_accuracy: 0.8293\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7056 - accuracy: 0.8378 - val_loss: 0.7365 - val_accuracy: 0.8302\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7051 - accuracy: 0.8379 - val_loss: 0.7364 - val_accuracy: 0.8296\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7049 - accuracy: 0.8381 - val_loss: 0.7363 - val_accuracy: 0.8297\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7049 - accuracy: 0.8381 - val_loss: 0.7363 - val_accuracy: 0.8297\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:17.211977\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.2310 - accuracy: 0.2525 - val_loss: 1.8000 - val_accuracy: 0.5599\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5543 - accuracy: 0.6135 - val_loss: 1.3697 - val_accuracy: 0.6661\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2415 - accuracy: 0.6956 - val_loss: 1.1638 - val_accuracy: 0.7188\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0603 - accuracy: 0.7435 - val_loss: 1.0409 - val_accuracy: 0.7451\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9453 - accuracy: 0.7740 - val_loss: 0.9376 - val_accuracy: 0.7715\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8672 - accuracy: 0.7936 - val_loss: 0.8665 - val_accuracy: 0.7969\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8134 - accuracy: 0.8079 - val_loss: 0.8306 - val_accuracy: 0.8032\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7763 - accuracy: 0.8162 - val_loss: 0.8020 - val_accuracy: 0.8113\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7490 - accuracy: 0.8238 - val_loss: 0.7858 - val_accuracy: 0.8184\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7252 - accuracy: 0.8297 - val_loss: 0.7585 - val_accuracy: 0.8194\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7064 - accuracy: 0.8354 - val_loss: 0.7398 - val_accuracy: 0.8246\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6900 - accuracy: 0.8402 - val_loss: 0.7282 - val_accuracy: 0.8297\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6768 - accuracy: 0.8426 - val_loss: 0.7157 - val_accuracy: 0.8337\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6655 - accuracy: 0.8455 - val_loss: 0.7069 - val_accuracy: 0.8341\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6552 - accuracy: 0.8484 - val_loss: 0.7014 - val_accuracy: 0.8368\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6467 - accuracy: 0.8502 - val_loss: 0.6965 - val_accuracy: 0.8368\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6391 - accuracy: 0.8532 - val_loss: 0.6859 - val_accuracy: 0.8403\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6324 - accuracy: 0.8544 - val_loss: 0.6842 - val_accuracy: 0.8379\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6263 - accuracy: 0.8558 - val_loss: 0.6778 - val_accuracy: 0.8406\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6210 - accuracy: 0.8564 - val_loss: 0.6712 - val_accuracy: 0.8422\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:59.024404\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6122 - accuracy: 0.8602 - val_loss: 0.6665 - val_accuracy: 0.8441\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6078 - accuracy: 0.8615 - val_loss: 0.6673 - val_accuracy: 0.8433\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6057 - accuracy: 0.8619 - val_loss: 0.6642 - val_accuracy: 0.8438\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6045 - accuracy: 0.8625 - val_loss: 0.6642 - val_accuracy: 0.8440\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:01:47.881332\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6523 - accuracy: 0.1544 - val_loss: 2.1548 - val_accuracy: 0.4570\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6281 - accuracy: 0.5995 - val_loss: 1.4225 - val_accuracy: 0.6532\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2472 - accuracy: 0.6976 - val_loss: 1.1414 - val_accuracy: 0.7199\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0532 - accuracy: 0.7484 - val_loss: 1.0085 - val_accuracy: 0.7594\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9364 - accuracy: 0.7763 - val_loss: 0.9064 - val_accuracy: 0.7858\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8555 - accuracy: 0.7983 - val_loss: 0.8460 - val_accuracy: 0.7986\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8035 - accuracy: 0.8118 - val_loss: 0.8112 - val_accuracy: 0.8112\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7665 - accuracy: 0.8208 - val_loss: 0.7720 - val_accuracy: 0.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7387 - accuracy: 0.8265 - val_loss: 0.7689 - val_accuracy: 0.8164\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7165 - accuracy: 0.8333 - val_loss: 0.7395 - val_accuracy: 0.8289\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6989 - accuracy: 0.8372 - val_loss: 0.7283 - val_accuracy: 0.8297\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6827 - accuracy: 0.8413 - val_loss: 0.7184 - val_accuracy: 0.8318\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6702 - accuracy: 0.8440 - val_loss: 0.7073 - val_accuracy: 0.8359\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6585 - accuracy: 0.8474 - val_loss: 0.6991 - val_accuracy: 0.8359\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6484 - accuracy: 0.8492 - val_loss: 0.6866 - val_accuracy: 0.8388\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6403 - accuracy: 0.8517 - val_loss: 0.6821 - val_accuracy: 0.8401\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6327 - accuracy: 0.8540 - val_loss: 0.6749 - val_accuracy: 0.8410\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6263 - accuracy: 0.8548 - val_loss: 0.6724 - val_accuracy: 0.8414\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6203 - accuracy: 0.8571 - val_loss: 0.6680 - val_accuracy: 0.8444\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6151 - accuracy: 0.8575 - val_loss: 0.6670 - val_accuracy: 0.8415\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:00.662216\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6071 - accuracy: 0.8603 - val_loss: 0.6601 - val_accuracy: 0.8457\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6025 - accuracy: 0.8620 - val_loss: 0.6572 - val_accuracy: 0.8478\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6002 - accuracy: 0.8632 - val_loss: 0.6561 - val_accuracy: 0.8478\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5991 - accuracy: 0.8637 - val_loss: 0.6555 - val_accuracy: 0.8480\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5985 - accuracy: 0.8639 - val_loss: 0.6555 - val_accuracy: 0.8484\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5982 - accuracy: 0.8639 - val_loss: 0.6554 - val_accuracy: 0.8484\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5980 - accuracy: 0.8640 - val_loss: 0.6554 - val_accuracy: 0.8484\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5980 - accuracy: 0.8641 - val_loss: 0.6554 - val_accuracy: 0.8484\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5979 - accuracy: 0.8640 - val_loss: 0.6554 - val_accuracy: 0.8484\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5979 - accuracy: 0.8640 - val_loss: 0.6554 - val_accuracy: 0.8484\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5979 - accuracy: 0.8640 - val_loss: 0.6554 - val_accuracy: 0.8484\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:57.523405\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3115 - accuracy: 0.2226 - val_loss: 1.8792 - val_accuracy: 0.5369\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5656 - accuracy: 0.6132 - val_loss: 1.4061 - val_accuracy: 0.6573\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2461 - accuracy: 0.6993 - val_loss: 1.1257 - val_accuracy: 0.7313\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0577 - accuracy: 0.7464 - val_loss: 0.9962 - val_accuracy: 0.7596\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9392 - accuracy: 0.7767 - val_loss: 0.8997 - val_accuracy: 0.7891\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8587 - accuracy: 0.7975 - val_loss: 0.8532 - val_accuracy: 0.7974\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8063 - accuracy: 0.8101 - val_loss: 0.8001 - val_accuracy: 0.8131\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7689 - accuracy: 0.8198 - val_loss: 0.7797 - val_accuracy: 0.8114\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7394 - accuracy: 0.8277 - val_loss: 0.7489 - val_accuracy: 0.8226\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7179 - accuracy: 0.8331 - val_loss: 0.7330 - val_accuracy: 0.8229\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6988 - accuracy: 0.8383 - val_loss: 0.7200 - val_accuracy: 0.8284\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6841 - accuracy: 0.8412 - val_loss: 0.7053 - val_accuracy: 0.8323\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6697 - accuracy: 0.8445 - val_loss: 0.6923 - val_accuracy: 0.8335\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6594 - accuracy: 0.8472 - val_loss: 0.6917 - val_accuracy: 0.8356\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6494 - accuracy: 0.8505 - val_loss: 0.6812 - val_accuracy: 0.8354\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6401 - accuracy: 0.8520 - val_loss: 0.6757 - val_accuracy: 0.8353\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6321 - accuracy: 0.8539 - val_loss: 0.6709 - val_accuracy: 0.8390\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6264 - accuracy: 0.8556 - val_loss: 0.6655 - val_accuracy: 0.8383\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6203 - accuracy: 0.8572 - val_loss: 0.6574 - val_accuracy: 0.8403\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6151 - accuracy: 0.8588 - val_loss: 0.6557 - val_accuracy: 0.8417\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:05.696968\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6066 - accuracy: 0.8615 - val_loss: 0.6489 - val_accuracy: 0.8438\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6022 - accuracy: 0.8626 - val_loss: 0.6477 - val_accuracy: 0.8453\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5998 - accuracy: 0.8637 - val_loss: 0.6459 - val_accuracy: 0.8450\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5987 - accuracy: 0.8641 - val_loss: 0.6455 - val_accuracy: 0.8457\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5982 - accuracy: 0.8642 - val_loss: 0.6453 - val_accuracy: 0.8460\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5979 - accuracy: 0.8644 - val_loss: 0.6452 - val_accuracy: 0.8460\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5977 - accuracy: 0.8642 - val_loss: 0.6452 - val_accuracy: 0.8459\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5976 - accuracy: 0.8643 - val_loss: 0.6452 - val_accuracy: 0.8459\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:34.236208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.2456 - accuracy: 0.2329 - val_loss: 1.7764 - val_accuracy: 0.5640\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5329 - accuracy: 0.6210 - val_loss: 1.3889 - val_accuracy: 0.6516\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2147 - accuracy: 0.7053 - val_loss: 1.1234 - val_accuracy: 0.7258\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0334 - accuracy: 0.7516 - val_loss: 0.9859 - val_accuracy: 0.7664\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9225 - accuracy: 0.7802 - val_loss: 0.9218 - val_accuracy: 0.7718\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8470 - accuracy: 0.7993 - val_loss: 0.8438 - val_accuracy: 0.7976\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7983 - accuracy: 0.8121 - val_loss: 0.8023 - val_accuracy: 0.8085\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7630 - accuracy: 0.8213 - val_loss: 0.7712 - val_accuracy: 0.8191\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7353 - accuracy: 0.8284 - val_loss: 0.7475 - val_accuracy: 0.8222\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7132 - accuracy: 0.8345 - val_loss: 0.7346 - val_accuracy: 0.8271\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6959 - accuracy: 0.8387 - val_loss: 0.7193 - val_accuracy: 0.8309\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6806 - accuracy: 0.8418 - val_loss: 0.7102 - val_accuracy: 0.8305\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6681 - accuracy: 0.8451 - val_loss: 0.7024 - val_accuracy: 0.8352\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6563 - accuracy: 0.8486 - val_loss: 0.7022 - val_accuracy: 0.8327\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6467 - accuracy: 0.8505 - val_loss: 0.6879 - val_accuracy: 0.8365\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6386 - accuracy: 0.8522 - val_loss: 0.6744 - val_accuracy: 0.8418\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6305 - accuracy: 0.8538 - val_loss: 0.6716 - val_accuracy: 0.8413\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6240 - accuracy: 0.8561 - val_loss: 0.6663 - val_accuracy: 0.8418\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6180 - accuracy: 0.8583 - val_loss: 0.6598 - val_accuracy: 0.8433\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6126 - accuracy: 0.8591 - val_loss: 0.6578 - val_accuracy: 0.8469\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:57.446498\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6046 - accuracy: 0.8617 - val_loss: 0.6524 - val_accuracy: 0.8472\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6002 - accuracy: 0.8632 - val_loss: 0.6483 - val_accuracy: 0.8499\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5981 - accuracy: 0.8638 - val_loss: 0.6472 - val_accuracy: 0.8486\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5969 - accuracy: 0.8647 - val_loss: 0.6469 - val_accuracy: 0.8496\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5963 - accuracy: 0.8646 - val_loss: 0.6467 - val_accuracy: 0.8499\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:14.468998\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4462 - accuracy: 0.1934 - val_loss: 1.9521 - val_accuracy: 0.5072\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5842 - accuracy: 0.6084 - val_loss: 1.3730 - val_accuracy: 0.6629\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2326 - accuracy: 0.6993 - val_loss: 1.1293 - val_accuracy: 0.7241\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0375 - accuracy: 0.7519 - val_loss: 0.9653 - val_accuracy: 0.7683\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9242 - accuracy: 0.7790 - val_loss: 0.8818 - val_accuracy: 0.7911\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8479 - accuracy: 0.7995 - val_loss: 0.8422 - val_accuracy: 0.8004\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7986 - accuracy: 0.8123 - val_loss: 0.7978 - val_accuracy: 0.8118\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7629 - accuracy: 0.8217 - val_loss: 0.7626 - val_accuracy: 0.8205\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7365 - accuracy: 0.8272 - val_loss: 0.7427 - val_accuracy: 0.8277\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7137 - accuracy: 0.8337 - val_loss: 0.7394 - val_accuracy: 0.8258\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6964 - accuracy: 0.8375 - val_loss: 0.7164 - val_accuracy: 0.8316\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6810 - accuracy: 0.8420 - val_loss: 0.7124 - val_accuracy: 0.8316\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6679 - accuracy: 0.8449 - val_loss: 0.6918 - val_accuracy: 0.8392\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6556 - accuracy: 0.8488 - val_loss: 0.6901 - val_accuracy: 0.8380\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6466 - accuracy: 0.8503 - val_loss: 0.6870 - val_accuracy: 0.8373\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6380 - accuracy: 0.8536 - val_loss: 0.6783 - val_accuracy: 0.8408\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6303 - accuracy: 0.8539 - val_loss: 0.6720 - val_accuracy: 0.8411\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6237 - accuracy: 0.8566 - val_loss: 0.6675 - val_accuracy: 0.8416\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6178 - accuracy: 0.8572 - val_loss: 0.6616 - val_accuracy: 0.8448\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6124 - accuracy: 0.8584 - val_loss: 0.6562 - val_accuracy: 0.8450\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:56.449815\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6040 - accuracy: 0.8617 - val_loss: 0.6525 - val_accuracy: 0.8465\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5997 - accuracy: 0.8632 - val_loss: 0.6520 - val_accuracy: 0.8457\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5976 - accuracy: 0.8638 - val_loss: 0.6499 - val_accuracy: 0.8469\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5964 - accuracy: 0.8651 - val_loss: 0.6494 - val_accuracy: 0.8481\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5958 - accuracy: 0.8650 - val_loss: 0.6494 - val_accuracy: 0.8478\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5955 - accuracy: 0.8651 - val_loss: 0.6493 - val_accuracy: 0.8480\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5953 - accuracy: 0.8652 - val_loss: 0.6493 - val_accuracy: 0.8481\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:08.135090\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.8500 - accuracy: 0.3371 - val_loss: 1.6657 - val_accuracy: 0.5859\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4514 - accuracy: 0.6470 - val_loss: 1.3105 - val_accuracy: 0.6814\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1922 - accuracy: 0.7133 - val_loss: 1.0869 - val_accuracy: 0.7466\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0240 - accuracy: 0.7563 - val_loss: 0.9587 - val_accuracy: 0.7742\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9109 - accuracy: 0.7863 - val_loss: 0.8934 - val_accuracy: 0.7911\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8348 - accuracy: 0.8051 - val_loss: 0.8258 - val_accuracy: 0.8097\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7856 - accuracy: 0.8177 - val_loss: 0.8002 - val_accuracy: 0.8124\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7501 - accuracy: 0.8255 - val_loss: 0.7682 - val_accuracy: 0.8158\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7243 - accuracy: 0.8323 - val_loss: 0.7457 - val_accuracy: 0.8238\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7018 - accuracy: 0.8380 - val_loss: 0.7276 - val_accuracy: 0.8295\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6843 - accuracy: 0.8429 - val_loss: 0.7120 - val_accuracy: 0.8319\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6690 - accuracy: 0.8465 - val_loss: 0.7104 - val_accuracy: 0.8294\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6570 - accuracy: 0.8486 - val_loss: 0.6885 - val_accuracy: 0.8398\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6462 - accuracy: 0.8515 - val_loss: 0.6830 - val_accuracy: 0.8401\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6362 - accuracy: 0.8543 - val_loss: 0.6755 - val_accuracy: 0.8432\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6285 - accuracy: 0.8562 - val_loss: 0.6699 - val_accuracy: 0.8432\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6214 - accuracy: 0.8579 - val_loss: 0.6682 - val_accuracy: 0.8417\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6144 - accuracy: 0.8595 - val_loss: 0.6630 - val_accuracy: 0.8397\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:11.483655\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6221 - accuracy: 0.8589 - val_loss: 0.6670 - val_accuracy: 0.8452\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6167 - accuracy: 0.8610 - val_loss: 0.6661 - val_accuracy: 0.8445\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6140 - accuracy: 0.8626 - val_loss: 0.6640 - val_accuracy: 0.8459\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6127 - accuracy: 0.8627 - val_loss: 0.6635 - val_accuracy: 0.8463\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6120 - accuracy: 0.8632 - val_loss: 0.6634 - val_accuracy: 0.8462\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6116 - accuracy: 0.8632 - val_loss: 0.6632 - val_accuracy: 0.8461\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6115 - accuracy: 0.8631 - val_loss: 0.6632 - val_accuracy: 0.8461\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:11.680085\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.9376 - accuracy: 0.3199 - val_loss: 1.6480 - val_accuracy: 0.5959\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4504 - accuracy: 0.6485 - val_loss: 1.2758 - val_accuracy: 0.6887\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1930 - accuracy: 0.7130 - val_loss: 1.1075 - val_accuracy: 0.7342\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0199 - accuracy: 0.7571 - val_loss: 0.9484 - val_accuracy: 0.7779\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9110 - accuracy: 0.7847 - val_loss: 0.8531 - val_accuracy: 0.8032\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8354 - accuracy: 0.8028 - val_loss: 0.8065 - val_accuracy: 0.8141\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7885 - accuracy: 0.8160 - val_loss: 0.7778 - val_accuracy: 0.8182\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7528 - accuracy: 0.8252 - val_loss: 0.7450 - val_accuracy: 0.8295\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7251 - accuracy: 0.8315 - val_loss: 0.7257 - val_accuracy: 0.8329\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7043 - accuracy: 0.8367 - val_loss: 0.7192 - val_accuracy: 0.8339\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6866 - accuracy: 0.8408 - val_loss: 0.6974 - val_accuracy: 0.8377\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6720 - accuracy: 0.8448 - val_loss: 0.6901 - val_accuracy: 0.8387\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6592 - accuracy: 0.8474 - val_loss: 0.6813 - val_accuracy: 0.8414\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6482 - accuracy: 0.8512 - val_loss: 0.6702 - val_accuracy: 0.8451\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6385 - accuracy: 0.8532 - val_loss: 0.6627 - val_accuracy: 0.8456\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6301 - accuracy: 0.8553 - val_loss: 0.6584 - val_accuracy: 0.8480\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6230 - accuracy: 0.8571 - val_loss: 0.6552 - val_accuracy: 0.8481\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6161 - accuracy: 0.8587 - val_loss: 0.6518 - val_accuracy: 0.8480\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6106 - accuracy: 0.8594 - val_loss: 0.6435 - val_accuracy: 0.8509\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6057 - accuracy: 0.8612 - val_loss: 0.6420 - val_accuracy: 0.8504\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:07.399482\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5976 - accuracy: 0.8643 - val_loss: 0.6371 - val_accuracy: 0.8513\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5935 - accuracy: 0.8656 - val_loss: 0.6358 - val_accuracy: 0.8532\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5914 - accuracy: 0.8664 - val_loss: 0.6340 - val_accuracy: 0.8544\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5902 - accuracy: 0.8668 - val_loss: 0.6340 - val_accuracy: 0.8533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5897 - accuracy: 0.8669 - val_loss: 0.6337 - val_accuracy: 0.8535\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5894 - accuracy: 0.8670 - val_loss: 0.6335 - val_accuracy: 0.8536\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:43.747376\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.8246 - accuracy: 0.3575 - val_loss: 1.6830 - val_accuracy: 0.5881\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4364 - accuracy: 0.6507 - val_loss: 1.2741 - val_accuracy: 0.6900\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1683 - accuracy: 0.7200 - val_loss: 1.0791 - val_accuracy: 0.7419\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0001 - accuracy: 0.7620 - val_loss: 0.9437 - val_accuracy: 0.7746\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8926 - accuracy: 0.7898 - val_loss: 0.8503 - val_accuracy: 0.7983\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8247 - accuracy: 0.8080 - val_loss: 0.8138 - val_accuracy: 0.8058\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7772 - accuracy: 0.8192 - val_loss: 0.7752 - val_accuracy: 0.8170\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7433 - accuracy: 0.8282 - val_loss: 0.7480 - val_accuracy: 0.8215\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7176 - accuracy: 0.8347 - val_loss: 0.7223 - val_accuracy: 0.8309\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6969 - accuracy: 0.8400 - val_loss: 0.7158 - val_accuracy: 0.8293\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6793 - accuracy: 0.8452 - val_loss: 0.6923 - val_accuracy: 0.8354\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6652 - accuracy: 0.8480 - val_loss: 0.6843 - val_accuracy: 0.8388\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6528 - accuracy: 0.8509 - val_loss: 0.6774 - val_accuracy: 0.8379\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6420 - accuracy: 0.8530 - val_loss: 0.6658 - val_accuracy: 0.8428\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6325 - accuracy: 0.8553 - val_loss: 0.6575 - val_accuracy: 0.8450\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6244 - accuracy: 0.8585 - val_loss: 0.6542 - val_accuracy: 0.8460\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6175 - accuracy: 0.8595 - val_loss: 0.6503 - val_accuracy: 0.8461\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6108 - accuracy: 0.8617 - val_loss: 0.6485 - val_accuracy: 0.8457\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6051 - accuracy: 0.8631 - val_loss: 0.6396 - val_accuracy: 0.8482\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6004 - accuracy: 0.8640 - val_loss: 0.6355 - val_accuracy: 0.8477\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:06.766929\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.5924 - accuracy: 0.8663 - val_loss: 0.6337 - val_accuracy: 0.8499\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.5883 - accuracy: 0.8679 - val_loss: 0.6302 - val_accuracy: 0.8516\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.5861 - accuracy: 0.8692 - val_loss: 0.6291 - val_accuracy: 0.8512\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5850 - accuracy: 0.8696 - val_loss: 0.6282 - val_accuracy: 0.8520\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5844 - accuracy: 0.8694 - val_loss: 0.6282 - val_accuracy: 0.8515\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.5841 - accuracy: 0.8696 - val_loss: 0.6281 - val_accuracy: 0.8519\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5840 - accuracy: 0.8698 - val_loss: 0.6281 - val_accuracy: 0.8517\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:22.931934\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.8533 - accuracy: 0.3437 - val_loss: 1.6198 - val_accuracy: 0.6120\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4248 - accuracy: 0.6535 - val_loss: 1.2741 - val_accuracy: 0.6961\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1610 - accuracy: 0.7222 - val_loss: 1.0800 - val_accuracy: 0.7461\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0021 - accuracy: 0.7614 - val_loss: 0.9707 - val_accuracy: 0.7707\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9018 - accuracy: 0.7882 - val_loss: 0.8970 - val_accuracy: 0.7855\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8328 - accuracy: 0.8061 - val_loss: 0.8317 - val_accuracy: 0.8079\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7855 - accuracy: 0.8166 - val_loss: 0.7990 - val_accuracy: 0.8150\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7513 - accuracy: 0.8258 - val_loss: 0.7761 - val_accuracy: 0.8202\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7250 - accuracy: 0.8315 - val_loss: 0.7485 - val_accuracy: 0.8219\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7028 - accuracy: 0.8379 - val_loss: 0.7364 - val_accuracy: 0.8273\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6854 - accuracy: 0.8433 - val_loss: 0.7262 - val_accuracy: 0.8293\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6707 - accuracy: 0.8455 - val_loss: 0.7131 - val_accuracy: 0.8315\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6576 - accuracy: 0.8492 - val_loss: 0.7081 - val_accuracy: 0.8351\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6471 - accuracy: 0.8514 - val_loss: 0.6913 - val_accuracy: 0.8386\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6375 - accuracy: 0.8533 - val_loss: 0.6868 - val_accuracy: 0.8389\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6291 - accuracy: 0.8559 - val_loss: 0.6800 - val_accuracy: 0.8381\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6217 - accuracy: 0.8579 - val_loss: 0.6767 - val_accuracy: 0.8383\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6154 - accuracy: 0.8589 - val_loss: 0.6730 - val_accuracy: 0.8392\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6093 - accuracy: 0.8609 - val_loss: 0.6705 - val_accuracy: 0.8385\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6047 - accuracy: 0.8614 - val_loss: 0.6622 - val_accuracy: 0.8456\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:06.764970\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5965 - accuracy: 0.8650 - val_loss: 0.6579 - val_accuracy: 0.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.5925 - accuracy: 0.8661 - val_loss: 0.6565 - val_accuracy: 0.8452\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5904 - accuracy: 0.8661 - val_loss: 0.6556 - val_accuracy: 0.8444\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5892 - accuracy: 0.8665 - val_loss: 0.6546 - val_accuracy: 0.8453\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5887 - accuracy: 0.8671 - val_loss: 0.6546 - val_accuracy: 0.8457\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5884 - accuracy: 0.8671 - val_loss: 0.6546 - val_accuracy: 0.8457\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5883 - accuracy: 0.8671 - val_loss: 0.6546 - val_accuracy: 0.8457\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5882 - accuracy: 0.8673 - val_loss: 0.6545 - val_accuracy: 0.8455\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:44.767030\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.8116 - accuracy: 0.3568 - val_loss: 1.6993 - val_accuracy: 0.5760\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4804 - accuracy: 0.6390 - val_loss: 1.3431 - val_accuracy: 0.6779\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2337 - accuracy: 0.7028 - val_loss: 1.1378 - val_accuracy: 0.7284\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0598 - accuracy: 0.7471 - val_loss: 1.0130 - val_accuracy: 0.7597\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9362 - accuracy: 0.7798 - val_loss: 0.8998 - val_accuracy: 0.7899\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8507 - accuracy: 0.8012 - val_loss: 0.8534 - val_accuracy: 0.7980\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7953 - accuracy: 0.8156 - val_loss: 0.8107 - val_accuracy: 0.8094\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7567 - accuracy: 0.8249 - val_loss: 0.7789 - val_accuracy: 0.8194\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7274 - accuracy: 0.8325 - val_loss: 0.7550 - val_accuracy: 0.8236\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7049 - accuracy: 0.8373 - val_loss: 0.7378 - val_accuracy: 0.8263\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6860 - accuracy: 0.8426 - val_loss: 0.7179 - val_accuracy: 0.8333\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6705 - accuracy: 0.8455 - val_loss: 0.7128 - val_accuracy: 0.8328\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6571 - accuracy: 0.8496 - val_loss: 0.6976 - val_accuracy: 0.8369\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6461 - accuracy: 0.8523 - val_loss: 0.6887 - val_accuracy: 0.8384\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6365 - accuracy: 0.8536 - val_loss: 0.6858 - val_accuracy: 0.8398\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6275 - accuracy: 0.8562 - val_loss: 0.6781 - val_accuracy: 0.8411\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6206 - accuracy: 0.8592 - val_loss: 0.6717 - val_accuracy: 0.8416\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6136 - accuracy: 0.8600 - val_loss: 0.6662 - val_accuracy: 0.8450\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6081 - accuracy: 0.8616 - val_loss: 0.6603 - val_accuracy: 0.8460\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6027 - accuracy: 0.8625 - val_loss: 0.6607 - val_accuracy: 0.8444\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:05.815426\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5951 - accuracy: 0.8650 - val_loss: 0.6534 - val_accuracy: 0.8471\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5911 - accuracy: 0.8663 - val_loss: 0.6511 - val_accuracy: 0.8476\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5888 - accuracy: 0.8676 - val_loss: 0.6501 - val_accuracy: 0.8478\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5878 - accuracy: 0.8678 - val_loss: 0.6500 - val_accuracy: 0.8474\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5872 - accuracy: 0.8680 - val_loss: 0.6499 - val_accuracy: 0.8481\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5869 - accuracy: 0.8681 - val_loss: 0.6497 - val_accuracy: 0.8481\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5868 - accuracy: 0.8684 - val_loss: 0.6497 - val_accuracy: 0.8480\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.5867 - accuracy: 0.8684 - val_loss: 0.6497 - val_accuracy: 0.8479\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.5867 - accuracy: 0.8684 - val_loss: 0.6497 - val_accuracy: 0.8479\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:07.381200\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.1219 - accuracy: 0.2550 - val_loss: 1.7577 - val_accuracy: 0.5624\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5583 - accuracy: 0.6178 - val_loss: 1.3891 - val_accuracy: 0.6509\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2636 - accuracy: 0.6948 - val_loss: 1.1338 - val_accuracy: 0.7245\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0780 - accuracy: 0.7422 - val_loss: 0.9954 - val_accuracy: 0.7651\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9562 - accuracy: 0.7734 - val_loss: 0.9090 - val_accuracy: 0.7799\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8738 - accuracy: 0.7952 - val_loss: 0.8537 - val_accuracy: 0.7953\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8196 - accuracy: 0.8087 - val_loss: 0.8255 - val_accuracy: 0.8023\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7810 - accuracy: 0.8182 - val_loss: 0.7714 - val_accuracy: 0.8133\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7527 - accuracy: 0.8247 - val_loss: 0.7563 - val_accuracy: 0.8211\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7294 - accuracy: 0.8302 - val_loss: 0.7288 - val_accuracy: 0.8301\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.7106 - accuracy: 0.8361 - val_loss: 0.7221 - val_accuracy: 0.8290\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6946 - accuracy: 0.8389 - val_loss: 0.7037 - val_accuracy: 0.8329\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6812 - accuracy: 0.8421 - val_loss: 0.7071 - val_accuracy: 0.8311\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6694 - accuracy: 0.8455 - val_loss: 0.6830 - val_accuracy: 0.8405\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6589 - accuracy: 0.8483 - val_loss: 0.6786 - val_accuracy: 0.8384\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6503 - accuracy: 0.8505 - val_loss: 0.6687 - val_accuracy: 0.8420\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6429 - accuracy: 0.8530 - val_loss: 0.6676 - val_accuracy: 0.8440\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6360 - accuracy: 0.8536 - val_loss: 0.6558 - val_accuracy: 0.8473\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6294 - accuracy: 0.8557 - val_loss: 0.6561 - val_accuracy: 0.8445\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6247 - accuracy: 0.8572 - val_loss: 0.6508 - val_accuracy: 0.8465\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:32.096427\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6159 - accuracy: 0.8595 - val_loss: 0.6453 - val_accuracy: 0.8488\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6114 - accuracy: 0.8607 - val_loss: 0.6426 - val_accuracy: 0.8498\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6092 - accuracy: 0.8616 - val_loss: 0.6415 - val_accuracy: 0.8504\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6080 - accuracy: 0.8624 - val_loss: 0.6408 - val_accuracy: 0.8512\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6075 - accuracy: 0.8626 - val_loss: 0.6406 - val_accuracy: 0.8516\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6071 - accuracy: 0.8628 - val_loss: 0.6405 - val_accuracy: 0.8516\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6070 - accuracy: 0.8631 - val_loss: 0.6404 - val_accuracy: 0.8517\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6069 - accuracy: 0.8631 - val_loss: 0.6404 - val_accuracy: 0.8518\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6069 - accuracy: 0.8631 - val_loss: 0.6404 - val_accuracy: 0.8519\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6069 - accuracy: 0.8631 - val_loss: 0.6404 - val_accuracy: 0.8519\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6069 - accuracy: 0.8631 - val_loss: 0.6404 - val_accuracy: 0.8519\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6069 - accuracy: 0.8631 - val_loss: 0.6404 - val_accuracy: 0.8519\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:45.778007\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3549 - accuracy: 0.2132 - val_loss: 1.9222 - val_accuracy: 0.5158\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6199 - accuracy: 0.6019 - val_loss: 1.4294 - val_accuracy: 0.6550\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2994 - accuracy: 0.6820 - val_loss: 1.1988 - val_accuracy: 0.7094\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.0958 - accuracy: 0.7365 - val_loss: 1.0288 - val_accuracy: 0.7588\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9609 - accuracy: 0.7717 - val_loss: 0.9369 - val_accuracy: 0.7803\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8735 - accuracy: 0.7956 - val_loss: 0.8596 - val_accuracy: 0.8008\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8168 - accuracy: 0.8086 - val_loss: 0.8329 - val_accuracy: 0.7993\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7781 - accuracy: 0.8184 - val_loss: 0.7868 - val_accuracy: 0.8176\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7487 - accuracy: 0.8263 - val_loss: 0.7695 - val_accuracy: 0.8143\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7255 - accuracy: 0.8323 - val_loss: 0.7444 - val_accuracy: 0.8281\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7061 - accuracy: 0.8364 - val_loss: 0.7334 - val_accuracy: 0.8277\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6902 - accuracy: 0.8405 - val_loss: 0.7216 - val_accuracy: 0.8319\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6764 - accuracy: 0.8436 - val_loss: 0.7164 - val_accuracy: 0.8318\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6649 - accuracy: 0.8459 - val_loss: 0.7014 - val_accuracy: 0.8367\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6548 - accuracy: 0.8492 - val_loss: 0.6915 - val_accuracy: 0.8387\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6462 - accuracy: 0.8503 - val_loss: 0.6835 - val_accuracy: 0.8388\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6380 - accuracy: 0.8533 - val_loss: 0.6827 - val_accuracy: 0.8387\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6315 - accuracy: 0.8544 - val_loss: 0.6723 - val_accuracy: 0.8438\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6250 - accuracy: 0.8559 - val_loss: 0.6743 - val_accuracy: 0.8399\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6195 - accuracy: 0.8574 - val_loss: 0.6651 - val_accuracy: 0.8442\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:32.627046\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6116 - accuracy: 0.8608 - val_loss: 0.6604 - val_accuracy: 0.8467\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6071 - accuracy: 0.8615 - val_loss: 0.6578 - val_accuracy: 0.8473\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6049 - accuracy: 0.8632 - val_loss: 0.6571 - val_accuracy: 0.8473\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6038 - accuracy: 0.8632 - val_loss: 0.6563 - val_accuracy: 0.8469\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6032 - accuracy: 0.8633 - val_loss: 0.6562 - val_accuracy: 0.8468\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:24.136423\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.1650 - accuracy: 0.2640 - val_loss: 1.8617 - val_accuracy: 0.5381\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.5707 - accuracy: 0.6129 - val_loss: 1.3996 - val_accuracy: 0.6571\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2698 - accuracy: 0.6913 - val_loss: 1.2178 - val_accuracy: 0.7064\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0781 - accuracy: 0.7407 - val_loss: 1.0156 - val_accuracy: 0.7595\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9508 - accuracy: 0.7730 - val_loss: 0.9245 - val_accuracy: 0.7770\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8664 - accuracy: 0.7946 - val_loss: 0.8693 - val_accuracy: 0.7930\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8106 - accuracy: 0.8095 - val_loss: 0.8282 - val_accuracy: 0.8019\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7720 - accuracy: 0.8188 - val_loss: 0.7925 - val_accuracy: 0.8152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7435 - accuracy: 0.8264 - val_loss: 0.7703 - val_accuracy: 0.8208\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7199 - accuracy: 0.8322 - val_loss: 0.7526 - val_accuracy: 0.8218\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7009 - accuracy: 0.8362 - val_loss: 0.7344 - val_accuracy: 0.8270\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6852 - accuracy: 0.8400 - val_loss: 0.7252 - val_accuracy: 0.8301\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6728 - accuracy: 0.8429 - val_loss: 0.7177 - val_accuracy: 0.8313\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6596 - accuracy: 0.8457 - val_loss: 0.7124 - val_accuracy: 0.8317\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6502 - accuracy: 0.8497 - val_loss: 0.7020 - val_accuracy: 0.8332\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6418 - accuracy: 0.8518 - val_loss: 0.6987 - val_accuracy: 0.8349\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6338 - accuracy: 0.8530 - val_loss: 0.6893 - val_accuracy: 0.8377\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6269 - accuracy: 0.8546 - val_loss: 0.6861 - val_accuracy: 0.8379\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6209 - accuracy: 0.8570 - val_loss: 0.6791 - val_accuracy: 0.8405\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6154 - accuracy: 0.8586 - val_loss: 0.6792 - val_accuracy: 0.8388\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:29.806241\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6069 - accuracy: 0.8607 - val_loss: 0.6728 - val_accuracy: 0.8417\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6026 - accuracy: 0.8615 - val_loss: 0.6689 - val_accuracy: 0.8428\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6003 - accuracy: 0.8622 - val_loss: 0.6681 - val_accuracy: 0.8428\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5991 - accuracy: 0.8625 - val_loss: 0.6673 - val_accuracy: 0.8437\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5985 - accuracy: 0.8625 - val_loss: 0.6672 - val_accuracy: 0.8438\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5982 - accuracy: 0.8627 - val_loss: 0.6671 - val_accuracy: 0.8435\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.5980 - accuracy: 0.8628 - val_loss: 0.6671 - val_accuracy: 0.8436\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.5979 - accuracy: 0.8628 - val_loss: 0.6671 - val_accuracy: 0.8436\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:50.367711\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4964 - accuracy: 0.1902 - val_loss: 1.9287 - val_accuracy: 0.5215\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6334 - accuracy: 0.5999 - val_loss: 1.3917 - val_accuracy: 0.6604\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.2899 - accuracy: 0.6858 - val_loss: 1.1903 - val_accuracy: 0.7063\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0924 - accuracy: 0.7374 - val_loss: 1.0188 - val_accuracy: 0.7542\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9635 - accuracy: 0.7712 - val_loss: 0.9249 - val_accuracy: 0.7808\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8772 - accuracy: 0.7936 - val_loss: 0.8723 - val_accuracy: 0.7849\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8233 - accuracy: 0.8075 - val_loss: 0.8069 - val_accuracy: 0.8049\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7819 - accuracy: 0.8164 - val_loss: 0.7808 - val_accuracy: 0.8129\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7520 - accuracy: 0.8248 - val_loss: 0.7518 - val_accuracy: 0.8234\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7275 - accuracy: 0.8305 - val_loss: 0.7396 - val_accuracy: 0.8245\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7090 - accuracy: 0.8351 - val_loss: 0.7218 - val_accuracy: 0.8279\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6921 - accuracy: 0.8395 - val_loss: 0.7109 - val_accuracy: 0.8307\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6784 - accuracy: 0.8427 - val_loss: 0.6983 - val_accuracy: 0.8309\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6671 - accuracy: 0.8462 - val_loss: 0.6829 - val_accuracy: 0.8378\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6563 - accuracy: 0.8483 - val_loss: 0.6829 - val_accuracy: 0.8367\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6478 - accuracy: 0.8512 - val_loss: 0.6744 - val_accuracy: 0.8366\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6400 - accuracy: 0.8517 - val_loss: 0.6722 - val_accuracy: 0.8384\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6330 - accuracy: 0.8544 - val_loss: 0.6626 - val_accuracy: 0.8418\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.6267 - accuracy: 0.8557 - val_loss: 0.6598 - val_accuracy: 0.8441\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6211 - accuracy: 0.8568 - val_loss: 0.6546 - val_accuracy: 0.8449\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:31.414192\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6128 - accuracy: 0.8607 - val_loss: 0.6514 - val_accuracy: 0.8468\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6084 - accuracy: 0.8616 - val_loss: 0.6484 - val_accuracy: 0.8470\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6061 - accuracy: 0.8627 - val_loss: 0.6477 - val_accuracy: 0.8458\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6051 - accuracy: 0.8626 - val_loss: 0.6464 - val_accuracy: 0.8469\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6045 - accuracy: 0.8631 - val_loss: 0.6465 - val_accuracy: 0.8464\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:22.981444\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2644 - accuracy: 0.2432 - val_loss: 1.8925 - val_accuracy: 0.5317\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5943 - accuracy: 0.6051 - val_loss: 1.4661 - val_accuracy: 0.6391\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2968 - accuracy: 0.6845 - val_loss: 1.2275 - val_accuracy: 0.6998\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1052 - accuracy: 0.7314 - val_loss: 1.0471 - val_accuracy: 0.7524\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9678 - accuracy: 0.7681 - val_loss: 0.9272 - val_accuracy: 0.7821\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8773 - accuracy: 0.7910 - val_loss: 0.8716 - val_accuracy: 0.7938\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8184 - accuracy: 0.8074 - val_loss: 0.8410 - val_accuracy: 0.7987\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7789 - accuracy: 0.8171 - val_loss: 0.8102 - val_accuracy: 0.8060\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7495 - accuracy: 0.8250 - val_loss: 0.7797 - val_accuracy: 0.8115\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7254 - accuracy: 0.8302 - val_loss: 0.7593 - val_accuracy: 0.8211\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7077 - accuracy: 0.8342 - val_loss: 0.7446 - val_accuracy: 0.8235\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6908 - accuracy: 0.8391 - val_loss: 0.7276 - val_accuracy: 0.8293\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6771 - accuracy: 0.8429 - val_loss: 0.7175 - val_accuracy: 0.8309\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6655 - accuracy: 0.8463 - val_loss: 0.7070 - val_accuracy: 0.8328\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6555 - accuracy: 0.8488 - val_loss: 0.6996 - val_accuracy: 0.8361\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6466 - accuracy: 0.8510 - val_loss: 0.6981 - val_accuracy: 0.8349\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6389 - accuracy: 0.8528 - val_loss: 0.6927 - val_accuracy: 0.8368\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6319 - accuracy: 0.8541 - val_loss: 0.6829 - val_accuracy: 0.8396\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6262 - accuracy: 0.8559 - val_loss: 0.6786 - val_accuracy: 0.8399\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6207 - accuracy: 0.8571 - val_loss: 0.6714 - val_accuracy: 0.8420\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:29.875860\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6123 - accuracy: 0.8601 - val_loss: 0.6679 - val_accuracy: 0.8429\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6079 - accuracy: 0.8612 - val_loss: 0.6657 - val_accuracy: 0.8430\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6058 - accuracy: 0.8617 - val_loss: 0.6640 - val_accuracy: 0.8450\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6047 - accuracy: 0.8623 - val_loss: 0.6636 - val_accuracy: 0.8439\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6041 - accuracy: 0.8624 - val_loss: 0.6635 - val_accuracy: 0.8441\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6038 - accuracy: 0.8623 - val_loss: 0.6634 - val_accuracy: 0.8441\n",
      " Hyperparameter combinations for training, {'optimizer': 'sgd', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:51.657782\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.4920 - accuracy: 0.3756 - val_loss: 1.8415 - val_accuracy: 0.5798\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6947 - accuracy: 0.5790 - val_loss: 1.4254 - val_accuracy: 0.6604\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4147 - accuracy: 0.6447 - val_loss: 1.2219 - val_accuracy: 0.7026\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2480 - accuracy: 0.6795 - val_loss: 1.0879 - val_accuracy: 0.7286\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1316 - accuracy: 0.7067 - val_loss: 0.9999 - val_accuracy: 0.7466\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0467 - accuracy: 0.7242 - val_loss: 0.9310 - val_accuracy: 0.7579\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9890 - accuracy: 0.7370 - val_loss: 0.8860 - val_accuracy: 0.7683\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9455 - accuracy: 0.7448 - val_loss: 0.8505 - val_accuracy: 0.7766\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9118 - accuracy: 0.7543 - val_loss: 0.8233 - val_accuracy: 0.7832\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8863 - accuracy: 0.7603 - val_loss: 0.8008 - val_accuracy: 0.7875\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.8656 - accuracy: 0.7628 - val_loss: 0.7856 - val_accuracy: 0.7906\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8480 - accuracy: 0.7670 - val_loss: 0.7698 - val_accuracy: 0.7937\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8353 - accuracy: 0.7696 - val_loss: 0.7578 - val_accuracy: 0.7963\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8202 - accuracy: 0.7739 - val_loss: 0.7480 - val_accuracy: 0.7979\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8136 - accuracy: 0.7740 - val_loss: 0.7404 - val_accuracy: 0.7995\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8005 - accuracy: 0.7784 - val_loss: 0.7320 - val_accuracy: 0.8006\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7960 - accuracy: 0.7775 - val_loss: 0.7266 - val_accuracy: 0.8015\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7863 - accuracy: 0.7799 - val_loss: 0.7209 - val_accuracy: 0.8027\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7808 - accuracy: 0.7827 - val_loss: 0.7159 - val_accuracy: 0.8038\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7764 - accuracy: 0.7823 - val_loss: 0.7120 - val_accuracy: 0.8039\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:53.994995\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7749 - accuracy: 0.7829 - val_loss: 0.7107 - val_accuracy: 0.8047\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7721 - accuracy: 0.7843 - val_loss: 0.7099 - val_accuracy: 0.8048\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7717 - accuracy: 0.7843 - val_loss: 0.7088 - val_accuracy: 0.8051\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7706 - accuracy: 0.7834 - val_loss: 0.7090 - val_accuracy: 0.8052\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7704 - accuracy: 0.7843 - val_loss: 0.7090 - val_accuracy: 0.8050\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7709 - accuracy: 0.7837 - val_loss: 0.7084 - val_accuracy: 0.8049\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7701 - accuracy: 0.7840 - val_loss: 0.7085 - val_accuracy: 0.8051\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:06.745171\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 2.4877 - accuracy: 0.3767 - val_loss: 1.8134 - val_accuracy: 0.5819\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 26s 37ms/step - loss: 1.6889 - accuracy: 0.5786 - val_loss: 1.4046 - val_accuracy: 0.6596\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4260 - accuracy: 0.6378 - val_loss: 1.2228 - val_accuracy: 0.6980\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.2685 - accuracy: 0.6717 - val_loss: 1.0998 - val_accuracy: 0.7244\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.1548 - accuracy: 0.6975 - val_loss: 1.0053 - val_accuracy: 0.7415\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0687 - accuracy: 0.7170 - val_loss: 0.9407 - val_accuracy: 0.7536\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.0089 - accuracy: 0.7290 - val_loss: 0.8937 - val_accuracy: 0.7639\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9667 - accuracy: 0.7384 - val_loss: 0.8599 - val_accuracy: 0.7715\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9313 - accuracy: 0.7489 - val_loss: 0.8330 - val_accuracy: 0.7769\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.9033 - accuracy: 0.7537 - val_loss: 0.8106 - val_accuracy: 0.7808\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8828 - accuracy: 0.7581 - val_loss: 0.7943 - val_accuracy: 0.7850\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8626 - accuracy: 0.7640 - val_loss: 0.7778 - val_accuracy: 0.7865\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8501 - accuracy: 0.7659 - val_loss: 0.7666 - val_accuracy: 0.7892\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8378 - accuracy: 0.7670 - val_loss: 0.7566 - val_accuracy: 0.7914\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8268 - accuracy: 0.7700 - val_loss: 0.7473 - val_accuracy: 0.7938\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8169 - accuracy: 0.7714 - val_loss: 0.7397 - val_accuracy: 0.7960\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8101 - accuracy: 0.7741 - val_loss: 0.7353 - val_accuracy: 0.7964\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.8051 - accuracy: 0.7745 - val_loss: 0.7294 - val_accuracy: 0.7978\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7991 - accuracy: 0.7751 - val_loss: 0.7254 - val_accuracy: 0.7994\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7934 - accuracy: 0.7795 - val_loss: 0.7209 - val_accuracy: 0.7996\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:47.683812\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7911 - accuracy: 0.7766 - val_loss: 0.7180 - val_accuracy: 0.7996\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7894 - accuracy: 0.7794 - val_loss: 0.7178 - val_accuracy: 0.8000\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7894 - accuracy: 0.7782 - val_loss: 0.7180 - val_accuracy: 0.8000\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7877 - accuracy: 0.7791 - val_loss: 0.7167 - val_accuracy: 0.8001\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7878 - accuracy: 0.7780 - val_loss: 0.7169 - val_accuracy: 0.8005\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7867 - accuracy: 0.7799 - val_loss: 0.7174 - val_accuracy: 0.8005\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7868 - accuracy: 0.7803 - val_loss: 0.7168 - val_accuracy: 0.8005\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7865 - accuracy: 0.7792 - val_loss: 0.7171 - val_accuracy: 0.8001\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:38.821123\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.5432 - accuracy: 0.3682 - val_loss: 1.8978 - val_accuracy: 0.5720\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7635 - accuracy: 0.5663 - val_loss: 1.4804 - val_accuracy: 0.6501\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4738 - accuracy: 0.6313 - val_loss: 1.2688 - val_accuracy: 0.6892\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2941 - accuracy: 0.6692 - val_loss: 1.1256 - val_accuracy: 0.7161\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1687 - accuracy: 0.6967 - val_loss: 1.0271 - val_accuracy: 0.7367\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0789 - accuracy: 0.7160 - val_loss: 0.9610 - val_accuracy: 0.7501\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0192 - accuracy: 0.7295 - val_loss: 0.9117 - val_accuracy: 0.7607\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9729 - accuracy: 0.7397 - val_loss: 0.8756 - val_accuracy: 0.7670\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9395 - accuracy: 0.7446 - val_loss: 0.8461 - val_accuracy: 0.7744\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9119 - accuracy: 0.7521 - val_loss: 0.8224 - val_accuracy: 0.7787\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8886 - accuracy: 0.7565 - val_loss: 0.8040 - val_accuracy: 0.7822\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8703 - accuracy: 0.7627 - val_loss: 0.7897 - val_accuracy: 0.7852\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8560 - accuracy: 0.7652 - val_loss: 0.7781 - val_accuracy: 0.7887\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8447 - accuracy: 0.7668 - val_loss: 0.7675 - val_accuracy: 0.7914\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8331 - accuracy: 0.7703 - val_loss: 0.7586 - val_accuracy: 0.7926\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8256 - accuracy: 0.7724 - val_loss: 0.7512 - val_accuracy: 0.7949\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8179 - accuracy: 0.7736 - val_loss: 0.7446 - val_accuracy: 0.7959\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8115 - accuracy: 0.7745 - val_loss: 0.7385 - val_accuracy: 0.7972\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8033 - accuracy: 0.7763 - val_loss: 0.7345 - val_accuracy: 0.7982\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8018 - accuracy: 0.7759 - val_loss: 0.7305 - val_accuracy: 0.7992\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:02.216635\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7967 - accuracy: 0.7767 - val_loss: 0.7281 - val_accuracy: 0.7998\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7944 - accuracy: 0.7781 - val_loss: 0.7271 - val_accuracy: 0.7993\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7940 - accuracy: 0.7784 - val_loss: 0.7269 - val_accuracy: 0.7996\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7948 - accuracy: 0.7777 - val_loss: 0.7263 - val_accuracy: 0.7997\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:01:48.921583\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.4361 - accuracy: 0.3855 - val_loss: 1.7840 - val_accuracy: 0.5857\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6651 - accuracy: 0.5801 - val_loss: 1.3929 - val_accuracy: 0.6633\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4061 - accuracy: 0.6412 - val_loss: 1.2067 - val_accuracy: 0.7011\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2436 - accuracy: 0.6771 - val_loss: 1.0770 - val_accuracy: 0.7252\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1314 - accuracy: 0.6990 - val_loss: 0.9858 - val_accuracy: 0.7441\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0458 - accuracy: 0.7199 - val_loss: 0.9216 - val_accuracy: 0.7581\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9902 - accuracy: 0.7339 - val_loss: 0.8722 - val_accuracy: 0.7656\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9442 - accuracy: 0.7430 - val_loss: 0.8376 - val_accuracy: 0.7733\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9126 - accuracy: 0.7497 - val_loss: 0.8109 - val_accuracy: 0.7802\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8849 - accuracy: 0.7555 - val_loss: 0.7868 - val_accuracy: 0.7840\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8637 - accuracy: 0.7616 - val_loss: 0.7707 - val_accuracy: 0.7872\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8479 - accuracy: 0.7640 - val_loss: 0.7557 - val_accuracy: 0.7899\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8336 - accuracy: 0.7663 - val_loss: 0.7443 - val_accuracy: 0.7918\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8221 - accuracy: 0.7702 - val_loss: 0.7336 - val_accuracy: 0.7944\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8095 - accuracy: 0.7718 - val_loss: 0.7256 - val_accuracy: 0.7960\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8030 - accuracy: 0.7749 - val_loss: 0.7185 - val_accuracy: 0.7977\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7951 - accuracy: 0.7753 - val_loss: 0.7127 - val_accuracy: 0.7991\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7870 - accuracy: 0.7780 - val_loss: 0.7068 - val_accuracy: 0.7999\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7845 - accuracy: 0.7768 - val_loss: 0.7020 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7772 - accuracy: 0.7813 - val_loss: 0.6986 - val_accuracy: 0.8008\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:01.924730\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7748 - accuracy: 0.7808 - val_loss: 0.6970 - val_accuracy: 0.8013\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7738 - accuracy: 0.7818 - val_loss: 0.6957 - val_accuracy: 0.8015\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7742 - accuracy: 0.7798 - val_loss: 0.6959 - val_accuracy: 0.8018\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7689 - accuracy: 0.7819 - val_loss: 0.6950 - val_accuracy: 0.8015\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7716 - accuracy: 0.7817 - val_loss: 0.6953 - val_accuracy: 0.8013\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7702 - accuracy: 0.7832 - val_loss: 0.6951 - val_accuracy: 0.8020\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7694 - accuracy: 0.7812 - val_loss: 0.6947 - val_accuracy: 0.8015\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7699 - accuracy: 0.7822 - val_loss: 0.6954 - val_accuracy: 0.8021\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7726 - accuracy: 0.7805 - val_loss: 0.6953 - val_accuracy: 0.8021\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7710 - accuracy: 0.7822 - val_loss: 0.6954 - val_accuracy: 0.8019\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7711 - accuracy: 0.7819 - val_loss: 0.6951 - val_accuracy: 0.8015\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:56.695995\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.5006 - accuracy: 0.3735 - val_loss: 1.8700 - val_accuracy: 0.5734\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7409 - accuracy: 0.5708 - val_loss: 1.4694 - val_accuracy: 0.6507\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4719 - accuracy: 0.6340 - val_loss: 1.2685 - val_accuracy: 0.6938\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3037 - accuracy: 0.6708 - val_loss: 1.1353 - val_accuracy: 0.7205\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1839 - accuracy: 0.6957 - val_loss: 1.0367 - val_accuracy: 0.7402\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0931 - accuracy: 0.7155 - val_loss: 0.9683 - val_accuracy: 0.7537\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0299 - accuracy: 0.7298 - val_loss: 0.9168 - val_accuracy: 0.7626\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9830 - accuracy: 0.7383 - val_loss: 0.8795 - val_accuracy: 0.7688\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9462 - accuracy: 0.7480 - val_loss: 0.8496 - val_accuracy: 0.7754\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9197 - accuracy: 0.7526 - val_loss: 0.8265 - val_accuracy: 0.7781\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8964 - accuracy: 0.7585 - val_loss: 0.8074 - val_accuracy: 0.7822\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8800 - accuracy: 0.7606 - val_loss: 0.7927 - val_accuracy: 0.7855\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8636 - accuracy: 0.7658 - val_loss: 0.7799 - val_accuracy: 0.7878\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8486 - accuracy: 0.7677 - val_loss: 0.7688 - val_accuracy: 0.7906\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8377 - accuracy: 0.7695 - val_loss: 0.7597 - val_accuracy: 0.7932\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8298 - accuracy: 0.7717 - val_loss: 0.7528 - val_accuracy: 0.7941\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8214 - accuracy: 0.7734 - val_loss: 0.7454 - val_accuracy: 0.7947\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8149 - accuracy: 0.7757 - val_loss: 0.7400 - val_accuracy: 0.7966\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8094 - accuracy: 0.7766 - val_loss: 0.7353 - val_accuracy: 0.7968\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8049 - accuracy: 0.7764 - val_loss: 0.7304 - val_accuracy: 0.7984\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:00.875145\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8002 - accuracy: 0.7794 - val_loss: 0.7288 - val_accuracy: 0.7985\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 0.7984 - accuracy: 0.7783 - val_loss: 0.7280 - val_accuracy: 0.7990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7983 - accuracy: 0.7792 - val_loss: 0.7279 - val_accuracy: 0.7988\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7974 - accuracy: 0.7785 - val_loss: 0.7272 - val_accuracy: 0.7992\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7972 - accuracy: 0.7790 - val_loss: 0.7273 - val_accuracy: 0.7988\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7971 - accuracy: 0.7794 - val_loss: 0.7268 - val_accuracy: 0.7991\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 0.7973 - accuracy: 0.7781 - val_loss: 0.7268 - val_accuracy: 0.7992\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:05.358811\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2771 - accuracy: 0.4021 - val_loss: 1.5669 - val_accuracy: 0.6098\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5185 - accuracy: 0.5917 - val_loss: 1.2599 - val_accuracy: 0.6703\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3070 - accuracy: 0.6427 - val_loss: 1.1112 - val_accuracy: 0.7034\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1766 - accuracy: 0.6764 - val_loss: 1.0131 - val_accuracy: 0.7243\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0845 - accuracy: 0.6995 - val_loss: 0.9408 - val_accuracy: 0.7408\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0189 - accuracy: 0.7167 - val_loss: 0.8858 - val_accuracy: 0.7537\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9677 - accuracy: 0.7279 - val_loss: 0.8474 - val_accuracy: 0.7636\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9306 - accuracy: 0.7382 - val_loss: 0.8187 - val_accuracy: 0.7703\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9017 - accuracy: 0.7446 - val_loss: 0.7954 - val_accuracy: 0.7751\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8797 - accuracy: 0.7503 - val_loss: 0.7776 - val_accuracy: 0.7800\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8598 - accuracy: 0.7556 - val_loss: 0.7623 - val_accuracy: 0.7836\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8416 - accuracy: 0.7602 - val_loss: 0.7498 - val_accuracy: 0.7865\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8323 - accuracy: 0.7628 - val_loss: 0.7399 - val_accuracy: 0.7879\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8210 - accuracy: 0.7636 - val_loss: 0.7314 - val_accuracy: 0.7909\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8130 - accuracy: 0.7666 - val_loss: 0.7245 - val_accuracy: 0.7930\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8043 - accuracy: 0.7684 - val_loss: 0.7178 - val_accuracy: 0.7937\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7973 - accuracy: 0.7717 - val_loss: 0.7130 - val_accuracy: 0.7949\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7930 - accuracy: 0.7716 - val_loss: 0.7082 - val_accuracy: 0.7955\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7874 - accuracy: 0.7729 - val_loss: 0.7043 - val_accuracy: 0.7963\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7843 - accuracy: 0.7747 - val_loss: 0.7009 - val_accuracy: 0.7966\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:58.253273\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7793 - accuracy: 0.7753 - val_loss: 0.6986 - val_accuracy: 0.7977\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7792 - accuracy: 0.7746 - val_loss: 0.6984 - val_accuracy: 0.7974\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7790 - accuracy: 0.7756 - val_loss: 0.6979 - val_accuracy: 0.7980\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7784 - accuracy: 0.7753 - val_loss: 0.6977 - val_accuracy: 0.7973\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7775 - accuracy: 0.7768 - val_loss: 0.6976 - val_accuracy: 0.7979\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7787 - accuracy: 0.7763 - val_loss: 0.6976 - val_accuracy: 0.7978\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:41.927658\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2732 - accuracy: 0.3995 - val_loss: 1.5875 - val_accuracy: 0.6043\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5138 - accuracy: 0.5925 - val_loss: 1.2747 - val_accuracy: 0.6668\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2911 - accuracy: 0.6474 - val_loss: 1.1166 - val_accuracy: 0.7038\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1503 - accuracy: 0.6844 - val_loss: 1.0117 - val_accuracy: 0.7273\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0557 - accuracy: 0.7072 - val_loss: 0.9354 - val_accuracy: 0.7456\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9839 - accuracy: 0.7258 - val_loss: 0.8857 - val_accuracy: 0.7578\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9351 - accuracy: 0.7368 - val_loss: 0.8431 - val_accuracy: 0.7665\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8995 - accuracy: 0.7474 - val_loss: 0.8143 - val_accuracy: 0.7733\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8713 - accuracy: 0.7523 - val_loss: 0.7928 - val_accuracy: 0.7787\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8503 - accuracy: 0.7581 - val_loss: 0.7746 - val_accuracy: 0.7838\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8292 - accuracy: 0.7651 - val_loss: 0.7606 - val_accuracy: 0.7870\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8155 - accuracy: 0.7665 - val_loss: 0.7480 - val_accuracy: 0.7895\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8058 - accuracy: 0.7691 - val_loss: 0.7402 - val_accuracy: 0.7912\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7935 - accuracy: 0.7731 - val_loss: 0.7316 - val_accuracy: 0.7928\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7875 - accuracy: 0.7741 - val_loss: 0.7244 - val_accuracy: 0.7948\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7776 - accuracy: 0.7756 - val_loss: 0.7192 - val_accuracy: 0.7963\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7733 - accuracy: 0.7772 - val_loss: 0.7139 - val_accuracy: 0.7970\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7658 - accuracy: 0.7787 - val_loss: 0.7094 - val_accuracy: 0.7975\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7617 - accuracy: 0.7800 - val_loss: 0.7060 - val_accuracy: 0.7985\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7585 - accuracy: 0.7813 - val_loss: 0.7027 - val_accuracy: 0.7992\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:57.568151\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7557 - accuracy: 0.7812 - val_loss: 0.7012 - val_accuracy: 0.7990\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7545 - accuracy: 0.7829 - val_loss: 0.7006 - val_accuracy: 0.7994\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7531 - accuracy: 0.7824 - val_loss: 0.6998 - val_accuracy: 0.7997\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7538 - accuracy: 0.7814 - val_loss: 0.6997 - val_accuracy: 0.7996\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7527 - accuracy: 0.7821 - val_loss: 0.6996 - val_accuracy: 0.7999\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7522 - accuracy: 0.7835 - val_loss: 0.6997 - val_accuracy: 0.7996\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7525 - accuracy: 0.7817 - val_loss: 0.7001 - val_accuracy: 0.7997\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7532 - accuracy: 0.7812 - val_loss: 0.6996 - val_accuracy: 0.7998\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:35.148544\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2229 - accuracy: 0.4151 - val_loss: 1.5376 - val_accuracy: 0.6205\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4869 - accuracy: 0.5985 - val_loss: 1.2325 - val_accuracy: 0.6852\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2722 - accuracy: 0.6540 - val_loss: 1.0845 - val_accuracy: 0.7180\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1422 - accuracy: 0.6866 - val_loss: 0.9858 - val_accuracy: 0.7391\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0496 - accuracy: 0.7078 - val_loss: 0.9154 - val_accuracy: 0.7540\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9821 - accuracy: 0.7258 - val_loss: 0.8657 - val_accuracy: 0.7641\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9345 - accuracy: 0.7386 - val_loss: 0.8293 - val_accuracy: 0.7711\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8989 - accuracy: 0.7463 - val_loss: 0.8022 - val_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8740 - accuracy: 0.7513 - val_loss: 0.7806 - val_accuracy: 0.7832\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8510 - accuracy: 0.7587 - val_loss: 0.7633 - val_accuracy: 0.7875\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8326 - accuracy: 0.7621 - val_loss: 0.7505 - val_accuracy: 0.7901\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8201 - accuracy: 0.7651 - val_loss: 0.7393 - val_accuracy: 0.7922\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8093 - accuracy: 0.7672 - val_loss: 0.7308 - val_accuracy: 0.7934\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7985 - accuracy: 0.7701 - val_loss: 0.7222 - val_accuracy: 0.7957\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7915 - accuracy: 0.7708 - val_loss: 0.7156 - val_accuracy: 0.7969\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7830 - accuracy: 0.7743 - val_loss: 0.7103 - val_accuracy: 0.7980\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7778 - accuracy: 0.7753 - val_loss: 0.7055 - val_accuracy: 0.7993\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7734 - accuracy: 0.7753 - val_loss: 0.7014 - val_accuracy: 0.7998\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7665 - accuracy: 0.7774 - val_loss: 0.6976 - val_accuracy: 0.8005\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7621 - accuracy: 0.7796 - val_loss: 0.6946 - val_accuracy: 0.8012\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:55.648169\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7587 - accuracy: 0.7797 - val_loss: 0.6929 - val_accuracy: 0.8014\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7587 - accuracy: 0.7806 - val_loss: 0.6924 - val_accuracy: 0.8019\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7583 - accuracy: 0.7805 - val_loss: 0.6924 - val_accuracy: 0.8019\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7565 - accuracy: 0.7807 - val_loss: 0.6920 - val_accuracy: 0.8020\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7564 - accuracy: 0.7804 - val_loss: 0.6919 - val_accuracy: 0.8021\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7591 - accuracy: 0.7806 - val_loss: 0.6923 - val_accuracy: 0.8020\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7587 - accuracy: 0.7798 - val_loss: 0.6917 - val_accuracy: 0.8021\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7594 - accuracy: 0.7795 - val_loss: 0.6920 - val_accuracy: 0.8019\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:34.244783\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2544 - accuracy: 0.4090 - val_loss: 1.5953 - val_accuracy: 0.6033\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5160 - accuracy: 0.5938 - val_loss: 1.2780 - val_accuracy: 0.6682\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2915 - accuracy: 0.6492 - val_loss: 1.1278 - val_accuracy: 0.7005\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1592 - accuracy: 0.6814 - val_loss: 1.0209 - val_accuracy: 0.7271\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0636 - accuracy: 0.7064 - val_loss: 0.9446 - val_accuracy: 0.7434\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9973 - accuracy: 0.7217 - val_loss: 0.8931 - val_accuracy: 0.7553\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9455 - accuracy: 0.7348 - val_loss: 0.8543 - val_accuracy: 0.7653\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9110 - accuracy: 0.7433 - val_loss: 0.8264 - val_accuracy: 0.7719\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8819 - accuracy: 0.7513 - val_loss: 0.8029 - val_accuracy: 0.7761\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8589 - accuracy: 0.7553 - val_loss: 0.7852 - val_accuracy: 0.7807\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8433 - accuracy: 0.7590 - val_loss: 0.7713 - val_accuracy: 0.7835\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8283 - accuracy: 0.7624 - val_loss: 0.7593 - val_accuracy: 0.7852\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8154 - accuracy: 0.7664 - val_loss: 0.7489 - val_accuracy: 0.7887\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8050 - accuracy: 0.7695 - val_loss: 0.7411 - val_accuracy: 0.7903\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7960 - accuracy: 0.7715 - val_loss: 0.7339 - val_accuracy: 0.7924\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7883 - accuracy: 0.7736 - val_loss: 0.7273 - val_accuracy: 0.7932\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7840 - accuracy: 0.7736 - val_loss: 0.7225 - val_accuracy: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7765 - accuracy: 0.7753 - val_loss: 0.7182 - val_accuracy: 0.7953\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7738 - accuracy: 0.7762 - val_loss: 0.7146 - val_accuracy: 0.7965\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7680 - accuracy: 0.7782 - val_loss: 0.7110 - val_accuracy: 0.7967\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:56.609526\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7652 - accuracy: 0.7789 - val_loss: 0.7101 - val_accuracy: 0.7973\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7645 - accuracy: 0.7779 - val_loss: 0.7087 - val_accuracy: 0.7973\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7641 - accuracy: 0.7789 - val_loss: 0.7085 - val_accuracy: 0.7977\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7646 - accuracy: 0.7782 - val_loss: 0.7079 - val_accuracy: 0.7975\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7627 - accuracy: 0.7797 - val_loss: 0.7086 - val_accuracy: 0.7975\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7611 - accuracy: 0.7803 - val_loss: 0.7083 - val_accuracy: 0.7975\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:41.113355\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2738 - accuracy: 0.4041 - val_loss: 1.5831 - val_accuracy: 0.6025\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5313 - accuracy: 0.5889 - val_loss: 1.2816 - val_accuracy: 0.6657\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3029 - accuracy: 0.6446 - val_loss: 1.1188 - val_accuracy: 0.7052\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1633 - accuracy: 0.6790 - val_loss: 1.0064 - val_accuracy: 0.7307\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0653 - accuracy: 0.7045 - val_loss: 0.9321 - val_accuracy: 0.7488\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9931 - accuracy: 0.7226 - val_loss: 0.8767 - val_accuracy: 0.7619\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9460 - accuracy: 0.7349 - val_loss: 0.8402 - val_accuracy: 0.7703\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9099 - accuracy: 0.7426 - val_loss: 0.8117 - val_accuracy: 0.7774\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8814 - accuracy: 0.7502 - val_loss: 0.7891 - val_accuracy: 0.7812\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8595 - accuracy: 0.7564 - val_loss: 0.7718 - val_accuracy: 0.7848\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8411 - accuracy: 0.7604 - val_loss: 0.7582 - val_accuracy: 0.7880\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8279 - accuracy: 0.7629 - val_loss: 0.7456 - val_accuracy: 0.7915\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8156 - accuracy: 0.7655 - val_loss: 0.7361 - val_accuracy: 0.7941\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8044 - accuracy: 0.7682 - val_loss: 0.7283 - val_accuracy: 0.7960\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7965 - accuracy: 0.7709 - val_loss: 0.7214 - val_accuracy: 0.7972\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7918 - accuracy: 0.7714 - val_loss: 0.7157 - val_accuracy: 0.7981\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7819 - accuracy: 0.7753 - val_loss: 0.7109 - val_accuracy: 0.7992\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7780 - accuracy: 0.7766 - val_loss: 0.7068 - val_accuracy: 0.7997\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7736 - accuracy: 0.7759 - val_loss: 0.7028 - val_accuracy: 0.8010\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7690 - accuracy: 0.7789 - val_loss: 0.6996 - val_accuracy: 0.8020\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:08:54.373502\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7662 - accuracy: 0.7782 - val_loss: 0.6977 - val_accuracy: 0.8020\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7646 - accuracy: 0.7783 - val_loss: 0.6972 - val_accuracy: 0.8022\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7644 - accuracy: 0.7780 - val_loss: 0.6968 - val_accuracy: 0.8026\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7635 - accuracy: 0.7779 - val_loss: 0.6965 - val_accuracy: 0.8020\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7627 - accuracy: 0.7793 - val_loss: 0.6966 - val_accuracy: 0.8023\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7617 - accuracy: 0.7806 - val_loss: 0.6968 - val_accuracy: 0.8026\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7635 - accuracy: 0.7794 - val_loss: 0.6970 - val_accuracy: 0.8025\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7640 - accuracy: 0.7790 - val_loss: 0.6970 - val_accuracy: 0.8023\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7624 - accuracy: 0.7805 - val_loss: 0.6962 - val_accuracy: 0.8023\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:01.927279\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3393 - accuracy: 0.4089 - val_loss: 1.6668 - val_accuracy: 0.6065\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5401 - accuracy: 0.6012 - val_loss: 1.2958 - val_accuracy: 0.6709\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3031 - accuracy: 0.6542 - val_loss: 1.1333 - val_accuracy: 0.7053\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1562 - accuracy: 0.6881 - val_loss: 1.0219 - val_accuracy: 0.7292\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0557 - accuracy: 0.7108 - val_loss: 0.9425 - val_accuracy: 0.7439\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9821 - accuracy: 0.7271 - val_loss: 0.8856 - val_accuracy: 0.7582\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9303 - accuracy: 0.7425 - val_loss: 0.8458 - val_accuracy: 0.7679\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8924 - accuracy: 0.7501 - val_loss: 0.8164 - val_accuracy: 0.7739\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8619 - accuracy: 0.7561 - val_loss: 0.7921 - val_accuracy: 0.7789\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8399 - accuracy: 0.7629 - val_loss: 0.7740 - val_accuracy: 0.7836\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8205 - accuracy: 0.7663 - val_loss: 0.7587 - val_accuracy: 0.7879\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8015 - accuracy: 0.7728 - val_loss: 0.7452 - val_accuracy: 0.7908\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7949 - accuracy: 0.7718 - val_loss: 0.7357 - val_accuracy: 0.7930\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7827 - accuracy: 0.7767 - val_loss: 0.7263 - val_accuracy: 0.7949\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7738 - accuracy: 0.7775 - val_loss: 0.7191 - val_accuracy: 0.7965\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7662 - accuracy: 0.7784 - val_loss: 0.7130 - val_accuracy: 0.7978\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7575 - accuracy: 0.7815 - val_loss: 0.7080 - val_accuracy: 0.7987\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7555 - accuracy: 0.7821 - val_loss: 0.7033 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7484 - accuracy: 0.7842 - val_loss: 0.6990 - val_accuracy: 0.8009\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7456 - accuracy: 0.7838 - val_loss: 0.6957 - val_accuracy: 0.8026\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:15.857685\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7404 - accuracy: 0.7849 - val_loss: 0.6943 - val_accuracy: 0.8024\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7404 - accuracy: 0.7857 - val_loss: 0.6934 - val_accuracy: 0.8027\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7383 - accuracy: 0.7870 - val_loss: 0.6929 - val_accuracy: 0.8025\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7386 - accuracy: 0.7875 - val_loss: 0.6927 - val_accuracy: 0.8030\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7389 - accuracy: 0.7853 - val_loss: 0.6928 - val_accuracy: 0.8027\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7379 - accuracy: 0.7862 - val_loss: 0.6928 - val_accuracy: 0.8031\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7381 - accuracy: 0.7861 - val_loss: 0.6925 - val_accuracy: 0.8033\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7375 - accuracy: 0.7874 - val_loss: 0.6927 - val_accuracy: 0.8028\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7371 - accuracy: 0.7869 - val_loss: 0.6929 - val_accuracy: 0.8031\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7376 - accuracy: 0.7850 - val_loss: 0.6926 - val_accuracy: 0.8027\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:36.366790\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3162 - accuracy: 0.4063 - val_loss: 1.6408 - val_accuracy: 0.6003\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5411 - accuracy: 0.5977 - val_loss: 1.3005 - val_accuracy: 0.6657\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3124 - accuracy: 0.6515 - val_loss: 1.1378 - val_accuracy: 0.7015\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1750 - accuracy: 0.6839 - val_loss: 1.0319 - val_accuracy: 0.7233\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0778 - accuracy: 0.7058 - val_loss: 0.9535 - val_accuracy: 0.7418\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0064 - accuracy: 0.7238 - val_loss: 0.8976 - val_accuracy: 0.7565\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9553 - accuracy: 0.7343 - val_loss: 0.8562 - val_accuracy: 0.7669\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9202 - accuracy: 0.7432 - val_loss: 0.8265 - val_accuracy: 0.7730\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8883 - accuracy: 0.7510 - val_loss: 0.8017 - val_accuracy: 0.7783\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8634 - accuracy: 0.7590 - val_loss: 0.7827 - val_accuracy: 0.7827\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8469 - accuracy: 0.7615 - val_loss: 0.7663 - val_accuracy: 0.7856\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8310 - accuracy: 0.7644 - val_loss: 0.7552 - val_accuracy: 0.7887\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8177 - accuracy: 0.7675 - val_loss: 0.7430 - val_accuracy: 0.7910\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8072 - accuracy: 0.7703 - val_loss: 0.7345 - val_accuracy: 0.7932\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7989 - accuracy: 0.7714 - val_loss: 0.7271 - val_accuracy: 0.7942\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7898 - accuracy: 0.7741 - val_loss: 0.7205 - val_accuracy: 0.7962\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7814 - accuracy: 0.7763 - val_loss: 0.7152 - val_accuracy: 0.7977\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7782 - accuracy: 0.7758 - val_loss: 0.7105 - val_accuracy: 0.7988\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7729 - accuracy: 0.7788 - val_loss: 0.7063 - val_accuracy: 0.7995\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7680 - accuracy: 0.7798 - val_loss: 0.7023 - val_accuracy: 0.8006\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:13.652869\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7635 - accuracy: 0.7802 - val_loss: 0.7006 - val_accuracy: 0.8014\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7643 - accuracy: 0.7817 - val_loss: 0.6998 - val_accuracy: 0.8022\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7620 - accuracy: 0.7814 - val_loss: 0.6997 - val_accuracy: 0.8017\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7613 - accuracy: 0.7811 - val_loss: 0.6998 - val_accuracy: 0.8017\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7601 - accuracy: 0.7817 - val_loss: 0.6990 - val_accuracy: 0.8018\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:18.308397\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.3780 - accuracy: 0.3860 - val_loss: 1.6884 - val_accuracy: 0.5974\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5751 - accuracy: 0.5861 - val_loss: 1.2889 - val_accuracy: 0.6719\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3203 - accuracy: 0.6460 - val_loss: 1.1083 - val_accuracy: 0.7129\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1682 - accuracy: 0.6836 - val_loss: 0.9937 - val_accuracy: 0.7369\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0632 - accuracy: 0.7079 - val_loss: 0.9094 - val_accuracy: 0.7563\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9894 - accuracy: 0.7235 - val_loss: 0.8535 - val_accuracy: 0.7704\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9354 - accuracy: 0.7363 - val_loss: 0.8147 - val_accuracy: 0.7795\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8983 - accuracy: 0.7475 - val_loss: 0.7849 - val_accuracy: 0.7839\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8677 - accuracy: 0.7542 - val_loss: 0.7598 - val_accuracy: 0.7892\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8426 - accuracy: 0.7607 - val_loss: 0.7416 - val_accuracy: 0.7922\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8256 - accuracy: 0.7655 - val_loss: 0.7261 - val_accuracy: 0.7966\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8118 - accuracy: 0.7683 - val_loss: 0.7145 - val_accuracy: 0.7991\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7985 - accuracy: 0.7701 - val_loss: 0.7043 - val_accuracy: 0.8012\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7874 - accuracy: 0.7736 - val_loss: 0.6959 - val_accuracy: 0.8037\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7791 - accuracy: 0.7750 - val_loss: 0.6889 - val_accuracy: 0.8040\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7717 - accuracy: 0.7771 - val_loss: 0.6826 - val_accuracy: 0.8049\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7680 - accuracy: 0.7788 - val_loss: 0.6772 - val_accuracy: 0.8070\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7594 - accuracy: 0.7808 - val_loss: 0.6723 - val_accuracy: 0.8077\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7536 - accuracy: 0.7810 - val_loss: 0.6690 - val_accuracy: 0.8076\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7503 - accuracy: 0.7822 - val_loss: 0.6653 - val_accuracy: 0.8088\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:11.791655\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7487 - accuracy: 0.7819 - val_loss: 0.6640 - val_accuracy: 0.8086\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7470 - accuracy: 0.7817 - val_loss: 0.6628 - val_accuracy: 0.8090\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7461 - accuracy: 0.7835 - val_loss: 0.6627 - val_accuracy: 0.8089\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7437 - accuracy: 0.7851 - val_loss: 0.6624 - val_accuracy: 0.8094\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7448 - accuracy: 0.7840 - val_loss: 0.6626 - val_accuracy: 0.8090\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7436 - accuracy: 0.7845 - val_loss: 0.6621 - val_accuracy: 0.8094\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7432 - accuracy: 0.7840 - val_loss: 0.6625 - val_accuracy: 0.8089\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7437 - accuracy: 0.7833 - val_loss: 0.6618 - val_accuracy: 0.8093\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7438 - accuracy: 0.7839 - val_loss: 0.6620 - val_accuracy: 0.8093\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:08.594045\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.3713 - accuracy: 0.3951 - val_loss: 1.6671 - val_accuracy: 0.6019\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5446 - accuracy: 0.5968 - val_loss: 1.2832 - val_accuracy: 0.6735\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2989 - accuracy: 0.6517 - val_loss: 1.1152 - val_accuracy: 0.7080\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1543 - accuracy: 0.6873 - val_loss: 1.0084 - val_accuracy: 0.7302\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0554 - accuracy: 0.7091 - val_loss: 0.9285 - val_accuracy: 0.7482\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9832 - accuracy: 0.7273 - val_loss: 0.8748 - val_accuracy: 0.7605\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9328 - accuracy: 0.7399 - val_loss: 0.8345 - val_accuracy: 0.7705\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8953 - accuracy: 0.7488 - val_loss: 0.8050 - val_accuracy: 0.7768\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8641 - accuracy: 0.7557 - val_loss: 0.7818 - val_accuracy: 0.7806\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8449 - accuracy: 0.7599 - val_loss: 0.7623 - val_accuracy: 0.7852\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8256 - accuracy: 0.7648 - val_loss: 0.7464 - val_accuracy: 0.7881\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8096 - accuracy: 0.7693 - val_loss: 0.7356 - val_accuracy: 0.7917\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7965 - accuracy: 0.7721 - val_loss: 0.7248 - val_accuracy: 0.7924\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7887 - accuracy: 0.7734 - val_loss: 0.7169 - val_accuracy: 0.7957\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7789 - accuracy: 0.7751 - val_loss: 0.7097 - val_accuracy: 0.7960\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7693 - accuracy: 0.7780 - val_loss: 0.7032 - val_accuracy: 0.7978\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7631 - accuracy: 0.7802 - val_loss: 0.6979 - val_accuracy: 0.7993\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7579 - accuracy: 0.7814 - val_loss: 0.6940 - val_accuracy: 0.7998\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7497 - accuracy: 0.7831 - val_loss: 0.6898 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7498 - accuracy: 0.7831 - val_loss: 0.6868 - val_accuracy: 0.8009\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:11.431923\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7440 - accuracy: 0.7860 - val_loss: 0.6845 - val_accuracy: 0.8017\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7435 - accuracy: 0.7842 - val_loss: 0.6839 - val_accuracy: 0.8018\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7433 - accuracy: 0.7844 - val_loss: 0.6838 - val_accuracy: 0.8020\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7431 - accuracy: 0.7846 - val_loss: 0.6833 - val_accuracy: 0.8020\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7425 - accuracy: 0.7852 - val_loss: 0.6832 - val_accuracy: 0.8021\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7434 - accuracy: 0.7851 - val_loss: 0.6832 - val_accuracy: 0.8023\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7426 - accuracy: 0.7848 - val_loss: 0.6835 - val_accuracy: 0.8019\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7415 - accuracy: 0.7850 - val_loss: 0.6831 - val_accuracy: 0.8020\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7427 - accuracy: 0.7843 - val_loss: 0.6835 - val_accuracy: 0.8020\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:08.482873\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.4555 - accuracy: 0.3742 - val_loss: 1.7101 - val_accuracy: 0.5947\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5591 - accuracy: 0.5945 - val_loss: 1.2606 - val_accuracy: 0.6829\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2803 - accuracy: 0.6586 - val_loss: 1.0745 - val_accuracy: 0.7210\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1208 - accuracy: 0.6957 - val_loss: 0.9591 - val_accuracy: 0.7485\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0189 - accuracy: 0.7212 - val_loss: 0.8805 - val_accuracy: 0.7641\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9506 - accuracy: 0.7371 - val_loss: 0.8270 - val_accuracy: 0.7752\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9004 - accuracy: 0.7479 - val_loss: 0.7891 - val_accuracy: 0.7823\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8659 - accuracy: 0.7563 - val_loss: 0.7601 - val_accuracy: 0.7896\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8390 - accuracy: 0.7609 - val_loss: 0.7395 - val_accuracy: 0.7947\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8159 - accuracy: 0.7677 - val_loss: 0.7219 - val_accuracy: 0.7987\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8015 - accuracy: 0.7703 - val_loss: 0.7091 - val_accuracy: 0.8019\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7861 - accuracy: 0.7744 - val_loss: 0.6984 - val_accuracy: 0.8035\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7748 - accuracy: 0.7766 - val_loss: 0.6888 - val_accuracy: 0.8060\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7650 - accuracy: 0.7787 - val_loss: 0.6808 - val_accuracy: 0.8073\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7558 - accuracy: 0.7805 - val_loss: 0.6744 - val_accuracy: 0.8093\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7496 - accuracy: 0.7836 - val_loss: 0.6692 - val_accuracy: 0.8104\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7453 - accuracy: 0.7847 - val_loss: 0.6646 - val_accuracy: 0.8118\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7381 - accuracy: 0.7859 - val_loss: 0.6601 - val_accuracy: 0.8127\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7342 - accuracy: 0.7858 - val_loss: 0.6565 - val_accuracy: 0.8135\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7303 - accuracy: 0.7874 - val_loss: 0.6535 - val_accuracy: 0.8141\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:16.001789\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7278 - accuracy: 0.7877 - val_loss: 0.6518 - val_accuracy: 0.8141\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.7243 - accuracy: 0.7887 - val_loss: 0.6513 - val_accuracy: 0.8147\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7270 - accuracy: 0.7883 - val_loss: 0.6511 - val_accuracy: 0.8148\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7246 - accuracy: 0.7896 - val_loss: 0.6510 - val_accuracy: 0.8147\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7242 - accuracy: 0.7881 - val_loss: 0.6511 - val_accuracy: 0.8146\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7270 - accuracy: 0.7885 - val_loss: 0.6508 - val_accuracy: 0.8147\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:51.752529\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.3966 - accuracy: 0.3608 - val_loss: 7.5377 - val_accuracy: 0.5639\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.1889 - accuracy: 0.5702 - val_loss: 6.7181 - val_accuracy: 0.6531\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.5341 - accuracy: 0.6381 - val_loss: 6.1560 - val_accuracy: 0.6975\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.0324 - accuracy: 0.6780 - val_loss: 5.7086 - val_accuracy: 0.7269\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 5.6107 - accuracy: 0.7063 - val_loss: 5.3244 - val_accuracy: 0.7457\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 5.2583 - accuracy: 0.7258 - val_loss: 5.0157 - val_accuracy: 0.7625\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.9761 - accuracy: 0.7391 - val_loss: 4.7611 - val_accuracy: 0.7728\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.7428 - accuracy: 0.7485 - val_loss: 4.5522 - val_accuracy: 0.7801\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.5478 - accuracy: 0.7555 - val_loss: 4.3774 - val_accuracy: 0.7857\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.3820 - accuracy: 0.7631 - val_loss: 4.2282 - val_accuracy: 0.7897\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.2427 - accuracy: 0.7672 - val_loss: 4.1010 - val_accuracy: 0.7934\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.1241 - accuracy: 0.7720 - val_loss: 3.9945 - val_accuracy: 0.7958\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 4.0219 - accuracy: 0.7743 - val_loss: 3.8998 - val_accuracy: 0.7983\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9358 - accuracy: 0.7764 - val_loss: 3.8195 - val_accuracy: 0.8003\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8575 - accuracy: 0.7816 - val_loss: 3.7489 - val_accuracy: 0.8024\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.7914 - accuracy: 0.7818 - val_loss: 3.6895 - val_accuracy: 0.8038\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.7360 - accuracy: 0.7822 - val_loss: 3.6365 - val_accuracy: 0.8039\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.6848 - accuracy: 0.7851 - val_loss: 3.5900 - val_accuracy: 0.8054\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.6414 - accuracy: 0.7853 - val_loss: 3.5500 - val_accuracy: 0.8068\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.6018 - accuracy: 0.7868 - val_loss: 3.5151 - val_accuracy: 0.8079\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:49.559716\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5736 - accuracy: 0.7875 - val_loss: 3.4966 - val_accuracy: 0.8078\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5630 - accuracy: 0.7877 - val_loss: 3.4882 - val_accuracy: 0.8077\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5543 - accuracy: 0.7887 - val_loss: 3.4841 - val_accuracy: 0.8078\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5537 - accuracy: 0.7878 - val_loss: 3.4822 - val_accuracy: 0.8081\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.5496 - accuracy: 0.7900 - val_loss: 3.4813 - val_accuracy: 0.8081\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.5525 - accuracy: 0.7887 - val_loss: 3.4809 - val_accuracy: 0.8081\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 3.5504 - accuracy: 0.7895 - val_loss: 3.4808 - val_accuracy: 0.8079\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:06.301266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.4929 - accuracy: 0.3357 - val_loss: 7.6122 - val_accuracy: 0.5475\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 7.2032 - accuracy: 0.5614 - val_loss: 6.7100 - val_accuracy: 0.6475\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.5213 - accuracy: 0.6348 - val_loss: 6.1420 - val_accuracy: 0.6977\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.0053 - accuracy: 0.6752 - val_loss: 5.6798 - val_accuracy: 0.7243\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.5681 - accuracy: 0.7035 - val_loss: 5.2813 - val_accuracy: 0.7447\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.2061 - accuracy: 0.7227 - val_loss: 4.9630 - val_accuracy: 0.7609\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.9134 - accuracy: 0.7379 - val_loss: 4.7010 - val_accuracy: 0.7688\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.6718 - accuracy: 0.7470 - val_loss: 4.4854 - val_accuracy: 0.7778\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.4695 - accuracy: 0.7543 - val_loss: 4.3019 - val_accuracy: 0.7832\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.3018 - accuracy: 0.7594 - val_loss: 4.1468 - val_accuracy: 0.7884\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.1577 - accuracy: 0.7645 - val_loss: 4.0151 - val_accuracy: 0.7909\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0329 - accuracy: 0.7700 - val_loss: 3.9021 - val_accuracy: 0.7948\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9287 - accuracy: 0.7718 - val_loss: 3.8046 - val_accuracy: 0.7983\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8370 - accuracy: 0.7757 - val_loss: 3.7210 - val_accuracy: 0.8005\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7571 - accuracy: 0.7770 - val_loss: 3.6487 - val_accuracy: 0.8018\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6873 - accuracy: 0.7783 - val_loss: 3.5849 - val_accuracy: 0.8029\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6296 - accuracy: 0.7801 - val_loss: 3.5291 - val_accuracy: 0.8043\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5749 - accuracy: 0.7817 - val_loss: 3.4804 - val_accuracy: 0.8056\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5311 - accuracy: 0.7810 - val_loss: 3.4384 - val_accuracy: 0.8066\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.4889 - accuracy: 0.7856 - val_loss: 3.4010 - val_accuracy: 0.8071\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:14.940475\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4598 - accuracy: 0.7846 - val_loss: 3.3831 - val_accuracy: 0.8081\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4463 - accuracy: 0.7864 - val_loss: 3.3726 - val_accuracy: 0.8078\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.4403 - accuracy: 0.7862 - val_loss: 3.3694 - val_accuracy: 0.8082\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4366 - accuracy: 0.7853 - val_loss: 3.3674 - val_accuracy: 0.8082\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.4347 - accuracy: 0.7861 - val_loss: 3.3664 - val_accuracy: 0.8080\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4340 - accuracy: 0.7852 - val_loss: 3.3657 - val_accuracy: 0.8081\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:45.557834\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.3601 - accuracy: 0.3679 - val_loss: 7.5339 - val_accuracy: 0.5702\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 7.2044 - accuracy: 0.5640 - val_loss: 6.7523 - val_accuracy: 0.6461\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.5785 - accuracy: 0.6264 - val_loss: 6.2217 - val_accuracy: 0.6855\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.0845 - accuracy: 0.6616 - val_loss: 5.7671 - val_accuracy: 0.7109\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.6603 - accuracy: 0.6886 - val_loss: 5.3744 - val_accuracy: 0.7336\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.3008 - accuracy: 0.7109 - val_loss: 5.0604 - val_accuracy: 0.7455\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.0102 - accuracy: 0.7228 - val_loss: 4.7987 - val_accuracy: 0.7574\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.7717 - accuracy: 0.7354 - val_loss: 4.5852 - val_accuracy: 0.7652\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.5709 - accuracy: 0.7427 - val_loss: 4.4035 - val_accuracy: 0.7722\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.4006 - accuracy: 0.7492 - val_loss: 4.2482 - val_accuracy: 0.7771\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2586 - accuracy: 0.7533 - val_loss: 4.1182 - val_accuracy: 0.7805\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1353 - accuracy: 0.7586 - val_loss: 4.0051 - val_accuracy: 0.7838\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0301 - accuracy: 0.7624 - val_loss: 3.9077 - val_accuracy: 0.7855\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9392 - accuracy: 0.7638 - val_loss: 3.8258 - val_accuracy: 0.7883\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8608 - accuracy: 0.7683 - val_loss: 3.7544 - val_accuracy: 0.7911\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7912 - accuracy: 0.7694 - val_loss: 3.6907 - val_accuracy: 0.7915\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7326 - accuracy: 0.7707 - val_loss: 3.6363 - val_accuracy: 0.7935\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6797 - accuracy: 0.7728 - val_loss: 3.5885 - val_accuracy: 0.7947\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6354 - accuracy: 0.7736 - val_loss: 3.5463 - val_accuracy: 0.7961\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5934 - accuracy: 0.7769 - val_loss: 3.5098 - val_accuracy: 0.7969\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:08.612101\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5670 - accuracy: 0.7744 - val_loss: 3.4907 - val_accuracy: 0.7969\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5542 - accuracy: 0.7768 - val_loss: 3.4831 - val_accuracy: 0.7969\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5464 - accuracy: 0.7773 - val_loss: 3.4784 - val_accuracy: 0.7974\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5438 - accuracy: 0.7776 - val_loss: 3.4765 - val_accuracy: 0.7973\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5428 - accuracy: 0.7764 - val_loss: 3.4758 - val_accuracy: 0.7978\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5409 - accuracy: 0.7767 - val_loss: 3.4748 - val_accuracy: 0.7977\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5423 - accuracy: 0.7766 - val_loss: 3.4748 - val_accuracy: 0.7975\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5429 - accuracy: 0.7759 - val_loss: 3.4752 - val_accuracy: 0.7974\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:37.385464\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.2440 - accuracy: 0.3893 - val_loss: 7.3954 - val_accuracy: 0.5821\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.0717 - accuracy: 0.5870 - val_loss: 6.6353 - val_accuracy: 0.6610\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.4541 - accuracy: 0.6496 - val_loss: 6.1047 - val_accuracy: 0.7034\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.9610 - accuracy: 0.6870 - val_loss: 5.6651 - val_accuracy: 0.7300\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5462 - accuracy: 0.7128 - val_loss: 5.2839 - val_accuracy: 0.7499\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.2014 - accuracy: 0.7327 - val_loss: 4.9792 - val_accuracy: 0.7632\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9199 - accuracy: 0.7445 - val_loss: 4.7247 - val_accuracy: 0.7713\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.6855 - accuracy: 0.7546 - val_loss: 4.5160 - val_accuracy: 0.7790\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.4906 - accuracy: 0.7615 - val_loss: 4.3402 - val_accuracy: 0.7842\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.3269 - accuracy: 0.7686 - val_loss: 4.1893 - val_accuracy: 0.7895\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1870 - accuracy: 0.7732 - val_loss: 4.0643 - val_accuracy: 0.7918\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0692 - accuracy: 0.7750 - val_loss: 3.9564 - val_accuracy: 0.7943\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9636 - accuracy: 0.7803 - val_loss: 3.8623 - val_accuracy: 0.7976\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8753 - accuracy: 0.7817 - val_loss: 3.7804 - val_accuracy: 0.7991\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7974 - accuracy: 0.7852 - val_loss: 3.7090 - val_accuracy: 0.8008\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7320 - accuracy: 0.7850 - val_loss: 3.6490 - val_accuracy: 0.8020\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6759 - accuracy: 0.7865 - val_loss: 3.5949 - val_accuracy: 0.8034\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6229 - accuracy: 0.7894 - val_loss: 3.5487 - val_accuracy: 0.8047\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5786 - accuracy: 0.7904 - val_loss: 3.5077 - val_accuracy: 0.8054\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5399 - accuracy: 0.7909 - val_loss: 3.4711 - val_accuracy: 0.8060\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:00.969946\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5128 - accuracy: 0.7914 - val_loss: 3.4536 - val_accuracy: 0.8066\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5004 - accuracy: 0.7913 - val_loss: 3.4450 - val_accuracy: 0.8071\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4920 - accuracy: 0.7939 - val_loss: 3.4410 - val_accuracy: 0.8066\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4887 - accuracy: 0.7930 - val_loss: 3.4391 - val_accuracy: 0.8067\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4881 - accuracy: 0.7927 - val_loss: 3.4384 - val_accuracy: 0.8067\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:20.145530\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.3144 - accuracy: 0.3654 - val_loss: 7.4603 - val_accuracy: 0.5668\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.1274 - accuracy: 0.5698 - val_loss: 6.6477 - val_accuracy: 0.6573\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.4834 - accuracy: 0.6389 - val_loss: 6.1006 - val_accuracy: 0.7029\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.9828 - accuracy: 0.6793 - val_loss: 5.6578 - val_accuracy: 0.7283\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5618 - accuracy: 0.7058 - val_loss: 5.2676 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.2105 - accuracy: 0.7247 - val_loss: 4.9564 - val_accuracy: 0.7641\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9225 - accuracy: 0.7377 - val_loss: 4.6998 - val_accuracy: 0.7728\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.6860 - accuracy: 0.7461 - val_loss: 4.4884 - val_accuracy: 0.7800\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.4851 - accuracy: 0.7564 - val_loss: 4.3089 - val_accuracy: 0.7854\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.3199 - accuracy: 0.7621 - val_loss: 4.1584 - val_accuracy: 0.7899\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1761 - accuracy: 0.7670 - val_loss: 4.0262 - val_accuracy: 0.7937\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0543 - accuracy: 0.7702 - val_loss: 3.9154 - val_accuracy: 0.7963\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9511 - accuracy: 0.7726 - val_loss: 3.8195 - val_accuracy: 0.7980\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8612 - accuracy: 0.7755 - val_loss: 3.7375 - val_accuracy: 0.8004\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7831 - accuracy: 0.7790 - val_loss: 3.6659 - val_accuracy: 0.8021\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7144 - accuracy: 0.7802 - val_loss: 3.6045 - val_accuracy: 0.8033\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6553 - accuracy: 0.7824 - val_loss: 3.5495 - val_accuracy: 0.8048\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6024 - accuracy: 0.7833 - val_loss: 3.5015 - val_accuracy: 0.8064\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5580 - accuracy: 0.7834 - val_loss: 3.4603 - val_accuracy: 0.8070\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5179 - accuracy: 0.7845 - val_loss: 3.4223 - val_accuracy: 0.8078\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:00.360146\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4902 - accuracy: 0.7849 - val_loss: 3.4042 - val_accuracy: 0.8079\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4775 - accuracy: 0.7871 - val_loss: 3.3954 - val_accuracy: 0.8081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4703 - accuracy: 0.7867 - val_loss: 3.3909 - val_accuracy: 0.8082\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4674 - accuracy: 0.7871 - val_loss: 3.3897 - val_accuracy: 0.8084\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4655 - accuracy: 0.7867 - val_loss: 3.3881 - val_accuracy: 0.8081\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4651 - accuracy: 0.7875 - val_loss: 3.3879 - val_accuracy: 0.8082\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4649 - accuracy: 0.7871 - val_loss: 3.3877 - val_accuracy: 0.8084\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4633 - accuracy: 0.7878 - val_loss: 3.3882 - val_accuracy: 0.8083\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4656 - accuracy: 0.7864 - val_loss: 3.3880 - val_accuracy: 0.8086\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4637 - accuracy: 0.7875 - val_loss: 3.3878 - val_accuracy: 0.8086\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4648 - accuracy: 0.7865 - val_loss: 3.3882 - val_accuracy: 0.8083\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.4637 - accuracy: 0.7872 - val_loss: 3.3879 - val_accuracy: 0.8084\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:24.236552\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 8.0655 - accuracy: 0.4061 - val_loss: 7.1788 - val_accuracy: 0.6129\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.9361 - accuracy: 0.5934 - val_loss: 6.5052 - val_accuracy: 0.6730\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.3614 - accuracy: 0.6505 - val_loss: 6.0092 - val_accuracy: 0.7083\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.9007 - accuracy: 0.6846 - val_loss: 5.5946 - val_accuracy: 0.7359\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.5054 - accuracy: 0.7110 - val_loss: 5.2319 - val_accuracy: 0.7557\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.1752 - accuracy: 0.7295 - val_loss: 4.9426 - val_accuracy: 0.7690\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9065 - accuracy: 0.7434 - val_loss: 4.7062 - val_accuracy: 0.7786\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.6882 - accuracy: 0.7542 - val_loss: 4.5101 - val_accuracy: 0.7850\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.5076 - accuracy: 0.7599 - val_loss: 4.3445 - val_accuracy: 0.7898\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3534 - accuracy: 0.7663 - val_loss: 4.2084 - val_accuracy: 0.7950\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2226 - accuracy: 0.7710 - val_loss: 4.0897 - val_accuracy: 0.7992\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1138 - accuracy: 0.7736 - val_loss: 3.9901 - val_accuracy: 0.8012\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0194 - accuracy: 0.7764 - val_loss: 3.9041 - val_accuracy: 0.8039\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9391 - accuracy: 0.7796 - val_loss: 3.8307 - val_accuracy: 0.8059\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8672 - accuracy: 0.7829 - val_loss: 3.7668 - val_accuracy: 0.8075\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8088 - accuracy: 0.7842 - val_loss: 3.7105 - val_accuracy: 0.8087\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7554 - accuracy: 0.7855 - val_loss: 3.6624 - val_accuracy: 0.8099\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7099 - accuracy: 0.7867 - val_loss: 3.6212 - val_accuracy: 0.8109\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6682 - accuracy: 0.7883 - val_loss: 3.5851 - val_accuracy: 0.8113\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6343 - accuracy: 0.7891 - val_loss: 3.5521 - val_accuracy: 0.8125\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:07.843656\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6101 - accuracy: 0.7901 - val_loss: 3.5366 - val_accuracy: 0.8125\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5984 - accuracy: 0.7892 - val_loss: 3.5285 - val_accuracy: 0.8130\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5928 - accuracy: 0.7903 - val_loss: 3.5251 - val_accuracy: 0.8129\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5902 - accuracy: 0.7897 - val_loss: 3.5235 - val_accuracy: 0.8130\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5894 - accuracy: 0.7912 - val_loss: 3.5226 - val_accuracy: 0.8127\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:16.943972\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.0549 - accuracy: 0.4161 - val_loss: 7.1926 - val_accuracy: 0.6064\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.9316 - accuracy: 0.5945 - val_loss: 6.5194 - val_accuracy: 0.6700\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.3586 - accuracy: 0.6495 - val_loss: 6.0255 - val_accuracy: 0.7071\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.8961 - accuracy: 0.6863 - val_loss: 5.6124 - val_accuracy: 0.7314\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.5068 - accuracy: 0.7109 - val_loss: 5.2517 - val_accuracy: 0.7490\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.1770 - accuracy: 0.7283 - val_loss: 4.9631 - val_accuracy: 0.7635\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9105 - accuracy: 0.7432 - val_loss: 4.7266 - val_accuracy: 0.7734\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.6926 - accuracy: 0.7505 - val_loss: 4.5296 - val_accuracy: 0.7790\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.5082 - accuracy: 0.7609 - val_loss: 4.3672 - val_accuracy: 0.7825\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3556 - accuracy: 0.7635 - val_loss: 4.2271 - val_accuracy: 0.7882\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2243 - accuracy: 0.7700 - val_loss: 4.1091 - val_accuracy: 0.7911\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1161 - accuracy: 0.7730 - val_loss: 4.0085 - val_accuracy: 0.7958\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0199 - accuracy: 0.7760 - val_loss: 3.9226 - val_accuracy: 0.7978\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9402 - accuracy: 0.7787 - val_loss: 3.8479 - val_accuracy: 0.8003\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8680 - accuracy: 0.7794 - val_loss: 3.7836 - val_accuracy: 0.8014\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8043 - accuracy: 0.7846 - val_loss: 3.7285 - val_accuracy: 0.8031\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7528 - accuracy: 0.7847 - val_loss: 3.6786 - val_accuracy: 0.8039\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7066 - accuracy: 0.7867 - val_loss: 3.6366 - val_accuracy: 0.8041\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6662 - accuracy: 0.7885 - val_loss: 3.5989 - val_accuracy: 0.8060\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6326 - accuracy: 0.7873 - val_loss: 3.5667 - val_accuracy: 0.8062\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:09.020515\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6082 - accuracy: 0.7887 - val_loss: 3.5512 - val_accuracy: 0.8078\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5931 - accuracy: 0.7904 - val_loss: 3.5426 - val_accuracy: 0.8071\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5886 - accuracy: 0.7899 - val_loss: 3.5395 - val_accuracy: 0.8072\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5858 - accuracy: 0.7889 - val_loss: 3.5377 - val_accuracy: 0.8072\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:50.262861\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.0110 - accuracy: 0.4248 - val_loss: 7.1426 - val_accuracy: 0.6231\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.8860 - accuracy: 0.6100 - val_loss: 6.4663 - val_accuracy: 0.6847\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.3181 - accuracy: 0.6644 - val_loss: 5.9818 - val_accuracy: 0.7209\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.8681 - accuracy: 0.6950 - val_loss: 5.5734 - val_accuracy: 0.7436\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.4773 - accuracy: 0.7205 - val_loss: 5.2195 - val_accuracy: 0.7605\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.1543 - accuracy: 0.7367 - val_loss: 4.9323 - val_accuracy: 0.7719\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.8902 - accuracy: 0.7468 - val_loss: 4.6961 - val_accuracy: 0.7797\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.6683 - accuracy: 0.7571 - val_loss: 4.4996 - val_accuracy: 0.7847\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.4828 - accuracy: 0.7635 - val_loss: 4.3336 - val_accuracy: 0.7905\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3293 - accuracy: 0.7691 - val_loss: 4.1925 - val_accuracy: 0.7943\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1975 - accuracy: 0.7728 - val_loss: 4.0721 - val_accuracy: 0.7975\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0841 - accuracy: 0.7754 - val_loss: 3.9708 - val_accuracy: 0.7988\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9903 - accuracy: 0.7785 - val_loss: 3.8827 - val_accuracy: 0.8008\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9058 - accuracy: 0.7808 - val_loss: 3.8065 - val_accuracy: 0.8032\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8345 - accuracy: 0.7810 - val_loss: 3.7402 - val_accuracy: 0.8044\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7719 - accuracy: 0.7849 - val_loss: 3.6833 - val_accuracy: 0.8047\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7201 - accuracy: 0.7829 - val_loss: 3.6336 - val_accuracy: 0.8060\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6683 - accuracy: 0.7868 - val_loss: 3.5898 - val_accuracy: 0.8066\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6295 - accuracy: 0.7877 - val_loss: 3.5513 - val_accuracy: 0.8079\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5920 - accuracy: 0.7890 - val_loss: 3.5180 - val_accuracy: 0.8077\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:08.318165\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5669 - accuracy: 0.7891 - val_loss: 3.5005 - val_accuracy: 0.8090\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5544 - accuracy: 0.7897 - val_loss: 3.4929 - val_accuracy: 0.8088\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5477 - accuracy: 0.7893 - val_loss: 3.4894 - val_accuracy: 0.8092\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5442 - accuracy: 0.7907 - val_loss: 3.4877 - val_accuracy: 0.8090\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5428 - accuracy: 0.7904 - val_loss: 3.4864 - val_accuracy: 0.8088\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5450 - accuracy: 0.7895 - val_loss: 3.4858 - val_accuracy: 0.8090\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:44.702266\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.1165 - accuracy: 0.3955 - val_loss: 7.2159 - val_accuracy: 0.5945\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.9733 - accuracy: 0.5838 - val_loss: 6.5456 - val_accuracy: 0.6602\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.4032 - accuracy: 0.6387 - val_loss: 6.0516 - val_accuracy: 0.6967\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.9379 - accuracy: 0.6758 - val_loss: 5.6387 - val_accuracy: 0.7238\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.5444 - accuracy: 0.7001 - val_loss: 5.2731 - val_accuracy: 0.7426\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.2115 - accuracy: 0.7208 - val_loss: 4.9824 - val_accuracy: 0.7560\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9449 - accuracy: 0.7339 - val_loss: 4.7446 - val_accuracy: 0.7678\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.7230 - accuracy: 0.7463 - val_loss: 4.5491 - val_accuracy: 0.7737\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.5395 - accuracy: 0.7536 - val_loss: 4.3843 - val_accuracy: 0.7815\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3879 - accuracy: 0.7587 - val_loss: 4.2458 - val_accuracy: 0.7865\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2575 - accuracy: 0.7632 - val_loss: 4.1292 - val_accuracy: 0.7886\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1477 - accuracy: 0.7692 - val_loss: 4.0306 - val_accuracy: 0.7913\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0552 - accuracy: 0.7708 - val_loss: 3.9444 - val_accuracy: 0.7949\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9733 - accuracy: 0.7737 - val_loss: 3.8704 - val_accuracy: 0.7967\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9043 - accuracy: 0.7764 - val_loss: 3.8076 - val_accuracy: 0.7986\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8443 - accuracy: 0.7777 - val_loss: 3.7513 - val_accuracy: 0.8006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7897 - accuracy: 0.7802 - val_loss: 3.7040 - val_accuracy: 0.8019\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7462 - accuracy: 0.7808 - val_loss: 3.6622 - val_accuracy: 0.8014\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7065 - accuracy: 0.7830 - val_loss: 3.6261 - val_accuracy: 0.8029\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6721 - accuracy: 0.7839 - val_loss: 3.5939 - val_accuracy: 0.8043\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:05.300800\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6472 - accuracy: 0.7841 - val_loss: 3.5781 - val_accuracy: 0.8041\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6331 - accuracy: 0.7857 - val_loss: 3.5706 - val_accuracy: 0.8043\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6298 - accuracy: 0.7840 - val_loss: 3.5664 - val_accuracy: 0.8044\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6272 - accuracy: 0.7846 - val_loss: 3.5653 - val_accuracy: 0.8045\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6239 - accuracy: 0.7855 - val_loss: 3.5643 - val_accuracy: 0.8045\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6236 - accuracy: 0.7854 - val_loss: 3.5641 - val_accuracy: 0.8045\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6241 - accuracy: 0.7855 - val_loss: 3.5639 - val_accuracy: 0.8045\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6240 - accuracy: 0.7848 - val_loss: 3.5638 - val_accuracy: 0.8045\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:38.477193\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.0833 - accuracy: 0.4134 - val_loss: 7.2081 - val_accuracy: 0.6046\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.9434 - accuracy: 0.5947 - val_loss: 6.5256 - val_accuracy: 0.6704\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.3656 - accuracy: 0.6519 - val_loss: 6.0249 - val_accuracy: 0.7064\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.9045 - accuracy: 0.6856 - val_loss: 5.6072 - val_accuracy: 0.7309\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.5107 - accuracy: 0.7105 - val_loss: 5.2446 - val_accuracy: 0.7521\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.1780 - accuracy: 0.7301 - val_loss: 4.9537 - val_accuracy: 0.7666\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9107 - accuracy: 0.7421 - val_loss: 4.7152 - val_accuracy: 0.7743\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.6889 - accuracy: 0.7520 - val_loss: 4.5178 - val_accuracy: 0.7802\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.5060 - accuracy: 0.7591 - val_loss: 4.3521 - val_accuracy: 0.7848\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3530 - accuracy: 0.7639 - val_loss: 4.2123 - val_accuracy: 0.7883\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2235 - accuracy: 0.7680 - val_loss: 4.0930 - val_accuracy: 0.7932\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1115 - accuracy: 0.7711 - val_loss: 3.9925 - val_accuracy: 0.7967\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0142 - accuracy: 0.7760 - val_loss: 3.9056 - val_accuracy: 0.7984\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9301 - accuracy: 0.7790 - val_loss: 3.8293 - val_accuracy: 0.8011\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8615 - accuracy: 0.7801 - val_loss: 3.7646 - val_accuracy: 0.8023\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8011 - accuracy: 0.7811 - val_loss: 3.7078 - val_accuracy: 0.8043\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7474 - accuracy: 0.7839 - val_loss: 3.6601 - val_accuracy: 0.8044\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7020 - accuracy: 0.7838 - val_loss: 3.6160 - val_accuracy: 0.8056\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6591 - accuracy: 0.7865 - val_loss: 3.5794 - val_accuracy: 0.8066\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6233 - accuracy: 0.7874 - val_loss: 3.5462 - val_accuracy: 0.8070\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:06.640130\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5985 - accuracy: 0.7888 - val_loss: 3.5307 - val_accuracy: 0.8075\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5869 - accuracy: 0.7888 - val_loss: 3.5222 - val_accuracy: 0.8077\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5816 - accuracy: 0.7891 - val_loss: 3.5188 - val_accuracy: 0.8080\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5792 - accuracy: 0.7878 - val_loss: 3.5168 - val_accuracy: 0.8077\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5770 - accuracy: 0.7872 - val_loss: 3.5159 - val_accuracy: 0.8079\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5772 - accuracy: 0.7884 - val_loss: 3.5156 - val_accuracy: 0.8079\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:44.254409\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.2093 - accuracy: 0.3870 - val_loss: 7.3052 - val_accuracy: 0.5953\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9682 - accuracy: 0.5981 - val_loss: 6.5246 - val_accuracy: 0.6746\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3473 - accuracy: 0.6616 - val_loss: 6.0067 - val_accuracy: 0.7135\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8689 - accuracy: 0.6972 - val_loss: 5.5803 - val_accuracy: 0.7381\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4671 - accuracy: 0.7205 - val_loss: 5.2131 - val_accuracy: 0.7557\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1309 - accuracy: 0.7378 - val_loss: 4.9153 - val_accuracy: 0.7673\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8560 - accuracy: 0.7504 - val_loss: 4.6700 - val_accuracy: 0.7779\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6314 - accuracy: 0.7584 - val_loss: 4.4669 - val_accuracy: 0.7844\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4429 - accuracy: 0.7648 - val_loss: 4.2960 - val_accuracy: 0.7895\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2847 - accuracy: 0.7708 - val_loss: 4.1491 - val_accuracy: 0.7937\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1486 - accuracy: 0.7736 - val_loss: 4.0281 - val_accuracy: 0.7965\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0334 - accuracy: 0.7782 - val_loss: 3.9233 - val_accuracy: 0.8004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9315 - accuracy: 0.7824 - val_loss: 3.8323 - val_accuracy: 0.8015\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8466 - accuracy: 0.7849 - val_loss: 3.7533 - val_accuracy: 0.8037\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7721 - accuracy: 0.7861 - val_loss: 3.6859 - val_accuracy: 0.8049\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.7088 - accuracy: 0.7891 - val_loss: 3.6273 - val_accuracy: 0.8051\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6548 - accuracy: 0.7878 - val_loss: 3.5763 - val_accuracy: 0.8070\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6018 - accuracy: 0.7921 - val_loss: 3.5309 - val_accuracy: 0.8079\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5624 - accuracy: 0.7924 - val_loss: 3.4917 - val_accuracy: 0.8087\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5246 - accuracy: 0.7917 - val_loss: 3.4576 - val_accuracy: 0.8090\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:27.247348\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4981 - accuracy: 0.7950 - val_loss: 3.4408 - val_accuracy: 0.8096\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4855 - accuracy: 0.7929 - val_loss: 3.4326 - val_accuracy: 0.8098\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4820 - accuracy: 0.7924 - val_loss: 3.4290 - val_accuracy: 0.8097\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4761 - accuracy: 0.7931 - val_loss: 3.4267 - val_accuracy: 0.8095\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4772 - accuracy: 0.7942 - val_loss: 3.4260 - val_accuracy: 0.8098\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:22.306136\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.2128 - accuracy: 0.3911 - val_loss: 7.2929 - val_accuracy: 0.5998\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9719 - accuracy: 0.5999 - val_loss: 6.5318 - val_accuracy: 0.6740\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3678 - accuracy: 0.6560 - val_loss: 6.0232 - val_accuracy: 0.7134\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8974 - accuracy: 0.6922 - val_loss: 5.6058 - val_accuracy: 0.7379\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4999 - accuracy: 0.7158 - val_loss: 5.2398 - val_accuracy: 0.7561\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1643 - accuracy: 0.7328 - val_loss: 4.9415 - val_accuracy: 0.7663\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8902 - accuracy: 0.7458 - val_loss: 4.6976 - val_accuracy: 0.7773\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6677 - accuracy: 0.7539 - val_loss: 4.4943 - val_accuracy: 0.7846\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4780 - accuracy: 0.7609 - val_loss: 4.3235 - val_accuracy: 0.7893\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3178 - accuracy: 0.7671 - val_loss: 4.1818 - val_accuracy: 0.7933\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1832 - accuracy: 0.7714 - val_loss: 4.0589 - val_accuracy: 0.7964\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0695 - accuracy: 0.7757 - val_loss: 3.9541 - val_accuracy: 0.8008\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9709 - accuracy: 0.7779 - val_loss: 3.8639 - val_accuracy: 0.8022\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8845 - accuracy: 0.7807 - val_loss: 3.7862 - val_accuracy: 0.8052\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8121 - accuracy: 0.7832 - val_loss: 3.7185 - val_accuracy: 0.8038\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7483 - accuracy: 0.7845 - val_loss: 3.6603 - val_accuracy: 0.8073\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6918 - accuracy: 0.7865 - val_loss: 3.6092 - val_accuracy: 0.8085\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6447 - accuracy: 0.7876 - val_loss: 3.5647 - val_accuracy: 0.8094\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6029 - accuracy: 0.7878 - val_loss: 3.5262 - val_accuracy: 0.8090\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5638 - accuracy: 0.7903 - val_loss: 3.4920 - val_accuracy: 0.8109\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:26.553915\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5383 - accuracy: 0.7910 - val_loss: 3.4752 - val_accuracy: 0.8109\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5286 - accuracy: 0.7904 - val_loss: 3.4668 - val_accuracy: 0.8111\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5193 - accuracy: 0.7924 - val_loss: 3.4636 - val_accuracy: 0.8116\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5178 - accuracy: 0.7919 - val_loss: 3.4616 - val_accuracy: 0.8109\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5166 - accuracy: 0.7915 - val_loss: 3.4601 - val_accuracy: 0.8110\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5157 - accuracy: 0.7904 - val_loss: 3.4601 - val_accuracy: 0.8113\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:48.892756\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.1562 - accuracy: 0.4024 - val_loss: 7.2479 - val_accuracy: 0.6066\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9346 - accuracy: 0.6052 - val_loss: 6.4840 - val_accuracy: 0.6860\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3330 - accuracy: 0.6653 - val_loss: 5.9817 - val_accuracy: 0.7215\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8672 - accuracy: 0.6986 - val_loss: 5.5645 - val_accuracy: 0.7457\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4727 - accuracy: 0.7228 - val_loss: 5.2027 - val_accuracy: 0.7613\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1388 - accuracy: 0.7414 - val_loss: 4.9095 - val_accuracy: 0.7736\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8702 - accuracy: 0.7521 - val_loss: 4.6719 - val_accuracy: 0.7816\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6483 - accuracy: 0.7616 - val_loss: 4.4706 - val_accuracy: 0.7868\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4641 - accuracy: 0.7678 - val_loss: 4.3040 - val_accuracy: 0.7919\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3079 - accuracy: 0.7727 - val_loss: 4.1626 - val_accuracy: 0.7953\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1755 - accuracy: 0.7761 - val_loss: 4.0424 - val_accuracy: 0.7992\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0617 - accuracy: 0.7798 - val_loss: 3.9380 - val_accuracy: 0.8006\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9640 - accuracy: 0.7837 - val_loss: 3.8498 - val_accuracy: 0.8014\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8810 - accuracy: 0.7850 - val_loss: 3.7730 - val_accuracy: 0.8043\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8070 - accuracy: 0.7877 - val_loss: 3.7060 - val_accuracy: 0.8059\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7460 - accuracy: 0.7883 - val_loss: 3.6481 - val_accuracy: 0.8068\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6909 - accuracy: 0.7918 - val_loss: 3.5980 - val_accuracy: 0.8074\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6445 - accuracy: 0.7905 - val_loss: 3.5542 - val_accuracy: 0.8086\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6022 - accuracy: 0.7925 - val_loss: 3.5160 - val_accuracy: 0.8099\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5651 - accuracy: 0.7926 - val_loss: 3.4825 - val_accuracy: 0.8102\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:24.106755\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5404 - accuracy: 0.7939 - val_loss: 3.4660 - val_accuracy: 0.8100\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5261 - accuracy: 0.7944 - val_loss: 3.4579 - val_accuracy: 0.8104\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.5210 - accuracy: 0.7943 - val_loss: 3.4535 - val_accuracy: 0.8102\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5185 - accuracy: 0.7948 - val_loss: 3.4517 - val_accuracy: 0.8106\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5160 - accuracy: 0.7959 - val_loss: 3.4510 - val_accuracy: 0.8105\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5142 - accuracy: 0.7947 - val_loss: 3.4510 - val_accuracy: 0.8108\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5170 - accuracy: 0.7936 - val_loss: 3.4507 - val_accuracy: 0.8106\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5147 - accuracy: 0.7952 - val_loss: 3.4498 - val_accuracy: 0.8105\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5151 - accuracy: 0.7947 - val_loss: 3.4507 - val_accuracy: 0.8104\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:14.085341\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.1766 - accuracy: 0.3939 - val_loss: 7.2495 - val_accuracy: 0.6070\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9369 - accuracy: 0.6065 - val_loss: 6.5072 - val_accuracy: 0.6768\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3434 - accuracy: 0.6640 - val_loss: 6.0038 - val_accuracy: 0.7144\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8756 - accuracy: 0.7006 - val_loss: 5.5820 - val_accuracy: 0.7392\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4759 - accuracy: 0.7231 - val_loss: 5.2183 - val_accuracy: 0.7567\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1451 - accuracy: 0.7374 - val_loss: 4.9240 - val_accuracy: 0.7690\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8721 - accuracy: 0.7505 - val_loss: 4.6807 - val_accuracy: 0.7774\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6478 - accuracy: 0.7586 - val_loss: 4.4808 - val_accuracy: 0.7831\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4592 - accuracy: 0.7661 - val_loss: 4.3114 - val_accuracy: 0.7887\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3020 - accuracy: 0.7704 - val_loss: 4.1683 - val_accuracy: 0.7919\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1701 - accuracy: 0.7748 - val_loss: 4.0467 - val_accuracy: 0.7960\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0543 - accuracy: 0.7789 - val_loss: 3.9427 - val_accuracy: 0.7978\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9578 - accuracy: 0.7814 - val_loss: 3.8532 - val_accuracy: 0.8003\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8729 - accuracy: 0.7843 - val_loss: 3.7763 - val_accuracy: 0.8032\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8003 - accuracy: 0.7847 - val_loss: 3.7104 - val_accuracy: 0.8034\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7380 - accuracy: 0.7872 - val_loss: 3.6510 - val_accuracy: 0.8050\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6810 - accuracy: 0.7893 - val_loss: 3.6013 - val_accuracy: 0.8062\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6330 - accuracy: 0.7905 - val_loss: 3.5569 - val_accuracy: 0.8066\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5906 - accuracy: 0.7920 - val_loss: 3.5184 - val_accuracy: 0.8076\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5539 - accuracy: 0.7926 - val_loss: 3.4847 - val_accuracy: 0.8083\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:23.602442\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5292 - accuracy: 0.7918 - val_loss: 3.4675 - val_accuracy: 0.8086\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5155 - accuracy: 0.7936 - val_loss: 3.4596 - val_accuracy: 0.8088\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5085 - accuracy: 0.7942 - val_loss: 3.4555 - val_accuracy: 0.8088\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5055 - accuracy: 0.7929 - val_loss: 3.4540 - val_accuracy: 0.8085\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5054 - accuracy: 0.7940 - val_loss: 3.4532 - val_accuracy: 0.8091\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5040 - accuracy: 0.7935 - val_loss: 3.4527 - val_accuracy: 0.8089\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5051 - accuracy: 0.7939 - val_loss: 3.4525 - val_accuracy: 0.8087\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5040 - accuracy: 0.7939 - val_loss: 3.4524 - val_accuracy: 0.8084\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:47.573242\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.1874 - accuracy: 0.4036 - val_loss: 7.2868 - val_accuracy: 0.6080\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9724 - accuracy: 0.6013 - val_loss: 6.5152 - val_accuracy: 0.6777\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3694 - accuracy: 0.6546 - val_loss: 6.0023 - val_accuracy: 0.7117\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8865 - accuracy: 0.6896 - val_loss: 5.5652 - val_accuracy: 0.7394\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4734 - accuracy: 0.7160 - val_loss: 5.1861 - val_accuracy: 0.7586\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1243 - accuracy: 0.7333 - val_loss: 4.8778 - val_accuracy: 0.7726\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8395 - accuracy: 0.7463 - val_loss: 4.6249 - val_accuracy: 0.7814\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6053 - accuracy: 0.7563 - val_loss: 4.4158 - val_accuracy: 0.7883\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4120 - accuracy: 0.7639 - val_loss: 4.2399 - val_accuracy: 0.7941\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2465 - accuracy: 0.7707 - val_loss: 4.0928 - val_accuracy: 0.7984\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1074 - accuracy: 0.7738 - val_loss: 3.9638 - val_accuracy: 0.8012\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9873 - accuracy: 0.7787 - val_loss: 3.8545 - val_accuracy: 0.8035\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8843 - accuracy: 0.7805 - val_loss: 3.7622 - val_accuracy: 0.8046\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7984 - accuracy: 0.7834 - val_loss: 3.6819 - val_accuracy: 0.8076\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7191 - accuracy: 0.7860 - val_loss: 3.6118 - val_accuracy: 0.8086\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6552 - accuracy: 0.7874 - val_loss: 3.5509 - val_accuracy: 0.8100\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5968 - accuracy: 0.7890 - val_loss: 3.4981 - val_accuracy: 0.8117\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5479 - accuracy: 0.7898 - val_loss: 3.4521 - val_accuracy: 0.8127\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5022 - accuracy: 0.7920 - val_loss: 3.4109 - val_accuracy: 0.8132\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4657 - accuracy: 0.7924 - val_loss: 3.3758 - val_accuracy: 0.8139\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:25.760056\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 3.4376 - accuracy: 0.7930 - val_loss: 3.3584 - val_accuracy: 0.8146\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4256 - accuracy: 0.7949 - val_loss: 3.3495 - val_accuracy: 0.8146\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4185 - accuracy: 0.7935 - val_loss: 3.3457 - val_accuracy: 0.8147\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4139 - accuracy: 0.7947 - val_loss: 3.3438 - val_accuracy: 0.8150\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.4125 - accuracy: 0.7953 - val_loss: 3.3429 - val_accuracy: 0.8142\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4120 - accuracy: 0.7950 - val_loss: 3.3429 - val_accuracy: 0.8149\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4115 - accuracy: 0.7944 - val_loss: 3.3426 - val_accuracy: 0.8148\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:22.976646\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.7461 - accuracy: 0.3707 - val_loss: 2.0992 - val_accuracy: 0.5645\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9827 - accuracy: 0.5641 - val_loss: 1.7139 - val_accuracy: 0.6392\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7143 - accuracy: 0.6265 - val_loss: 1.5188 - val_accuracy: 0.6816\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5540 - accuracy: 0.6595 - val_loss: 1.3870 - val_accuracy: 0.7112\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4323 - accuracy: 0.6870 - val_loss: 1.2905 - val_accuracy: 0.7302\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3445 - accuracy: 0.7061 - val_loss: 1.2204 - val_accuracy: 0.7434\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2808 - accuracy: 0.7215 - val_loss: 1.1691 - val_accuracy: 0.7526\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2332 - accuracy: 0.7309 - val_loss: 1.1275 - val_accuracy: 0.7623\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1931 - accuracy: 0.7394 - val_loss: 1.0958 - val_accuracy: 0.7694\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1648 - accuracy: 0.7471 - val_loss: 1.0710 - val_accuracy: 0.7747\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1391 - accuracy: 0.7525 - val_loss: 1.0517 - val_accuracy: 0.7777\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1211 - accuracy: 0.7561 - val_loss: 1.0340 - val_accuracy: 0.7820\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1042 - accuracy: 0.7581 - val_loss: 1.0198 - val_accuracy: 0.7848\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0905 - accuracy: 0.7612 - val_loss: 1.0086 - val_accuracy: 0.7865\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0774 - accuracy: 0.7649 - val_loss: 0.9994 - val_accuracy: 0.7889\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0664 - accuracy: 0.7668 - val_loss: 0.9897 - val_accuracy: 0.7902\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0590 - accuracy: 0.7692 - val_loss: 0.9835 - val_accuracy: 0.7920\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0536 - accuracy: 0.7691 - val_loss: 0.9774 - val_accuracy: 0.7932\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0480 - accuracy: 0.7709 - val_loss: 0.9716 - val_accuracy: 0.7947\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0407 - accuracy: 0.7724 - val_loss: 0.9668 - val_accuracy: 0.7956\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:54.533581\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0372 - accuracy: 0.7736 - val_loss: 0.9654 - val_accuracy: 0.7956\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0335 - accuracy: 0.7742 - val_loss: 0.9639 - val_accuracy: 0.7959\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0339 - accuracy: 0.7740 - val_loss: 0.9633 - val_accuracy: 0.7966\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0317 - accuracy: 0.7739 - val_loss: 0.9630 - val_accuracy: 0.7965\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0317 - accuracy: 0.7754 - val_loss: 0.9632 - val_accuracy: 0.7965\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0322 - accuracy: 0.7748 - val_loss: 0.9633 - val_accuracy: 0.7965\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:41.025925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.6858 - accuracy: 0.3814 - val_loss: 2.0509 - val_accuracy: 0.5771\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9253 - accuracy: 0.5796 - val_loss: 1.6585 - val_accuracy: 0.6604\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6576 - accuracy: 0.6402 - val_loss: 1.4604 - val_accuracy: 0.6989\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4937 - accuracy: 0.6773 - val_loss: 1.3370 - val_accuracy: 0.7235\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3815 - accuracy: 0.7016 - val_loss: 1.2422 - val_accuracy: 0.7446\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2998 - accuracy: 0.7185 - val_loss: 1.1797 - val_accuracy: 0.7566\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2431 - accuracy: 0.7330 - val_loss: 1.1346 - val_accuracy: 0.7669\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1993 - accuracy: 0.7410 - val_loss: 1.0946 - val_accuracy: 0.7742\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1658 - accuracy: 0.7477 - val_loss: 1.0668 - val_accuracy: 0.7794\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1382 - accuracy: 0.7536 - val_loss: 1.0445 - val_accuracy: 0.7853\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1155 - accuracy: 0.7576 - val_loss: 1.0285 - val_accuracy: 0.7877\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0980 - accuracy: 0.7620 - val_loss: 1.0123 - val_accuracy: 0.7914\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0821 - accuracy: 0.7653 - val_loss: 0.9997 - val_accuracy: 0.7933\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0685 - accuracy: 0.7681 - val_loss: 0.9889 - val_accuracy: 0.7956\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0594 - accuracy: 0.7711 - val_loss: 0.9795 - val_accuracy: 0.7972\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0499 - accuracy: 0.7734 - val_loss: 0.9724 - val_accuracy: 0.7988\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0422 - accuracy: 0.7743 - val_loss: 0.9657 - val_accuracy: 0.7998\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0345 - accuracy: 0.7763 - val_loss: 0.9596 - val_accuracy: 0.8004\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0313 - accuracy: 0.7754 - val_loss: 0.9550 - val_accuracy: 0.8012\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0237 - accuracy: 0.7769 - val_loss: 0.9504 - val_accuracy: 0.8019\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:25.339349\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0200 - accuracy: 0.7783 - val_loss: 0.9489 - val_accuracy: 0.8023\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0197 - accuracy: 0.7793 - val_loss: 0.9478 - val_accuracy: 0.8027\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0191 - accuracy: 0.7789 - val_loss: 0.9481 - val_accuracy: 0.8029\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0171 - accuracy: 0.7791 - val_loss: 0.9472 - val_accuracy: 0.8029\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0168 - accuracy: 0.7803 - val_loss: 0.9467 - val_accuracy: 0.8030\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0218 - accuracy: 0.7784 - val_loss: 0.9467 - val_accuracy: 0.8026\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0186 - accuracy: 0.7790 - val_loss: 0.9473 - val_accuracy: 0.8031\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0193 - accuracy: 0.7780 - val_loss: 0.9471 - val_accuracy: 0.8028\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0189 - accuracy: 0.7780 - val_loss: 0.9472 - val_accuracy: 0.8027\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0164 - accuracy: 0.7789 - val_loss: 0.9467 - val_accuracy: 0.8030\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:40.125948\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.8263 - accuracy: 0.3554 - val_loss: 2.1003 - val_accuracy: 0.5745\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9480 - accuracy: 0.5751 - val_loss: 1.6348 - val_accuracy: 0.6604\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6481 - accuracy: 0.6436 - val_loss: 1.4325 - val_accuracy: 0.7072\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4688 - accuracy: 0.6847 - val_loss: 1.2925 - val_accuracy: 0.7326\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3501 - accuracy: 0.7091 - val_loss: 1.1973 - val_accuracy: 0.7523\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2614 - accuracy: 0.7273 - val_loss: 1.1315 - val_accuracy: 0.7639\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2036 - accuracy: 0.7403 - val_loss: 1.0847 - val_accuracy: 0.7730\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1601 - accuracy: 0.7479 - val_loss: 1.0504 - val_accuracy: 0.7809\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1247 - accuracy: 0.7558 - val_loss: 1.0227 - val_accuracy: 0.7851\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0992 - accuracy: 0.7612 - val_loss: 1.0031 - val_accuracy: 0.7898\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0777 - accuracy: 0.7667 - val_loss: 0.9849 - val_accuracy: 0.7911\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0603 - accuracy: 0.7696 - val_loss: 0.9690 - val_accuracy: 0.7954\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0456 - accuracy: 0.7709 - val_loss: 0.9588 - val_accuracy: 0.7973\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0343 - accuracy: 0.7739 - val_loss: 0.9489 - val_accuracy: 0.7984\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0245 - accuracy: 0.7778 - val_loss: 0.9390 - val_accuracy: 0.7999\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0148 - accuracy: 0.7790 - val_loss: 0.9324 - val_accuracy: 0.8017\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0051 - accuracy: 0.7819 - val_loss: 0.9258 - val_accuracy: 0.8035\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0022 - accuracy: 0.7818 - val_loss: 0.9207 - val_accuracy: 0.8040\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9955 - accuracy: 0.7826 - val_loss: 0.9164 - val_accuracy: 0.8047\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9901 - accuracy: 0.7843 - val_loss: 0.9127 - val_accuracy: 0.8048\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:18.507695\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9868 - accuracy: 0.7858 - val_loss: 0.9110 - val_accuracy: 0.8058\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9842 - accuracy: 0.7843 - val_loss: 0.9099 - val_accuracy: 0.8059\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9853 - accuracy: 0.7847 - val_loss: 0.9091 - val_accuracy: 0.8061\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9851 - accuracy: 0.7859 - val_loss: 0.9095 - val_accuracy: 0.8059\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9833 - accuracy: 0.7868 - val_loss: 0.9089 - val_accuracy: 0.8059\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9829 - accuracy: 0.7863 - val_loss: 0.9089 - val_accuracy: 0.8061\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:45.597612\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.7918 - accuracy: 0.3569 - val_loss: 2.1611 - val_accuracy: 0.5621\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.0101 - accuracy: 0.5610 - val_loss: 1.7234 - val_accuracy: 0.6499\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7189 - accuracy: 0.6274 - val_loss: 1.5208 - val_accuracy: 0.6894\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5400 - accuracy: 0.6680 - val_loss: 1.3806 - val_accuracy: 0.7170\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4148 - accuracy: 0.6934 - val_loss: 1.2754 - val_accuracy: 0.7378\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3243 - accuracy: 0.7127 - val_loss: 1.2011 - val_accuracy: 0.7503\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2602 - accuracy: 0.7287 - val_loss: 1.1505 - val_accuracy: 0.7579\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2086 - accuracy: 0.7381 - val_loss: 1.1112 - val_accuracy: 0.7668\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1709 - accuracy: 0.7462 - val_loss: 1.0780 - val_accuracy: 0.7726\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1416 - accuracy: 0.7520 - val_loss: 1.0521 - val_accuracy: 0.7765\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1167 - accuracy: 0.7575 - val_loss: 1.0336 - val_accuracy: 0.7824\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0967 - accuracy: 0.7611 - val_loss: 1.0161 - val_accuracy: 0.7860\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0807 - accuracy: 0.7640 - val_loss: 1.0023 - val_accuracy: 0.7880\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0692 - accuracy: 0.7666 - val_loss: 0.9923 - val_accuracy: 0.7896\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0577 - accuracy: 0.7694 - val_loss: 0.9825 - val_accuracy: 0.7904\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0459 - accuracy: 0.7729 - val_loss: 0.9738 - val_accuracy: 0.7922\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0392 - accuracy: 0.7723 - val_loss: 0.9668 - val_accuracy: 0.7933\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0310 - accuracy: 0.7752 - val_loss: 0.9596 - val_accuracy: 0.7946\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0252 - accuracy: 0.7761 - val_loss: 0.9552 - val_accuracy: 0.7953\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0211 - accuracy: 0.7774 - val_loss: 0.9514 - val_accuracy: 0.7953\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:11.568958\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0167 - accuracy: 0.7777 - val_loss: 0.9486 - val_accuracy: 0.7965\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0164 - accuracy: 0.7792 - val_loss: 0.9470 - val_accuracy: 0.7966\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0129 - accuracy: 0.7804 - val_loss: 0.9469 - val_accuracy: 0.7964\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0128 - accuracy: 0.7797 - val_loss: 0.9463 - val_accuracy: 0.7969\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0125 - accuracy: 0.7792 - val_loss: 0.9466 - val_accuracy: 0.7969\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0140 - accuracy: 0.7797 - val_loss: 0.9466 - val_accuracy: 0.7965\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0131 - accuracy: 0.7795 - val_loss: 0.9466 - val_accuracy: 0.7964\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:12.797902\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.7023 - accuracy: 0.3839 - val_loss: 2.0868 - val_accuracy: 0.5786\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9643 - accuracy: 0.5740 - val_loss: 1.6889 - val_accuracy: 0.6551\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6869 - accuracy: 0.6362 - val_loss: 1.4912 - val_accuracy: 0.6930\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5164 - accuracy: 0.6749 - val_loss: 1.3576 - val_accuracy: 0.7226\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3958 - accuracy: 0.7010 - val_loss: 1.2546 - val_accuracy: 0.7445\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3068 - accuracy: 0.7207 - val_loss: 1.1842 - val_accuracy: 0.7582\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2426 - accuracy: 0.7351 - val_loss: 1.1363 - val_accuracy: 0.7681\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1941 - accuracy: 0.7446 - val_loss: 1.0988 - val_accuracy: 0.7749\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1606 - accuracy: 0.7514 - val_loss: 1.0681 - val_accuracy: 0.7815\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1311 - accuracy: 0.7574 - val_loss: 1.0443 - val_accuracy: 0.7847\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1085 - accuracy: 0.7617 - val_loss: 1.0254 - val_accuracy: 0.7876\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0906 - accuracy: 0.7656 - val_loss: 1.0102 - val_accuracy: 0.7915\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0752 - accuracy: 0.7680 - val_loss: 0.9967 - val_accuracy: 0.7943\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0609 - accuracy: 0.7719 - val_loss: 0.9872 - val_accuracy: 0.7957\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0509 - accuracy: 0.7728 - val_loss: 0.9757 - val_accuracy: 0.7982\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0422 - accuracy: 0.7754 - val_loss: 0.9689 - val_accuracy: 0.7994\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0337 - accuracy: 0.7771 - val_loss: 0.9615 - val_accuracy: 0.8011\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0258 - accuracy: 0.7785 - val_loss: 0.9567 - val_accuracy: 0.8018\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0204 - accuracy: 0.7799 - val_loss: 0.9502 - val_accuracy: 0.8031\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0152 - accuracy: 0.7803 - val_loss: 0.9466 - val_accuracy: 0.8032\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:10.449719\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0088 - accuracy: 0.7820 - val_loss: 0.9437 - val_accuracy: 0.8038\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0099 - accuracy: 0.7817 - val_loss: 0.9435 - val_accuracy: 0.8039\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0077 - accuracy: 0.7826 - val_loss: 0.9431 - val_accuracy: 0.8042\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0071 - accuracy: 0.7825 - val_loss: 0.9431 - val_accuracy: 0.8046\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0062 - accuracy: 0.7819 - val_loss: 0.9427 - val_accuracy: 0.8043\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0080 - accuracy: 0.7822 - val_loss: 0.9422 - val_accuracy: 0.8045\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0089 - accuracy: 0.7817 - val_loss: 0.9426 - val_accuracy: 0.8043\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:12.514654\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.5537 - accuracy: 0.4007 - val_loss: 1.8432 - val_accuracy: 0.6101\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7760 - accuracy: 0.5932 - val_loss: 1.5233 - val_accuracy: 0.6714\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5431 - accuracy: 0.6484 - val_loss: 1.3614 - val_accuracy: 0.7035\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3990 - accuracy: 0.6827 - val_loss: 1.2487 - val_accuracy: 0.7300\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2970 - accuracy: 0.7071 - val_loss: 1.1685 - val_accuracy: 0.7503\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2229 - accuracy: 0.7255 - val_loss: 1.1135 - val_accuracy: 0.7619\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1691 - accuracy: 0.7380 - val_loss: 1.0714 - val_accuracy: 0.7714\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1314 - accuracy: 0.7474 - val_loss: 1.0397 - val_accuracy: 0.7797\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0991 - accuracy: 0.7543 - val_loss: 1.0158 - val_accuracy: 0.7847\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0808 - accuracy: 0.7577 - val_loss: 0.9974 - val_accuracy: 0.7882\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0591 - accuracy: 0.7638 - val_loss: 0.9820 - val_accuracy: 0.7909\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0459 - accuracy: 0.7656 - val_loss: 0.9685 - val_accuracy: 0.7933\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0300 - accuracy: 0.7695 - val_loss: 0.9583 - val_accuracy: 0.7965\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0180 - accuracy: 0.7738 - val_loss: 0.9496 - val_accuracy: 0.7975\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0088 - accuracy: 0.7749 - val_loss: 0.9423 - val_accuracy: 0.7995\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0023 - accuracy: 0.7760 - val_loss: 0.9352 - val_accuracy: 0.8012\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9925 - accuracy: 0.7783 - val_loss: 0.9303 - val_accuracy: 0.8020\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9899 - accuracy: 0.7795 - val_loss: 0.9254 - val_accuracy: 0.8029\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9835 - accuracy: 0.7812 - val_loss: 0.9219 - val_accuracy: 0.8041\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9790 - accuracy: 0.7816 - val_loss: 0.9187 - val_accuracy: 0.8042\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:20.008679\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9768 - accuracy: 0.7825 - val_loss: 0.9162 - val_accuracy: 0.8051\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9741 - accuracy: 0.7827 - val_loss: 0.9154 - val_accuracy: 0.8050\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9738 - accuracy: 0.7835 - val_loss: 0.9149 - val_accuracy: 0.8049\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9754 - accuracy: 0.7819 - val_loss: 0.9147 - val_accuracy: 0.8050\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:51.994795\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.5631 - accuracy: 0.3960 - val_loss: 1.8301 - val_accuracy: 0.6108\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7328 - accuracy: 0.6053 - val_loss: 1.4871 - val_accuracy: 0.6807\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4979 - accuracy: 0.6589 - val_loss: 1.3227 - val_accuracy: 0.7170\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3614 - accuracy: 0.6925 - val_loss: 1.2161 - val_accuracy: 0.7369\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2645 - accuracy: 0.7168 - val_loss: 1.1411 - val_accuracy: 0.7542\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1954 - accuracy: 0.7332 - val_loss: 1.0920 - val_accuracy: 0.7642\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1498 - accuracy: 0.7440 - val_loss: 1.0534 - val_accuracy: 0.7734\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1144 - accuracy: 0.7517 - val_loss: 1.0255 - val_accuracy: 0.7796\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0885 - accuracy: 0.7573 - val_loss: 1.0041 - val_accuracy: 0.7838\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0666 - accuracy: 0.7627 - val_loss: 0.9861 - val_accuracy: 0.7882\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0494 - accuracy: 0.7647 - val_loss: 0.9723 - val_accuracy: 0.7907\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0345 - accuracy: 0.7696 - val_loss: 0.9601 - val_accuracy: 0.7935\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.0230 - accuracy: 0.7724 - val_loss: 0.9510 - val_accuracy: 0.7955\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0134 - accuracy: 0.7745 - val_loss: 0.9418 - val_accuracy: 0.7973\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9999 - accuracy: 0.7786 - val_loss: 0.9362 - val_accuracy: 0.7984\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9970 - accuracy: 0.7777 - val_loss: 0.9294 - val_accuracy: 0.7993\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9907 - accuracy: 0.7800 - val_loss: 0.9244 - val_accuracy: 0.8005\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9830 - accuracy: 0.7816 - val_loss: 0.9200 - val_accuracy: 0.8018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9797 - accuracy: 0.7811 - val_loss: 0.9163 - val_accuracy: 0.8017\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9783 - accuracy: 0.7823 - val_loss: 0.9124 - val_accuracy: 0.8025\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:27.892159\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9727 - accuracy: 0.7826 - val_loss: 0.9111 - val_accuracy: 0.8029\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9726 - accuracy: 0.7846 - val_loss: 0.9102 - val_accuracy: 0.8033\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9705 - accuracy: 0.7853 - val_loss: 0.9098 - val_accuracy: 0.8033\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9702 - accuracy: 0.7845 - val_loss: 0.9097 - val_accuracy: 0.8036\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9716 - accuracy: 0.7837 - val_loss: 0.9099 - val_accuracy: 0.8035\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9689 - accuracy: 0.7844 - val_loss: 0.9096 - val_accuracy: 0.8035\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9701 - accuracy: 0.7862 - val_loss: 0.9097 - val_accuracy: 0.8036\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:14.357591\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.4718 - accuracy: 0.4167 - val_loss: 1.7854 - val_accuracy: 0.6148\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7066 - accuracy: 0.6095 - val_loss: 1.4724 - val_accuracy: 0.6805\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4915 - accuracy: 0.6588 - val_loss: 1.3226 - val_accuracy: 0.7126\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3586 - accuracy: 0.6916 - val_loss: 1.2197 - val_accuracy: 0.7370\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2648 - accuracy: 0.7114 - val_loss: 1.1455 - val_accuracy: 0.7527\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1987 - accuracy: 0.7316 - val_loss: 1.0924 - val_accuracy: 0.7643\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1499 - accuracy: 0.7429 - val_loss: 1.0557 - val_accuracy: 0.7734\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1174 - accuracy: 0.7506 - val_loss: 1.0276 - val_accuracy: 0.7787\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0853 - accuracy: 0.7588 - val_loss: 1.0043 - val_accuracy: 0.7828\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0634 - accuracy: 0.7618 - val_loss: 0.9868 - val_accuracy: 0.7871\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0468 - accuracy: 0.7656 - val_loss: 0.9729 - val_accuracy: 0.7895\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0332 - accuracy: 0.7698 - val_loss: 0.9617 - val_accuracy: 0.7914\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0188 - accuracy: 0.7724 - val_loss: 0.9506 - val_accuracy: 0.7936\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0085 - accuracy: 0.7764 - val_loss: 0.9425 - val_accuracy: 0.7960\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0016 - accuracy: 0.7763 - val_loss: 0.9356 - val_accuracy: 0.7973\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9925 - accuracy: 0.7790 - val_loss: 0.9293 - val_accuracy: 0.7986\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9858 - accuracy: 0.7813 - val_loss: 0.9237 - val_accuracy: 0.7998\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9818 - accuracy: 0.7812 - val_loss: 0.9199 - val_accuracy: 0.8004\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9759 - accuracy: 0.7821 - val_loss: 0.9155 - val_accuracy: 0.8019\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9728 - accuracy: 0.7829 - val_loss: 0.9125 - val_accuracy: 0.8021\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:16.139039\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9710 - accuracy: 0.7840 - val_loss: 0.9103 - val_accuracy: 0.8026\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9683 - accuracy: 0.7853 - val_loss: 0.9094 - val_accuracy: 0.8023\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9663 - accuracy: 0.7863 - val_loss: 0.9095 - val_accuracy: 0.8025\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9669 - accuracy: 0.7845 - val_loss: 0.9095 - val_accuracy: 0.8027\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9674 - accuracy: 0.7845 - val_loss: 0.9091 - val_accuracy: 0.8025\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9666 - accuracy: 0.7850 - val_loss: 0.9090 - val_accuracy: 0.8023\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9659 - accuracy: 0.7846 - val_loss: 0.9092 - val_accuracy: 0.8026\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:14.574926\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.5411 - accuracy: 0.3995 - val_loss: 1.8350 - val_accuracy: 0.6059\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7632 - accuracy: 0.5912 - val_loss: 1.5171 - val_accuracy: 0.6660\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5374 - accuracy: 0.6467 - val_loss: 1.3572 - val_accuracy: 0.7027\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3952 - accuracy: 0.6822 - val_loss: 1.2466 - val_accuracy: 0.7275\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2949 - accuracy: 0.7060 - val_loss: 1.1693 - val_accuracy: 0.7461\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2227 - accuracy: 0.7238 - val_loss: 1.1146 - val_accuracy: 0.7580\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1737 - accuracy: 0.7351 - val_loss: 1.0753 - val_accuracy: 0.7669\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1340 - accuracy: 0.7451 - val_loss: 1.0445 - val_accuracy: 0.7740\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1067 - accuracy: 0.7500 - val_loss: 1.0213 - val_accuracy: 0.7788\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0827 - accuracy: 0.7569 - val_loss: 1.0027 - val_accuracy: 0.7834\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0636 - accuracy: 0.7625 - val_loss: 0.9866 - val_accuracy: 0.7866\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0494 - accuracy: 0.7669 - val_loss: 0.9741 - val_accuracy: 0.7892\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0358 - accuracy: 0.7688 - val_loss: 0.9641 - val_accuracy: 0.7906\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0259 - accuracy: 0.7682 - val_loss: 0.9550 - val_accuracy: 0.7930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0164 - accuracy: 0.7716 - val_loss: 0.9478 - val_accuracy: 0.7949\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0086 - accuracy: 0.7748 - val_loss: 0.9415 - val_accuracy: 0.7959\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0005 - accuracy: 0.7771 - val_loss: 0.9361 - val_accuracy: 0.7972\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9973 - accuracy: 0.7766 - val_loss: 0.9317 - val_accuracy: 0.7986\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9910 - accuracy: 0.7791 - val_loss: 0.9275 - val_accuracy: 0.8002\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9861 - accuracy: 0.7794 - val_loss: 0.9236 - val_accuracy: 0.8009\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:15.948855\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9815 - accuracy: 0.7810 - val_loss: 0.9225 - val_accuracy: 0.8008\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9834 - accuracy: 0.7800 - val_loss: 0.9213 - val_accuracy: 0.8013\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9794 - accuracy: 0.7805 - val_loss: 0.9208 - val_accuracy: 0.8011\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9813 - accuracy: 0.7812 - val_loss: 0.9210 - val_accuracy: 0.8014\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9806 - accuracy: 0.7816 - val_loss: 0.9202 - val_accuracy: 0.8017\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9807 - accuracy: 0.7811 - val_loss: 0.9207 - val_accuracy: 0.8015\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9809 - accuracy: 0.7803 - val_loss: 0.9203 - val_accuracy: 0.8017\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9812 - accuracy: 0.7810 - val_loss: 0.9203 - val_accuracy: 0.8015\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:42.295792\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.5128 - accuracy: 0.4083 - val_loss: 1.8016 - val_accuracy: 0.6133\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7636 - accuracy: 0.5933 - val_loss: 1.5051 - val_accuracy: 0.6701\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5448 - accuracy: 0.6474 - val_loss: 1.3496 - val_accuracy: 0.7069\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4070 - accuracy: 0.6784 - val_loss: 1.2376 - val_accuracy: 0.7324\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3071 - accuracy: 0.7021 - val_loss: 1.1625 - val_accuracy: 0.7479\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2338 - accuracy: 0.7200 - val_loss: 1.1037 - val_accuracy: 0.7604\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1823 - accuracy: 0.7315 - val_loss: 1.0628 - val_accuracy: 0.7707\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1397 - accuracy: 0.7425 - val_loss: 1.0323 - val_accuracy: 0.7769\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1107 - accuracy: 0.7493 - val_loss: 1.0077 - val_accuracy: 0.7827\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0864 - accuracy: 0.7554 - val_loss: 0.9892 - val_accuracy: 0.7876\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0661 - accuracy: 0.7613 - val_loss: 0.9728 - val_accuracy: 0.7910\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0530 - accuracy: 0.7641 - val_loss: 0.9611 - val_accuracy: 0.7942\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0388 - accuracy: 0.7669 - val_loss: 0.9500 - val_accuracy: 0.7979\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0286 - accuracy: 0.7693 - val_loss: 0.9417 - val_accuracy: 0.7995\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0195 - accuracy: 0.7708 - val_loss: 0.9337 - val_accuracy: 0.8009\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0114 - accuracy: 0.7725 - val_loss: 0.9274 - val_accuracy: 0.8013\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0028 - accuracy: 0.7750 - val_loss: 0.9214 - val_accuracy: 0.8027\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9966 - accuracy: 0.7756 - val_loss: 0.9172 - val_accuracy: 0.8029\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9916 - accuracy: 0.7770 - val_loss: 0.9130 - val_accuracy: 0.8044\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9893 - accuracy: 0.7777 - val_loss: 0.9095 - val_accuracy: 0.8046\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:13.903612\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9844 - accuracy: 0.7783 - val_loss: 0.9081 - val_accuracy: 0.8044\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9811 - accuracy: 0.7817 - val_loss: 0.9071 - val_accuracy: 0.8051\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9819 - accuracy: 0.7811 - val_loss: 0.9061 - val_accuracy: 0.8053\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9823 - accuracy: 0.7792 - val_loss: 0.9068 - val_accuracy: 0.8051\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9823 - accuracy: 0.7792 - val_loss: 0.9068 - val_accuracy: 0.8052\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9823 - accuracy: 0.7786 - val_loss: 0.9062 - val_accuracy: 0.8052\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:46.630837\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.5694 - accuracy: 0.4024 - val_loss: 1.8795 - val_accuracy: 0.6050\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7828 - accuracy: 0.5961 - val_loss: 1.5227 - val_accuracy: 0.6753\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5426 - accuracy: 0.6525 - val_loss: 1.3495 - val_accuracy: 0.7129\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4012 - accuracy: 0.6839 - val_loss: 1.2403 - val_accuracy: 0.7348\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2972 - accuracy: 0.7083 - val_loss: 1.1589 - val_accuracy: 0.7536\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2239 - accuracy: 0.7272 - val_loss: 1.1028 - val_accuracy: 0.7669\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1717 - accuracy: 0.7371 - val_loss: 1.0604 - val_accuracy: 0.7741\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1298 - accuracy: 0.7473 - val_loss: 1.0269 - val_accuracy: 0.7822\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0980 - accuracy: 0.7548 - val_loss: 1.0020 - val_accuracy: 0.7865\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0737 - accuracy: 0.7604 - val_loss: 0.9816 - val_accuracy: 0.7913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0544 - accuracy: 0.7661 - val_loss: 0.9655 - val_accuracy: 0.7948\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0385 - accuracy: 0.7689 - val_loss: 0.9526 - val_accuracy: 0.7977\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0259 - accuracy: 0.7717 - val_loss: 0.9403 - val_accuracy: 0.7991\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0153 - accuracy: 0.7737 - val_loss: 0.9324 - val_accuracy: 0.8013\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0025 - accuracy: 0.7767 - val_loss: 0.9248 - val_accuracy: 0.8029\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9962 - accuracy: 0.7791 - val_loss: 0.9178 - val_accuracy: 0.8049\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9884 - accuracy: 0.7803 - val_loss: 0.9123 - val_accuracy: 0.8053\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9828 - accuracy: 0.7825 - val_loss: 0.9075 - val_accuracy: 0.8063\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9783 - accuracy: 0.7835 - val_loss: 0.9031 - val_accuracy: 0.8070\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9745 - accuracy: 0.7841 - val_loss: 0.8995 - val_accuracy: 0.8079\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.287043\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9705 - accuracy: 0.7848 - val_loss: 0.8972 - val_accuracy: 0.8081\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9693 - accuracy: 0.7848 - val_loss: 0.8967 - val_accuracy: 0.8079\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9679 - accuracy: 0.7848 - val_loss: 0.8966 - val_accuracy: 0.8084\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9664 - accuracy: 0.7850 - val_loss: 0.8957 - val_accuracy: 0.8084\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9690 - accuracy: 0.7830 - val_loss: 0.8958 - val_accuracy: 0.8086\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9685 - accuracy: 0.7833 - val_loss: 0.8959 - val_accuracy: 0.8082\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9677 - accuracy: 0.7847 - val_loss: 0.8958 - val_accuracy: 0.8082\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9697 - accuracy: 0.7838 - val_loss: 0.8957 - val_accuracy: 0.8084\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:51.225493\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.5246 - accuracy: 0.4180 - val_loss: 1.8635 - val_accuracy: 0.6106\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7774 - accuracy: 0.5979 - val_loss: 1.5353 - val_accuracy: 0.6699\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5569 - accuracy: 0.6473 - val_loss: 1.3766 - val_accuracy: 0.7044\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4176 - accuracy: 0.6788 - val_loss: 1.2648 - val_accuracy: 0.7300\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3139 - accuracy: 0.7027 - val_loss: 1.1824 - val_accuracy: 0.7464\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2389 - accuracy: 0.7202 - val_loss: 1.1209 - val_accuracy: 0.7586\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1850 - accuracy: 0.7321 - val_loss: 1.0784 - val_accuracy: 0.7698\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1424 - accuracy: 0.7440 - val_loss: 1.0445 - val_accuracy: 0.7759\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1104 - accuracy: 0.7512 - val_loss: 1.0174 - val_accuracy: 0.7812\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0850 - accuracy: 0.7577 - val_loss: 0.9984 - val_accuracy: 0.7859\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0636 - accuracy: 0.7623 - val_loss: 0.9807 - val_accuracy: 0.7892\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0466 - accuracy: 0.7669 - val_loss: 0.9663 - val_accuracy: 0.7916\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0326 - accuracy: 0.7696 - val_loss: 0.9553 - val_accuracy: 0.7937\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0234 - accuracy: 0.7702 - val_loss: 0.9457 - val_accuracy: 0.7961\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0110 - accuracy: 0.7737 - val_loss: 0.9376 - val_accuracy: 0.7981\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0042 - accuracy: 0.7754 - val_loss: 0.9306 - val_accuracy: 0.8000\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9970 - accuracy: 0.7773 - val_loss: 0.9248 - val_accuracy: 0.8008\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9896 - accuracy: 0.7790 - val_loss: 0.9192 - val_accuracy: 0.8019\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9849 - accuracy: 0.7807 - val_loss: 0.9148 - val_accuracy: 0.8032\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9783 - accuracy: 0.7822 - val_loss: 0.9111 - val_accuracy: 0.8038\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.194209\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9780 - accuracy: 0.7807 - val_loss: 0.9089 - val_accuracy: 0.8041\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9735 - accuracy: 0.7833 - val_loss: 0.9081 - val_accuracy: 0.8043\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9727 - accuracy: 0.7821 - val_loss: 0.9076 - val_accuracy: 0.8044\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9732 - accuracy: 0.7828 - val_loss: 0.9074 - val_accuracy: 0.8041\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9737 - accuracy: 0.7823 - val_loss: 0.9071 - val_accuracy: 0.8048\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9732 - accuracy: 0.7833 - val_loss: 0.9076 - val_accuracy: 0.8046\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9739 - accuracy: 0.7826 - val_loss: 0.9070 - val_accuracy: 0.8045\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9726 - accuracy: 0.7842 - val_loss: 0.9069 - val_accuracy: 0.8045\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:51.496487\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.6649 - accuracy: 0.3817 - val_loss: 1.9490 - val_accuracy: 0.5907\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8111 - accuracy: 0.5896 - val_loss: 1.5554 - val_accuracy: 0.6668\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5602 - accuracy: 0.6469 - val_loss: 1.3797 - val_accuracy: 0.7039\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4092 - accuracy: 0.6815 - val_loss: 1.2626 - val_accuracy: 0.7280\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3037 - accuracy: 0.7061 - val_loss: 1.1768 - val_accuracy: 0.7455\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2270 - accuracy: 0.7232 - val_loss: 1.1186 - val_accuracy: 0.7586\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1737 - accuracy: 0.7373 - val_loss: 1.0757 - val_accuracy: 0.7669\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1323 - accuracy: 0.7466 - val_loss: 1.0428 - val_accuracy: 0.7758\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1017 - accuracy: 0.7536 - val_loss: 1.0170 - val_accuracy: 0.7809\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0765 - accuracy: 0.7598 - val_loss: 0.9972 - val_accuracy: 0.7842\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0553 - accuracy: 0.7655 - val_loss: 0.9806 - val_accuracy: 0.7877\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0386 - accuracy: 0.7677 - val_loss: 0.9668 - val_accuracy: 0.7907\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0259 - accuracy: 0.7697 - val_loss: 0.9559 - val_accuracy: 0.7932\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0149 - accuracy: 0.7727 - val_loss: 0.9460 - val_accuracy: 0.7953\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0042 - accuracy: 0.7758 - val_loss: 0.9382 - val_accuracy: 0.7964\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9962 - accuracy: 0.7784 - val_loss: 0.9314 - val_accuracy: 0.7979\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9895 - accuracy: 0.7793 - val_loss: 0.9262 - val_accuracy: 0.7984\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9845 - accuracy: 0.7810 - val_loss: 0.9203 - val_accuracy: 0.8004\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9787 - accuracy: 0.7822 - val_loss: 0.9164 - val_accuracy: 0.8003\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9752 - accuracy: 0.7812 - val_loss: 0.9123 - val_accuracy: 0.8022\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.849707\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9714 - accuracy: 0.7830 - val_loss: 0.9105 - val_accuracy: 0.8018\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9674 - accuracy: 0.7852 - val_loss: 0.9096 - val_accuracy: 0.8023\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9670 - accuracy: 0.7849 - val_loss: 0.9092 - val_accuracy: 0.8025\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9686 - accuracy: 0.7833 - val_loss: 0.9095 - val_accuracy: 0.8018\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9661 - accuracy: 0.7868 - val_loss: 0.9089 - val_accuracy: 0.8023\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9690 - accuracy: 0.7841 - val_loss: 0.9087 - val_accuracy: 0.8024\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:52.605291\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.6597 - accuracy: 0.3925 - val_loss: 1.9645 - val_accuracy: 0.5996\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.8315 - accuracy: 0.5916 - val_loss: 1.5512 - val_accuracy: 0.6725\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5716 - accuracy: 0.6484 - val_loss: 1.3701 - val_accuracy: 0.7093\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4120 - accuracy: 0.6851 - val_loss: 1.2505 - val_accuracy: 0.7363\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3047 - accuracy: 0.7086 - val_loss: 1.1659 - val_accuracy: 0.7536\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.2278 - accuracy: 0.7268 - val_loss: 1.1072 - val_accuracy: 0.7657\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1715 - accuracy: 0.7382 - val_loss: 1.0634 - val_accuracy: 0.7738\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1307 - accuracy: 0.7488 - val_loss: 1.0313 - val_accuracy: 0.7807\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.0967 - accuracy: 0.7571 - val_loss: 1.0062 - val_accuracy: 0.7841\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0738 - accuracy: 0.7632 - val_loss: 0.9858 - val_accuracy: 0.7900\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0539 - accuracy: 0.7649 - val_loss: 0.9701 - val_accuracy: 0.7934\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0383 - accuracy: 0.7707 - val_loss: 0.9568 - val_accuracy: 0.7947\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0241 - accuracy: 0.7730 - val_loss: 0.9455 - val_accuracy: 0.7969\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.0125 - accuracy: 0.7753 - val_loss: 0.9359 - val_accuracy: 0.7981\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0020 - accuracy: 0.7768 - val_loss: 0.9283 - val_accuracy: 0.7998\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9938 - accuracy: 0.7806 - val_loss: 0.9216 - val_accuracy: 0.8007\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9872 - accuracy: 0.7824 - val_loss: 0.9161 - val_accuracy: 0.8016\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9809 - accuracy: 0.7830 - val_loss: 0.9101 - val_accuracy: 0.8026\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9762 - accuracy: 0.7833 - val_loss: 0.9070 - val_accuracy: 0.8036\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9710 - accuracy: 0.7847 - val_loss: 0.9029 - val_accuracy: 0.8043\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:32.582633\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9672 - accuracy: 0.7854 - val_loss: 0.9010 - val_accuracy: 0.8047\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9661 - accuracy: 0.7861 - val_loss: 0.9007 - val_accuracy: 0.8051\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9641 - accuracy: 0.7876 - val_loss: 0.8993 - val_accuracy: 0.8054\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9655 - accuracy: 0.7861 - val_loss: 0.8991 - val_accuracy: 0.8052\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9638 - accuracy: 0.7876 - val_loss: 0.8994 - val_accuracy: 0.8056\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9642 - accuracy: 0.7870 - val_loss: 0.8993 - val_accuracy: 0.8052\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9655 - accuracy: 0.7849 - val_loss: 0.8993 - val_accuracy: 0.8052\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9652 - accuracy: 0.7861 - val_loss: 0.8990 - val_accuracy: 0.8052\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:51.436567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.5684 - accuracy: 0.4062 - val_loss: 1.8824 - val_accuracy: 0.6106\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7665 - accuracy: 0.6008 - val_loss: 1.4971 - val_accuracy: 0.6793\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5173 - accuracy: 0.6578 - val_loss: 1.3359 - val_accuracy: 0.7127\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3696 - accuracy: 0.6925 - val_loss: 1.2205 - val_accuracy: 0.7376\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2674 - accuracy: 0.7152 - val_loss: 1.1359 - val_accuracy: 0.7586\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1931 - accuracy: 0.7318 - val_loss: 1.0781 - val_accuracy: 0.7715\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.1386 - accuracy: 0.7430 - val_loss: 1.0379 - val_accuracy: 0.7795\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1007 - accuracy: 0.7537 - val_loss: 1.0057 - val_accuracy: 0.7857\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0696 - accuracy: 0.7605 - val_loss: 0.9822 - val_accuracy: 0.7907\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0461 - accuracy: 0.7655 - val_loss: 0.9650 - val_accuracy: 0.7943\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0279 - accuracy: 0.7695 - val_loss: 0.9497 - val_accuracy: 0.7977\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0123 - accuracy: 0.7753 - val_loss: 0.9375 - val_accuracy: 0.8003\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9992 - accuracy: 0.7768 - val_loss: 0.9268 - val_accuracy: 0.8017\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9909 - accuracy: 0.7775 - val_loss: 0.9180 - val_accuracy: 0.8043\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9809 - accuracy: 0.7800 - val_loss: 0.9106 - val_accuracy: 0.8055\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9723 - accuracy: 0.7833 - val_loss: 0.9058 - val_accuracy: 0.8072\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9660 - accuracy: 0.7857 - val_loss: 0.8998 - val_accuracy: 0.8078\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9610 - accuracy: 0.7854 - val_loss: 0.8950 - val_accuracy: 0.8098\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9572 - accuracy: 0.7871 - val_loss: 0.8913 - val_accuracy: 0.8105\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9519 - accuracy: 0.7893 - val_loss: 0.8878 - val_accuracy: 0.8104\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:39.520115\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.9471 - accuracy: 0.7906 - val_loss: 0.8864 - val_accuracy: 0.8105\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.9470 - accuracy: 0.7881 - val_loss: 0.8857 - val_accuracy: 0.8112\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9468 - accuracy: 0.7891 - val_loss: 0.8854 - val_accuracy: 0.8114\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9468 - accuracy: 0.7888 - val_loss: 0.8850 - val_accuracy: 0.8108\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9477 - accuracy: 0.7883 - val_loss: 0.8851 - val_accuracy: 0.8115\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9464 - accuracy: 0.7897 - val_loss: 0.8852 - val_accuracy: 0.8113\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9451 - accuracy: 0.7896 - val_loss: 0.8848 - val_accuracy: 0.8112\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9462 - accuracy: 0.7896 - val_loss: 0.8847 - val_accuracy: 0.8116\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9476 - accuracy: 0.7891 - val_loss: 0.8850 - val_accuracy: 0.8110\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9459 - accuracy: 0.7886 - val_loss: 0.8851 - val_accuracy: 0.8116\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.9456 - accuracy: 0.7893 - val_loss: 0.8853 - val_accuracy: 0.8114\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:21.118237\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.3899 - accuracy: 0.4272 - val_loss: 1.8161 - val_accuracy: 0.5797\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5846 - accuracy: 0.6277 - val_loss: 1.4162 - val_accuracy: 0.6552\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3144 - accuracy: 0.6829 - val_loss: 1.2126 - val_accuracy: 0.6970\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1494 - accuracy: 0.7162 - val_loss: 1.0790 - val_accuracy: 0.7225\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0353 - accuracy: 0.7399 - val_loss: 0.9857 - val_accuracy: 0.7440\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9548 - accuracy: 0.7555 - val_loss: 0.9192 - val_accuracy: 0.7577\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8959 - accuracy: 0.7677 - val_loss: 0.8703 - val_accuracy: 0.7671\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8539 - accuracy: 0.7763 - val_loss: 0.8353 - val_accuracy: 0.7770\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8218 - accuracy: 0.7829 - val_loss: 0.8077 - val_accuracy: 0.7817\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7964 - accuracy: 0.7878 - val_loss: 0.7851 - val_accuracy: 0.7867\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.7759 - accuracy: 0.7919 - val_loss: 0.7677 - val_accuracy: 0.7907\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7595 - accuracy: 0.7958 - val_loss: 0.7531 - val_accuracy: 0.7949\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7453 - accuracy: 0.7985 - val_loss: 0.7413 - val_accuracy: 0.7975\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7337 - accuracy: 0.8013 - val_loss: 0.7308 - val_accuracy: 0.7983\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7238 - accuracy: 0.8026 - val_loss: 0.7226 - val_accuracy: 0.8006\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7159 - accuracy: 0.8044 - val_loss: 0.7157 - val_accuracy: 0.8024\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7082 - accuracy: 0.8068 - val_loss: 0.7089 - val_accuracy: 0.8035\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.7018 - accuracy: 0.8079 - val_loss: 0.7041 - val_accuracy: 0.8048\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6969 - accuracy: 0.8086 - val_loss: 0.6999 - val_accuracy: 0.8057\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6926 - accuracy: 0.8092 - val_loss: 0.6958 - val_accuracy: 0.8065\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.385925\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6895 - accuracy: 0.8104 - val_loss: 0.6934 - val_accuracy: 0.8066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6868 - accuracy: 0.8117 - val_loss: 0.6927 - val_accuracy: 0.8067\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6868 - accuracy: 0.8110 - val_loss: 0.6917 - val_accuracy: 0.8073\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6864 - accuracy: 0.8114 - val_loss: 0.6915 - val_accuracy: 0.8070\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6857 - accuracy: 0.8118 - val_loss: 0.6914 - val_accuracy: 0.8077\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6862 - accuracy: 0.8120 - val_loss: 0.6912 - val_accuracy: 0.8073\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6865 - accuracy: 0.8111 - val_loss: 0.6921 - val_accuracy: 0.8067\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6861 - accuracy: 0.8112 - val_loss: 0.6916 - val_accuracy: 0.8078\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.6860 - accuracy: 0.8112 - val_loss: 0.6916 - val_accuracy: 0.8072\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6865 - accuracy: 0.8118 - val_loss: 0.6918 - val_accuracy: 0.8070\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.6859 - accuracy: 0.8105 - val_loss: 0.6918 - val_accuracy: 0.8074\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:01.397643\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.4246 - accuracy: 0.4207 - val_loss: 1.8157 - val_accuracy: 0.5844\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6080 - accuracy: 0.6190 - val_loss: 1.4132 - val_accuracy: 0.6565\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3405 - accuracy: 0.6746 - val_loss: 1.2236 - val_accuracy: 0.6969\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1817 - accuracy: 0.7071 - val_loss: 1.1033 - val_accuracy: 0.7259\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0684 - accuracy: 0.7308 - val_loss: 1.0085 - val_accuracy: 0.7419\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9866 - accuracy: 0.7477 - val_loss: 0.9408 - val_accuracy: 0.7570\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9281 - accuracy: 0.7608 - val_loss: 0.8952 - val_accuracy: 0.7675\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8845 - accuracy: 0.7690 - val_loss: 0.8565 - val_accuracy: 0.7755\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8507 - accuracy: 0.7759 - val_loss: 0.8283 - val_accuracy: 0.7808\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8236 - accuracy: 0.7814 - val_loss: 0.8054 - val_accuracy: 0.7853\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8025 - accuracy: 0.7862 - val_loss: 0.7879 - val_accuracy: 0.7897\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7849 - accuracy: 0.7893 - val_loss: 0.7714 - val_accuracy: 0.7929\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7698 - accuracy: 0.7929 - val_loss: 0.7594 - val_accuracy: 0.7943\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7583 - accuracy: 0.7956 - val_loss: 0.7490 - val_accuracy: 0.7968\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7480 - accuracy: 0.7977 - val_loss: 0.7391 - val_accuracy: 0.7983\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7390 - accuracy: 0.7997 - val_loss: 0.7322 - val_accuracy: 0.8005\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7318 - accuracy: 0.8015 - val_loss: 0.7251 - val_accuracy: 0.8012\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7259 - accuracy: 0.8023 - val_loss: 0.7193 - val_accuracy: 0.8021\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7205 - accuracy: 0.8029 - val_loss: 0.7158 - val_accuracy: 0.8037\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7154 - accuracy: 0.8042 - val_loss: 0.7109 - val_accuracy: 0.8037\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:24.720729\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7119 - accuracy: 0.8063 - val_loss: 0.7092 - val_accuracy: 0.8042\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7102 - accuracy: 0.8060 - val_loss: 0.7087 - val_accuracy: 0.8043\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7094 - accuracy: 0.8063 - val_loss: 0.7083 - val_accuracy: 0.8047\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7091 - accuracy: 0.8062 - val_loss: 0.7073 - val_accuracy: 0.8051\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7084 - accuracy: 0.8059 - val_loss: 0.7077 - val_accuracy: 0.8048\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7091 - accuracy: 0.8058 - val_loss: 0.7076 - val_accuracy: 0.8051\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7086 - accuracy: 0.8064 - val_loss: 0.7075 - val_accuracy: 0.8048\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:16.873091\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.4732 - accuracy: 0.4011 - val_loss: 1.8847 - val_accuracy: 0.5546\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6649 - accuracy: 0.6049 - val_loss: 1.4792 - val_accuracy: 0.6426\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3797 - accuracy: 0.6669 - val_loss: 1.2712 - val_accuracy: 0.6865\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2057 - accuracy: 0.7048 - val_loss: 1.1314 - val_accuracy: 0.7147\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0845 - accuracy: 0.7292 - val_loss: 1.0270 - val_accuracy: 0.7385\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9951 - accuracy: 0.7481 - val_loss: 0.9529 - val_accuracy: 0.7545\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9318 - accuracy: 0.7625 - val_loss: 0.8980 - val_accuracy: 0.7643\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8845 - accuracy: 0.7710 - val_loss: 0.8596 - val_accuracy: 0.7720\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8491 - accuracy: 0.7789 - val_loss: 0.8309 - val_accuracy: 0.7801\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8213 - accuracy: 0.7851 - val_loss: 0.8062 - val_accuracy: 0.7840\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7991 - accuracy: 0.7893 - val_loss: 0.7875 - val_accuracy: 0.7893\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7809 - accuracy: 0.7927 - val_loss: 0.7707 - val_accuracy: 0.7917\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7663 - accuracy: 0.7962 - val_loss: 0.7592 - val_accuracy: 0.7953\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7537 - accuracy: 0.7983 - val_loss: 0.7473 - val_accuracy: 0.7965\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7436 - accuracy: 0.8015 - val_loss: 0.7391 - val_accuracy: 0.7991\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7350 - accuracy: 0.8021 - val_loss: 0.7320 - val_accuracy: 0.7997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7262 - accuracy: 0.8045 - val_loss: 0.7244 - val_accuracy: 0.8014\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7208 - accuracy: 0.8055 - val_loss: 0.7192 - val_accuracy: 0.8019\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7157 - accuracy: 0.8058 - val_loss: 0.7138 - val_accuracy: 0.8034\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7106 - accuracy: 0.8077 - val_loss: 0.7099 - val_accuracy: 0.8042\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:21.529836\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7068 - accuracy: 0.8083 - val_loss: 0.7076 - val_accuracy: 0.8043\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7050 - accuracy: 0.8090 - val_loss: 0.7067 - val_accuracy: 0.8048\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7042 - accuracy: 0.8090 - val_loss: 0.7064 - val_accuracy: 0.8045\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7034 - accuracy: 0.8085 - val_loss: 0.7065 - val_accuracy: 0.8046\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7034 - accuracy: 0.8091 - val_loss: 0.7060 - val_accuracy: 0.8044\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:18.707749\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.3521 - accuracy: 0.4434 - val_loss: 1.8178 - val_accuracy: 0.5777\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5971 - accuracy: 0.6264 - val_loss: 1.4506 - val_accuracy: 0.6465\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3405 - accuracy: 0.6776 - val_loss: 1.2595 - val_accuracy: 0.6891\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1776 - accuracy: 0.7096 - val_loss: 1.1310 - val_accuracy: 0.7174\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0624 - accuracy: 0.7346 - val_loss: 1.0284 - val_accuracy: 0.7366\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9801 - accuracy: 0.7514 - val_loss: 0.9601 - val_accuracy: 0.7507\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9217 - accuracy: 0.7639 - val_loss: 0.9104 - val_accuracy: 0.7618\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8781 - accuracy: 0.7732 - val_loss: 0.8733 - val_accuracy: 0.7689\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8441 - accuracy: 0.7795 - val_loss: 0.8446 - val_accuracy: 0.7757\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8181 - accuracy: 0.7852 - val_loss: 0.8210 - val_accuracy: 0.7801\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7965 - accuracy: 0.7890 - val_loss: 0.8014 - val_accuracy: 0.7834\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7790 - accuracy: 0.7922 - val_loss: 0.7864 - val_accuracy: 0.7871\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7653 - accuracy: 0.7955 - val_loss: 0.7739 - val_accuracy: 0.7892\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7531 - accuracy: 0.7988 - val_loss: 0.7632 - val_accuracy: 0.7909\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7431 - accuracy: 0.7997 - val_loss: 0.7544 - val_accuracy: 0.7923\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7348 - accuracy: 0.8015 - val_loss: 0.7465 - val_accuracy: 0.7937\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7273 - accuracy: 0.8034 - val_loss: 0.7398 - val_accuracy: 0.7953\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7212 - accuracy: 0.8042 - val_loss: 0.7344 - val_accuracy: 0.7966\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7162 - accuracy: 0.8053 - val_loss: 0.7297 - val_accuracy: 0.7963\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7114 - accuracy: 0.8058 - val_loss: 0.7261 - val_accuracy: 0.7985\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:14.588553\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7073 - accuracy: 0.8078 - val_loss: 0.7232 - val_accuracy: 0.7981\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7058 - accuracy: 0.8076 - val_loss: 0.7220 - val_accuracy: 0.7981\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7051 - accuracy: 0.8074 - val_loss: 0.7219 - val_accuracy: 0.7982\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7043 - accuracy: 0.8078 - val_loss: 0.7214 - val_accuracy: 0.7984\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7044 - accuracy: 0.8079 - val_loss: 0.7218 - val_accuracy: 0.7984\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7040 - accuracy: 0.8077 - val_loss: 0.7217 - val_accuracy: 0.7984\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7048 - accuracy: 0.8083 - val_loss: 0.7216 - val_accuracy: 0.7986\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7038 - accuracy: 0.8081 - val_loss: 0.7215 - val_accuracy: 0.7986\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7040 - accuracy: 0.8081 - val_loss: 0.7213 - val_accuracy: 0.7987\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7041 - accuracy: 0.8080 - val_loss: 0.7215 - val_accuracy: 0.7984\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7041 - accuracy: 0.8081 - val_loss: 0.7215 - val_accuracy: 0.7987\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7042 - accuracy: 0.8074 - val_loss: 0.7213 - val_accuracy: 0.7984\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:33.035443\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.3280 - accuracy: 0.4365 - val_loss: 1.7457 - val_accuracy: 0.5941\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5253 - accuracy: 0.6375 - val_loss: 1.3471 - val_accuracy: 0.6739\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2631 - accuracy: 0.6931 - val_loss: 1.1581 - val_accuracy: 0.7117\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1107 - accuracy: 0.7221 - val_loss: 1.0420 - val_accuracy: 0.7380\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0048 - accuracy: 0.7443 - val_loss: 0.9528 - val_accuracy: 0.7555\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9293 - accuracy: 0.7594 - val_loss: 0.8932 - val_accuracy: 0.7669\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8762 - accuracy: 0.7708 - val_loss: 0.8484 - val_accuracy: 0.7767\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8363 - accuracy: 0.7792 - val_loss: 0.8151 - val_accuracy: 0.7832\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8062 - accuracy: 0.7858 - val_loss: 0.7898 - val_accuracy: 0.7890\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7826 - accuracy: 0.7907 - val_loss: 0.7701 - val_accuracy: 0.7915\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7628 - accuracy: 0.7951 - val_loss: 0.7536 - val_accuracy: 0.7948\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7476 - accuracy: 0.7977 - val_loss: 0.7404 - val_accuracy: 0.7971\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7349 - accuracy: 0.8007 - val_loss: 0.7293 - val_accuracy: 0.7997\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7235 - accuracy: 0.8032 - val_loss: 0.7203 - val_accuracy: 0.8004\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7146 - accuracy: 0.8055 - val_loss: 0.7118 - val_accuracy: 0.8023\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7069 - accuracy: 0.8071 - val_loss: 0.7062 - val_accuracy: 0.8033\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.7003 - accuracy: 0.8092 - val_loss: 0.6995 - val_accuracy: 0.8052\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6940 - accuracy: 0.8091 - val_loss: 0.6955 - val_accuracy: 0.8053\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6893 - accuracy: 0.8105 - val_loss: 0.6913 - val_accuracy: 0.8062\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6854 - accuracy: 0.8108 - val_loss: 0.6870 - val_accuracy: 0.8075\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:14.018166\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6826 - accuracy: 0.8114 - val_loss: 0.6855 - val_accuracy: 0.8074\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6804 - accuracy: 0.8124 - val_loss: 0.6843 - val_accuracy: 0.8078\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6795 - accuracy: 0.8130 - val_loss: 0.6841 - val_accuracy: 0.8081\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6798 - accuracy: 0.8125 - val_loss: 0.6843 - val_accuracy: 0.8079\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6794 - accuracy: 0.8132 - val_loss: 0.6841 - val_accuracy: 0.8080\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.6791 - accuracy: 0.8127 - val_loss: 0.6841 - val_accuracy: 0.8080\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:46.267152\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0329 - accuracy: 0.4887 - val_loss: 1.5164 - val_accuracy: 0.6203\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3619 - accuracy: 0.6544 - val_loss: 1.2410 - val_accuracy: 0.6750\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1639 - accuracy: 0.6990 - val_loss: 1.0892 - val_accuracy: 0.7123\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0385 - accuracy: 0.7280 - val_loss: 0.9900 - val_accuracy: 0.7357\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9507 - accuracy: 0.7482 - val_loss: 0.9176 - val_accuracy: 0.7508\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8877 - accuracy: 0.7621 - val_loss: 0.8635 - val_accuracy: 0.7635\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8420 - accuracy: 0.7730 - val_loss: 0.8261 - val_accuracy: 0.7706\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8086 - accuracy: 0.7804 - val_loss: 0.7976 - val_accuracy: 0.7779\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7817 - accuracy: 0.7868 - val_loss: 0.7765 - val_accuracy: 0.7827\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7605 - accuracy: 0.7919 - val_loss: 0.7593 - val_accuracy: 0.7875\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7454 - accuracy: 0.7947 - val_loss: 0.7450 - val_accuracy: 0.7917\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7314 - accuracy: 0.7985 - val_loss: 0.7321 - val_accuracy: 0.7935\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7203 - accuracy: 0.8021 - val_loss: 0.7233 - val_accuracy: 0.7960\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7111 - accuracy: 0.8036 - val_loss: 0.7152 - val_accuracy: 0.7970\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7022 - accuracy: 0.8055 - val_loss: 0.7083 - val_accuracy: 0.8001\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6955 - accuracy: 0.8070 - val_loss: 0.7021 - val_accuracy: 0.8007\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6902 - accuracy: 0.8077 - val_loss: 0.6977 - val_accuracy: 0.8016\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6854 - accuracy: 0.8094 - val_loss: 0.6926 - val_accuracy: 0.8032\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6808 - accuracy: 0.8107 - val_loss: 0.6893 - val_accuracy: 0.8031\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6775 - accuracy: 0.8105 - val_loss: 0.6863 - val_accuracy: 0.8044\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:23.397748\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6739 - accuracy: 0.8113 - val_loss: 0.6846 - val_accuracy: 0.8046\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6725 - accuracy: 0.8122 - val_loss: 0.6833 - val_accuracy: 0.8048\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6725 - accuracy: 0.8121 - val_loss: 0.6836 - val_accuracy: 0.8049\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6714 - accuracy: 0.8122 - val_loss: 0.6836 - val_accuracy: 0.8049\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6715 - accuracy: 0.8119 - val_loss: 0.6835 - val_accuracy: 0.8051\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6711 - accuracy: 0.8122 - val_loss: 0.6835 - val_accuracy: 0.8052\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6718 - accuracy: 0.8122 - val_loss: 0.6833 - val_accuracy: 0.8051\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6710 - accuracy: 0.8136 - val_loss: 0.6839 - val_accuracy: 0.8053\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6716 - accuracy: 0.8126 - val_loss: 0.6828 - val_accuracy: 0.8049\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6720 - accuracy: 0.8125 - val_loss: 0.6830 - val_accuracy: 0.8050\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6717 - accuracy: 0.8124 - val_loss: 0.6833 - val_accuracy: 0.8050\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:10.612834\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0933 - accuracy: 0.4698 - val_loss: 1.5285 - val_accuracy: 0.6176\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3610 - accuracy: 0.6538 - val_loss: 1.2312 - val_accuracy: 0.6800\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1575 - accuracy: 0.7000 - val_loss: 1.0836 - val_accuracy: 0.7148\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0321 - accuracy: 0.7276 - val_loss: 0.9809 - val_accuracy: 0.7389\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9451 - accuracy: 0.7477 - val_loss: 0.9085 - val_accuracy: 0.7568\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8827 - accuracy: 0.7619 - val_loss: 0.8577 - val_accuracy: 0.7681\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8384 - accuracy: 0.7723 - val_loss: 0.8198 - val_accuracy: 0.7786\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8050 - accuracy: 0.7792 - val_loss: 0.7928 - val_accuracy: 0.7847\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7797 - accuracy: 0.7853 - val_loss: 0.7716 - val_accuracy: 0.7898\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7605 - accuracy: 0.7903 - val_loss: 0.7535 - val_accuracy: 0.7948\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7436 - accuracy: 0.7953 - val_loss: 0.7393 - val_accuracy: 0.7977\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7308 - accuracy: 0.7981 - val_loss: 0.7290 - val_accuracy: 0.8007\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7199 - accuracy: 0.7998 - val_loss: 0.7195 - val_accuracy: 0.8016\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7113 - accuracy: 0.8015 - val_loss: 0.7115 - val_accuracy: 0.8043\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7041 - accuracy: 0.8038 - val_loss: 0.7052 - val_accuracy: 0.8051\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6962 - accuracy: 0.8049 - val_loss: 0.6986 - val_accuracy: 0.8066\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6917 - accuracy: 0.8057 - val_loss: 0.6935 - val_accuracy: 0.8077\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6856 - accuracy: 0.8076 - val_loss: 0.6901 - val_accuracy: 0.8085\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6822 - accuracy: 0.8076 - val_loss: 0.6862 - val_accuracy: 0.8088\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6789 - accuracy: 0.8083 - val_loss: 0.6830 - val_accuracy: 0.8096\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:24.307152\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6758 - accuracy: 0.8095 - val_loss: 0.6814 - val_accuracy: 0.8105\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6741 - accuracy: 0.8103 - val_loss: 0.6809 - val_accuracy: 0.8106\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6741 - accuracy: 0.8102 - val_loss: 0.6804 - val_accuracy: 0.8103\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6730 - accuracy: 0.8108 - val_loss: 0.6801 - val_accuracy: 0.8111\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6734 - accuracy: 0.8108 - val_loss: 0.6801 - val_accuracy: 0.8107\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6733 - accuracy: 0.8107 - val_loss: 0.6800 - val_accuracy: 0.8109\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6733 - accuracy: 0.8101 - val_loss: 0.6802 - val_accuracy: 0.8111\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:17.062781\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0724 - accuracy: 0.4777 - val_loss: 1.5510 - val_accuracy: 0.6148\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3894 - accuracy: 0.6448 - val_loss: 1.2629 - val_accuracy: 0.6768\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1848 - accuracy: 0.6921 - val_loss: 1.1079 - val_accuracy: 0.7127\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0553 - accuracy: 0.7226 - val_loss: 1.0036 - val_accuracy: 0.7372\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9633 - accuracy: 0.7439 - val_loss: 0.9263 - val_accuracy: 0.7534\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8976 - accuracy: 0.7579 - val_loss: 0.8723 - val_accuracy: 0.7647\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8496 - accuracy: 0.7696 - val_loss: 0.8321 - val_accuracy: 0.7731\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8147 - accuracy: 0.7772 - val_loss: 0.8044 - val_accuracy: 0.7781\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7880 - accuracy: 0.7839 - val_loss: 0.7812 - val_accuracy: 0.7823\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7666 - accuracy: 0.7888 - val_loss: 0.7641 - val_accuracy: 0.7879\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7496 - accuracy: 0.7922 - val_loss: 0.7491 - val_accuracy: 0.7914\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7353 - accuracy: 0.7966 - val_loss: 0.7372 - val_accuracy: 0.7934\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7247 - accuracy: 0.7984 - val_loss: 0.7274 - val_accuracy: 0.7962\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7148 - accuracy: 0.8009 - val_loss: 0.7189 - val_accuracy: 0.7977\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7068 - accuracy: 0.8028 - val_loss: 0.7123 - val_accuracy: 0.7987\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6997 - accuracy: 0.8037 - val_loss: 0.7067 - val_accuracy: 0.7998\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6936 - accuracy: 0.8057 - val_loss: 0.7009 - val_accuracy: 0.8011\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6885 - accuracy: 0.8065 - val_loss: 0.6972 - val_accuracy: 0.8021\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6838 - accuracy: 0.8080 - val_loss: 0.6929 - val_accuracy: 0.8034\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6798 - accuracy: 0.8080 - val_loss: 0.6902 - val_accuracy: 0.8047\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:22.358633\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6770 - accuracy: 0.8097 - val_loss: 0.6879 - val_accuracy: 0.8042\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6757 - accuracy: 0.8089 - val_loss: 0.6872 - val_accuracy: 0.8046\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6748 - accuracy: 0.8098 - val_loss: 0.6870 - val_accuracy: 0.8047\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6747 - accuracy: 0.8093 - val_loss: 0.6865 - val_accuracy: 0.8046\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6745 - accuracy: 0.8102 - val_loss: 0.6865 - val_accuracy: 0.8048\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6744 - accuracy: 0.8097 - val_loss: 0.6866 - val_accuracy: 0.8047\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6747 - accuracy: 0.8103 - val_loss: 0.6864 - val_accuracy: 0.8046\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6741 - accuracy: 0.8100 - val_loss: 0.6867 - val_accuracy: 0.8049\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6750 - accuracy: 0.8096 - val_loss: 0.6864 - val_accuracy: 0.8049\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6746 - accuracy: 0.8091 - val_loss: 0.6867 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6742 - accuracy: 0.8105 - val_loss: 0.6865 - val_accuracy: 0.8045\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6747 - accuracy: 0.8099 - val_loss: 0.6868 - val_accuracy: 0.8045\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:37.960861\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0657 - accuracy: 0.4772 - val_loss: 1.5120 - val_accuracy: 0.6258\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3507 - accuracy: 0.6546 - val_loss: 1.2119 - val_accuracy: 0.6893\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1489 - accuracy: 0.7011 - val_loss: 1.0634 - val_accuracy: 0.7211\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0240 - accuracy: 0.7306 - val_loss: 0.9651 - val_accuracy: 0.7408\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9374 - accuracy: 0.7502 - val_loss: 0.8929 - val_accuracy: 0.7570\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8751 - accuracy: 0.7647 - val_loss: 0.8441 - val_accuracy: 0.7688\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8296 - accuracy: 0.7748 - val_loss: 0.8064 - val_accuracy: 0.7782\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7964 - accuracy: 0.7838 - val_loss: 0.7787 - val_accuracy: 0.7836\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7705 - accuracy: 0.7893 - val_loss: 0.7566 - val_accuracy: 0.7881\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7500 - accuracy: 0.7942 - val_loss: 0.7402 - val_accuracy: 0.7914\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7345 - accuracy: 0.7973 - val_loss: 0.7257 - val_accuracy: 0.7944\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7214 - accuracy: 0.8001 - val_loss: 0.7145 - val_accuracy: 0.7984\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7096 - accuracy: 0.8028 - val_loss: 0.7049 - val_accuracy: 0.7986\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7002 - accuracy: 0.8044 - val_loss: 0.6965 - val_accuracy: 0.8004\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6922 - accuracy: 0.8072 - val_loss: 0.6901 - val_accuracy: 0.8018\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6860 - accuracy: 0.8078 - val_loss: 0.6843 - val_accuracy: 0.8027\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6795 - accuracy: 0.8100 - val_loss: 0.6794 - val_accuracy: 0.8034\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6749 - accuracy: 0.8105 - val_loss: 0.6752 - val_accuracy: 0.8042\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6709 - accuracy: 0.8123 - val_loss: 0.6713 - val_accuracy: 0.8054\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6677 - accuracy: 0.8127 - val_loss: 0.6686 - val_accuracy: 0.8067\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:24.522507\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6641 - accuracy: 0.8136 - val_loss: 0.6671 - val_accuracy: 0.8064\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6626 - accuracy: 0.8141 - val_loss: 0.6665 - val_accuracy: 0.8072\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6622 - accuracy: 0.8137 - val_loss: 0.6656 - val_accuracy: 0.8074\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6619 - accuracy: 0.8146 - val_loss: 0.6654 - val_accuracy: 0.8071\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6618 - accuracy: 0.8138 - val_loss: 0.6654 - val_accuracy: 0.8070\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6623 - accuracy: 0.8150 - val_loss: 0.6654 - val_accuracy: 0.8072\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:49.277905\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.1189 - accuracy: 0.4636 - val_loss: 1.5821 - val_accuracy: 0.6039\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4122 - accuracy: 0.6423 - val_loss: 1.2779 - val_accuracy: 0.6710\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2049 - accuracy: 0.6880 - val_loss: 1.1300 - val_accuracy: 0.7031\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0759 - accuracy: 0.7185 - val_loss: 1.0207 - val_accuracy: 0.7276\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9830 - accuracy: 0.7397 - val_loss: 0.9447 - val_accuracy: 0.7437\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9146 - accuracy: 0.7565 - val_loss: 0.8878 - val_accuracy: 0.7563\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8661 - accuracy: 0.7670 - val_loss: 0.8469 - val_accuracy: 0.7651\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8286 - accuracy: 0.7753 - val_loss: 0.8160 - val_accuracy: 0.7729\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8004 - accuracy: 0.7818 - val_loss: 0.7935 - val_accuracy: 0.7789\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7774 - accuracy: 0.7873 - val_loss: 0.7740 - val_accuracy: 0.7835\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7601 - accuracy: 0.7914 - val_loss: 0.7591 - val_accuracy: 0.7865\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7453 - accuracy: 0.7948 - val_loss: 0.7460 - val_accuracy: 0.7902\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7325 - accuracy: 0.7988 - val_loss: 0.7355 - val_accuracy: 0.7918\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7235 - accuracy: 0.8003 - val_loss: 0.7273 - val_accuracy: 0.7940\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7142 - accuracy: 0.8021 - val_loss: 0.7199 - val_accuracy: 0.7966\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7076 - accuracy: 0.8039 - val_loss: 0.7135 - val_accuracy: 0.7981\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.7005 - accuracy: 0.8056 - val_loss: 0.7081 - val_accuracy: 0.7998\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6958 - accuracy: 0.8069 - val_loss: 0.7029 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6910 - accuracy: 0.8071 - val_loss: 0.6994 - val_accuracy: 0.8010\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6870 - accuracy: 0.8091 - val_loss: 0.6959 - val_accuracy: 0.8019\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:25.952980\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6840 - accuracy: 0.8086 - val_loss: 0.6938 - val_accuracy: 0.8028\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6825 - accuracy: 0.8094 - val_loss: 0.6937 - val_accuracy: 0.8032\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6815 - accuracy: 0.8101 - val_loss: 0.6932 - val_accuracy: 0.8031\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6809 - accuracy: 0.8102 - val_loss: 0.6930 - val_accuracy: 0.8029\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.6807 - accuracy: 0.8109 - val_loss: 0.6926 - val_accuracy: 0.8031\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:21.246515\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.2766 - accuracy: 0.4411 - val_loss: 1.6514 - val_accuracy: 0.6092\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4389 - accuracy: 0.6443 - val_loss: 1.2792 - val_accuracy: 0.6743\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1970 - accuracy: 0.6949 - val_loss: 1.1061 - val_accuracy: 0.7130\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0559 - accuracy: 0.7257 - val_loss: 0.9951 - val_accuracy: 0.7372\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9593 - accuracy: 0.7475 - val_loss: 0.9143 - val_accuracy: 0.7546\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8900 - accuracy: 0.7627 - val_loss: 0.8577 - val_accuracy: 0.7663\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8405 - accuracy: 0.7739 - val_loss: 0.8176 - val_accuracy: 0.7761\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8043 - accuracy: 0.7825 - val_loss: 0.7882 - val_accuracy: 0.7817\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7760 - accuracy: 0.7890 - val_loss: 0.7641 - val_accuracy: 0.7883\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7536 - accuracy: 0.7942 - val_loss: 0.7452 - val_accuracy: 0.7918\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7359 - accuracy: 0.7986 - val_loss: 0.7302 - val_accuracy: 0.7960\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7214 - accuracy: 0.8020 - val_loss: 0.7172 - val_accuracy: 0.7978\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7097 - accuracy: 0.8043 - val_loss: 0.7067 - val_accuracy: 0.8008\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6998 - accuracy: 0.8073 - val_loss: 0.6991 - val_accuracy: 0.8016\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6910 - accuracy: 0.8088 - val_loss: 0.6917 - val_accuracy: 0.8029\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6840 - accuracy: 0.8103 - val_loss: 0.6849 - val_accuracy: 0.8049\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6773 - accuracy: 0.8114 - val_loss: 0.6799 - val_accuracy: 0.8061\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6732 - accuracy: 0.8128 - val_loss: 0.6756 - val_accuracy: 0.8068\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6682 - accuracy: 0.8141 - val_loss: 0.6716 - val_accuracy: 0.8076\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6633 - accuracy: 0.8157 - val_loss: 0.6682 - val_accuracy: 0.8088\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:41.370899\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6608 - accuracy: 0.8162 - val_loss: 0.6657 - val_accuracy: 0.8088\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6595 - accuracy: 0.8166 - val_loss: 0.6653 - val_accuracy: 0.8090\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6581 - accuracy: 0.8163 - val_loss: 0.6654 - val_accuracy: 0.8088\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6578 - accuracy: 0.8168 - val_loss: 0.6648 - val_accuracy: 0.8091\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6583 - accuracy: 0.8161 - val_loss: 0.6643 - val_accuracy: 0.8090\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6581 - accuracy: 0.8165 - val_loss: 0.6649 - val_accuracy: 0.8090\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6574 - accuracy: 0.8163 - val_loss: 0.6650 - val_accuracy: 0.8088\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:23.447447\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.3311 - accuracy: 0.4308 - val_loss: 1.7072 - val_accuracy: 0.5898\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4687 - accuracy: 0.6349 - val_loss: 1.3051 - val_accuracy: 0.6663\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2192 - accuracy: 0.6892 - val_loss: 1.1379 - val_accuracy: 0.7048\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0762 - accuracy: 0.7213 - val_loss: 1.0262 - val_accuracy: 0.7313\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9763 - accuracy: 0.7433 - val_loss: 0.9405 - val_accuracy: 0.7486\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9050 - accuracy: 0.7581 - val_loss: 0.8854 - val_accuracy: 0.7629\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8556 - accuracy: 0.7690 - val_loss: 0.8438 - val_accuracy: 0.7724\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8177 - accuracy: 0.7781 - val_loss: 0.8108 - val_accuracy: 0.7810\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7888 - accuracy: 0.7840 - val_loss: 0.7871 - val_accuracy: 0.7845\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7658 - accuracy: 0.7893 - val_loss: 0.7688 - val_accuracy: 0.7882\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7472 - accuracy: 0.7928 - val_loss: 0.7520 - val_accuracy: 0.7931\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7326 - accuracy: 0.7975 - val_loss: 0.7389 - val_accuracy: 0.7945\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7200 - accuracy: 0.8003 - val_loss: 0.7278 - val_accuracy: 0.7974\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7091 - accuracy: 0.8028 - val_loss: 0.7190 - val_accuracy: 0.7996\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7015 - accuracy: 0.8043 - val_loss: 0.7120 - val_accuracy: 0.8009\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6941 - accuracy: 0.8061 - val_loss: 0.7052 - val_accuracy: 0.8015\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6872 - accuracy: 0.8078 - val_loss: 0.6996 - val_accuracy: 0.8029\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6812 - accuracy: 0.8093 - val_loss: 0.6953 - val_accuracy: 0.8048\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6763 - accuracy: 0.8101 - val_loss: 0.6910 - val_accuracy: 0.8050\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6725 - accuracy: 0.8107 - val_loss: 0.6872 - val_accuracy: 0.8056\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:43.168718\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6700 - accuracy: 0.8115 - val_loss: 0.6856 - val_accuracy: 0.8064\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6676 - accuracy: 0.8122 - val_loss: 0.6849 - val_accuracy: 0.8059\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6678 - accuracy: 0.8116 - val_loss: 0.6846 - val_accuracy: 0.8067\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6672 - accuracy: 0.8122 - val_loss: 0.6843 - val_accuracy: 0.8065\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6671 - accuracy: 0.8112 - val_loss: 0.6840 - val_accuracy: 0.8067\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6669 - accuracy: 0.8116 - val_loss: 0.6842 - val_accuracy: 0.8064\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:55.862813\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.2215 - accuracy: 0.4478 - val_loss: 1.6240 - val_accuracy: 0.6091\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4324 - accuracy: 0.6468 - val_loss: 1.2721 - val_accuracy: 0.6794\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1996 - accuracy: 0.6966 - val_loss: 1.1063 - val_accuracy: 0.7135\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0592 - accuracy: 0.7268 - val_loss: 0.9926 - val_accuracy: 0.7366\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9610 - accuracy: 0.7477 - val_loss: 0.9115 - val_accuracy: 0.7525\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8914 - accuracy: 0.7634 - val_loss: 0.8529 - val_accuracy: 0.7674\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8420 - accuracy: 0.7746 - val_loss: 0.8131 - val_accuracy: 0.7754\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8048 - accuracy: 0.7831 - val_loss: 0.7825 - val_accuracy: 0.7816\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7763 - accuracy: 0.7890 - val_loss: 0.7576 - val_accuracy: 0.7879\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7547 - accuracy: 0.7936 - val_loss: 0.7394 - val_accuracy: 0.7911\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7368 - accuracy: 0.7980 - val_loss: 0.7242 - val_accuracy: 0.7962\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7223 - accuracy: 0.8004 - val_loss: 0.7123 - val_accuracy: 0.7973\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7109 - accuracy: 0.8037 - val_loss: 0.7025 - val_accuracy: 0.8002\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7005 - accuracy: 0.8054 - val_loss: 0.6934 - val_accuracy: 0.8027\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6930 - accuracy: 0.8078 - val_loss: 0.6867 - val_accuracy: 0.8037\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6851 - accuracy: 0.8094 - val_loss: 0.6798 - val_accuracy: 0.8055\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6791 - accuracy: 0.8111 - val_loss: 0.6752 - val_accuracy: 0.8059\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6738 - accuracy: 0.8113 - val_loss: 0.6711 - val_accuracy: 0.8075\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6695 - accuracy: 0.8123 - val_loss: 0.6668 - val_accuracy: 0.8079\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6650 - accuracy: 0.8137 - val_loss: 0.6632 - val_accuracy: 0.8084\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:42.163832\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6621 - accuracy: 0.8148 - val_loss: 0.6617 - val_accuracy: 0.8087\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6616 - accuracy: 0.8148 - val_loss: 0.6614 - val_accuracy: 0.8090\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6602 - accuracy: 0.8147 - val_loss: 0.6601 - val_accuracy: 0.8093\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6602 - accuracy: 0.8149 - val_loss: 0.6603 - val_accuracy: 0.8092\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.6601 - accuracy: 0.8148 - val_loss: 0.6600 - val_accuracy: 0.8091\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.6596 - accuracy: 0.8150 - val_loss: 0.6607 - val_accuracy: 0.8092\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:55.989416\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.1849 - accuracy: 0.4671 - val_loss: 1.5876 - val_accuracy: 0.6168\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4024 - accuracy: 0.6522 - val_loss: 1.2606 - val_accuracy: 0.6801\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.1853 - accuracy: 0.6994 - val_loss: 1.1019 - val_accuracy: 0.7119\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0520 - accuracy: 0.7259 - val_loss: 0.9982 - val_accuracy: 0.7365\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9583 - accuracy: 0.7473 - val_loss: 0.9187 - val_accuracy: 0.7544\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8920 - accuracy: 0.7609 - val_loss: 0.8618 - val_accuracy: 0.7693\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8436 - accuracy: 0.7719 - val_loss: 0.8235 - val_accuracy: 0.7771\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8077 - accuracy: 0.7799 - val_loss: 0.7921 - val_accuracy: 0.7825\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7802 - accuracy: 0.7858 - val_loss: 0.7682 - val_accuracy: 0.7895\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7588 - accuracy: 0.7904 - val_loss: 0.7504 - val_accuracy: 0.7945\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.7404 - accuracy: 0.7949 - val_loss: 0.7347 - val_accuracy: 0.7965\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7265 - accuracy: 0.7974 - val_loss: 0.7218 - val_accuracy: 0.7994\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7143 - accuracy: 0.7999 - val_loss: 0.7118 - val_accuracy: 0.8017\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7044 - accuracy: 0.8026 - val_loss: 0.7028 - val_accuracy: 0.8037\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6962 - accuracy: 0.8043 - val_loss: 0.6956 - val_accuracy: 0.8049\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6891 - accuracy: 0.8059 - val_loss: 0.6888 - val_accuracy: 0.8067\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.6831 - accuracy: 0.8078 - val_loss: 0.6838 - val_accuracy: 0.8078\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6774 - accuracy: 0.8083 - val_loss: 0.6788 - val_accuracy: 0.8096\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.6732 - accuracy: 0.8093 - val_loss: 0.6748 - val_accuracy: 0.8101\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6699 - accuracy: 0.8107 - val_loss: 0.6712 - val_accuracy: 0.8110\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:50.544934\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 0.6668 - accuracy: 0.8113 - val_loss: 0.6703 - val_accuracy: 0.8113\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.6655 - accuracy: 0.8116 - val_loss: 0.6687 - val_accuracy: 0.8113\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.6640 - accuracy: 0.8118 - val_loss: 0.6680 - val_accuracy: 0.8115\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.6641 - accuracy: 0.8118 - val_loss: 0.6680 - val_accuracy: 0.8117\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6633 - accuracy: 0.8120 - val_loss: 0.6684 - val_accuracy: 0.8117\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6632 - accuracy: 0.8128 - val_loss: 0.6684 - val_accuracy: 0.8111\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6639 - accuracy: 0.8117 - val_loss: 0.6682 - val_accuracy: 0.8116\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:28.983306\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 2.3081 - accuracy: 0.4298 - val_loss: 1.6427 - val_accuracy: 0.5972\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4487 - accuracy: 0.6371 - val_loss: 1.2762 - val_accuracy: 0.6680\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.2095 - accuracy: 0.6875 - val_loss: 1.1144 - val_accuracy: 0.7064\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.0679 - accuracy: 0.7200 - val_loss: 1.0016 - val_accuracy: 0.7339\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9668 - accuracy: 0.7432 - val_loss: 0.9181 - val_accuracy: 0.7510\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8940 - accuracy: 0.7595 - val_loss: 0.8611 - val_accuracy: 0.7629\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8429 - accuracy: 0.7718 - val_loss: 0.8203 - val_accuracy: 0.7745\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8045 - accuracy: 0.7805 - val_loss: 0.7881 - val_accuracy: 0.7812\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7748 - accuracy: 0.7874 - val_loss: 0.7638 - val_accuracy: 0.7868\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7522 - accuracy: 0.7936 - val_loss: 0.7442 - val_accuracy: 0.7912\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.7335 - accuracy: 0.7968 - val_loss: 0.7293 - val_accuracy: 0.7935\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.7188 - accuracy: 0.8004 - val_loss: 0.7163 - val_accuracy: 0.7975\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.7066 - accuracy: 0.8036 - val_loss: 0.7060 - val_accuracy: 0.8003\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6963 - accuracy: 0.8055 - val_loss: 0.6970 - val_accuracy: 0.8013\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6880 - accuracy: 0.8082 - val_loss: 0.6900 - val_accuracy: 0.8034\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6807 - accuracy: 0.8094 - val_loss: 0.6837 - val_accuracy: 0.8043\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6745 - accuracy: 0.8110 - val_loss: 0.6784 - val_accuracy: 0.8055\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6689 - accuracy: 0.8114 - val_loss: 0.6740 - val_accuracy: 0.8059\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6639 - accuracy: 0.8129 - val_loss: 0.6698 - val_accuracy: 0.8071\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.6602 - accuracy: 0.8138 - val_loss: 0.6667 - val_accuracy: 0.8082\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:47.103012\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6580 - accuracy: 0.8150 - val_loss: 0.6646 - val_accuracy: 0.8084\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6558 - accuracy: 0.8155 - val_loss: 0.6640 - val_accuracy: 0.8083\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6551 - accuracy: 0.8155 - val_loss: 0.6634 - val_accuracy: 0.8084\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.6541 - accuracy: 0.8154 - val_loss: 0.6638 - val_accuracy: 0.8084\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:01:57.668921\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.2143 - accuracy: 0.4229 - val_loss: 7.4571 - val_accuracy: 0.5695\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.0438 - accuracy: 0.6181 - val_loss: 6.7028 - val_accuracy: 0.6445\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.4103 - accuracy: 0.6739 - val_loss: 6.1502 - val_accuracy: 0.6894\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.9074 - accuracy: 0.7099 - val_loss: 5.6921 - val_accuracy: 0.7171\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.4783 - accuracy: 0.7359 - val_loss: 5.2910 - val_accuracy: 0.7418\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1159 - accuracy: 0.7545 - val_loss: 4.9686 - val_accuracy: 0.7555\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8217 - accuracy: 0.7680 - val_loss: 4.7022 - val_accuracy: 0.7683\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5800 - accuracy: 0.7781 - val_loss: 4.4822 - val_accuracy: 0.7757\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3770 - accuracy: 0.7864 - val_loss: 4.2979 - val_accuracy: 0.7830\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.2080 - accuracy: 0.7913 - val_loss: 4.1434 - val_accuracy: 0.7893\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0635 - accuracy: 0.7964 - val_loss: 4.0107 - val_accuracy: 0.7920\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9410 - accuracy: 0.8000 - val_loss: 3.8986 - val_accuracy: 0.7951\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8360 - accuracy: 0.8027 - val_loss: 3.8009 - val_accuracy: 0.7979\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7453 - accuracy: 0.8062 - val_loss: 3.7178 - val_accuracy: 0.8000\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6667 - accuracy: 0.8074 - val_loss: 3.6444 - val_accuracy: 0.8026\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5990 - accuracy: 0.8095 - val_loss: 3.5819 - val_accuracy: 0.8042\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5402 - accuracy: 0.8116 - val_loss: 3.5278 - val_accuracy: 0.8047\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4872 - accuracy: 0.8122 - val_loss: 3.4792 - val_accuracy: 0.8062\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4420 - accuracy: 0.8132 - val_loss: 3.4379 - val_accuracy: 0.8068\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4038 - accuracy: 0.8146 - val_loss: 3.4016 - val_accuracy: 0.8073\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:22.269858\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3754 - accuracy: 0.8157 - val_loss: 3.3830 - val_accuracy: 0.8092\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 40ms/step - loss: 3.3622 - accuracy: 0.8157 - val_loss: 3.3741 - val_accuracy: 0.8087\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3548 - accuracy: 0.8171 - val_loss: 3.3695 - val_accuracy: 0.8091\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3522 - accuracy: 0.8165 - val_loss: 3.3680 - val_accuracy: 0.8088\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:01:53.500911\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.2335 - accuracy: 0.4235 - val_loss: 7.4454 - val_accuracy: 0.5859\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.0189 - accuracy: 0.6264 - val_loss: 6.6456 - val_accuracy: 0.6669\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3716 - accuracy: 0.6818 - val_loss: 6.0943 - val_accuracy: 0.7051\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.8678 - accuracy: 0.7159 - val_loss: 5.6432 - val_accuracy: 0.7292\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4433 - accuracy: 0.7390 - val_loss: 5.2451 - val_accuracy: 0.7507\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.0857 - accuracy: 0.7557 - val_loss: 4.9258 - val_accuracy: 0.7625\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.7939 - accuracy: 0.7683 - val_loss: 4.6635 - val_accuracy: 0.7716\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.5531 - accuracy: 0.7768 - val_loss: 4.4467 - val_accuracy: 0.7812\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.3504 - accuracy: 0.7844 - val_loss: 4.2603 - val_accuracy: 0.7877\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.1801 - accuracy: 0.7891 - val_loss: 4.1030 - val_accuracy: 0.7935\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0347 - accuracy: 0.7944 - val_loss: 3.9708 - val_accuracy: 0.7956\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9100 - accuracy: 0.7972 - val_loss: 3.8563 - val_accuracy: 0.7983\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.8025 - accuracy: 0.7997 - val_loss: 3.7573 - val_accuracy: 0.8010\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7090 - accuracy: 0.8021 - val_loss: 3.6714 - val_accuracy: 0.8030\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6285 - accuracy: 0.8042 - val_loss: 3.5963 - val_accuracy: 0.8053\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5584 - accuracy: 0.8058 - val_loss: 3.5315 - val_accuracy: 0.8059\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4980 - accuracy: 0.8081 - val_loss: 3.4747 - val_accuracy: 0.8074\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4439 - accuracy: 0.8087 - val_loss: 3.4261 - val_accuracy: 0.8092\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3971 - accuracy: 0.8100 - val_loss: 3.3821 - val_accuracy: 0.8098\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3563 - accuracy: 0.8120 - val_loss: 3.3434 - val_accuracy: 0.8109\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:19.839953\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3273 - accuracy: 0.8125 - val_loss: 3.3248 - val_accuracy: 0.8113\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3134 - accuracy: 0.8128 - val_loss: 3.3155 - val_accuracy: 0.8120\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3061 - accuracy: 0.8124 - val_loss: 3.3113 - val_accuracy: 0.8115\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3027 - accuracy: 0.8129 - val_loss: 3.3088 - val_accuracy: 0.8117\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3012 - accuracy: 0.8133 - val_loss: 3.3085 - val_accuracy: 0.8118\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:21.540729\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.2405 - accuracy: 0.4153 - val_loss: 7.4450 - val_accuracy: 0.5889\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.0189 - accuracy: 0.6278 - val_loss: 6.6365 - val_accuracy: 0.6650\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3734 - accuracy: 0.6849 - val_loss: 6.0891 - val_accuracy: 0.7075\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8704 - accuracy: 0.7178 - val_loss: 5.6341 - val_accuracy: 0.7325\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4412 - accuracy: 0.7413 - val_loss: 5.2360 - val_accuracy: 0.7518\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.0804 - accuracy: 0.7581 - val_loss: 4.9126 - val_accuracy: 0.7653\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7850 - accuracy: 0.7696 - val_loss: 4.6477 - val_accuracy: 0.7750\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5394 - accuracy: 0.7808 - val_loss: 4.4258 - val_accuracy: 0.7849\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3355 - accuracy: 0.7865 - val_loss: 4.2383 - val_accuracy: 0.7892\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1625 - accuracy: 0.7925 - val_loss: 4.0813 - val_accuracy: 0.7935\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0154 - accuracy: 0.7965 - val_loss: 3.9452 - val_accuracy: 0.7978\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8888 - accuracy: 0.8015 - val_loss: 3.8296 - val_accuracy: 0.8005\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7815 - accuracy: 0.8038 - val_loss: 3.7307 - val_accuracy: 0.8014\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6885 - accuracy: 0.8059 - val_loss: 3.6452 - val_accuracy: 0.8042\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6081 - accuracy: 0.8080 - val_loss: 3.5700 - val_accuracy: 0.8056\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5373 - accuracy: 0.8095 - val_loss: 3.5048 - val_accuracy: 0.8088\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4766 - accuracy: 0.8113 - val_loss: 3.4481 - val_accuracy: 0.8084\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4230 - accuracy: 0.8124 - val_loss: 3.3989 - val_accuracy: 0.8100\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3760 - accuracy: 0.8135 - val_loss: 3.3554 - val_accuracy: 0.8106\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3351 - accuracy: 0.8141 - val_loss: 3.3167 - val_accuracy: 0.8112\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:22.081863\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3063 - accuracy: 0.8150 - val_loss: 3.2968 - val_accuracy: 0.8124\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2912 - accuracy: 0.8154 - val_loss: 3.2885 - val_accuracy: 0.8128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2850 - accuracy: 0.8162 - val_loss: 3.2838 - val_accuracy: 0.8128\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2818 - accuracy: 0.8161 - val_loss: 3.2813 - val_accuracy: 0.8128\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2798 - accuracy: 0.8162 - val_loss: 3.2807 - val_accuracy: 0.8123\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:20.326689\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.2411 - accuracy: 0.4242 - val_loss: 7.4419 - val_accuracy: 0.5868\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.0243 - accuracy: 0.6318 - val_loss: 6.6582 - val_accuracy: 0.6610\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3907 - accuracy: 0.6868 - val_loss: 6.1228 - val_accuracy: 0.7023\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8992 - accuracy: 0.7193 - val_loss: 5.6737 - val_accuracy: 0.7262\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4809 - accuracy: 0.7418 - val_loss: 5.2873 - val_accuracy: 0.7440\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1282 - accuracy: 0.7573 - val_loss: 4.9711 - val_accuracy: 0.7578\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8412 - accuracy: 0.7681 - val_loss: 4.7096 - val_accuracy: 0.7667\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6033 - accuracy: 0.7775 - val_loss: 4.4936 - val_accuracy: 0.7766\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4037 - accuracy: 0.7844 - val_loss: 4.3129 - val_accuracy: 0.7819\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.2355 - accuracy: 0.7889 - val_loss: 4.1587 - val_accuracy: 0.7862\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0926 - accuracy: 0.7927 - val_loss: 4.0255 - val_accuracy: 0.7904\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9696 - accuracy: 0.7963 - val_loss: 3.9141 - val_accuracy: 0.7935\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8645 - accuracy: 0.7990 - val_loss: 3.8167 - val_accuracy: 0.7965\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7746 - accuracy: 0.8009 - val_loss: 3.7326 - val_accuracy: 0.7981\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6954 - accuracy: 0.8042 - val_loss: 3.6605 - val_accuracy: 0.8008\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6271 - accuracy: 0.8053 - val_loss: 3.5966 - val_accuracy: 0.8017\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5676 - accuracy: 0.8062 - val_loss: 3.5423 - val_accuracy: 0.8043\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5162 - accuracy: 0.8077 - val_loss: 3.4932 - val_accuracy: 0.8047\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4703 - accuracy: 0.8098 - val_loss: 3.4513 - val_accuracy: 0.8057\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4304 - accuracy: 0.8105 - val_loss: 3.4132 - val_accuracy: 0.8064\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:20.092951\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4019 - accuracy: 0.8109 - val_loss: 3.3957 - val_accuracy: 0.8068\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3890 - accuracy: 0.8119 - val_loss: 3.3863 - val_accuracy: 0.8070\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3816 - accuracy: 0.8119 - val_loss: 3.3825 - val_accuracy: 0.8068\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3790 - accuracy: 0.8115 - val_loss: 3.3800 - val_accuracy: 0.8070\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3775 - accuracy: 0.8116 - val_loss: 3.3790 - val_accuracy: 0.8072\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3769 - accuracy: 0.8120 - val_loss: 3.3789 - val_accuracy: 0.8071\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3766 - accuracy: 0.8113 - val_loss: 3.3788 - val_accuracy: 0.8072\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3761 - accuracy: 0.8116 - val_loss: 3.3791 - val_accuracy: 0.8074\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3754 - accuracy: 0.8117 - val_loss: 3.3791 - val_accuracy: 0.8073\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3762 - accuracy: 0.8118 - val_loss: 3.3793 - val_accuracy: 0.8076\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3761 - accuracy: 0.8118 - val_loss: 3.3792 - val_accuracy: 0.8076\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3762 - accuracy: 0.8121 - val_loss: 3.3790 - val_accuracy: 0.8072\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3761 - accuracy: 0.8122 - val_loss: 3.3788 - val_accuracy: 0.8073\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3763 - accuracy: 0.8118 - val_loss: 3.3783 - val_accuracy: 0.8071\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:06:32.436518\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.2039 - accuracy: 0.4218 - val_loss: 7.4073 - val_accuracy: 0.5854\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9898 - accuracy: 0.6302 - val_loss: 6.6079 - val_accuracy: 0.6700\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.3469 - accuracy: 0.6885 - val_loss: 6.0545 - val_accuracy: 0.7131\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.8415 - accuracy: 0.7233 - val_loss: 5.5987 - val_accuracy: 0.7408\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4141 - accuracy: 0.7457 - val_loss: 5.2043 - val_accuracy: 0.7603\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.0530 - accuracy: 0.7635 - val_loss: 4.8830 - val_accuracy: 0.7734\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7591 - accuracy: 0.7751 - val_loss: 4.6178 - val_accuracy: 0.7822\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5162 - accuracy: 0.7830 - val_loss: 4.3954 - val_accuracy: 0.7904\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3110 - accuracy: 0.7907 - val_loss: 4.2118 - val_accuracy: 0.7944\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1382 - accuracy: 0.7961 - val_loss: 4.0521 - val_accuracy: 0.7980\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9907 - accuracy: 0.8001 - val_loss: 3.9170 - val_accuracy: 0.8022\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8647 - accuracy: 0.8032 - val_loss: 3.8014 - val_accuracy: 0.8045\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7565 - accuracy: 0.8056 - val_loss: 3.7017 - val_accuracy: 0.8056\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6628 - accuracy: 0.8083 - val_loss: 3.6147 - val_accuracy: 0.8077\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5808 - accuracy: 0.8107 - val_loss: 3.5401 - val_accuracy: 0.8088\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5102 - accuracy: 0.8122 - val_loss: 3.4742 - val_accuracy: 0.8107\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4489 - accuracy: 0.8136 - val_loss: 3.4165 - val_accuracy: 0.8112\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3948 - accuracy: 0.8148 - val_loss: 3.3666 - val_accuracy: 0.8118\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3470 - accuracy: 0.8162 - val_loss: 3.3229 - val_accuracy: 0.8131\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3053 - accuracy: 0.8164 - val_loss: 3.2838 - val_accuracy: 0.8132\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:23.384733\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.2762 - accuracy: 0.8171 - val_loss: 3.2648 - val_accuracy: 0.8134\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.2616 - accuracy: 0.8179 - val_loss: 3.2557 - val_accuracy: 0.8144\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.2550 - accuracy: 0.8176 - val_loss: 3.2510 - val_accuracy: 0.8140\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.2520 - accuracy: 0.8181 - val_loss: 3.2490 - val_accuracy: 0.8140\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2501 - accuracy: 0.8180 - val_loss: 3.2476 - val_accuracy: 0.8144\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:18.175876\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.8879 - accuracy: 0.4840 - val_loss: 7.1612 - val_accuracy: 0.6209\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.7743 - accuracy: 0.6558 - val_loss: 6.4750 - val_accuracy: 0.6796\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.2031 - accuracy: 0.7031 - val_loss: 5.9769 - val_accuracy: 0.7135\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7443 - accuracy: 0.7320 - val_loss: 5.5540 - val_accuracy: 0.7374\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.3481 - accuracy: 0.7530 - val_loss: 5.1854 - val_accuracy: 0.7533\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.0127 - accuracy: 0.7687 - val_loss: 4.8836 - val_accuracy: 0.7674\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7398 - accuracy: 0.7793 - val_loss: 4.6378 - val_accuracy: 0.7763\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5131 - accuracy: 0.7871 - val_loss: 4.4306 - val_accuracy: 0.7820\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3229 - accuracy: 0.7932 - val_loss: 4.2593 - val_accuracy: 0.7893\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1626 - accuracy: 0.7985 - val_loss: 4.1125 - val_accuracy: 0.7936\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0270 - accuracy: 0.8015 - val_loss: 3.9868 - val_accuracy: 0.7961\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9110 - accuracy: 0.8056 - val_loss: 3.8799 - val_accuracy: 0.8001\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8113 - accuracy: 0.8083 - val_loss: 3.7890 - val_accuracy: 0.8005\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7253 - accuracy: 0.8100 - val_loss: 3.7101 - val_accuracy: 0.8020\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6511 - accuracy: 0.8119 - val_loss: 3.6415 - val_accuracy: 0.8034\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5871 - accuracy: 0.8137 - val_loss: 3.5814 - val_accuracy: 0.8051\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5309 - accuracy: 0.8149 - val_loss: 3.5300 - val_accuracy: 0.8067\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4827 - accuracy: 0.8172 - val_loss: 3.4845 - val_accuracy: 0.8075\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4400 - accuracy: 0.8179 - val_loss: 3.4457 - val_accuracy: 0.8078\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4035 - accuracy: 0.8174 - val_loss: 3.4112 - val_accuracy: 0.8086\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:20.147148\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3771 - accuracy: 0.8175 - val_loss: 3.3942 - val_accuracy: 0.8093\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3634 - accuracy: 0.8187 - val_loss: 3.3853 - val_accuracy: 0.8090\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3581 - accuracy: 0.8180 - val_loss: 3.3812 - val_accuracy: 0.8087\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3545 - accuracy: 0.8193 - val_loss: 3.3794 - val_accuracy: 0.8094\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3531 - accuracy: 0.8197 - val_loss: 3.3789 - val_accuracy: 0.8095\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3524 - accuracy: 0.8194 - val_loss: 3.3787 - val_accuracy: 0.8093\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3520 - accuracy: 0.8193 - val_loss: 3.3785 - val_accuracy: 0.8093\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3526 - accuracy: 0.8185 - val_loss: 3.3783 - val_accuracy: 0.8093\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:43.666860\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.9061 - accuracy: 0.4718 - val_loss: 7.1352 - val_accuracy: 0.6221\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.7777 - accuracy: 0.6548 - val_loss: 6.4514 - val_accuracy: 0.6830\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.2075 - accuracy: 0.7024 - val_loss: 5.9519 - val_accuracy: 0.7195\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.7459 - accuracy: 0.7314 - val_loss: 5.5262 - val_accuracy: 0.7417\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.3496 - accuracy: 0.7522 - val_loss: 5.1585 - val_accuracy: 0.7595\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.0142 - accuracy: 0.7671 - val_loss: 4.8571 - val_accuracy: 0.7700\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7403 - accuracy: 0.7777 - val_loss: 4.6113 - val_accuracy: 0.7795\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.5138 - accuracy: 0.7863 - val_loss: 4.4055 - val_accuracy: 0.7857\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3235 - accuracy: 0.7918 - val_loss: 4.2336 - val_accuracy: 0.7901\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1645 - accuracy: 0.7970 - val_loss: 4.0863 - val_accuracy: 0.7949\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0275 - accuracy: 0.8015 - val_loss: 3.9624 - val_accuracy: 0.7971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9113 - accuracy: 0.8045 - val_loss: 3.8565 - val_accuracy: 0.7996\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8119 - accuracy: 0.8059 - val_loss: 3.7640 - val_accuracy: 0.8026\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7256 - accuracy: 0.8091 - val_loss: 3.6860 - val_accuracy: 0.8030\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6514 - accuracy: 0.8110 - val_loss: 3.6168 - val_accuracy: 0.8063\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5877 - accuracy: 0.8120 - val_loss: 3.5571 - val_accuracy: 0.8072\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5322 - accuracy: 0.8130 - val_loss: 3.5052 - val_accuracy: 0.8087\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4833 - accuracy: 0.8139 - val_loss: 3.4603 - val_accuracy: 0.8102\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4397 - accuracy: 0.8153 - val_loss: 3.4209 - val_accuracy: 0.8108\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4028 - accuracy: 0.8167 - val_loss: 3.3857 - val_accuracy: 0.8114\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:19.270540\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3766 - accuracy: 0.8168 - val_loss: 3.3688 - val_accuracy: 0.8111\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3634 - accuracy: 0.8175 - val_loss: 3.3608 - val_accuracy: 0.8115\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3579 - accuracy: 0.8169 - val_loss: 3.3568 - val_accuracy: 0.8117\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3546 - accuracy: 0.8178 - val_loss: 3.3552 - val_accuracy: 0.8113\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3530 - accuracy: 0.8182 - val_loss: 3.3541 - val_accuracy: 0.8117\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3528 - accuracy: 0.8173 - val_loss: 3.3536 - val_accuracy: 0.8117\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:47.511957\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 7.9175 - accuracy: 0.4714 - val_loss: 7.1499 - val_accuracy: 0.6197\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.8084 - accuracy: 0.6435 - val_loss: 6.4764 - val_accuracy: 0.6791\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.2374 - accuracy: 0.6901 - val_loss: 5.9793 - val_accuracy: 0.7124\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.7713 - accuracy: 0.7219 - val_loss: 5.5521 - val_accuracy: 0.7379\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.3709 - accuracy: 0.7444 - val_loss: 5.1813 - val_accuracy: 0.7563\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.0318 - accuracy: 0.7604 - val_loss: 4.8784 - val_accuracy: 0.7698\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.7553 - accuracy: 0.7740 - val_loss: 4.6301 - val_accuracy: 0.7801\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.5273 - accuracy: 0.7813 - val_loss: 4.4235 - val_accuracy: 0.7861\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.3368 - accuracy: 0.7886 - val_loss: 4.2496 - val_accuracy: 0.7930\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1763 - accuracy: 0.7943 - val_loss: 4.1034 - val_accuracy: 0.7980\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0392 - accuracy: 0.7987 - val_loss: 3.9791 - val_accuracy: 0.8008\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9235 - accuracy: 0.8022 - val_loss: 3.8728 - val_accuracy: 0.8031\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8244 - accuracy: 0.8047 - val_loss: 3.7808 - val_accuracy: 0.8051\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7384 - accuracy: 0.8074 - val_loss: 3.7023 - val_accuracy: 0.8063\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6648 - accuracy: 0.8092 - val_loss: 3.6337 - val_accuracy: 0.8088\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6005 - accuracy: 0.8108 - val_loss: 3.5746 - val_accuracy: 0.8109\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5455 - accuracy: 0.8119 - val_loss: 3.5230 - val_accuracy: 0.8111\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4965 - accuracy: 0.8132 - val_loss: 3.4783 - val_accuracy: 0.8130\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4539 - accuracy: 0.8140 - val_loss: 3.4394 - val_accuracy: 0.8134\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.4168 - accuracy: 0.8150 - val_loss: 3.4048 - val_accuracy: 0.8142\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:14.858589\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3899 - accuracy: 0.8161 - val_loss: 3.3876 - val_accuracy: 0.8141\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3779 - accuracy: 0.8164 - val_loss: 3.3792 - val_accuracy: 0.8149\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3709 - accuracy: 0.8170 - val_loss: 3.3755 - val_accuracy: 0.8145\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3687 - accuracy: 0.8178 - val_loss: 3.3738 - val_accuracy: 0.8148\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.3673 - accuracy: 0.8169 - val_loss: 3.3727 - val_accuracy: 0.8144\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:18.001445\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 7.8996 - accuracy: 0.4771 - val_loss: 7.1476 - val_accuracy: 0.6197\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.7791 - accuracy: 0.6541 - val_loss: 6.4720 - val_accuracy: 0.6822\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.2045 - accuracy: 0.7029 - val_loss: 5.9638 - val_accuracy: 0.7202\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.7388 - accuracy: 0.7353 - val_loss: 5.5372 - val_accuracy: 0.7437\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.3393 - accuracy: 0.7567 - val_loss: 5.1612 - val_accuracy: 0.7610\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.0022 - accuracy: 0.7730 - val_loss: 4.8598 - val_accuracy: 0.7723\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.7267 - accuracy: 0.7826 - val_loss: 4.6117 - val_accuracy: 0.7836\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.4993 - accuracy: 0.7916 - val_loss: 4.4079 - val_accuracy: 0.7901\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.3102 - accuracy: 0.7969 - val_loss: 4.2328 - val_accuracy: 0.7947\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.1500 - accuracy: 0.8023 - val_loss: 4.0879 - val_accuracy: 0.7979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0141 - accuracy: 0.8057 - val_loss: 3.9620 - val_accuracy: 0.8003\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.8982 - accuracy: 0.8089 - val_loss: 3.8561 - val_accuracy: 0.8021\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7985 - accuracy: 0.8124 - val_loss: 3.7643 - val_accuracy: 0.8051\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7138 - accuracy: 0.8141 - val_loss: 3.6859 - val_accuracy: 0.8061\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6398 - accuracy: 0.8144 - val_loss: 3.6173 - val_accuracy: 0.8077\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5756 - accuracy: 0.8166 - val_loss: 3.5585 - val_accuracy: 0.8086\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5198 - accuracy: 0.8173 - val_loss: 3.5060 - val_accuracy: 0.8098\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4713 - accuracy: 0.8187 - val_loss: 3.4612 - val_accuracy: 0.8100\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4284 - accuracy: 0.8200 - val_loss: 3.4220 - val_accuracy: 0.8117\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3916 - accuracy: 0.8196 - val_loss: 3.3871 - val_accuracy: 0.8112\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:13.397460\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3652 - accuracy: 0.8213 - val_loss: 3.3701 - val_accuracy: 0.8117\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3520 - accuracy: 0.8212 - val_loss: 3.3619 - val_accuracy: 0.8123\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3460 - accuracy: 0.8208 - val_loss: 3.3578 - val_accuracy: 0.8123\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3434 - accuracy: 0.8216 - val_loss: 3.3559 - val_accuracy: 0.8124\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3418 - accuracy: 0.8217 - val_loss: 3.3548 - val_accuracy: 0.8124\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3416 - accuracy: 0.8218 - val_loss: 3.3543 - val_accuracy: 0.8125\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3414 - accuracy: 0.8216 - val_loss: 3.3551 - val_accuracy: 0.8125\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3411 - accuracy: 0.8221 - val_loss: 3.3542 - val_accuracy: 0.8118\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3409 - accuracy: 0.8224 - val_loss: 3.3547 - val_accuracy: 0.8121\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:08.931600\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 7.8876 - accuracy: 0.4745 - val_loss: 7.1486 - val_accuracy: 0.6116\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.7976 - accuracy: 0.6442 - val_loss: 6.4856 - val_accuracy: 0.6710\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.2396 - accuracy: 0.6893 - val_loss: 5.9938 - val_accuracy: 0.7062\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.7826 - accuracy: 0.7192 - val_loss: 5.5721 - val_accuracy: 0.7320\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.3874 - accuracy: 0.7413 - val_loss: 5.2050 - val_accuracy: 0.7505\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.0522 - accuracy: 0.7596 - val_loss: 4.9011 - val_accuracy: 0.7625\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.7790 - accuracy: 0.7720 - val_loss: 4.6583 - val_accuracy: 0.7730\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.5544 - accuracy: 0.7804 - val_loss: 4.4552 - val_accuracy: 0.7803\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3668 - accuracy: 0.7883 - val_loss: 4.2841 - val_accuracy: 0.7862\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.2092 - accuracy: 0.7928 - val_loss: 4.1397 - val_accuracy: 0.7915\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0751 - accuracy: 0.7973 - val_loss: 4.0176 - val_accuracy: 0.7940\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9620 - accuracy: 0.8011 - val_loss: 3.9136 - val_accuracy: 0.7984\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.8640 - accuracy: 0.8042 - val_loss: 3.8244 - val_accuracy: 0.8010\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7805 - accuracy: 0.8066 - val_loss: 3.7465 - val_accuracy: 0.8031\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7084 - accuracy: 0.8081 - val_loss: 3.6811 - val_accuracy: 0.8049\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6456 - accuracy: 0.8098 - val_loss: 3.6224 - val_accuracy: 0.8072\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5919 - accuracy: 0.8116 - val_loss: 3.5731 - val_accuracy: 0.8072\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.5436 - accuracy: 0.8126 - val_loss: 3.5291 - val_accuracy: 0.8091\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5027 - accuracy: 0.8147 - val_loss: 3.4913 - val_accuracy: 0.8102\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4669 - accuracy: 0.8154 - val_loss: 3.4568 - val_accuracy: 0.8110\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:11.843924\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4410 - accuracy: 0.8160 - val_loss: 3.4409 - val_accuracy: 0.8122\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4286 - accuracy: 0.8165 - val_loss: 3.4323 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.4233 - accuracy: 0.8162 - val_loss: 3.4294 - val_accuracy: 0.8125\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4201 - accuracy: 0.8160 - val_loss: 3.4271 - val_accuracy: 0.8118\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4185 - accuracy: 0.8167 - val_loss: 3.4263 - val_accuracy: 0.8125\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:19.837366\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.0960 - accuracy: 0.4388 - val_loss: 7.2358 - val_accuracy: 0.6133\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.8190 - accuracy: 0.6538 - val_loss: 6.4609 - val_accuracy: 0.6849\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 6.2057 - accuracy: 0.7074 - val_loss: 5.9424 - val_accuracy: 0.7236\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.7283 - accuracy: 0.7366 - val_loss: 5.5089 - val_accuracy: 0.7446\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.3208 - accuracy: 0.7591 - val_loss: 5.1300 - val_accuracy: 0.7637\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.9767 - accuracy: 0.7731 - val_loss: 4.8237 - val_accuracy: 0.7758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.6961 - accuracy: 0.7837 - val_loss: 4.5688 - val_accuracy: 0.7829\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.4623 - accuracy: 0.7920 - val_loss: 4.3585 - val_accuracy: 0.7904\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2661 - accuracy: 0.7989 - val_loss: 4.1798 - val_accuracy: 0.7951\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1019 - accuracy: 0.8034 - val_loss: 4.0288 - val_accuracy: 0.7990\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9619 - accuracy: 0.8064 - val_loss: 3.9005 - val_accuracy: 0.8026\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8418 - accuracy: 0.8098 - val_loss: 3.7895 - val_accuracy: 0.8061\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7389 - accuracy: 0.8124 - val_loss: 3.6959 - val_accuracy: 0.8082\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6506 - accuracy: 0.8139 - val_loss: 3.6145 - val_accuracy: 0.8093\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5736 - accuracy: 0.8170 - val_loss: 3.5427 - val_accuracy: 0.8111\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5072 - accuracy: 0.8176 - val_loss: 3.4826 - val_accuracy: 0.8124\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4494 - accuracy: 0.8195 - val_loss: 3.4284 - val_accuracy: 0.8145\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3987 - accuracy: 0.8205 - val_loss: 3.3819 - val_accuracy: 0.8148\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3541 - accuracy: 0.8215 - val_loss: 3.3410 - val_accuracy: 0.8157\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3157 - accuracy: 0.8226 - val_loss: 3.3045 - val_accuracy: 0.8164\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:36.178023\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2879 - accuracy: 0.8233 - val_loss: 3.2864 - val_accuracy: 0.8168\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2748 - accuracy: 0.8229 - val_loss: 3.2777 - val_accuracy: 0.8168\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2684 - accuracy: 0.8231 - val_loss: 3.2731 - val_accuracy: 0.8174\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2652 - accuracy: 0.8233 - val_loss: 3.2722 - val_accuracy: 0.8172\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2637 - accuracy: 0.8241 - val_loss: 3.2711 - val_accuracy: 0.8169\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2639 - accuracy: 0.8231 - val_loss: 3.2703 - val_accuracy: 0.8173\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:53.210729\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.0053 - accuracy: 0.4616 - val_loss: 7.2065 - val_accuracy: 0.6123\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.8186 - accuracy: 0.6493 - val_loss: 6.4995 - val_accuracy: 0.6764\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.2351 - accuracy: 0.6958 - val_loss: 5.9856 - val_accuracy: 0.7100\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.7633 - accuracy: 0.7263 - val_loss: 5.5540 - val_accuracy: 0.7356\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.3550 - accuracy: 0.7479 - val_loss: 5.1727 - val_accuracy: 0.7540\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.0089 - accuracy: 0.7649 - val_loss: 4.8646 - val_accuracy: 0.7684\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.7269 - accuracy: 0.7753 - val_loss: 4.6082 - val_accuracy: 0.7775\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.4925 - accuracy: 0.7847 - val_loss: 4.3943 - val_accuracy: 0.7853\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2952 - accuracy: 0.7912 - val_loss: 4.2156 - val_accuracy: 0.7909\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1288 - accuracy: 0.7964 - val_loss: 4.0625 - val_accuracy: 0.7962\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9870 - accuracy: 0.8006 - val_loss: 3.9335 - val_accuracy: 0.7997\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8665 - accuracy: 0.8038 - val_loss: 3.8230 - val_accuracy: 0.8040\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7624 - accuracy: 0.8072 - val_loss: 3.7272 - val_accuracy: 0.8057\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6727 - accuracy: 0.8098 - val_loss: 3.6436 - val_accuracy: 0.8077\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5955 - accuracy: 0.8110 - val_loss: 3.5722 - val_accuracy: 0.8094\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5283 - accuracy: 0.8129 - val_loss: 3.5106 - val_accuracy: 0.8119\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.4697 - accuracy: 0.8143 - val_loss: 3.4554 - val_accuracy: 0.8134\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4183 - accuracy: 0.8158 - val_loss: 3.4092 - val_accuracy: 0.8144\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3734 - accuracy: 0.8167 - val_loss: 3.3674 - val_accuracy: 0.8141\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3338 - accuracy: 0.8171 - val_loss: 3.3309 - val_accuracy: 0.8152\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:33.858343\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3068 - accuracy: 0.8181 - val_loss: 3.3128 - val_accuracy: 0.8163\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.2936 - accuracy: 0.8180 - val_loss: 3.3041 - val_accuracy: 0.8166\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2864 - accuracy: 0.8184 - val_loss: 3.2998 - val_accuracy: 0.8168\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2839 - accuracy: 0.8187 - val_loss: 3.2975 - val_accuracy: 0.8167\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2819 - accuracy: 0.8191 - val_loss: 3.2971 - val_accuracy: 0.8168\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2817 - accuracy: 0.8182 - val_loss: 3.2967 - val_accuracy: 0.8166\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:51.777438\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.0454 - accuracy: 0.4482 - val_loss: 7.2031 - val_accuracy: 0.6083\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.7983 - accuracy: 0.6523 - val_loss: 6.4383 - val_accuracy: 0.6871\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.1925 - accuracy: 0.7066 - val_loss: 5.9211 - val_accuracy: 0.7276\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7165 - accuracy: 0.7374 - val_loss: 5.4886 - val_accuracy: 0.7501\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.3099 - accuracy: 0.7595 - val_loss: 5.1108 - val_accuracy: 0.7693\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.9665 - accuracy: 0.7740 - val_loss: 4.8050 - val_accuracy: 0.7798\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.6853 - accuracy: 0.7854 - val_loss: 4.5511 - val_accuracy: 0.7887\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4520 - accuracy: 0.7929 - val_loss: 4.3379 - val_accuracy: 0.7944\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2570 - accuracy: 0.7991 - val_loss: 4.1586 - val_accuracy: 0.8011\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0918 - accuracy: 0.8030 - val_loss: 4.0090 - val_accuracy: 0.8037\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9513 - accuracy: 0.8078 - val_loss: 3.8798 - val_accuracy: 0.8076\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8305 - accuracy: 0.8106 - val_loss: 3.7702 - val_accuracy: 0.8096\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7267 - accuracy: 0.8131 - val_loss: 3.6748 - val_accuracy: 0.8117\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6378 - accuracy: 0.8143 - val_loss: 3.5919 - val_accuracy: 0.8141\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5609 - accuracy: 0.8166 - val_loss: 3.5204 - val_accuracy: 0.8154\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.4933 - accuracy: 0.8184 - val_loss: 3.4589 - val_accuracy: 0.8171\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4351 - accuracy: 0.8199 - val_loss: 3.4047 - val_accuracy: 0.8174\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3837 - accuracy: 0.8213 - val_loss: 3.3569 - val_accuracy: 0.8188\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3398 - accuracy: 0.8210 - val_loss: 3.3161 - val_accuracy: 0.8191\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3005 - accuracy: 0.8222 - val_loss: 3.2789 - val_accuracy: 0.8203\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:30.139560\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.2732 - accuracy: 0.8232 - val_loss: 3.2613 - val_accuracy: 0.8199\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2590 - accuracy: 0.8235 - val_loss: 3.2527 - val_accuracy: 0.8203\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2533 - accuracy: 0.8228 - val_loss: 3.2485 - val_accuracy: 0.8204\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.2497 - accuracy: 0.8235 - val_loss: 3.2464 - val_accuracy: 0.8203\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2490 - accuracy: 0.8239 - val_loss: 3.2454 - val_accuracy: 0.8203\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.2483 - accuracy: 0.8244 - val_loss: 3.2454 - val_accuracy: 0.8202\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:51.262522\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.1421 - accuracy: 0.4264 - val_loss: 7.3134 - val_accuracy: 0.5871\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.8787 - accuracy: 0.6447 - val_loss: 6.5403 - val_accuracy: 0.6703\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.2669 - accuracy: 0.6967 - val_loss: 6.0167 - val_accuracy: 0.7091\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7858 - accuracy: 0.7287 - val_loss: 5.5784 - val_accuracy: 0.7353\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.3752 - accuracy: 0.7510 - val_loss: 5.1945 - val_accuracy: 0.7534\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 5.0287 - accuracy: 0.7672 - val_loss: 4.8865 - val_accuracy: 0.7659\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 4.7470 - accuracy: 0.7795 - val_loss: 4.6312 - val_accuracy: 0.7763\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5120 - accuracy: 0.7878 - val_loss: 4.4186 - val_accuracy: 0.7832\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 4.3159 - accuracy: 0.7937 - val_loss: 4.2409 - val_accuracy: 0.7887\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1515 - accuracy: 0.7989 - val_loss: 4.0884 - val_accuracy: 0.7937\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0103 - accuracy: 0.8032 - val_loss: 3.9594 - val_accuracy: 0.7970\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8909 - accuracy: 0.8056 - val_loss: 3.8502 - val_accuracy: 0.7996\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7875 - accuracy: 0.8092 - val_loss: 3.7541 - val_accuracy: 0.8023\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6984 - accuracy: 0.8109 - val_loss: 3.6724 - val_accuracy: 0.8040\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6214 - accuracy: 0.8131 - val_loss: 3.6016 - val_accuracy: 0.8061\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5548 - accuracy: 0.8144 - val_loss: 3.5390 - val_accuracy: 0.8076\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.4968 - accuracy: 0.8160 - val_loss: 3.4850 - val_accuracy: 0.8088\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4456 - accuracy: 0.8162 - val_loss: 3.4376 - val_accuracy: 0.8093\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4014 - accuracy: 0.8177 - val_loss: 3.3967 - val_accuracy: 0.8103\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3619 - accuracy: 0.8184 - val_loss: 3.3602 - val_accuracy: 0.8118\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:30.755085\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.3344 - accuracy: 0.8198 - val_loss: 3.3416 - val_accuracy: 0.8121\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3208 - accuracy: 0.8195 - val_loss: 3.3339 - val_accuracy: 0.8121\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3147 - accuracy: 0.8200 - val_loss: 3.3293 - val_accuracy: 0.8117\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3112 - accuracy: 0.8198 - val_loss: 3.3277 - val_accuracy: 0.8121\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:01:54.064548\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 8.0762 - accuracy: 0.4485 - val_loss: 7.2568 - val_accuracy: 0.6101\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.8629 - accuracy: 0.6446 - val_loss: 6.5132 - val_accuracy: 0.6826\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 41ms/step - loss: 6.2633 - accuracy: 0.6978 - val_loss: 6.0024 - val_accuracy: 0.7175\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.7874 - accuracy: 0.7296 - val_loss: 5.5647 - val_accuracy: 0.7434\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.3810 - accuracy: 0.7523 - val_loss: 5.1868 - val_accuracy: 0.7627\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.0383 - accuracy: 0.7681 - val_loss: 4.8815 - val_accuracy: 0.7755\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.7600 - accuracy: 0.7800 - val_loss: 4.6320 - val_accuracy: 0.7846\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5299 - accuracy: 0.7881 - val_loss: 4.4220 - val_accuracy: 0.7923\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3366 - accuracy: 0.7951 - val_loss: 4.2497 - val_accuracy: 0.7965\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1740 - accuracy: 0.8001 - val_loss: 4.0987 - val_accuracy: 0.7999\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0358 - accuracy: 0.8033 - val_loss: 3.9731 - val_accuracy: 0.8035\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9178 - accuracy: 0.8066 - val_loss: 3.8651 - val_accuracy: 0.8059\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8169 - accuracy: 0.8095 - val_loss: 3.7720 - val_accuracy: 0.8086\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7295 - accuracy: 0.8112 - val_loss: 3.6913 - val_accuracy: 0.8118\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6543 - accuracy: 0.8127 - val_loss: 3.6218 - val_accuracy: 0.8122\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5892 - accuracy: 0.8154 - val_loss: 3.5613 - val_accuracy: 0.8137\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.5315 - accuracy: 0.8168 - val_loss: 3.5085 - val_accuracy: 0.8153\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4820 - accuracy: 0.8178 - val_loss: 3.4628 - val_accuracy: 0.8159\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4384 - accuracy: 0.8180 - val_loss: 3.4219 - val_accuracy: 0.8166\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.4011 - accuracy: 0.8195 - val_loss: 3.3872 - val_accuracy: 0.8170\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.542764\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.3738 - accuracy: 0.8197 - val_loss: 3.3696 - val_accuracy: 0.8182\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 3.3607 - accuracy: 0.8199 - val_loss: 3.3609 - val_accuracy: 0.8181\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 3.3545 - accuracy: 0.8207 - val_loss: 3.3572 - val_accuracy: 0.8184\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.3517 - accuracy: 0.8203 - val_loss: 3.3548 - val_accuracy: 0.8183\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3500 - accuracy: 0.8211 - val_loss: 3.3543 - val_accuracy: 0.8186\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3490 - accuracy: 0.8204 - val_loss: 3.3539 - val_accuracy: 0.8184\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3495 - accuracy: 0.8208 - val_loss: 3.3536 - val_accuracy: 0.8180\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3494 - accuracy: 0.8207 - val_loss: 3.3541 - val_accuracy: 0.8183\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:58.803251\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.6632 - accuracy: 0.4218 - val_loss: 2.0680 - val_accuracy: 0.5836\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8167 - accuracy: 0.6309 - val_loss: 1.6344 - val_accuracy: 0.6632\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5318 - accuracy: 0.6884 - val_loss: 1.4259 - val_accuracy: 0.7074\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3620 - accuracy: 0.7231 - val_loss: 1.2965 - val_accuracy: 0.7330\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2482 - accuracy: 0.7454 - val_loss: 1.2032 - val_accuracy: 0.7510\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1700 - accuracy: 0.7610 - val_loss: 1.1398 - val_accuracy: 0.7648\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1132 - accuracy: 0.7711 - val_loss: 1.0938 - val_accuracy: 0.7729\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0721 - accuracy: 0.7788 - val_loss: 1.0566 - val_accuracy: 0.7812\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0398 - accuracy: 0.7853 - val_loss: 1.0309 - val_accuracy: 0.7857\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0142 - accuracy: 0.7899 - val_loss: 1.0089 - val_accuracy: 0.7901\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9942 - accuracy: 0.7947 - val_loss: 0.9908 - val_accuracy: 0.7941\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9773 - accuracy: 0.7980 - val_loss: 0.9767 - val_accuracy: 0.7964\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9636 - accuracy: 0.8003 - val_loss: 0.9654 - val_accuracy: 0.7988\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9518 - accuracy: 0.8034 - val_loss: 0.9553 - val_accuracy: 0.8005\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9424 - accuracy: 0.8049 - val_loss: 0.9456 - val_accuracy: 0.8022\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9334 - accuracy: 0.8069 - val_loss: 0.9389 - val_accuracy: 0.8037\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9267 - accuracy: 0.8076 - val_loss: 0.9320 - val_accuracy: 0.8041\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9201 - accuracy: 0.8088 - val_loss: 0.9267 - val_accuracy: 0.8056\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9154 - accuracy: 0.8103 - val_loss: 0.9221 - val_accuracy: 0.8063\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9102 - accuracy: 0.8107 - val_loss: 0.9185 - val_accuracy: 0.8077\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:07.832093\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9073 - accuracy: 0.8107 - val_loss: 0.9160 - val_accuracy: 0.8085\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9055 - accuracy: 0.8122 - val_loss: 0.9147 - val_accuracy: 0.8082\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9046 - accuracy: 0.8126 - val_loss: 0.9144 - val_accuracy: 0.8080\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9043 - accuracy: 0.8121 - val_loss: 0.9142 - val_accuracy: 0.8081\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:01:50.227085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.5932 - accuracy: 0.4336 - val_loss: 1.9880 - val_accuracy: 0.5940\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7785 - accuracy: 0.6340 - val_loss: 1.6016 - val_accuracy: 0.6653\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5202 - accuracy: 0.6858 - val_loss: 1.4147 - val_accuracy: 0.7055\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3628 - accuracy: 0.7167 - val_loss: 1.2897 - val_accuracy: 0.7295\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2521 - accuracy: 0.7384 - val_loss: 1.1979 - val_accuracy: 0.7500\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1719 - accuracy: 0.7561 - val_loss: 1.1334 - val_accuracy: 0.7632\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1152 - accuracy: 0.7682 - val_loss: 1.0864 - val_accuracy: 0.7739\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0719 - accuracy: 0.7776 - val_loss: 1.0506 - val_accuracy: 0.7813\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0388 - accuracy: 0.7844 - val_loss: 1.0208 - val_accuracy: 0.7870\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0126 - accuracy: 0.7897 - val_loss: 0.9989 - val_accuracy: 0.7910\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9920 - accuracy: 0.7934 - val_loss: 0.9801 - val_accuracy: 0.7951\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9736 - accuracy: 0.7974 - val_loss: 0.9650 - val_accuracy: 0.7975\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9592 - accuracy: 0.8000 - val_loss: 0.9527 - val_accuracy: 0.8011\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9478 - accuracy: 0.8023 - val_loss: 0.9424 - val_accuracy: 0.8024\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9371 - accuracy: 0.8046 - val_loss: 0.9337 - val_accuracy: 0.8039\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9292 - accuracy: 0.8074 - val_loss: 0.9258 - val_accuracy: 0.8061\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9209 - accuracy: 0.8085 - val_loss: 0.9196 - val_accuracy: 0.8070\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9145 - accuracy: 0.8099 - val_loss: 0.9136 - val_accuracy: 0.8083\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9094 - accuracy: 0.8108 - val_loss: 0.9096 - val_accuracy: 0.8086\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9041 - accuracy: 0.8118 - val_loss: 0.9051 - val_accuracy: 0.8096\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.047285\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9006 - accuracy: 0.8128 - val_loss: 0.9033 - val_accuracy: 0.8098\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8990 - accuracy: 0.8126 - val_loss: 0.9021 - val_accuracy: 0.8104\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8980 - accuracy: 0.8139 - val_loss: 0.9017 - val_accuracy: 0.8101\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8981 - accuracy: 0.8126 - val_loss: 0.9014 - val_accuracy: 0.8101\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8972 - accuracy: 0.8132 - val_loss: 0.9015 - val_accuracy: 0.8101\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:17.479251\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.6699 - accuracy: 0.4240 - val_loss: 2.0494 - val_accuracy: 0.5919\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8094 - accuracy: 0.6361 - val_loss: 1.6194 - val_accuracy: 0.6689\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5299 - accuracy: 0.6904 - val_loss: 1.4234 - val_accuracy: 0.7066\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3637 - accuracy: 0.7227 - val_loss: 1.2920 - val_accuracy: 0.7340\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2496 - accuracy: 0.7437 - val_loss: 1.2006 - val_accuracy: 0.7524\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1687 - accuracy: 0.7612 - val_loss: 1.1351 - val_accuracy: 0.7634\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1121 - accuracy: 0.7726 - val_loss: 1.0896 - val_accuracy: 0.7741\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0694 - accuracy: 0.7805 - val_loss: 1.0541 - val_accuracy: 0.7801\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0370 - accuracy: 0.7866 - val_loss: 1.0258 - val_accuracy: 0.7865\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0108 - accuracy: 0.7921 - val_loss: 1.0039 - val_accuracy: 0.7915\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9896 - accuracy: 0.7958 - val_loss: 0.9849 - val_accuracy: 0.7944\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9721 - accuracy: 0.7992 - val_loss: 0.9709 - val_accuracy: 0.7974\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9584 - accuracy: 0.8016 - val_loss: 0.9585 - val_accuracy: 0.7992\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9464 - accuracy: 0.8040 - val_loss: 0.9483 - val_accuracy: 0.8011\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9359 - accuracy: 0.8073 - val_loss: 0.9396 - val_accuracy: 0.8034\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9273 - accuracy: 0.8083 - val_loss: 0.9323 - val_accuracy: 0.8050\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9197 - accuracy: 0.8097 - val_loss: 0.9249 - val_accuracy: 0.8059\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9135 - accuracy: 0.8110 - val_loss: 0.9197 - val_accuracy: 0.8068\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9078 - accuracy: 0.8116 - val_loss: 0.9148 - val_accuracy: 0.8075\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9028 - accuracy: 0.8128 - val_loss: 0.9105 - val_accuracy: 0.8092\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.142606\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8997 - accuracy: 0.8140 - val_loss: 0.9088 - val_accuracy: 0.8090\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8976 - accuracy: 0.8139 - val_loss: 0.9078 - val_accuracy: 0.8091\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8968 - accuracy: 0.8145 - val_loss: 0.9071 - val_accuracy: 0.8094\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8959 - accuracy: 0.8142 - val_loss: 0.9068 - val_accuracy: 0.8092\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8961 - accuracy: 0.8143 - val_loss: 0.9075 - val_accuracy: 0.8090\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8959 - accuracy: 0.8141 - val_loss: 0.9062 - val_accuracy: 0.8095\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8956 - accuracy: 0.8147 - val_loss: 0.9064 - val_accuracy: 0.8096\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8957 - accuracy: 0.8149 - val_loss: 0.9070 - val_accuracy: 0.8090\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.8964 - accuracy: 0.8144 - val_loss: 0.9064 - val_accuracy: 0.8093\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8960 - accuracy: 0.8152 - val_loss: 0.9071 - val_accuracy: 0.8093\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:33.104401\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.6508 - accuracy: 0.4202 - val_loss: 2.0701 - val_accuracy: 0.5797\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8266 - accuracy: 0.6277 - val_loss: 1.6362 - val_accuracy: 0.6683\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5380 - accuracy: 0.6873 - val_loss: 1.4226 - val_accuracy: 0.7098\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3659 - accuracy: 0.7221 - val_loss: 1.2914 - val_accuracy: 0.7373\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2500 - accuracy: 0.7457 - val_loss: 1.1984 - val_accuracy: 0.7564\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1690 - accuracy: 0.7619 - val_loss: 1.1320 - val_accuracy: 0.7668\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1123 - accuracy: 0.7731 - val_loss: 1.0849 - val_accuracy: 0.7762\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0704 - accuracy: 0.7818 - val_loss: 1.0505 - val_accuracy: 0.7828\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0381 - accuracy: 0.7874 - val_loss: 1.0223 - val_accuracy: 0.7863\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0132 - accuracy: 0.7930 - val_loss: 1.0010 - val_accuracy: 0.7922\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9918 - accuracy: 0.7968 - val_loss: 0.9829 - val_accuracy: 0.7955\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9750 - accuracy: 0.8000 - val_loss: 0.9687 - val_accuracy: 0.7978\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9611 - accuracy: 0.8020 - val_loss: 0.9570 - val_accuracy: 0.7998\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9495 - accuracy: 0.8053 - val_loss: 0.9471 - val_accuracy: 0.8017\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9396 - accuracy: 0.8063 - val_loss: 0.9389 - val_accuracy: 0.8034\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9308 - accuracy: 0.8086 - val_loss: 0.9302 - val_accuracy: 0.8051\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9236 - accuracy: 0.8100 - val_loss: 0.9250 - val_accuracy: 0.8050\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9175 - accuracy: 0.8116 - val_loss: 0.9188 - val_accuracy: 0.8069\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9115 - accuracy: 0.8117 - val_loss: 0.9147 - val_accuracy: 0.8070\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 0.9073 - accuracy: 0.8122 - val_loss: 0.9107 - val_accuracy: 0.8078\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:04.728915\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9036 - accuracy: 0.8129 - val_loss: 0.9084 - val_accuracy: 0.8084\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9016 - accuracy: 0.8139 - val_loss: 0.9078 - val_accuracy: 0.8092\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9015 - accuracy: 0.8138 - val_loss: 0.9072 - val_accuracy: 0.8090\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9015 - accuracy: 0.8140 - val_loss: 0.9069 - val_accuracy: 0.8094\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9007 - accuracy: 0.8136 - val_loss: 0.9064 - val_accuracy: 0.8093\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9003 - accuracy: 0.8145 - val_loss: 0.9069 - val_accuracy: 0.8094\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9003 - accuracy: 0.8143 - val_loss: 0.9069 - val_accuracy: 0.8089\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9005 - accuracy: 0.8141 - val_loss: 0.9072 - val_accuracy: 0.8098\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9004 - accuracy: 0.8141 - val_loss: 0.9067 - val_accuracy: 0.8090\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9005 - accuracy: 0.8146 - val_loss: 0.9070 - val_accuracy: 0.8094\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9006 - accuracy: 0.8142 - val_loss: 0.9072 - val_accuracy: 0.8091\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:10.327882\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.6730 - accuracy: 0.4220 - val_loss: 2.0832 - val_accuracy: 0.5896\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8670 - accuracy: 0.6252 - val_loss: 1.6709 - val_accuracy: 0.6620\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5861 - accuracy: 0.6829 - val_loss: 1.4718 - val_accuracy: 0.7001\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4137 - accuracy: 0.7144 - val_loss: 1.3344 - val_accuracy: 0.7266\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2927 - accuracy: 0.7376 - val_loss: 1.2338 - val_accuracy: 0.7447\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2068 - accuracy: 0.7541 - val_loss: 1.1654 - val_accuracy: 0.7567\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1463 - accuracy: 0.7665 - val_loss: 1.1161 - val_accuracy: 0.7672\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1021 - accuracy: 0.7763 - val_loss: 1.0792 - val_accuracy: 0.7750\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0673 - accuracy: 0.7824 - val_loss: 1.0487 - val_accuracy: 0.7815\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0401 - accuracy: 0.7881 - val_loss: 1.0241 - val_accuracy: 0.7872\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0179 - accuracy: 0.7924 - val_loss: 1.0070 - val_accuracy: 0.7900\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0006 - accuracy: 0.7955 - val_loss: 0.9893 - val_accuracy: 0.7930\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9853 - accuracy: 0.7983 - val_loss: 0.9769 - val_accuracy: 0.7949\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9734 - accuracy: 0.8009 - val_loss: 0.9663 - val_accuracy: 0.7967\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9626 - accuracy: 0.8033 - val_loss: 0.9576 - val_accuracy: 0.7987\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9544 - accuracy: 0.8047 - val_loss: 0.9484 - val_accuracy: 0.8011\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9466 - accuracy: 0.8058 - val_loss: 0.9426 - val_accuracy: 0.8032\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9395 - accuracy: 0.8079 - val_loss: 0.9364 - val_accuracy: 0.8037\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9337 - accuracy: 0.8088 - val_loss: 0.9315 - val_accuracy: 0.8042\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9290 - accuracy: 0.8106 - val_loss: 0.9265 - val_accuracy: 0.8055\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:20.628866\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9250 - accuracy: 0.8103 - val_loss: 0.9251 - val_accuracy: 0.8055\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9235 - accuracy: 0.8103 - val_loss: 0.9236 - val_accuracy: 0.8059\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9227 - accuracy: 0.8107 - val_loss: 0.9232 - val_accuracy: 0.8063\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9226 - accuracy: 0.8112 - val_loss: 0.9227 - val_accuracy: 0.8060\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9218 - accuracy: 0.8108 - val_loss: 0.9227 - val_accuracy: 0.8062\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9222 - accuracy: 0.8110 - val_loss: 0.9231 - val_accuracy: 0.8064\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9220 - accuracy: 0.8112 - val_loss: 0.9222 - val_accuracy: 0.8062\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9218 - accuracy: 0.8102 - val_loss: 0.9229 - val_accuracy: 0.8064\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9221 - accuracy: 0.8100 - val_loss: 0.9234 - val_accuracy: 0.8062\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9220 - accuracy: 0.8102 - val_loss: 0.9231 - val_accuracy: 0.8059\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9223 - accuracy: 0.8107 - val_loss: 0.9227 - val_accuracy: 0.8060\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:05:05.277622\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3179 - accuracy: 0.4778 - val_loss: 1.7890 - val_accuracy: 0.6124\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6162 - accuracy: 0.6489 - val_loss: 1.4922 - val_accuracy: 0.6743\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4140 - accuracy: 0.6952 - val_loss: 1.3458 - val_accuracy: 0.7068\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2884 - accuracy: 0.7234 - val_loss: 1.2437 - val_accuracy: 0.7297\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1986 - accuracy: 0.7434 - val_loss: 1.1676 - val_accuracy: 0.7474\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1317 - accuracy: 0.7588 - val_loss: 1.1124 - val_accuracy: 0.7582\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0839 - accuracy: 0.7692 - val_loss: 1.0708 - val_accuracy: 0.7666\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0475 - accuracy: 0.7771 - val_loss: 1.0431 - val_accuracy: 0.7740\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0189 - accuracy: 0.7840 - val_loss: 1.0173 - val_accuracy: 0.7795\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9964 - accuracy: 0.7890 - val_loss: 0.9980 - val_accuracy: 0.7839\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9780 - accuracy: 0.7927 - val_loss: 0.9824 - val_accuracy: 0.7873\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9640 - accuracy: 0.7955 - val_loss: 0.9688 - val_accuracy: 0.7898\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9517 - accuracy: 0.7981 - val_loss: 0.9582 - val_accuracy: 0.7931\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9410 - accuracy: 0.8011 - val_loss: 0.9497 - val_accuracy: 0.7932\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9319 - accuracy: 0.8033 - val_loss: 0.9413 - val_accuracy: 0.7953\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9242 - accuracy: 0.8041 - val_loss: 0.9346 - val_accuracy: 0.7973\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9180 - accuracy: 0.8058 - val_loss: 0.9294 - val_accuracy: 0.7986\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9125 - accuracy: 0.8068 - val_loss: 0.9249 - val_accuracy: 0.7997\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9078 - accuracy: 0.8088 - val_loss: 0.9206 - val_accuracy: 0.8009\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9030 - accuracy: 0.8094 - val_loss: 0.9164 - val_accuracy: 0.8017\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:19.781615\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8998 - accuracy: 0.8102 - val_loss: 0.9151 - val_accuracy: 0.8016\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8980 - accuracy: 0.8103 - val_loss: 0.9143 - val_accuracy: 0.8020\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8980 - accuracy: 0.8102 - val_loss: 0.9137 - val_accuracy: 0.8023\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8975 - accuracy: 0.8108 - val_loss: 0.9129 - val_accuracy: 0.8022\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8973 - accuracy: 0.8102 - val_loss: 0.9136 - val_accuracy: 0.8023\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8966 - accuracy: 0.8109 - val_loss: 0.9133 - val_accuracy: 0.8024\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8975 - accuracy: 0.8102 - val_loss: 0.9131 - val_accuracy: 0.8027\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8978 - accuracy: 0.8106 - val_loss: 0.9133 - val_accuracy: 0.8023\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8971 - accuracy: 0.8104 - val_loss: 0.9138 - val_accuracy: 0.8020\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8968 - accuracy: 0.8101 - val_loss: 0.9132 - val_accuracy: 0.8020\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:38.937820\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.2936 - accuracy: 0.4846 - val_loss: 1.7709 - val_accuracy: 0.6146\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6125 - accuracy: 0.6480 - val_loss: 1.4909 - val_accuracy: 0.6762\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4136 - accuracy: 0.6934 - val_loss: 1.3444 - val_accuracy: 0.7079\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.2871 - accuracy: 0.7226 - val_loss: 1.2409 - val_accuracy: 0.7316\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1961 - accuracy: 0.7434 - val_loss: 1.1662 - val_accuracy: 0.7463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1277 - accuracy: 0.7604 - val_loss: 1.1098 - val_accuracy: 0.7607\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0787 - accuracy: 0.7713 - val_loss: 1.0687 - val_accuracy: 0.7694\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0416 - accuracy: 0.7795 - val_loss: 1.0375 - val_accuracy: 0.7784\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0134 - accuracy: 0.7856 - val_loss: 1.0128 - val_accuracy: 0.7840\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9903 - accuracy: 0.7913 - val_loss: 0.9930 - val_accuracy: 0.7880\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9720 - accuracy: 0.7947 - val_loss: 0.9778 - val_accuracy: 0.7909\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9571 - accuracy: 0.7986 - val_loss: 0.9656 - val_accuracy: 0.7930\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9447 - accuracy: 0.8008 - val_loss: 0.9542 - val_accuracy: 0.7957\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9346 - accuracy: 0.8033 - val_loss: 0.9449 - val_accuracy: 0.7978\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9254 - accuracy: 0.8054 - val_loss: 0.9373 - val_accuracy: 0.7993\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9184 - accuracy: 0.8070 - val_loss: 0.9305 - val_accuracy: 0.8004\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9120 - accuracy: 0.8088 - val_loss: 0.9252 - val_accuracy: 0.8015\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9064 - accuracy: 0.8086 - val_loss: 0.9211 - val_accuracy: 0.8022\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9016 - accuracy: 0.8104 - val_loss: 0.9170 - val_accuracy: 0.8032\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8974 - accuracy: 0.8115 - val_loss: 0.9129 - val_accuracy: 0.8034\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:23.116078\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8942 - accuracy: 0.8122 - val_loss: 0.9115 - val_accuracy: 0.8040\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8927 - accuracy: 0.8121 - val_loss: 0.9102 - val_accuracy: 0.8039\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8916 - accuracy: 0.8122 - val_loss: 0.9099 - val_accuracy: 0.8043\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8917 - accuracy: 0.8129 - val_loss: 0.9098 - val_accuracy: 0.8044\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8914 - accuracy: 0.8125 - val_loss: 0.9097 - val_accuracy: 0.8043\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8912 - accuracy: 0.8126 - val_loss: 0.9102 - val_accuracy: 0.8038\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.8913 - accuracy: 0.8133 - val_loss: 0.9099 - val_accuracy: 0.8041\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:19.908031\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3157 - accuracy: 0.4788 - val_loss: 1.7486 - val_accuracy: 0.6230\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6067 - accuracy: 0.6494 - val_loss: 1.4671 - val_accuracy: 0.6811\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4091 - accuracy: 0.6942 - val_loss: 1.3179 - val_accuracy: 0.7136\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2840 - accuracy: 0.7229 - val_loss: 1.2157 - val_accuracy: 0.7385\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1943 - accuracy: 0.7430 - val_loss: 1.1382 - val_accuracy: 0.7556\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1281 - accuracy: 0.7591 - val_loss: 1.0871 - val_accuracy: 0.7675\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0814 - accuracy: 0.7699 - val_loss: 1.0468 - val_accuracy: 0.7748\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0454 - accuracy: 0.7770 - val_loss: 1.0169 - val_accuracy: 0.7812\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0183 - accuracy: 0.7827 - val_loss: 0.9935 - val_accuracy: 0.7871\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9967 - accuracy: 0.7887 - val_loss: 0.9731 - val_accuracy: 0.7926\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9794 - accuracy: 0.7916 - val_loss: 0.9592 - val_accuracy: 0.7939\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9643 - accuracy: 0.7952 - val_loss: 0.9460 - val_accuracy: 0.7977\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9531 - accuracy: 0.7976 - val_loss: 0.9361 - val_accuracy: 0.7993\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9427 - accuracy: 0.7996 - val_loss: 0.9264 - val_accuracy: 0.8008\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9342 - accuracy: 0.8017 - val_loss: 0.9198 - val_accuracy: 0.8031\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9274 - accuracy: 0.8036 - val_loss: 0.9134 - val_accuracy: 0.8041\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9210 - accuracy: 0.8042 - val_loss: 0.9073 - val_accuracy: 0.8053\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9156 - accuracy: 0.8055 - val_loss: 0.9033 - val_accuracy: 0.8066\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9112 - accuracy: 0.8068 - val_loss: 0.8998 - val_accuracy: 0.8071\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9070 - accuracy: 0.8076 - val_loss: 0.8955 - val_accuracy: 0.8075\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:18.139663\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9044 - accuracy: 0.8079 - val_loss: 0.8936 - val_accuracy: 0.8083\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9023 - accuracy: 0.8088 - val_loss: 0.8936 - val_accuracy: 0.8081\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9020 - accuracy: 0.8087 - val_loss: 0.8931 - val_accuracy: 0.8089\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9017 - accuracy: 0.8087 - val_loss: 0.8929 - val_accuracy: 0.8083\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9012 - accuracy: 0.8087 - val_loss: 0.8926 - val_accuracy: 0.8086\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9010 - accuracy: 0.8090 - val_loss: 0.8925 - val_accuracy: 0.8090\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9012 - accuracy: 0.8090 - val_loss: 0.8918 - val_accuracy: 0.8086\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9011 - accuracy: 0.8093 - val_loss: 0.8924 - val_accuracy: 0.8084\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9009 - accuracy: 0.8089 - val_loss: 0.8929 - val_accuracy: 0.8086\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:10.982604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.3704 - accuracy: 0.4654 - val_loss: 1.8158 - val_accuracy: 0.6064\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6610 - accuracy: 0.6389 - val_loss: 1.5283 - val_accuracy: 0.6657\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4557 - accuracy: 0.6825 - val_loss: 1.3739 - val_accuracy: 0.7002\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3243 - accuracy: 0.7141 - val_loss: 1.2673 - val_accuracy: 0.7257\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2285 - accuracy: 0.7353 - val_loss: 1.1859 - val_accuracy: 0.7428\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1577 - accuracy: 0.7522 - val_loss: 1.1289 - val_accuracy: 0.7563\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1058 - accuracy: 0.7650 - val_loss: 1.0841 - val_accuracy: 0.7676\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0673 - accuracy: 0.7734 - val_loss: 1.0525 - val_accuracy: 0.7753\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0369 - accuracy: 0.7809 - val_loss: 1.0268 - val_accuracy: 0.7823\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0138 - accuracy: 0.7849 - val_loss: 1.0062 - val_accuracy: 0.7865\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9938 - accuracy: 0.7893 - val_loss: 0.9911 - val_accuracy: 0.7901\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9782 - accuracy: 0.7929 - val_loss: 0.9763 - val_accuracy: 0.7922\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9651 - accuracy: 0.7966 - val_loss: 0.9659 - val_accuracy: 0.7951\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9536 - accuracy: 0.7987 - val_loss: 0.9562 - val_accuracy: 0.7967\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9437 - accuracy: 0.8003 - val_loss: 0.9482 - val_accuracy: 0.7989\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9357 - accuracy: 0.8015 - val_loss: 0.9409 - val_accuracy: 0.8016\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9298 - accuracy: 0.8029 - val_loss: 0.9352 - val_accuracy: 0.8020\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9238 - accuracy: 0.8040 - val_loss: 0.9312 - val_accuracy: 0.8031\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9191 - accuracy: 0.8049 - val_loss: 0.9263 - val_accuracy: 0.8034\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9139 - accuracy: 0.8065 - val_loss: 0.9225 - val_accuracy: 0.8040\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:15.829922\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9117 - accuracy: 0.8069 - val_loss: 0.9208 - val_accuracy: 0.8042\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9097 - accuracy: 0.8067 - val_loss: 0.9199 - val_accuracy: 0.8046\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9089 - accuracy: 0.8080 - val_loss: 0.9193 - val_accuracy: 0.8048\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9079 - accuracy: 0.8083 - val_loss: 0.9194 - val_accuracy: 0.8048\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9077 - accuracy: 0.8074 - val_loss: 0.9190 - val_accuracy: 0.8049\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9081 - accuracy: 0.8073 - val_loss: 0.9190 - val_accuracy: 0.8049\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9080 - accuracy: 0.8081 - val_loss: 0.9195 - val_accuracy: 0.8052\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9080 - accuracy: 0.8079 - val_loss: 0.9194 - val_accuracy: 0.8048\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9081 - accuracy: 0.8073 - val_loss: 0.9195 - val_accuracy: 0.8045\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9079 - accuracy: 0.8075 - val_loss: 0.9193 - val_accuracy: 0.8048\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:38.546048\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3447 - accuracy: 0.4691 - val_loss: 1.7855 - val_accuracy: 0.6127\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.6107 - accuracy: 0.6501 - val_loss: 1.4886 - val_accuracy: 0.6767\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4022 - accuracy: 0.6976 - val_loss: 1.3309 - val_accuracy: 0.7109\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2722 - accuracy: 0.7262 - val_loss: 1.2247 - val_accuracy: 0.7339\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1811 - accuracy: 0.7476 - val_loss: 1.1482 - val_accuracy: 0.7499\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1155 - accuracy: 0.7630 - val_loss: 1.0950 - val_accuracy: 0.7633\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0688 - accuracy: 0.7734 - val_loss: 1.0552 - val_accuracy: 0.7717\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0339 - accuracy: 0.7813 - val_loss: 1.0253 - val_accuracy: 0.7789\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0080 - accuracy: 0.7868 - val_loss: 1.0034 - val_accuracy: 0.7843\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9863 - accuracy: 0.7907 - val_loss: 0.9843 - val_accuracy: 0.7881\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9697 - accuracy: 0.7938 - val_loss: 0.9693 - val_accuracy: 0.7918\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9560 - accuracy: 0.7976 - val_loss: 0.9575 - val_accuracy: 0.7949\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9443 - accuracy: 0.8004 - val_loss: 0.9474 - val_accuracy: 0.7963\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9348 - accuracy: 0.8021 - val_loss: 0.9380 - val_accuracy: 0.7982\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9260 - accuracy: 0.8039 - val_loss: 0.9315 - val_accuracy: 0.8000\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9188 - accuracy: 0.8063 - val_loss: 0.9256 - val_accuracy: 0.8015\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9131 - accuracy: 0.8070 - val_loss: 0.9197 - val_accuracy: 0.8028\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9075 - accuracy: 0.8076 - val_loss: 0.9155 - val_accuracy: 0.8030\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9031 - accuracy: 0.8084 - val_loss: 0.9116 - val_accuracy: 0.8046\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9000 - accuracy: 0.8088 - val_loss: 0.9076 - val_accuracy: 0.8045\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:13.570022\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8974 - accuracy: 0.8096 - val_loss: 0.9063 - val_accuracy: 0.8047\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8949 - accuracy: 0.8103 - val_loss: 0.9051 - val_accuracy: 0.8055\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8940 - accuracy: 0.8106 - val_loss: 0.9048 - val_accuracy: 0.8055\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8945 - accuracy: 0.8108 - val_loss: 0.9048 - val_accuracy: 0.8057\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.8940 - accuracy: 0.8110 - val_loss: 0.9047 - val_accuracy: 0.8056\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8938 - accuracy: 0.8105 - val_loss: 0.9048 - val_accuracy: 0.8055\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.8945 - accuracy: 0.8107 - val_loss: 0.9045 - val_accuracy: 0.8056\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:13.314345\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.4865 - accuracy: 0.4472 - val_loss: 1.8685 - val_accuracy: 0.6016\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6670 - accuracy: 0.6417 - val_loss: 1.5070 - val_accuracy: 0.6747\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4357 - accuracy: 0.6915 - val_loss: 1.3470 - val_accuracy: 0.7080\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2994 - accuracy: 0.7206 - val_loss: 1.2392 - val_accuracy: 0.7322\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2023 - accuracy: 0.7428 - val_loss: 1.1574 - val_accuracy: 0.7478\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1311 - accuracy: 0.7584 - val_loss: 1.0985 - val_accuracy: 0.7604\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0801 - accuracy: 0.7698 - val_loss: 1.0590 - val_accuracy: 0.7693\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0420 - accuracy: 0.7777 - val_loss: 1.0252 - val_accuracy: 0.7785\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0119 - accuracy: 0.7845 - val_loss: 1.0009 - val_accuracy: 0.7834\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9892 - accuracy: 0.7899 - val_loss: 0.9797 - val_accuracy: 0.7886\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9695 - accuracy: 0.7940 - val_loss: 0.9640 - val_accuracy: 0.7926\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9548 - accuracy: 0.7979 - val_loss: 0.9498 - val_accuracy: 0.7951\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9416 - accuracy: 0.8007 - val_loss: 0.9381 - val_accuracy: 0.7978\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9309 - accuracy: 0.8020 - val_loss: 0.9301 - val_accuracy: 0.7999\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.9219 - accuracy: 0.8040 - val_loss: 0.9215 - val_accuracy: 0.8009\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9139 - accuracy: 0.8056 - val_loss: 0.9153 - val_accuracy: 0.8027\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9067 - accuracy: 0.8073 - val_loss: 0.9092 - val_accuracy: 0.8046\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9010 - accuracy: 0.8091 - val_loss: 0.9037 - val_accuracy: 0.8063\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8966 - accuracy: 0.8095 - val_loss: 0.8996 - val_accuracy: 0.8070\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8922 - accuracy: 0.8098 - val_loss: 0.8956 - val_accuracy: 0.8076\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:36.334946\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8883 - accuracy: 0.8113 - val_loss: 0.8936 - val_accuracy: 0.8079\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8869 - accuracy: 0.8116 - val_loss: 0.8929 - val_accuracy: 0.8083\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8863 - accuracy: 0.8127 - val_loss: 0.8929 - val_accuracy: 0.8085\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8863 - accuracy: 0.8122 - val_loss: 0.8927 - val_accuracy: 0.8086\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8855 - accuracy: 0.8128 - val_loss: 0.8923 - val_accuracy: 0.8082\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8856 - accuracy: 0.8121 - val_loss: 0.8922 - val_accuracy: 0.8084\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8854 - accuracy: 0.8121 - val_loss: 0.8925 - val_accuracy: 0.8086\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:23.290411\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.5263 - accuracy: 0.4384 - val_loss: 1.9108 - val_accuracy: 0.5974\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6817 - accuracy: 0.6430 - val_loss: 1.5194 - val_accuracy: 0.6713\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4312 - accuracy: 0.6948 - val_loss: 1.3449 - val_accuracy: 0.7110\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2871 - accuracy: 0.7264 - val_loss: 1.2318 - val_accuracy: 0.7348\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1878 - accuracy: 0.7471 - val_loss: 1.1477 - val_accuracy: 0.7549\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1167 - accuracy: 0.7630 - val_loss: 1.0896 - val_accuracy: 0.7650\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0654 - accuracy: 0.7747 - val_loss: 1.0496 - val_accuracy: 0.7736\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0278 - accuracy: 0.7830 - val_loss: 1.0177 - val_accuracy: 0.7813\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9992 - accuracy: 0.7900 - val_loss: 0.9933 - val_accuracy: 0.7867\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9764 - accuracy: 0.7949 - val_loss: 0.9743 - val_accuracy: 0.7878\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9588 - accuracy: 0.7982 - val_loss: 0.9570 - val_accuracy: 0.7933\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9435 - accuracy: 0.8015 - val_loss: 0.9441 - val_accuracy: 0.7960\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9307 - accuracy: 0.8039 - val_loss: 0.9343 - val_accuracy: 0.7984\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9207 - accuracy: 0.8062 - val_loss: 0.9259 - val_accuracy: 0.8008\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9113 - accuracy: 0.8086 - val_loss: 0.9179 - val_accuracy: 0.8022\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9039 - accuracy: 0.8086 - val_loss: 0.9113 - val_accuracy: 0.8040\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8976 - accuracy: 0.8107 - val_loss: 0.9056 - val_accuracy: 0.8040\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8926 - accuracy: 0.8125 - val_loss: 0.9006 - val_accuracy: 0.8053\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8875 - accuracy: 0.8130 - val_loss: 0.8964 - val_accuracy: 0.8055\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8828 - accuracy: 0.8136 - val_loss: 0.8926 - val_accuracy: 0.8060\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.222220\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8798 - accuracy: 0.8145 - val_loss: 0.8915 - val_accuracy: 0.8067\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8783 - accuracy: 0.8143 - val_loss: 0.8901 - val_accuracy: 0.8068\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8779 - accuracy: 0.8148 - val_loss: 0.8897 - val_accuracy: 0.8070\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8778 - accuracy: 0.8154 - val_loss: 0.8893 - val_accuracy: 0.8071\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8775 - accuracy: 0.8157 - val_loss: 0.8894 - val_accuracy: 0.8071\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 0.8770 - accuracy: 0.8155 - val_loss: 0.8893 - val_accuracy: 0.8073\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8774 - accuracy: 0.8154 - val_loss: 0.8893 - val_accuracy: 0.8069\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8770 - accuracy: 0.8156 - val_loss: 0.8895 - val_accuracy: 0.8070\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.8777 - accuracy: 0.8149 - val_loss: 0.8893 - val_accuracy: 0.8071\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:23.506059\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.4009 - accuracy: 0.4698 - val_loss: 1.8181 - val_accuracy: 0.6215\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6255 - accuracy: 0.6530 - val_loss: 1.4617 - val_accuracy: 0.6871\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.3981 - accuracy: 0.7020 - val_loss: 1.3017 - val_accuracy: 0.7215\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2621 - accuracy: 0.7303 - val_loss: 1.1953 - val_accuracy: 0.7463\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1676 - accuracy: 0.7514 - val_loss: 1.1153 - val_accuracy: 0.7647\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0995 - accuracy: 0.7661 - val_loss: 1.0620 - val_accuracy: 0.7751\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0516 - accuracy: 0.7772 - val_loss: 1.0200 - val_accuracy: 0.7847\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0155 - accuracy: 0.7847 - val_loss: 0.9923 - val_accuracy: 0.7895\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9880 - accuracy: 0.7902 - val_loss: 0.9675 - val_accuracy: 0.7950\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9660 - accuracy: 0.7954 - val_loss: 0.9476 - val_accuracy: 0.7994\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9477 - accuracy: 0.7995 - val_loss: 0.9333 - val_accuracy: 0.8005\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9340 - accuracy: 0.8018 - val_loss: 0.9207 - val_accuracy: 0.8030\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9212 - accuracy: 0.8054 - val_loss: 0.9097 - val_accuracy: 0.8061\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9120 - accuracy: 0.8069 - val_loss: 0.9016 - val_accuracy: 0.8072\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9032 - accuracy: 0.8097 - val_loss: 0.8944 - val_accuracy: 0.8087\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8951 - accuracy: 0.8108 - val_loss: 0.8883 - val_accuracy: 0.8094\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8887 - accuracy: 0.8119 - val_loss: 0.8825 - val_accuracy: 0.8102\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8843 - accuracy: 0.8134 - val_loss: 0.8778 - val_accuracy: 0.8110\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8793 - accuracy: 0.8140 - val_loss: 0.8743 - val_accuracy: 0.8130\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8753 - accuracy: 0.8148 - val_loss: 0.8697 - val_accuracy: 0.8132\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:39.337928\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8723 - accuracy: 0.8157 - val_loss: 0.8688 - val_accuracy: 0.8135\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8709 - accuracy: 0.8163 - val_loss: 0.8675 - val_accuracy: 0.8140\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8699 - accuracy: 0.8169 - val_loss: 0.8678 - val_accuracy: 0.8141\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8695 - accuracy: 0.8164 - val_loss: 0.8673 - val_accuracy: 0.8143\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8699 - accuracy: 0.8166 - val_loss: 0.8672 - val_accuracy: 0.8142\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8693 - accuracy: 0.8161 - val_loss: 0.8669 - val_accuracy: 0.8142\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8697 - accuracy: 0.8162 - val_loss: 0.8672 - val_accuracy: 0.8140\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:22.636511\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.4522 - accuracy: 0.4592 - val_loss: 1.8187 - val_accuracy: 0.6168\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6251 - accuracy: 0.6526 - val_loss: 1.4624 - val_accuracy: 0.6854\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3933 - accuracy: 0.7013 - val_loss: 1.3002 - val_accuracy: 0.7191\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2536 - accuracy: 0.7321 - val_loss: 1.1886 - val_accuracy: 0.7473\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1570 - accuracy: 0.7547 - val_loss: 1.1078 - val_accuracy: 0.7650\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0882 - accuracy: 0.7686 - val_loss: 1.0534 - val_accuracy: 0.7782\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0387 - accuracy: 0.7802 - val_loss: 1.0135 - val_accuracy: 0.7858\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0031 - accuracy: 0.7874 - val_loss: 0.9832 - val_accuracy: 0.7918\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9740 - accuracy: 0.7945 - val_loss: 0.9602 - val_accuracy: 0.7961\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9531 - accuracy: 0.7993 - val_loss: 0.9418 - val_accuracy: 0.7996\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9353 - accuracy: 0.8029 - val_loss: 0.9267 - val_accuracy: 0.8035\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9217 - accuracy: 0.8050 - val_loss: 0.9147 - val_accuracy: 0.8062\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9096 - accuracy: 0.8075 - val_loss: 0.9043 - val_accuracy: 0.8079\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8994 - accuracy: 0.8096 - val_loss: 0.8957 - val_accuracy: 0.8094\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8909 - accuracy: 0.8120 - val_loss: 0.8885 - val_accuracy: 0.8117\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8834 - accuracy: 0.8133 - val_loss: 0.8816 - val_accuracy: 0.8128\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8775 - accuracy: 0.8145 - val_loss: 0.8763 - val_accuracy: 0.8138\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8719 - accuracy: 0.8152 - val_loss: 0.8718 - val_accuracy: 0.8148\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8681 - accuracy: 0.8168 - val_loss: 0.8684 - val_accuracy: 0.8155\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8635 - accuracy: 0.8173 - val_loss: 0.8640 - val_accuracy: 0.8167\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.647566\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8614 - accuracy: 0.8181 - val_loss: 0.8631 - val_accuracy: 0.8164\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.8594 - accuracy: 0.8184 - val_loss: 0.8622 - val_accuracy: 0.8165\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8589 - accuracy: 0.8190 - val_loss: 0.8618 - val_accuracy: 0.8164\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8588 - accuracy: 0.8182 - val_loss: 0.8620 - val_accuracy: 0.8166\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8578 - accuracy: 0.8190 - val_loss: 0.8618 - val_accuracy: 0.8164\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8584 - accuracy: 0.8181 - val_loss: 0.8615 - val_accuracy: 0.8166\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8582 - accuracy: 0.8190 - val_loss: 0.8616 - val_accuracy: 0.8164\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:23.900192\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.4179 - accuracy: 0.4564 - val_loss: 1.8198 - val_accuracy: 0.6127\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6188 - accuracy: 0.6512 - val_loss: 1.4730 - val_accuracy: 0.6824\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3918 - accuracy: 0.7011 - val_loss: 1.3096 - val_accuracy: 0.7188\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2549 - accuracy: 0.7313 - val_loss: 1.2027 - val_accuracy: 0.7431\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1606 - accuracy: 0.7528 - val_loss: 1.1203 - val_accuracy: 0.7628\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0925 - accuracy: 0.7684 - val_loss: 1.0676 - val_accuracy: 0.7734\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0439 - accuracy: 0.7793 - val_loss: 1.0261 - val_accuracy: 0.7816\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0076 - accuracy: 0.7875 - val_loss: 0.9964 - val_accuracy: 0.7898\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9805 - accuracy: 0.7929 - val_loss: 0.9741 - val_accuracy: 0.7936\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9590 - accuracy: 0.7972 - val_loss: 0.9544 - val_accuracy: 0.7988\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9407 - accuracy: 0.8021 - val_loss: 0.9393 - val_accuracy: 0.8008\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9271 - accuracy: 0.8038 - val_loss: 0.9273 - val_accuracy: 0.8041\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9147 - accuracy: 0.8075 - val_loss: 0.9170 - val_accuracy: 0.8058\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.9053 - accuracy: 0.8092 - val_loss: 0.9086 - val_accuracy: 0.8082\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8966 - accuracy: 0.8101 - val_loss: 0.9007 - val_accuracy: 0.8097\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8892 - accuracy: 0.8122 - val_loss: 0.8950 - val_accuracy: 0.8111\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8840 - accuracy: 0.8132 - val_loss: 0.8898 - val_accuracy: 0.8122\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8784 - accuracy: 0.8155 - val_loss: 0.8851 - val_accuracy: 0.8134\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8731 - accuracy: 0.8165 - val_loss: 0.8816 - val_accuracy: 0.8135\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8693 - accuracy: 0.8168 - val_loss: 0.8780 - val_accuracy: 0.8141\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.563722\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8666 - accuracy: 0.8172 - val_loss: 0.8756 - val_accuracy: 0.8148\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8650 - accuracy: 0.8175 - val_loss: 0.8749 - val_accuracy: 0.8147\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8634 - accuracy: 0.8179 - val_loss: 0.8750 - val_accuracy: 0.8151\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 0.8635 - accuracy: 0.8181 - val_loss: 0.8750 - val_accuracy: 0.8157\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8632 - accuracy: 0.8183 - val_loss: 0.8750 - val_accuracy: 0.8147\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 0.8637 - accuracy: 0.8183 - val_loss: 0.8744 - val_accuracy: 0.8152\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.8637 - accuracy: 0.8176 - val_loss: 0.8747 - val_accuracy: 0.8152\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': True, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:21.820640\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8392 - accuracy: 0.0333 - val_loss: 3.8193 - val_accuracy: 0.0445\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7779 - accuracy: 0.0670 - val_loss: 3.7003 - val_accuracy: 0.1090\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5074 - accuracy: 0.1460 - val_loss: 3.1497 - val_accuracy: 0.2680\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.8084 - accuracy: 0.2731 - val_loss: 2.2565 - val_accuracy: 0.4554\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2401 - accuracy: 0.3882 - val_loss: 1.8211 - val_accuracy: 0.5341\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.9643 - accuracy: 0.4511 - val_loss: 1.6286 - val_accuracy: 0.5710\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8202 - accuracy: 0.4854 - val_loss: 1.5167 - val_accuracy: 0.5931\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7265 - accuracy: 0.5085 - val_loss: 1.4447 - val_accuracy: 0.6092\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6650 - accuracy: 0.5254 - val_loss: 1.3901 - val_accuracy: 0.6205\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6145 - accuracy: 0.5375 - val_loss: 1.3512 - val_accuracy: 0.6301\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5678 - accuracy: 0.5509 - val_loss: 1.3175 - val_accuracy: 0.6373\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5377 - accuracy: 0.5576 - val_loss: 1.2917 - val_accuracy: 0.6424\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5117 - accuracy: 0.5647 - val_loss: 1.2687 - val_accuracy: 0.6470\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4896 - accuracy: 0.5682 - val_loss: 1.2502 - val_accuracy: 0.6515\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4713 - accuracy: 0.5744 - val_loss: 1.2339 - val_accuracy: 0.6551\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4495 - accuracy: 0.5824 - val_loss: 1.2210 - val_accuracy: 0.6580\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4370 - accuracy: 0.5825 - val_loss: 1.2090 - val_accuracy: 0.6618\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4257 - accuracy: 0.5882 - val_loss: 1.1990 - val_accuracy: 0.6647\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4148 - accuracy: 0.5878 - val_loss: 1.1903 - val_accuracy: 0.6664\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4125 - accuracy: 0.5896 - val_loss: 1.1832 - val_accuracy: 0.6680\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:56.173845\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3997 - accuracy: 0.5936 - val_loss: 1.1792 - val_accuracy: 0.6688\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3948 - accuracy: 0.5963 - val_loss: 1.1771 - val_accuracy: 0.6692\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3957 - accuracy: 0.5943 - val_loss: 1.1763 - val_accuracy: 0.6694\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3929 - accuracy: 0.5950 - val_loss: 1.1759 - val_accuracy: 0.6697\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3973 - accuracy: 0.5949 - val_loss: 1.1758 - val_accuracy: 0.6699\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3927 - accuracy: 0.5959 - val_loss: 1.1757 - val_accuracy: 0.6698\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.3946 - accuracy: 0.5948 - val_loss: 1.1757 - val_accuracy: 0.6698\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3923 - accuracy: 0.5967 - val_loss: 1.1756 - val_accuracy: 0.6698\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:35.799991\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8252 - accuracy: 0.0418 - val_loss: 3.7904 - val_accuracy: 0.0637\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7086 - accuracy: 0.0864 - val_loss: 3.5460 - val_accuracy: 0.1832\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.2253 - accuracy: 0.2024 - val_loss: 2.6927 - val_accuracy: 0.3828\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.5067 - accuracy: 0.3310 - val_loss: 2.0139 - val_accuracy: 0.4949\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.1050 - accuracy: 0.4146 - val_loss: 1.7092 - val_accuracy: 0.5545\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8906 - accuracy: 0.4665 - val_loss: 1.5564 - val_accuracy: 0.5797\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7667 - accuracy: 0.4998 - val_loss: 1.4544 - val_accuracy: 0.6005\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6841 - accuracy: 0.5196 - val_loss: 1.3893 - val_accuracy: 0.6170\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6254 - accuracy: 0.5354 - val_loss: 1.3414 - val_accuracy: 0.6273\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5736 - accuracy: 0.5478 - val_loss: 1.3044 - val_accuracy: 0.6365\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5426 - accuracy: 0.5550 - val_loss: 1.2727 - val_accuracy: 0.6418\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.5139 - accuracy: 0.5635 - val_loss: 1.2484 - val_accuracy: 0.6479\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4862 - accuracy: 0.5715 - val_loss: 1.2277 - val_accuracy: 0.6534\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4691 - accuracy: 0.5743 - val_loss: 1.2127 - val_accuracy: 0.6564\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4526 - accuracy: 0.5812 - val_loss: 1.1981 - val_accuracy: 0.6609\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4322 - accuracy: 0.5859 - val_loss: 1.1849 - val_accuracy: 0.6633\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4238 - accuracy: 0.5847 - val_loss: 1.1746 - val_accuracy: 0.6662\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4097 - accuracy: 0.5905 - val_loss: 1.1650 - val_accuracy: 0.6675\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4045 - accuracy: 0.5912 - val_loss: 1.1562 - val_accuracy: 0.6709\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3928 - accuracy: 0.5955 - val_loss: 1.1490 - val_accuracy: 0.6724\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:53.816732\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3892 - accuracy: 0.5953 - val_loss: 1.1453 - val_accuracy: 0.6732\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3846 - accuracy: 0.5967 - val_loss: 1.1437 - val_accuracy: 0.6734\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3839 - accuracy: 0.5976 - val_loss: 1.1429 - val_accuracy: 0.6735\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3834 - accuracy: 0.5984 - val_loss: 1.1426 - val_accuracy: 0.6736\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.3808 - accuracy: 0.5993 - val_loss: 1.1424 - val_accuracy: 0.6736\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.3798 - accuracy: 0.5995 - val_loss: 1.1424 - val_accuracy: 0.6736\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.3779 - accuracy: 0.5985 - val_loss: 1.1423 - val_accuracy: 0.6736\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:07.726478\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8169 - accuracy: 0.0353 - val_loss: 3.7644 - val_accuracy: 0.0605\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 3.6306 - accuracy: 0.1099 - val_loss: 3.3619 - val_accuracy: 0.2394\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.9795 - accuracy: 0.2475 - val_loss: 2.3980 - val_accuracy: 0.4364\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3035 - accuracy: 0.3775 - val_loss: 1.8637 - val_accuracy: 0.5320\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9694 - accuracy: 0.4504 - val_loss: 1.6113 - val_accuracy: 0.5783\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7891 - accuracy: 0.4943 - val_loss: 1.4860 - val_accuracy: 0.6043\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.6766 - accuracy: 0.5218 - val_loss: 1.3985 - val_accuracy: 0.6216\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6029 - accuracy: 0.5396 - val_loss: 1.3406 - val_accuracy: 0.6353\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5461 - accuracy: 0.5534 - val_loss: 1.2985 - val_accuracy: 0.6443\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5028 - accuracy: 0.5662 - val_loss: 1.2618 - val_accuracy: 0.6506\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.4695 - accuracy: 0.5733 - val_loss: 1.2377 - val_accuracy: 0.6575\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4407 - accuracy: 0.5826 - val_loss: 1.2139 - val_accuracy: 0.6623\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4218 - accuracy: 0.5855 - val_loss: 1.1971 - val_accuracy: 0.6666\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3992 - accuracy: 0.5927 - val_loss: 1.1805 - val_accuracy: 0.6699\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.3829 - accuracy: 0.5974 - val_loss: 1.1666 - val_accuracy: 0.6743\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3692 - accuracy: 0.6004 - val_loss: 1.1550 - val_accuracy: 0.6770\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.3589 - accuracy: 0.6018 - val_loss: 1.1459 - val_accuracy: 0.6790\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3460 - accuracy: 0.6065 - val_loss: 1.1363 - val_accuracy: 0.6795\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3387 - accuracy: 0.6085 - val_loss: 1.1297 - val_accuracy: 0.6811\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3334 - accuracy: 0.6083 - val_loss: 1.1242 - val_accuracy: 0.6827\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:52.088835\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3247 - accuracy: 0.6095 - val_loss: 1.1206 - val_accuracy: 0.6833\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3217 - accuracy: 0.6120 - val_loss: 1.1190 - val_accuracy: 0.6840\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3178 - accuracy: 0.6135 - val_loss: 1.1183 - val_accuracy: 0.6843\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3194 - accuracy: 0.6108 - val_loss: 1.1180 - val_accuracy: 0.6842\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3183 - accuracy: 0.6123 - val_loss: 1.1178 - val_accuracy: 0.6844\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3174 - accuracy: 0.6122 - val_loss: 1.1177 - val_accuracy: 0.6844\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 26s 38ms/step - loss: 1.3197 - accuracy: 0.6134 - val_loss: 1.1177 - val_accuracy: 0.6844\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3197 - accuracy: 0.6118 - val_loss: 1.1177 - val_accuracy: 0.6844\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3183 - accuracy: 0.6120 - val_loss: 1.1177 - val_accuracy: 0.6844\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 26s 37ms/step - loss: 1.3179 - accuracy: 0.6140 - val_loss: 1.1177 - val_accuracy: 0.6844\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:25.160351\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8314 - accuracy: 0.0262 - val_loss: 3.7991 - val_accuracy: 0.0496\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7242 - accuracy: 0.0719 - val_loss: 3.5851 - val_accuracy: 0.1613\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.2620 - accuracy: 0.2021 - val_loss: 2.7421 - val_accuracy: 0.3731\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.4935 - accuracy: 0.3417 - val_loss: 2.0138 - val_accuracy: 0.5025\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.0547 - accuracy: 0.4323 - val_loss: 1.7047 - val_accuracy: 0.5584\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8525 - accuracy: 0.4780 - val_loss: 1.5499 - val_accuracy: 0.5905\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7300 - accuracy: 0.5106 - val_loss: 1.4567 - val_accuracy: 0.6106\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6491 - accuracy: 0.5304 - val_loss: 1.3861 - val_accuracy: 0.6270\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5854 - accuracy: 0.5480 - val_loss: 1.3362 - val_accuracy: 0.6379\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5362 - accuracy: 0.5569 - val_loss: 1.2967 - val_accuracy: 0.6448\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5000 - accuracy: 0.5676 - val_loss: 1.2642 - val_accuracy: 0.6526\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4641 - accuracy: 0.5778 - val_loss: 1.2377 - val_accuracy: 0.6572\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4426 - accuracy: 0.5822 - val_loss: 1.2173 - val_accuracy: 0.6634\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4218 - accuracy: 0.5875 - val_loss: 1.1976 - val_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4030 - accuracy: 0.5929 - val_loss: 1.1830 - val_accuracy: 0.6703\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3866 - accuracy: 0.5961 - val_loss: 1.1695 - val_accuracy: 0.6730\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3695 - accuracy: 0.6015 - val_loss: 1.1566 - val_accuracy: 0.6754\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3643 - accuracy: 0.6020 - val_loss: 1.1478 - val_accuracy: 0.6777\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3518 - accuracy: 0.6055 - val_loss: 1.1395 - val_accuracy: 0.6796\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3418 - accuracy: 0.6080 - val_loss: 1.1324 - val_accuracy: 0.6816\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:56.978029\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3406 - accuracy: 0.6083 - val_loss: 1.1288 - val_accuracy: 0.6822\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3336 - accuracy: 0.6117 - val_loss: 1.1269 - val_accuracy: 0.6824\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3320 - accuracy: 0.6105 - val_loss: 1.1260 - val_accuracy: 0.6827\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3305 - accuracy: 0.6106 - val_loss: 1.1255 - val_accuracy: 0.6828\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3299 - accuracy: 0.6119 - val_loss: 1.1253 - val_accuracy: 0.6828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3291 - accuracy: 0.6119 - val_loss: 1.1253 - val_accuracy: 0.6829\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3265 - accuracy: 0.6125 - val_loss: 1.1252 - val_accuracy: 0.6829\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3316 - accuracy: 0.6110 - val_loss: 1.1252 - val_accuracy: 0.6829\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3295 - accuracy: 0.6127 - val_loss: 1.1252 - val_accuracy: 0.6829\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3309 - accuracy: 0.6120 - val_loss: 1.1252 - val_accuracy: 0.6829\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:29.380794\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8148 - accuracy: 0.0446 - val_loss: 3.7529 - val_accuracy: 0.0904\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5856 - accuracy: 0.1230 - val_loss: 3.2568 - val_accuracy: 0.2512\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.8694 - accuracy: 0.2625 - val_loss: 2.3022 - val_accuracy: 0.4391\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2434 - accuracy: 0.3879 - val_loss: 1.8225 - val_accuracy: 0.5358\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9307 - accuracy: 0.4608 - val_loss: 1.5869 - val_accuracy: 0.5808\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7567 - accuracy: 0.5038 - val_loss: 1.4669 - val_accuracy: 0.6050\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6542 - accuracy: 0.5283 - val_loss: 1.3851 - val_accuracy: 0.6236\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5790 - accuracy: 0.5456 - val_loss: 1.3281 - val_accuracy: 0.6354\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5322 - accuracy: 0.5603 - val_loss: 1.2915 - val_accuracy: 0.6413\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4906 - accuracy: 0.5687 - val_loss: 1.2606 - val_accuracy: 0.6506\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4567 - accuracy: 0.5802 - val_loss: 1.2315 - val_accuracy: 0.6567\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4306 - accuracy: 0.5854 - val_loss: 1.2094 - val_accuracy: 0.6625\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4103 - accuracy: 0.5902 - val_loss: 1.1937 - val_accuracy: 0.6658\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3949 - accuracy: 0.5954 - val_loss: 1.1780 - val_accuracy: 0.6683\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3740 - accuracy: 0.6006 - val_loss: 1.1650 - val_accuracy: 0.6711\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3639 - accuracy: 0.6036 - val_loss: 1.1548 - val_accuracy: 0.6738\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3529 - accuracy: 0.6049 - val_loss: 1.1467 - val_accuracy: 0.6754\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3371 - accuracy: 0.6110 - val_loss: 1.1368 - val_accuracy: 0.6779\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3310 - accuracy: 0.6126 - val_loss: 1.1292 - val_accuracy: 0.6798\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3246 - accuracy: 0.6113 - val_loss: 1.1236 - val_accuracy: 0.6802\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:57.370644\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3143 - accuracy: 0.6160 - val_loss: 1.1199 - val_accuracy: 0.6815\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3148 - accuracy: 0.6172 - val_loss: 1.1184 - val_accuracy: 0.6812\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3113 - accuracy: 0.6166 - val_loss: 1.1176 - val_accuracy: 0.6814\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3142 - accuracy: 0.6157 - val_loss: 1.1173 - val_accuracy: 0.6814\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:01:48.174493\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7497 - accuracy: 0.0613 - val_loss: 3.5658 - val_accuracy: 0.1770\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1104 - accuracy: 0.2547 - val_loss: 2.4769 - val_accuracy: 0.4218\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.1841 - accuracy: 0.4184 - val_loss: 1.7802 - val_accuracy: 0.5468\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7825 - accuracy: 0.5041 - val_loss: 1.5227 - val_accuracy: 0.5938\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6056 - accuracy: 0.5482 - val_loss: 1.3922 - val_accuracy: 0.6230\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4973 - accuracy: 0.5756 - val_loss: 1.3162 - val_accuracy: 0.6360\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4280 - accuracy: 0.5932 - val_loss: 1.2606 - val_accuracy: 0.6502\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3766 - accuracy: 0.6056 - val_loss: 1.2183 - val_accuracy: 0.6614\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3377 - accuracy: 0.6169 - val_loss: 1.1874 - val_accuracy: 0.6668\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3145 - accuracy: 0.6210 - val_loss: 1.1613 - val_accuracy: 0.6715\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2826 - accuracy: 0.6295 - val_loss: 1.1389 - val_accuracy: 0.6769\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2597 - accuracy: 0.6354 - val_loss: 1.1197 - val_accuracy: 0.6811\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2426 - accuracy: 0.6388 - val_loss: 1.1047 - val_accuracy: 0.6853\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2286 - accuracy: 0.6439 - val_loss: 1.0921 - val_accuracy: 0.6883\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2134 - accuracy: 0.6474 - val_loss: 1.0795 - val_accuracy: 0.6910\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2033 - accuracy: 0.6498 - val_loss: 1.0696 - val_accuracy: 0.6938\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1916 - accuracy: 0.6521 - val_loss: 1.0601 - val_accuracy: 0.6965\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1838 - accuracy: 0.6554 - val_loss: 1.0533 - val_accuracy: 0.6974\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1763 - accuracy: 0.6558 - val_loss: 1.0462 - val_accuracy: 0.6990\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1685 - accuracy: 0.6568 - val_loss: 1.0405 - val_accuracy: 0.7008\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:09.120832\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.1617 - accuracy: 0.6608 - val_loss: 1.0373 - val_accuracy: 0.7008\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.1572 - accuracy: 0.6615 - val_loss: 1.0358 - val_accuracy: 0.7012\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1601 - accuracy: 0.6614 - val_loss: 1.0351 - val_accuracy: 0.7012\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1612 - accuracy: 0.6608 - val_loss: 1.0348 - val_accuracy: 0.7013\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1608 - accuracy: 0.6609 - val_loss: 1.0347 - val_accuracy: 0.7011\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1591 - accuracy: 0.6608 - val_loss: 1.0346 - val_accuracy: 0.7009\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1574 - accuracy: 0.6607 - val_loss: 1.0346 - val_accuracy: 0.7009\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:17.158161\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7870 - accuracy: 0.0582 - val_loss: 3.6746 - val_accuracy: 0.1338\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.3295 - accuracy: 0.2066 - val_loss: 2.7568 - val_accuracy: 0.3504\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.3404 - accuracy: 0.3850 - val_loss: 1.8694 - val_accuracy: 0.5337\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8457 - accuracy: 0.4905 - val_loss: 1.5643 - val_accuracy: 0.5897\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6456 - accuracy: 0.5407 - val_loss: 1.4299 - val_accuracy: 0.6152\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5390 - accuracy: 0.5640 - val_loss: 1.3497 - val_accuracy: 0.6308\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4705 - accuracy: 0.5829 - val_loss: 1.2956 - val_accuracy: 0.6423\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4243 - accuracy: 0.5931 - val_loss: 1.2567 - val_accuracy: 0.6502\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3870 - accuracy: 0.6032 - val_loss: 1.2239 - val_accuracy: 0.6596\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3541 - accuracy: 0.6119 - val_loss: 1.1992 - val_accuracy: 0.6648\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3325 - accuracy: 0.6155 - val_loss: 1.1808 - val_accuracy: 0.6704\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3093 - accuracy: 0.6233 - val_loss: 1.1601 - val_accuracy: 0.6743\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2919 - accuracy: 0.6279 - val_loss: 1.1463 - val_accuracy: 0.6773\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2775 - accuracy: 0.6323 - val_loss: 1.1327 - val_accuracy: 0.6813\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2654 - accuracy: 0.6350 - val_loss: 1.1218 - val_accuracy: 0.6837\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2553 - accuracy: 0.6370 - val_loss: 1.1117 - val_accuracy: 0.6863\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2453 - accuracy: 0.6389 - val_loss: 1.1035 - val_accuracy: 0.6875\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2348 - accuracy: 0.6426 - val_loss: 1.0957 - val_accuracy: 0.6906\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2284 - accuracy: 0.6434 - val_loss: 1.0901 - val_accuracy: 0.6918\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2244 - accuracy: 0.6454 - val_loss: 1.0839 - val_accuracy: 0.6922\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:11.556308\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2176 - accuracy: 0.6457 - val_loss: 1.0808 - val_accuracy: 0.6936\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2104 - accuracy: 0.6493 - val_loss: 1.0793 - val_accuracy: 0.6936\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2118 - accuracy: 0.6486 - val_loss: 1.0788 - val_accuracy: 0.6941\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2126 - accuracy: 0.6489 - val_loss: 1.0784 - val_accuracy: 0.6941\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2129 - accuracy: 0.6479 - val_loss: 1.0783 - val_accuracy: 0.6942\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2131 - accuracy: 0.6476 - val_loss: 1.0783 - val_accuracy: 0.6942\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2109 - accuracy: 0.6484 - val_loss: 1.0782 - val_accuracy: 0.6942\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2102 - accuracy: 0.6488 - val_loss: 1.0782 - val_accuracy: 0.6942\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:44.930213\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7623 - accuracy: 0.0747 - val_loss: 3.6007 - val_accuracy: 0.1908\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.1633 - accuracy: 0.2561 - val_loss: 2.5501 - val_accuracy: 0.4047\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.2122 - accuracy: 0.4218 - val_loss: 1.8167 - val_accuracy: 0.5330\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8021 - accuracy: 0.5040 - val_loss: 1.5564 - val_accuracy: 0.5854\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6191 - accuracy: 0.5451 - val_loss: 1.4228 - val_accuracy: 0.6110\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5207 - accuracy: 0.5685 - val_loss: 1.3437 - val_accuracy: 0.6275\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4516 - accuracy: 0.5867 - val_loss: 1.2881 - val_accuracy: 0.6387\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3987 - accuracy: 0.5998 - val_loss: 1.2479 - val_accuracy: 0.6482\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3598 - accuracy: 0.6097 - val_loss: 1.2186 - val_accuracy: 0.6578\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3325 - accuracy: 0.6167 - val_loss: 1.1910 - val_accuracy: 0.6650\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3045 - accuracy: 0.6242 - val_loss: 1.1700 - val_accuracy: 0.6707\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2827 - accuracy: 0.6295 - val_loss: 1.1520 - val_accuracy: 0.6745\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2660 - accuracy: 0.6347 - val_loss: 1.1375 - val_accuracy: 0.6767\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2511 - accuracy: 0.6373 - val_loss: 1.1233 - val_accuracy: 0.6818\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2374 - accuracy: 0.6416 - val_loss: 1.1112 - val_accuracy: 0.6836\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2279 - accuracy: 0.6434 - val_loss: 1.1010 - val_accuracy: 0.6858\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2189 - accuracy: 0.6446 - val_loss: 1.0926 - val_accuracy: 0.6875\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2092 - accuracy: 0.6475 - val_loss: 1.0848 - val_accuracy: 0.6890\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2011 - accuracy: 0.6500 - val_loss: 1.0789 - val_accuracy: 0.6902\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1913 - accuracy: 0.6522 - val_loss: 1.0729 - val_accuracy: 0.6926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:09.599603\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1895 - accuracy: 0.6540 - val_loss: 1.0699 - val_accuracy: 0.6932\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1883 - accuracy: 0.6534 - val_loss: 1.0684 - val_accuracy: 0.6933\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1848 - accuracy: 0.6564 - val_loss: 1.0677 - val_accuracy: 0.6930\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1846 - accuracy: 0.6555 - val_loss: 1.0674 - val_accuracy: 0.6933\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1838 - accuracy: 0.6551 - val_loss: 1.0673 - val_accuracy: 0.6934\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1836 - accuracy: 0.6543 - val_loss: 1.0672 - val_accuracy: 0.6935\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1830 - accuracy: 0.6550 - val_loss: 1.0672 - val_accuracy: 0.6935\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1834 - accuracy: 0.6558 - val_loss: 1.0672 - val_accuracy: 0.6935\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1833 - accuracy: 0.6558 - val_loss: 1.0672 - val_accuracy: 0.6935\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:08.253631\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7917 - accuracy: 0.0548 - val_loss: 3.6775 - val_accuracy: 0.1212\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.3591 - accuracy: 0.2158 - val_loss: 2.8268 - val_accuracy: 0.3816\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.3832 - accuracy: 0.3957 - val_loss: 1.9111 - val_accuracy: 0.5198\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8561 - accuracy: 0.4938 - val_loss: 1.5786 - val_accuracy: 0.5821\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6373 - accuracy: 0.5428 - val_loss: 1.4175 - val_accuracy: 0.6145\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5136 - accuracy: 0.5722 - val_loss: 1.3246 - val_accuracy: 0.6350\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4358 - accuracy: 0.5904 - val_loss: 1.2629 - val_accuracy: 0.6485\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3809 - accuracy: 0.6027 - val_loss: 1.2155 - val_accuracy: 0.6615\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3357 - accuracy: 0.6177 - val_loss: 1.1791 - val_accuracy: 0.6687\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3042 - accuracy: 0.6225 - val_loss: 1.1513 - val_accuracy: 0.6755\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2732 - accuracy: 0.6322 - val_loss: 1.1267 - val_accuracy: 0.6828\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2507 - accuracy: 0.6377 - val_loss: 1.1066 - val_accuracy: 0.6880\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2341 - accuracy: 0.6438 - val_loss: 1.0896 - val_accuracy: 0.6922\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2153 - accuracy: 0.6468 - val_loss: 1.0759 - val_accuracy: 0.6941\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2000 - accuracy: 0.6504 - val_loss: 1.0630 - val_accuracy: 0.6981\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1897 - accuracy: 0.6521 - val_loss: 1.0525 - val_accuracy: 0.6998\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1794 - accuracy: 0.6550 - val_loss: 1.0427 - val_accuracy: 0.7028\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1661 - accuracy: 0.6586 - val_loss: 1.0352 - val_accuracy: 0.7041\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1599 - accuracy: 0.6613 - val_loss: 1.0281 - val_accuracy: 0.7063\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1520 - accuracy: 0.6621 - val_loss: 1.0220 - val_accuracy: 0.7079\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:16.088923\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1498 - accuracy: 0.6627 - val_loss: 1.0191 - val_accuracy: 0.7085\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1457 - accuracy: 0.6628 - val_loss: 1.0175 - val_accuracy: 0.7088\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1436 - accuracy: 0.6656 - val_loss: 1.0168 - val_accuracy: 0.7092\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1451 - accuracy: 0.6646 - val_loss: 1.0164 - val_accuracy: 0.7093\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1439 - accuracy: 0.6653 - val_loss: 1.0163 - val_accuracy: 0.7093\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1423 - accuracy: 0.6640 - val_loss: 1.0162 - val_accuracy: 0.7092\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1448 - accuracy: 0.6640 - val_loss: 1.0162 - val_accuracy: 0.7092\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:12.075710\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7481 - accuracy: 0.0781 - val_loss: 3.5821 - val_accuracy: 0.1931\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1441 - accuracy: 0.2611 - val_loss: 2.5221 - val_accuracy: 0.4183\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.2050 - accuracy: 0.4196 - val_loss: 1.8055 - val_accuracy: 0.5402\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8006 - accuracy: 0.4996 - val_loss: 1.5441 - val_accuracy: 0.5894\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6192 - accuracy: 0.5420 - val_loss: 1.4125 - val_accuracy: 0.6150\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5153 - accuracy: 0.5709 - val_loss: 1.3327 - val_accuracy: 0.6334\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4470 - accuracy: 0.5884 - val_loss: 1.2790 - val_accuracy: 0.6444\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3980 - accuracy: 0.6007 - val_loss: 1.2362 - val_accuracy: 0.6545\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3623 - accuracy: 0.6088 - val_loss: 1.2080 - val_accuracy: 0.6616\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3313 - accuracy: 0.6170 - val_loss: 1.1818 - val_accuracy: 0.6685\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3057 - accuracy: 0.6234 - val_loss: 1.1593 - val_accuracy: 0.6745\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2839 - accuracy: 0.6301 - val_loss: 1.1428 - val_accuracy: 0.6780\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2689 - accuracy: 0.6330 - val_loss: 1.1278 - val_accuracy: 0.6815\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2531 - accuracy: 0.6369 - val_loss: 1.1137 - val_accuracy: 0.6851\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2423 - accuracy: 0.6392 - val_loss: 1.1030 - val_accuracy: 0.6868\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2308 - accuracy: 0.6426 - val_loss: 1.0934 - val_accuracy: 0.6887\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2214 - accuracy: 0.6455 - val_loss: 1.0845 - val_accuracy: 0.6906\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2106 - accuracy: 0.6473 - val_loss: 1.0777 - val_accuracy: 0.6932\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2054 - accuracy: 0.6498 - val_loss: 1.0713 - val_accuracy: 0.6949\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1949 - accuracy: 0.6523 - val_loss: 1.0650 - val_accuracy: 0.6959\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:07.486728\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1928 - accuracy: 0.6531 - val_loss: 1.0625 - val_accuracy: 0.6967\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1909 - accuracy: 0.6533 - val_loss: 1.0612 - val_accuracy: 0.6969\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1907 - accuracy: 0.6529 - val_loss: 1.0606 - val_accuracy: 0.6973\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1923 - accuracy: 0.6531 - val_loss: 1.0603 - val_accuracy: 0.6976\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1891 - accuracy: 0.6539 - val_loss: 1.0602 - val_accuracy: 0.6976\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1895 - accuracy: 0.6538 - val_loss: 1.0601 - val_accuracy: 0.6977\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1894 - accuracy: 0.6537 - val_loss: 1.0601 - val_accuracy: 0.6977\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1864 - accuracy: 0.6548 - val_loss: 1.0601 - val_accuracy: 0.6977\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1898 - accuracy: 0.6547 - val_loss: 1.0601 - val_accuracy: 0.6977\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1881 - accuracy: 0.6542 - val_loss: 1.0601 - val_accuracy: 0.6977\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1892 - accuracy: 0.6532 - val_loss: 1.0601 - val_accuracy: 0.6977\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:01.552701\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.8238 - accuracy: 0.0356 - val_loss: 3.7832 - val_accuracy: 0.0616\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6678 - accuracy: 0.1025 - val_loss: 3.4369 - val_accuracy: 0.1953\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.0217 - accuracy: 0.2431 - val_loss: 2.4023 - val_accuracy: 0.4278\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.2578 - accuracy: 0.3883 - val_loss: 1.8261 - val_accuracy: 0.5353\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9065 - accuracy: 0.4676 - val_loss: 1.5840 - val_accuracy: 0.5838\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7295 - accuracy: 0.5120 - val_loss: 1.4632 - val_accuracy: 0.6063\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6255 - accuracy: 0.5388 - val_loss: 1.3830 - val_accuracy: 0.6190\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5498 - accuracy: 0.5580 - val_loss: 1.3276 - val_accuracy: 0.6314\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4989 - accuracy: 0.5697 - val_loss: 1.2845 - val_accuracy: 0.6427\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4631 - accuracy: 0.5793 - val_loss: 1.2550 - val_accuracy: 0.6489\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4274 - accuracy: 0.5920 - val_loss: 1.2269 - val_accuracy: 0.6575\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4046 - accuracy: 0.5963 - val_loss: 1.2078 - val_accuracy: 0.6609\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3796 - accuracy: 0.6025 - val_loss: 1.1886 - val_accuracy: 0.6655\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3587 - accuracy: 0.6061 - val_loss: 1.1738 - val_accuracy: 0.6696\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3462 - accuracy: 0.6104 - val_loss: 1.1610 - val_accuracy: 0.6730\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3328 - accuracy: 0.6139 - val_loss: 1.1501 - val_accuracy: 0.6757\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3201 - accuracy: 0.6173 - val_loss: 1.1402 - val_accuracy: 0.6777\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3138 - accuracy: 0.6174 - val_loss: 1.1328 - val_accuracy: 0.6799\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3047 - accuracy: 0.6231 - val_loss: 1.1253 - val_accuracy: 0.6820\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2936 - accuracy: 0.6257 - val_loss: 1.1199 - val_accuracy: 0.6831\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:29.459610\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2877 - accuracy: 0.6260 - val_loss: 1.1164 - val_accuracy: 0.6840\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2896 - accuracy: 0.6250 - val_loss: 1.1149 - val_accuracy: 0.6840\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2883 - accuracy: 0.6256 - val_loss: 1.1143 - val_accuracy: 0.6841\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2845 - accuracy: 0.6274 - val_loss: 1.1140 - val_accuracy: 0.6845\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2854 - accuracy: 0.6257 - val_loss: 1.1138 - val_accuracy: 0.6846\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2859 - accuracy: 0.6258 - val_loss: 1.1138 - val_accuracy: 0.6847\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2844 - accuracy: 0.6280 - val_loss: 1.1138 - val_accuracy: 0.6847\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2852 - accuracy: 0.6272 - val_loss: 1.1138 - val_accuracy: 0.6847\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2850 - accuracy: 0.6261 - val_loss: 1.1138 - val_accuracy: 0.6846\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:14.850318\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.8166 - accuracy: 0.0484 - val_loss: 3.7607 - val_accuracy: 0.0863\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5951 - accuracy: 0.1225 - val_loss: 3.2468 - val_accuracy: 0.2714\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.8158 - accuracy: 0.2739 - val_loss: 2.2327 - val_accuracy: 0.4500\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.1762 - accuracy: 0.3999 - val_loss: 1.7805 - val_accuracy: 0.5371\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8671 - accuracy: 0.4757 - val_loss: 1.5584 - val_accuracy: 0.5830\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6957 - accuracy: 0.5179 - val_loss: 1.4358 - val_accuracy: 0.6081\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5927 - accuracy: 0.5434 - val_loss: 1.3560 - val_accuracy: 0.6266\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5141 - accuracy: 0.5638 - val_loss: 1.2966 - val_accuracy: 0.6389\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4610 - accuracy: 0.5788 - val_loss: 1.2548 - val_accuracy: 0.6505\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4177 - accuracy: 0.5896 - val_loss: 1.2202 - val_accuracy: 0.6575\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3838 - accuracy: 0.5989 - val_loss: 1.1905 - val_accuracy: 0.6646\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.3542 - accuracy: 0.6061 - val_loss: 1.1680 - val_accuracy: 0.6691\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3319 - accuracy: 0.6125 - val_loss: 1.1481 - val_accuracy: 0.6759\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3115 - accuracy: 0.6172 - val_loss: 1.1340 - val_accuracy: 0.6794\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2921 - accuracy: 0.6232 - val_loss: 1.1187 - val_accuracy: 0.6825\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.2858 - accuracy: 0.6239 - val_loss: 1.1077 - val_accuracy: 0.6850\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2694 - accuracy: 0.6281 - val_loss: 1.0970 - val_accuracy: 0.6887\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2602 - accuracy: 0.6305 - val_loss: 1.0887 - val_accuracy: 0.6906\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2497 - accuracy: 0.6351 - val_loss: 1.0805 - val_accuracy: 0.6929\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2420 - accuracy: 0.6342 - val_loss: 1.0744 - val_accuracy: 0.6952\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:30.918320\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2367 - accuracy: 0.6375 - val_loss: 1.0707 - val_accuracy: 0.6951\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2315 - accuracy: 0.6391 - val_loss: 1.0689 - val_accuracy: 0.6959\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2315 - accuracy: 0.6394 - val_loss: 1.0680 - val_accuracy: 0.6960\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2337 - accuracy: 0.6386 - val_loss: 1.0677 - val_accuracy: 0.6960\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2276 - accuracy: 0.6389 - val_loss: 1.0675 - val_accuracy: 0.6961\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2321 - accuracy: 0.6390 - val_loss: 1.0674 - val_accuracy: 0.6961\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2329 - accuracy: 0.6399 - val_loss: 1.0674 - val_accuracy: 0.6962\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2302 - accuracy: 0.6400 - val_loss: 1.0674 - val_accuracy: 0.6962\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2284 - accuracy: 0.6397 - val_loss: 1.0674 - val_accuracy: 0.6962\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2327 - accuracy: 0.6385 - val_loss: 1.0674 - val_accuracy: 0.6962\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:43.065533\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.8326 - accuracy: 0.0321 - val_loss: 3.7958 - val_accuracy: 0.0558\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6937 - accuracy: 0.0890 - val_loss: 3.4797 - val_accuracy: 0.1958\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.0753 - accuracy: 0.2390 - val_loss: 2.4583 - val_accuracy: 0.4264\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3004 - accuracy: 0.3789 - val_loss: 1.8498 - val_accuracy: 0.5320\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9198 - accuracy: 0.4609 - val_loss: 1.5953 - val_accuracy: 0.5804\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7325 - accuracy: 0.5084 - val_loss: 1.4631 - val_accuracy: 0.6099\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6183 - accuracy: 0.5378 - val_loss: 1.3832 - val_accuracy: 0.6225\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5482 - accuracy: 0.5561 - val_loss: 1.3272 - val_accuracy: 0.6357\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4931 - accuracy: 0.5692 - val_loss: 1.2858 - val_accuracy: 0.6456\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4475 - accuracy: 0.5812 - val_loss: 1.2517 - val_accuracy: 0.6547\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4167 - accuracy: 0.5915 - val_loss: 1.2234 - val_accuracy: 0.6602\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3886 - accuracy: 0.5976 - val_loss: 1.2033 - val_accuracy: 0.6650\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3640 - accuracy: 0.6043 - val_loss: 1.1839 - val_accuracy: 0.6701\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3430 - accuracy: 0.6091 - val_loss: 1.1678 - val_accuracy: 0.6738\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3299 - accuracy: 0.6146 - val_loss: 1.1551 - val_accuracy: 0.6766\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3141 - accuracy: 0.6172 - val_loss: 1.1433 - val_accuracy: 0.6791\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3047 - accuracy: 0.6198 - val_loss: 1.1328 - val_accuracy: 0.6818\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2940 - accuracy: 0.6211 - val_loss: 1.1257 - val_accuracy: 0.6841\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2801 - accuracy: 0.6266 - val_loss: 1.1164 - val_accuracy: 0.6862\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2729 - accuracy: 0.6286 - val_loss: 1.1106 - val_accuracy: 0.6866\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:28.129421\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2682 - accuracy: 0.6292 - val_loss: 1.1068 - val_accuracy: 0.6883\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2641 - accuracy: 0.6291 - val_loss: 1.1053 - val_accuracy: 0.6891\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2664 - accuracy: 0.6304 - val_loss: 1.1046 - val_accuracy: 0.6892\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2643 - accuracy: 0.6290 - val_loss: 1.1043 - val_accuracy: 0.6893\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2650 - accuracy: 0.6294 - val_loss: 1.1042 - val_accuracy: 0.6893\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2608 - accuracy: 0.6299 - val_loss: 1.1041 - val_accuracy: 0.6894\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2623 - accuracy: 0.6323 - val_loss: 1.1041 - val_accuracy: 0.6894\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2578 - accuracy: 0.6321 - val_loss: 1.1041 - val_accuracy: 0.6894\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2621 - accuracy: 0.6298 - val_loss: 1.1041 - val_accuracy: 0.6894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2620 - accuracy: 0.6310 - val_loss: 1.1041 - val_accuracy: 0.6894\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2628 - accuracy: 0.6302 - val_loss: 1.1041 - val_accuracy: 0.6894\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2622 - accuracy: 0.6298 - val_loss: 1.1041 - val_accuracy: 0.6894\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:38.438444\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8256 - accuracy: 0.0381 - val_loss: 3.7877 - val_accuracy: 0.0630\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6943 - accuracy: 0.0923 - val_loss: 3.5069 - val_accuracy: 0.1817\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.1338 - accuracy: 0.2172 - val_loss: 2.5638 - val_accuracy: 0.4027\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3619 - accuracy: 0.3606 - val_loss: 1.9230 - val_accuracy: 0.5090\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9600 - accuracy: 0.4510 - val_loss: 1.6386 - val_accuracy: 0.5646\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7631 - accuracy: 0.5001 - val_loss: 1.4997 - val_accuracy: 0.5928\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6433 - accuracy: 0.5323 - val_loss: 1.4125 - val_accuracy: 0.6123\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5675 - accuracy: 0.5498 - val_loss: 1.3556 - val_accuracy: 0.6262\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5105 - accuracy: 0.5648 - val_loss: 1.3098 - val_accuracy: 0.6354\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4713 - accuracy: 0.5755 - val_loss: 1.2768 - val_accuracy: 0.6444\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4290 - accuracy: 0.5857 - val_loss: 1.2486 - val_accuracy: 0.6509\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3991 - accuracy: 0.5949 - val_loss: 1.2242 - val_accuracy: 0.6562\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3785 - accuracy: 0.5996 - val_loss: 1.2060 - val_accuracy: 0.6606\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3555 - accuracy: 0.6052 - val_loss: 1.1889 - val_accuracy: 0.6650\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3423 - accuracy: 0.6107 - val_loss: 1.1749 - val_accuracy: 0.6686\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3304 - accuracy: 0.6129 - val_loss: 1.1643 - val_accuracy: 0.6724\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3178 - accuracy: 0.6164 - val_loss: 1.1540 - val_accuracy: 0.6735\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3049 - accuracy: 0.6193 - val_loss: 1.1459 - val_accuracy: 0.6752\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2967 - accuracy: 0.6230 - val_loss: 1.1375 - val_accuracy: 0.6776\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2910 - accuracy: 0.6237 - val_loss: 1.1305 - val_accuracy: 0.6787\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:24.218241\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2874 - accuracy: 0.6235 - val_loss: 1.1273 - val_accuracy: 0.6796\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2807 - accuracy: 0.6249 - val_loss: 1.1257 - val_accuracy: 0.6807\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2771 - accuracy: 0.6285 - val_loss: 1.1250 - val_accuracy: 0.6807\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2804 - accuracy: 0.6264 - val_loss: 1.1247 - val_accuracy: 0.6809\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2799 - accuracy: 0.6271 - val_loss: 1.1246 - val_accuracy: 0.6810\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2791 - accuracy: 0.6265 - val_loss: 1.1245 - val_accuracy: 0.6811\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2816 - accuracy: 0.6262 - val_loss: 1.1245 - val_accuracy: 0.6811\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2793 - accuracy: 0.6250 - val_loss: 1.1245 - val_accuracy: 0.6811\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2794 - accuracy: 0.6253 - val_loss: 1.1245 - val_accuracy: 0.6811\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2759 - accuracy: 0.6260 - val_loss: 1.1245 - val_accuracy: 0.6811\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2815 - accuracy: 0.6251 - val_loss: 1.1245 - val_accuracy: 0.6811\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:05:10.441887\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8088 - accuracy: 0.0419 - val_loss: 3.7445 - val_accuracy: 0.0819\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5465 - accuracy: 0.1239 - val_loss: 3.1717 - val_accuracy: 0.2851\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.7693 - accuracy: 0.2797 - val_loss: 2.2243 - val_accuracy: 0.4612\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.1584 - accuracy: 0.4046 - val_loss: 1.7943 - val_accuracy: 0.5319\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8738 - accuracy: 0.4733 - val_loss: 1.5854 - val_accuracy: 0.5760\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7164 - accuracy: 0.5135 - val_loss: 1.4742 - val_accuracy: 0.5996\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6162 - accuracy: 0.5374 - val_loss: 1.3987 - val_accuracy: 0.6164\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5476 - accuracy: 0.5554 - val_loss: 1.3493 - val_accuracy: 0.6243\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4967 - accuracy: 0.5694 - val_loss: 1.3097 - val_accuracy: 0.6361\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4560 - accuracy: 0.5817 - val_loss: 1.2788 - val_accuracy: 0.6431\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4268 - accuracy: 0.5868 - val_loss: 1.2523 - val_accuracy: 0.6490\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3991 - accuracy: 0.5964 - val_loss: 1.2311 - val_accuracy: 0.6531\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3775 - accuracy: 0.6018 - val_loss: 1.2135 - val_accuracy: 0.6582\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3607 - accuracy: 0.6050 - val_loss: 1.1978 - val_accuracy: 0.6618\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3427 - accuracy: 0.6118 - val_loss: 1.1847 - val_accuracy: 0.6650\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3290 - accuracy: 0.6122 - val_loss: 1.1737 - val_accuracy: 0.6685\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3163 - accuracy: 0.6176 - val_loss: 1.1646 - val_accuracy: 0.6706\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3031 - accuracy: 0.6206 - val_loss: 1.1554 - val_accuracy: 0.6720\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2975 - accuracy: 0.6220 - val_loss: 1.1480 - val_accuracy: 0.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2894 - accuracy: 0.6248 - val_loss: 1.1422 - val_accuracy: 0.6756\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:23.778754\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2844 - accuracy: 0.6255 - val_loss: 1.1392 - val_accuracy: 0.6770\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2823 - accuracy: 0.6265 - val_loss: 1.1375 - val_accuracy: 0.6776\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2796 - accuracy: 0.6267 - val_loss: 1.1367 - val_accuracy: 0.6778\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2791 - accuracy: 0.6271 - val_loss: 1.1364 - val_accuracy: 0.6780\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2779 - accuracy: 0.6275 - val_loss: 1.1362 - val_accuracy: 0.6781\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2792 - accuracy: 0.6266 - val_loss: 1.1362 - val_accuracy: 0.6781\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2770 - accuracy: 0.6269 - val_loss: 1.1361 - val_accuracy: 0.6780\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2790 - accuracy: 0.6258 - val_loss: 1.1361 - val_accuracy: 0.6780\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:45.738174\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 9.6304 - accuracy: 0.0543 - val_loss: 9.3538 - val_accuracy: 0.1078\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.9812 - accuracy: 0.1315 - val_loss: 8.4635 - val_accuracy: 0.2470\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 7.8887 - accuracy: 0.2578 - val_loss: 7.1531 - val_accuracy: 0.4343\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.9096 - accuracy: 0.3798 - val_loss: 6.3386 - val_accuracy: 0.5249\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.2867 - accuracy: 0.4492 - val_loss: 5.8051 - val_accuracy: 0.5690\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.8363 - accuracy: 0.4904 - val_loss: 5.4248 - val_accuracy: 0.5946\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5001 - accuracy: 0.5185 - val_loss: 5.1314 - val_accuracy: 0.6135\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.2353 - accuracy: 0.5344 - val_loss: 4.9008 - val_accuracy: 0.6243\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.0239 - accuracy: 0.5479 - val_loss: 4.7094 - val_accuracy: 0.6335\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.8373 - accuracy: 0.5584 - val_loss: 4.5478 - val_accuracy: 0.6397\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.6919 - accuracy: 0.5665 - val_loss: 4.4131 - val_accuracy: 0.6445\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.5590 - accuracy: 0.5749 - val_loss: 4.2965 - val_accuracy: 0.6485\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.4562 - accuracy: 0.5768 - val_loss: 4.2006 - val_accuracy: 0.6521\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.3551 - accuracy: 0.5838 - val_loss: 4.1130 - val_accuracy: 0.6554\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2803 - accuracy: 0.5844 - val_loss: 4.0401 - val_accuracy: 0.6590\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2075 - accuracy: 0.5898 - val_loss: 3.9789 - val_accuracy: 0.6601\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1511 - accuracy: 0.5912 - val_loss: 3.9214 - val_accuracy: 0.6633\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0929 - accuracy: 0.5963 - val_loss: 3.8732 - val_accuracy: 0.6644\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0477 - accuracy: 0.5975 - val_loss: 3.8307 - val_accuracy: 0.6659\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0030 - accuracy: 0.5997 - val_loss: 3.7932 - val_accuracy: 0.6676\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:01.038186\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9784 - accuracy: 0.5992 - val_loss: 3.7743 - val_accuracy: 0.6676\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9656 - accuracy: 0.6009 - val_loss: 3.7655 - val_accuracy: 0.6680\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9554 - accuracy: 0.6023 - val_loss: 3.7611 - val_accuracy: 0.6680\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9545 - accuracy: 0.5997 - val_loss: 3.7591 - val_accuracy: 0.6684\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9534 - accuracy: 0.6023 - val_loss: 3.7583 - val_accuracy: 0.6682\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9542 - accuracy: 0.6014 - val_loss: 3.7579 - val_accuracy: 0.6683\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9545 - accuracy: 0.5997 - val_loss: 3.7578 - val_accuracy: 0.6682\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:10.363960\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 9.6387 - accuracy: 0.0237 - val_loss: 9.3979 - val_accuracy: 0.0331\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 9.1527 - accuracy: 0.0390 - val_loss: 8.8825 - val_accuracy: 0.0589\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.5351 - accuracy: 0.1097 - val_loss: 8.0560 - val_accuracy: 0.2740\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.5111 - accuracy: 0.2641 - val_loss: 6.8091 - val_accuracy: 0.4483\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.5699 - accuracy: 0.3742 - val_loss: 6.0121 - val_accuracy: 0.5253\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.9829 - accuracy: 0.4371 - val_loss: 5.5272 - val_accuracy: 0.5621\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.5820 - accuracy: 0.4758 - val_loss: 5.1887 - val_accuracy: 0.5827\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.2816 - accuracy: 0.4994 - val_loss: 4.9275 - val_accuracy: 0.5962\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.0460 - accuracy: 0.5156 - val_loss: 4.7146 - val_accuracy: 0.6098\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.8468 - accuracy: 0.5284 - val_loss: 4.5392 - val_accuracy: 0.6191\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.6846 - accuracy: 0.5396 - val_loss: 4.3940 - val_accuracy: 0.6251\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.5510 - accuracy: 0.5464 - val_loss: 4.2723 - val_accuracy: 0.6305\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.4364 - accuracy: 0.5530 - val_loss: 4.1671 - val_accuracy: 0.6359\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.3396 - accuracy: 0.5579 - val_loss: 4.0793 - val_accuracy: 0.6383\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2578 - accuracy: 0.5622 - val_loss: 4.0025 - val_accuracy: 0.6418\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1828 - accuracy: 0.5659 - val_loss: 3.9341 - val_accuracy: 0.6454\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1194 - accuracy: 0.5701 - val_loss: 3.8768 - val_accuracy: 0.6466\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0663 - accuracy: 0.5706 - val_loss: 3.8257 - val_accuracy: 0.6497\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0155 - accuracy: 0.5735 - val_loss: 3.7822 - val_accuracy: 0.6505\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9707 - accuracy: 0.5777 - val_loss: 3.7431 - val_accuracy: 0.6519\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:00.593029\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9444 - accuracy: 0.5771 - val_loss: 3.7240 - val_accuracy: 0.6523\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9282 - accuracy: 0.5801 - val_loss: 3.7145 - val_accuracy: 0.6536\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9200 - accuracy: 0.5790 - val_loss: 3.7100 - val_accuracy: 0.6535\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9183 - accuracy: 0.5791 - val_loss: 3.7079 - val_accuracy: 0.6533\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9151 - accuracy: 0.5791 - val_loss: 3.7070 - val_accuracy: 0.6535\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:15.559611\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 9.6301 - accuracy: 0.0401 - val_loss: 9.3597 - val_accuracy: 0.0757\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 9.0173 - accuracy: 0.1080 - val_loss: 8.5578 - val_accuracy: 0.1996\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.9567 - accuracy: 0.2525 - val_loss: 7.1690 - val_accuracy: 0.4393\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.8969 - accuracy: 0.3873 - val_loss: 6.2848 - val_accuracy: 0.5391\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.2512 - accuracy: 0.4587 - val_loss: 5.7531 - val_accuracy: 0.5833\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.8062 - accuracy: 0.4993 - val_loss: 5.3753 - val_accuracy: 0.6077\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.4793 - accuracy: 0.5224 - val_loss: 5.0887 - val_accuracy: 0.6241\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.2132 - accuracy: 0.5420 - val_loss: 4.8576 - val_accuracy: 0.6350\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.0054 - accuracy: 0.5541 - val_loss: 4.6693 - val_accuracy: 0.6453\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.8269 - accuracy: 0.5617 - val_loss: 4.5086 - val_accuracy: 0.6513\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.6821 - accuracy: 0.5705 - val_loss: 4.3783 - val_accuracy: 0.6564\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.5512 - accuracy: 0.5766 - val_loss: 4.2632 - val_accuracy: 0.6622\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.4473 - accuracy: 0.5828 - val_loss: 4.1666 - val_accuracy: 0.6674\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.3554 - accuracy: 0.5880 - val_loss: 4.0817 - val_accuracy: 0.6695\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2749 - accuracy: 0.5925 - val_loss: 4.0105 - val_accuracy: 0.6741\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2085 - accuracy: 0.5941 - val_loss: 3.9469 - val_accuracy: 0.6760\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1458 - accuracy: 0.5986 - val_loss: 3.8919 - val_accuracy: 0.6777\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0952 - accuracy: 0.5999 - val_loss: 3.8442 - val_accuracy: 0.6788\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0475 - accuracy: 0.6035 - val_loss: 3.8012 - val_accuracy: 0.6805\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0052 - accuracy: 0.6022 - val_loss: 3.7641 - val_accuracy: 0.6822\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:00.598786\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9778 - accuracy: 0.6049 - val_loss: 3.7457 - val_accuracy: 0.6836\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9637 - accuracy: 0.6056 - val_loss: 3.7368 - val_accuracy: 0.6835\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9551 - accuracy: 0.6065 - val_loss: 3.7324 - val_accuracy: 0.6838\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9548 - accuracy: 0.6077 - val_loss: 3.7304 - val_accuracy: 0.6840\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9512 - accuracy: 0.6064 - val_loss: 3.7296 - val_accuracy: 0.6840\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9511 - accuracy: 0.6059 - val_loss: 3.7292 - val_accuracy: 0.6839\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9527 - accuracy: 0.6073 - val_loss: 3.7291 - val_accuracy: 0.6839\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9534 - accuracy: 0.6057 - val_loss: 3.7290 - val_accuracy: 0.6839\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:37.774860\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 9.6209 - accuracy: 0.0427 - val_loss: 9.3451 - val_accuracy: 0.0863\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.9821 - accuracy: 0.1301 - val_loss: 8.4893 - val_accuracy: 0.2343\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.9129 - accuracy: 0.2569 - val_loss: 7.1719 - val_accuracy: 0.4304\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.8951 - accuracy: 0.3786 - val_loss: 6.3088 - val_accuracy: 0.5242\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.2391 - accuracy: 0.4509 - val_loss: 5.7473 - val_accuracy: 0.5758\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.7755 - accuracy: 0.4931 - val_loss: 5.3518 - val_accuracy: 0.6027\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.4275 - accuracy: 0.5223 - val_loss: 5.0504 - val_accuracy: 0.6187\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.1514 - accuracy: 0.5376 - val_loss: 4.8069 - val_accuracy: 0.6305\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.9253 - accuracy: 0.5524 - val_loss: 4.6047 - val_accuracy: 0.6394\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7369 - accuracy: 0.5612 - val_loss: 4.4333 - val_accuracy: 0.6486\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.5780 - accuracy: 0.5706 - val_loss: 4.2898 - val_accuracy: 0.6537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.4426 - accuracy: 0.5767 - val_loss: 4.1650 - val_accuracy: 0.6584\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.3231 - accuracy: 0.5817 - val_loss: 4.0577 - val_accuracy: 0.6626\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2238 - accuracy: 0.5879 - val_loss: 3.9663 - val_accuracy: 0.6679\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1347 - accuracy: 0.5905 - val_loss: 3.8862 - val_accuracy: 0.6706\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0561 - accuracy: 0.5960 - val_loss: 3.8172 - val_accuracy: 0.6717\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9971 - accuracy: 0.5968 - val_loss: 3.7571 - val_accuracy: 0.6749\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9344 - accuracy: 0.6013 - val_loss: 3.7046 - val_accuracy: 0.6785\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8874 - accuracy: 0.6029 - val_loss: 3.6576 - val_accuracy: 0.6797\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8432 - accuracy: 0.6060 - val_loss: 3.6177 - val_accuracy: 0.6809\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:00.924521\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.8111 - accuracy: 0.6057 - val_loss: 3.5973 - val_accuracy: 0.6815\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7919 - accuracy: 0.6091 - val_loss: 3.5872 - val_accuracy: 0.6823\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7864 - accuracy: 0.6069 - val_loss: 3.5824 - val_accuracy: 0.6822\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7847 - accuracy: 0.6071 - val_loss: 3.5802 - val_accuracy: 0.6824\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7819 - accuracy: 0.6084 - val_loss: 3.5793 - val_accuracy: 0.6824\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7811 - accuracy: 0.6078 - val_loss: 3.5788 - val_accuracy: 0.6823\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7811 - accuracy: 0.6080 - val_loss: 3.5787 - val_accuracy: 0.6824\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:14.709120\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 9.6304 - accuracy: 0.0454 - val_loss: 9.3718 - val_accuracy: 0.1029\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 9.0642 - accuracy: 0.1113 - val_loss: 8.6639 - val_accuracy: 0.2053\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 8.1173 - accuracy: 0.2199 - val_loss: 7.3752 - val_accuracy: 0.3972\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.0347 - accuracy: 0.3504 - val_loss: 6.4020 - val_accuracy: 0.5203\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.3168 - accuracy: 0.4360 - val_loss: 5.7967 - val_accuracy: 0.5681\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.8247 - accuracy: 0.4850 - val_loss: 5.3806 - val_accuracy: 0.5981\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.4662 - accuracy: 0.5145 - val_loss: 5.0695 - val_accuracy: 0.6166\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.1849 - accuracy: 0.5330 - val_loss: 4.8260 - val_accuracy: 0.6296\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9584 - accuracy: 0.5492 - val_loss: 4.6246 - val_accuracy: 0.6396\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.7722 - accuracy: 0.5596 - val_loss: 4.4573 - val_accuracy: 0.6464\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.6152 - accuracy: 0.5679 - val_loss: 4.3158 - val_accuracy: 0.6534\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.4802 - accuracy: 0.5771 - val_loss: 4.1929 - val_accuracy: 0.6592\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3650 - accuracy: 0.5809 - val_loss: 4.0911 - val_accuracy: 0.6609\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2686 - accuracy: 0.5875 - val_loss: 4.0036 - val_accuracy: 0.6653\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1832 - accuracy: 0.5912 - val_loss: 3.9275 - val_accuracy: 0.6668\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.1115 - accuracy: 0.5961 - val_loss: 3.8606 - val_accuracy: 0.6700\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0468 - accuracy: 0.5975 - val_loss: 3.8026 - val_accuracy: 0.6722\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9953 - accuracy: 0.5994 - val_loss: 3.7532 - val_accuracy: 0.6741\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9413 - accuracy: 0.6029 - val_loss: 3.7078 - val_accuracy: 0.6756\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9031 - accuracy: 0.6023 - val_loss: 3.6695 - val_accuracy: 0.6769\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:03.014277\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8765 - accuracy: 0.6038 - val_loss: 3.6510 - val_accuracy: 0.6775\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8576 - accuracy: 0.6054 - val_loss: 3.6417 - val_accuracy: 0.6780\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8515 - accuracy: 0.6062 - val_loss: 3.6373 - val_accuracy: 0.6782\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8478 - accuracy: 0.6067 - val_loss: 3.6352 - val_accuracy: 0.6781\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8437 - accuracy: 0.6078 - val_loss: 3.6343 - val_accuracy: 0.6784\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8484 - accuracy: 0.6042 - val_loss: 3.6339 - val_accuracy: 0.6782\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.8423 - accuracy: 0.6087 - val_loss: 3.6337 - val_accuracy: 0.6782\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.8429 - accuracy: 0.6086 - val_loss: 3.6337 - val_accuracy: 0.6782\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:37.747862\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 9.5930 - accuracy: 0.0690 - val_loss: 9.2422 - val_accuracy: 0.1812\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.6843 - accuracy: 0.2425 - val_loss: 7.9203 - val_accuracy: 0.4056\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.3343 - accuracy: 0.4096 - val_loss: 6.7088 - val_accuracy: 0.5366\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.5188 - accuracy: 0.4948 - val_loss: 6.0907 - val_accuracy: 0.5896\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.0085 - accuracy: 0.5410 - val_loss: 5.6537 - val_accuracy: 0.6181\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.6280 - accuracy: 0.5675 - val_loss: 5.3302 - val_accuracy: 0.6363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.3374 - accuracy: 0.5844 - val_loss: 5.0732 - val_accuracy: 0.6468\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.1042 - accuracy: 0.5967 - val_loss: 4.8636 - val_accuracy: 0.6551\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.9057 - accuracy: 0.6076 - val_loss: 4.6891 - val_accuracy: 0.6636\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.7443 - accuracy: 0.6156 - val_loss: 4.5423 - val_accuracy: 0.6687\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.6093 - accuracy: 0.6219 - val_loss: 4.4214 - val_accuracy: 0.6729\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.4922 - accuracy: 0.6262 - val_loss: 4.3148 - val_accuracy: 0.6792\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.3968 - accuracy: 0.6308 - val_loss: 4.2255 - val_accuracy: 0.6797\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.3126 - accuracy: 0.6324 - val_loss: 4.1484 - val_accuracy: 0.6842\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.2364 - accuracy: 0.6382 - val_loss: 4.0811 - val_accuracy: 0.6864\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.1711 - accuracy: 0.6407 - val_loss: 4.0228 - val_accuracy: 0.6883\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.1180 - accuracy: 0.6424 - val_loss: 3.9724 - val_accuracy: 0.6905\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0720 - accuracy: 0.6442 - val_loss: 3.9285 - val_accuracy: 0.6918\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0280 - accuracy: 0.6464 - val_loss: 3.8898 - val_accuracy: 0.6926\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9911 - accuracy: 0.6482 - val_loss: 3.8561 - val_accuracy: 0.6942\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:14.644697\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9657 - accuracy: 0.6486 - val_loss: 3.8393 - val_accuracy: 0.6941\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9542 - accuracy: 0.6494 - val_loss: 3.8312 - val_accuracy: 0.6941\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9485 - accuracy: 0.6511 - val_loss: 3.8274 - val_accuracy: 0.6944\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9444 - accuracy: 0.6497 - val_loss: 3.8256 - val_accuracy: 0.6945\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9458 - accuracy: 0.6499 - val_loss: 3.8248 - val_accuracy: 0.6945\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9425 - accuracy: 0.6515 - val_loss: 3.8245 - val_accuracy: 0.6945\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9414 - accuracy: 0.6504 - val_loss: 3.8243 - val_accuracy: 0.6945\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9415 - accuracy: 0.6519 - val_loss: 3.8243 - val_accuracy: 0.6945\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:41.839824\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 9.5300 - accuracy: 0.1022 - val_loss: 9.0898 - val_accuracy: 0.2351\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.3742 - accuracy: 0.2938 - val_loss: 7.5532 - val_accuracy: 0.4316\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 7.1343 - accuracy: 0.4370 - val_loss: 6.6159 - val_accuracy: 0.5409\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.4574 - accuracy: 0.5098 - val_loss: 6.0764 - val_accuracy: 0.5836\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.9919 - accuracy: 0.5491 - val_loss: 5.6669 - val_accuracy: 0.6106\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.6311 - accuracy: 0.5730 - val_loss: 5.3553 - val_accuracy: 0.6257\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.3516 - accuracy: 0.5910 - val_loss: 5.1045 - val_accuracy: 0.6381\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1222 - accuracy: 0.6012 - val_loss: 4.9003 - val_accuracy: 0.6459\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.9304 - accuracy: 0.6111 - val_loss: 4.7289 - val_accuracy: 0.6533\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7717 - accuracy: 0.6178 - val_loss: 4.5867 - val_accuracy: 0.6590\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6362 - accuracy: 0.6248 - val_loss: 4.4628 - val_accuracy: 0.6635\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5236 - accuracy: 0.6298 - val_loss: 4.3587 - val_accuracy: 0.6683\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4246 - accuracy: 0.6338 - val_loss: 4.2703 - val_accuracy: 0.6710\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3407 - accuracy: 0.6375 - val_loss: 4.1933 - val_accuracy: 0.6742\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2679 - accuracy: 0.6383 - val_loss: 4.1258 - val_accuracy: 0.6763\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2090 - accuracy: 0.6408 - val_loss: 4.0681 - val_accuracy: 0.6794\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1506 - accuracy: 0.6441 - val_loss: 4.0174 - val_accuracy: 0.6813\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1052 - accuracy: 0.6469 - val_loss: 3.9741 - val_accuracy: 0.6834\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0595 - accuracy: 0.6499 - val_loss: 3.9357 - val_accuracy: 0.6838\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0269 - accuracy: 0.6493 - val_loss: 3.9011 - val_accuracy: 0.6867\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:20.934568\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9998 - accuracy: 0.6505 - val_loss: 3.8847 - val_accuracy: 0.6866\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.9854 - accuracy: 0.6520 - val_loss: 3.8765 - val_accuracy: 0.6870\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9843 - accuracy: 0.6510 - val_loss: 3.8727 - val_accuracy: 0.6871\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9776 - accuracy: 0.6526 - val_loss: 3.8709 - val_accuracy: 0.6871\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9778 - accuracy: 0.6505 - val_loss: 3.8701 - val_accuracy: 0.6873\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9752 - accuracy: 0.6526 - val_loss: 3.8697 - val_accuracy: 0.6873\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9763 - accuracy: 0.6512 - val_loss: 3.8696 - val_accuracy: 0.6873\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9752 - accuracy: 0.6534 - val_loss: 3.8696 - val_accuracy: 0.6873\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:47.587617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 9.5784 - accuracy: 0.0775 - val_loss: 9.2016 - val_accuracy: 0.1910\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 8.5759 - accuracy: 0.2596 - val_loss: 7.7382 - val_accuracy: 0.4260\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.2341 - accuracy: 0.4214 - val_loss: 6.6450 - val_accuracy: 0.5459\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.4846 - accuracy: 0.5049 - val_loss: 6.0663 - val_accuracy: 0.5924\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.0018 - accuracy: 0.5442 - val_loss: 5.6410 - val_accuracy: 0.6207\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.6326 - accuracy: 0.5688 - val_loss: 5.3246 - val_accuracy: 0.6374\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.3474 - accuracy: 0.5860 - val_loss: 5.0706 - val_accuracy: 0.6471\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 5.1136 - accuracy: 0.5970 - val_loss: 4.8630 - val_accuracy: 0.6563\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.9241 - accuracy: 0.6060 - val_loss: 4.6937 - val_accuracy: 0.6640\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.7619 - accuracy: 0.6161 - val_loss: 4.5466 - val_accuracy: 0.6694\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6272 - accuracy: 0.6199 - val_loss: 4.4259 - val_accuracy: 0.6746\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.5124 - accuracy: 0.6268 - val_loss: 4.3194 - val_accuracy: 0.6790\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4143 - accuracy: 0.6302 - val_loss: 4.2301 - val_accuracy: 0.6820\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3307 - accuracy: 0.6346 - val_loss: 4.1537 - val_accuracy: 0.6851\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2565 - accuracy: 0.6389 - val_loss: 4.0861 - val_accuracy: 0.6879\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1950 - accuracy: 0.6414 - val_loss: 4.0278 - val_accuracy: 0.6901\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.1380 - accuracy: 0.6433 - val_loss: 3.9773 - val_accuracy: 0.6915\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0937 - accuracy: 0.6438 - val_loss: 3.9331 - val_accuracy: 0.6932\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0506 - accuracy: 0.6480 - val_loss: 3.8950 - val_accuracy: 0.6950\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0111 - accuracy: 0.6496 - val_loss: 3.8614 - val_accuracy: 0.6951\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:18.649324\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9851 - accuracy: 0.6501 - val_loss: 3.8441 - val_accuracy: 0.6970\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9739 - accuracy: 0.6505 - val_loss: 3.8360 - val_accuracy: 0.6970\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9709 - accuracy: 0.6501 - val_loss: 3.8322 - val_accuracy: 0.6973\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9684 - accuracy: 0.6486 - val_loss: 3.8304 - val_accuracy: 0.6973\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9607 - accuracy: 0.6517 - val_loss: 3.8296 - val_accuracy: 0.6975\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9614 - accuracy: 0.6518 - val_loss: 3.8293 - val_accuracy: 0.6975\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9627 - accuracy: 0.6489 - val_loss: 3.8291 - val_accuracy: 0.6975\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9622 - accuracy: 0.6511 - val_loss: 3.8291 - val_accuracy: 0.6974\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:44.225811\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 9.5770 - accuracy: 0.0711 - val_loss: 9.2028 - val_accuracy: 0.1754\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.6273 - accuracy: 0.2440 - val_loss: 7.8774 - val_accuracy: 0.3950\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.3513 - accuracy: 0.3998 - val_loss: 6.7503 - val_accuracy: 0.5194\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.5489 - accuracy: 0.4888 - val_loss: 6.1176 - val_accuracy: 0.5813\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.0267 - accuracy: 0.5347 - val_loss: 5.6691 - val_accuracy: 0.6097\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.6364 - accuracy: 0.5625 - val_loss: 5.3299 - val_accuracy: 0.6281\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.3347 - accuracy: 0.5817 - val_loss: 5.0655 - val_accuracy: 0.6410\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.0892 - accuracy: 0.5937 - val_loss: 4.8493 - val_accuracy: 0.6506\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.8905 - accuracy: 0.6030 - val_loss: 4.6687 - val_accuracy: 0.6584\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7203 - accuracy: 0.6122 - val_loss: 4.5173 - val_accuracy: 0.6650\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5807 - accuracy: 0.6190 - val_loss: 4.3899 - val_accuracy: 0.6687\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4614 - accuracy: 0.6254 - val_loss: 4.2803 - val_accuracy: 0.6750\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3583 - accuracy: 0.6287 - val_loss: 4.1864 - val_accuracy: 0.6778\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2687 - accuracy: 0.6317 - val_loss: 4.1042 - val_accuracy: 0.6815\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1919 - accuracy: 0.6362 - val_loss: 4.0348 - val_accuracy: 0.6838\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1295 - accuracy: 0.6369 - val_loss: 3.9749 - val_accuracy: 0.6858\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0723 - accuracy: 0.6399 - val_loss: 3.9230 - val_accuracy: 0.6879\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0223 - accuracy: 0.6423 - val_loss: 3.8766 - val_accuracy: 0.6898\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9771 - accuracy: 0.6447 - val_loss: 3.8365 - val_accuracy: 0.6909\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9416 - accuracy: 0.6432 - val_loss: 3.8010 - val_accuracy: 0.6922\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:26.247754\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.9118 - accuracy: 0.6465 - val_loss: 3.7835 - val_accuracy: 0.6928\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8988 - accuracy: 0.6483 - val_loss: 3.7750 - val_accuracy: 0.6931\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8922 - accuracy: 0.6470 - val_loss: 3.7709 - val_accuracy: 0.6932\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8899 - accuracy: 0.6485 - val_loss: 3.7690 - val_accuracy: 0.6934\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.8871 - accuracy: 0.6474 - val_loss: 3.7682 - val_accuracy: 0.6934\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8866 - accuracy: 0.6490 - val_loss: 3.7678 - val_accuracy: 0.6934\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8875 - accuracy: 0.6478 - val_loss: 3.7677 - val_accuracy: 0.6934\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8867 - accuracy: 0.6488 - val_loss: 3.7676 - val_accuracy: 0.6934\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8891 - accuracy: 0.6467 - val_loss: 3.7676 - val_accuracy: 0.6934\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:17.676760\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 9.5823 - accuracy: 0.0647 - val_loss: 9.2173 - val_accuracy: 0.1770\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 8.6050 - accuracy: 0.2583 - val_loss: 7.7894 - val_accuracy: 0.4074\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 7.2695 - accuracy: 0.4169 - val_loss: 6.6859 - val_accuracy: 0.5356\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.5172 - accuracy: 0.4945 - val_loss: 6.1010 - val_accuracy: 0.5845\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.0205 - accuracy: 0.5374 - val_loss: 5.6644 - val_accuracy: 0.6114\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.6359 - accuracy: 0.5648 - val_loss: 5.3329 - val_accuracy: 0.6297\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.3396 - accuracy: 0.5819 - val_loss: 5.0707 - val_accuracy: 0.6406\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.0976 - accuracy: 0.5935 - val_loss: 4.8540 - val_accuracy: 0.6516\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.8959 - accuracy: 0.6043 - val_loss: 4.6757 - val_accuracy: 0.6593\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.7319 - accuracy: 0.6123 - val_loss: 4.5236 - val_accuracy: 0.6656\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5900 - accuracy: 0.6177 - val_loss: 4.3944 - val_accuracy: 0.6695\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.4703 - accuracy: 0.6231 - val_loss: 4.2863 - val_accuracy: 0.6728\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3687 - accuracy: 0.6280 - val_loss: 4.1925 - val_accuracy: 0.6759\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.2800 - accuracy: 0.6318 - val_loss: 4.1108 - val_accuracy: 0.6792\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2059 - accuracy: 0.6344 - val_loss: 4.0424 - val_accuracy: 0.6811\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1378 - accuracy: 0.6390 - val_loss: 3.9806 - val_accuracy: 0.6849\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0768 - accuracy: 0.6412 - val_loss: 3.9283 - val_accuracy: 0.6867\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 4.0298 - accuracy: 0.6419 - val_loss: 3.8825 - val_accuracy: 0.6888\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9836 - accuracy: 0.6464 - val_loss: 3.8418 - val_accuracy: 0.6906\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9487 - accuracy: 0.6469 - val_loss: 3.8071 - val_accuracy: 0.6916\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:38.839777\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9184 - accuracy: 0.6481 - val_loss: 3.7894 - val_accuracy: 0.6927\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.9056 - accuracy: 0.6488 - val_loss: 3.7810 - val_accuracy: 0.6935\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9019 - accuracy: 0.6497 - val_loss: 3.7769 - val_accuracy: 0.6935\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8980 - accuracy: 0.6495 - val_loss: 3.7751 - val_accuracy: 0.6937\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9006 - accuracy: 0.6466 - val_loss: 3.7742 - val_accuracy: 0.6937\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8968 - accuracy: 0.6487 - val_loss: 3.7739 - val_accuracy: 0.6938\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8981 - accuracy: 0.6477 - val_loss: 3.7738 - val_accuracy: 0.6938\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8973 - accuracy: 0.6503 - val_loss: 3.7737 - val_accuracy: 0.6938\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8982 - accuracy: 0.6501 - val_loss: 3.7737 - val_accuracy: 0.6938\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8979 - accuracy: 0.6484 - val_loss: 3.7737 - val_accuracy: 0.6938\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:47.420352\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 9.6491 - accuracy: 0.0286 - val_loss: 9.4044 - val_accuracy: 0.0437\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 9.1356 - accuracy: 0.0677 - val_loss: 8.8233 - val_accuracy: 0.1524\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 8.3477 - accuracy: 0.1835 - val_loss: 7.6783 - val_accuracy: 0.3332\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 7.1894 - accuracy: 0.3254 - val_loss: 6.5163 - val_accuracy: 0.4898\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 6.3548 - accuracy: 0.4319 - val_loss: 5.8491 - val_accuracy: 0.5599\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 33s 47ms/step - loss: 5.8322 - accuracy: 0.4866 - val_loss: 5.4327 - val_accuracy: 0.5877\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 5.4710 - accuracy: 0.5167 - val_loss: 5.1234 - val_accuracy: 0.6074\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 5.1895 - accuracy: 0.5377 - val_loss: 4.8748 - val_accuracy: 0.6215\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 33s 47ms/step - loss: 4.9654 - accuracy: 0.5521 - val_loss: 4.6757 - val_accuracy: 0.6327\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 4.7784 - accuracy: 0.5625 - val_loss: 4.5115 - val_accuracy: 0.6392\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 4.6216 - accuracy: 0.5710 - val_loss: 4.3672 - val_accuracy: 0.6476\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.4919 - accuracy: 0.5764 - val_loss: 4.2512 - val_accuracy: 0.6511\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.3808 - accuracy: 0.5822 - val_loss: 4.1487 - val_accuracy: 0.6531\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 4.2817 - accuracy: 0.5886 - val_loss: 4.0606 - val_accuracy: 0.6588\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 4.1958 - accuracy: 0.5930 - val_loss: 3.9845 - val_accuracy: 0.6620\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 32s 46ms/step - loss: 4.1289 - accuracy: 0.5953 - val_loss: 3.9200 - val_accuracy: 0.6639\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 4.0638 - accuracy: 0.5985 - val_loss: 3.8610 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 4.0108 - accuracy: 0.6011 - val_loss: 3.8119 - val_accuracy: 0.6668\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.9602 - accuracy: 0.6032 - val_loss: 3.7668 - val_accuracy: 0.6694\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 3.9203 - accuracy: 0.6053 - val_loss: 3.7279 - val_accuracy: 0.6715\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:10:15.643105\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.8892 - accuracy: 0.6056 - val_loss: 3.7089 - val_accuracy: 0.6715\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.8778 - accuracy: 0.6062 - val_loss: 3.6997 - val_accuracy: 0.6715\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8692 - accuracy: 0.6078 - val_loss: 3.6954 - val_accuracy: 0.6718\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.8643 - accuracy: 0.6089 - val_loss: 3.6933 - val_accuracy: 0.6719\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.8659 - accuracy: 0.6053 - val_loss: 3.6924 - val_accuracy: 0.6720\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 31s 45ms/step - loss: 3.8643 - accuracy: 0.6073 - val_loss: 3.6920 - val_accuracy: 0.6720\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.8589 - accuracy: 0.6087 - val_loss: 3.6919 - val_accuracy: 0.6720\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.8645 - accuracy: 0.6071 - val_loss: 3.6918 - val_accuracy: 0.6720\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:00.910686\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 9.6360 - accuracy: 0.0413 - val_loss: 9.3818 - val_accuracy: 0.0795\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 9.0965 - accuracy: 0.1023 - val_loss: 8.7453 - val_accuracy: 0.2134\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 8.2183 - accuracy: 0.2163 - val_loss: 7.4896 - val_accuracy: 0.3808\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 7.0666 - accuracy: 0.3557 - val_loss: 6.4289 - val_accuracy: 0.5053\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 6.3075 - accuracy: 0.4448 - val_loss: 5.8310 - val_accuracy: 0.5560\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 5.8299 - accuracy: 0.4904 - val_loss: 5.4410 - val_accuracy: 0.5822\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 5.4863 - accuracy: 0.5235 - val_loss: 5.1460 - val_accuracy: 0.6016\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 5.2225 - accuracy: 0.5410 - val_loss: 4.9167 - val_accuracy: 0.6142\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 5.0045 - accuracy: 0.5573 - val_loss: 4.7244 - val_accuracy: 0.6240\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.8320 - accuracy: 0.5659 - val_loss: 4.5711 - val_accuracy: 0.6334\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.6876 - accuracy: 0.5722 - val_loss: 4.4399 - val_accuracy: 0.6375\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.5622 - accuracy: 0.5823 - val_loss: 4.3275 - val_accuracy: 0.6424\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.4610 - accuracy: 0.5861 - val_loss: 4.2343 - val_accuracy: 0.6466\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3719 - accuracy: 0.5908 - val_loss: 4.1515 - val_accuracy: 0.6511\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2933 - accuracy: 0.5936 - val_loss: 4.0816 - val_accuracy: 0.6534\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2233 - accuracy: 0.5977 - val_loss: 4.0214 - val_accuracy: 0.6549\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1664 - accuracy: 0.6009 - val_loss: 3.9668 - val_accuracy: 0.6588\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1160 - accuracy: 0.6021 - val_loss: 3.9205 - val_accuracy: 0.6588\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0765 - accuracy: 0.6026 - val_loss: 3.8817 - val_accuracy: 0.6600\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0352 - accuracy: 0.6058 - val_loss: 3.8459 - val_accuracy: 0.6619\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:48.382780\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.0094 - accuracy: 0.6073 - val_loss: 3.8287 - val_accuracy: 0.6625\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9955 - accuracy: 0.6080 - val_loss: 3.8200 - val_accuracy: 0.6634\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9907 - accuracy: 0.6081 - val_loss: 3.8161 - val_accuracy: 0.6634\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.9827 - accuracy: 0.6091 - val_loss: 3.8142 - val_accuracy: 0.6634\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9825 - accuracy: 0.6099 - val_loss: 3.8134 - val_accuracy: 0.6633\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9859 - accuracy: 0.6077 - val_loss: 3.8130 - val_accuracy: 0.6632\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:55.303544\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 9.6156 - accuracy: 0.0500 - val_loss: 9.3133 - val_accuracy: 0.1152\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.8327 - accuracy: 0.1635 - val_loss: 8.1005 - val_accuracy: 0.3366\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 7.5143 - accuracy: 0.3341 - val_loss: 6.8035 - val_accuracy: 0.4963\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 6.6434 - accuracy: 0.4459 - val_loss: 6.1496 - val_accuracy: 0.5608\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.1077 - accuracy: 0.5050 - val_loss: 5.7025 - val_accuracy: 0.5974\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.7195 - accuracy: 0.5351 - val_loss: 5.3800 - val_accuracy: 0.6164\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.4250 - accuracy: 0.5552 - val_loss: 5.1204 - val_accuracy: 0.6315\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.1906 - accuracy: 0.5701 - val_loss: 4.9152 - val_accuracy: 0.6408\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.9978 - accuracy: 0.5829 - val_loss: 4.7464 - val_accuracy: 0.6481\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.8392 - accuracy: 0.5900 - val_loss: 4.6044 - val_accuracy: 0.6557\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.7047 - accuracy: 0.5972 - val_loss: 4.4841 - val_accuracy: 0.6600\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5910 - accuracy: 0.6052 - val_loss: 4.3827 - val_accuracy: 0.6636\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.4971 - accuracy: 0.6076 - val_loss: 4.2952 - val_accuracy: 0.6681\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.4128 - accuracy: 0.6130 - val_loss: 4.2193 - val_accuracy: 0.6716\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3440 - accuracy: 0.6160 - val_loss: 4.1552 - val_accuracy: 0.6736\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2761 - accuracy: 0.6184 - val_loss: 4.0980 - val_accuracy: 0.6755\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2285 - accuracy: 0.6207 - val_loss: 4.0489 - val_accuracy: 0.6785\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1787 - accuracy: 0.6221 - val_loss: 4.0061 - val_accuracy: 0.6797\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1347 - accuracy: 0.6260 - val_loss: 3.9675 - val_accuracy: 0.6803\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1012 - accuracy: 0.6268 - val_loss: 3.9352 - val_accuracy: 0.6817\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:40.180278\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0764 - accuracy: 0.6280 - val_loss: 3.9188 - val_accuracy: 0.6831\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0650 - accuracy: 0.6267 - val_loss: 3.9109 - val_accuracy: 0.6830\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0563 - accuracy: 0.6291 - val_loss: 3.9071 - val_accuracy: 0.6832\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0540 - accuracy: 0.6290 - val_loss: 3.9054 - val_accuracy: 0.6833\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0523 - accuracy: 0.6282 - val_loss: 3.9046 - val_accuracy: 0.6833\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0530 - accuracy: 0.6290 - val_loss: 3.9042 - val_accuracy: 0.6834\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0516 - accuracy: 0.6313 - val_loss: 3.9041 - val_accuracy: 0.6834\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0542 - accuracy: 0.6304 - val_loss: 3.9041 - val_accuracy: 0.6834\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0552 - accuracy: 0.6293 - val_loss: 3.9041 - val_accuracy: 0.6834\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:21.462109\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 9.6398 - accuracy: 0.0311 - val_loss: 9.3893 - val_accuracy: 0.0484\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 9.1094 - accuracy: 0.0688 - val_loss: 8.7714 - val_accuracy: 0.1340\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.2464 - accuracy: 0.1853 - val_loss: 7.5143 - val_accuracy: 0.3649\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 7.0680 - accuracy: 0.3429 - val_loss: 6.4407 - val_accuracy: 0.4945\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.3086 - accuracy: 0.4375 - val_loss: 5.8337 - val_accuracy: 0.5468\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.8147 - accuracy: 0.4858 - val_loss: 5.4335 - val_accuracy: 0.5778\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.4638 - accuracy: 0.5147 - val_loss: 5.1321 - val_accuracy: 0.5948\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.1877 - accuracy: 0.5369 - val_loss: 4.8930 - val_accuracy: 0.6075\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.9659 - accuracy: 0.5519 - val_loss: 4.6978 - val_accuracy: 0.6165\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.7837 - accuracy: 0.5635 - val_loss: 4.5333 - val_accuracy: 0.6240\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.6328 - accuracy: 0.5719 - val_loss: 4.3979 - val_accuracy: 0.6326\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5011 - accuracy: 0.5793 - val_loss: 4.2816 - val_accuracy: 0.6371\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3937 - accuracy: 0.5851 - val_loss: 4.1827 - val_accuracy: 0.6407\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2976 - accuracy: 0.5898 - val_loss: 4.0974 - val_accuracy: 0.6441\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2151 - accuracy: 0.5942 - val_loss: 4.0236 - val_accuracy: 0.6483\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1483 - accuracy: 0.5981 - val_loss: 3.9605 - val_accuracy: 0.6496\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0824 - accuracy: 0.6011 - val_loss: 3.9040 - val_accuracy: 0.6527\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0377 - accuracy: 0.6026 - val_loss: 3.8572 - val_accuracy: 0.6556\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9892 - accuracy: 0.6048 - val_loss: 3.8151 - val_accuracy: 0.6573\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9505 - accuracy: 0.6061 - val_loss: 3.7784 - val_accuracy: 0.6582\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:42.922538\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9233 - accuracy: 0.6078 - val_loss: 3.7597 - val_accuracy: 0.6591\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9090 - accuracy: 0.6089 - val_loss: 3.7509 - val_accuracy: 0.6597\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8979 - accuracy: 0.6110 - val_loss: 3.7466 - val_accuracy: 0.6599\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8950 - accuracy: 0.6113 - val_loss: 3.7447 - val_accuracy: 0.6602\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.8951 - accuracy: 0.6119 - val_loss: 3.7438 - val_accuracy: 0.6602\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8960 - accuracy: 0.6113 - val_loss: 3.7434 - val_accuracy: 0.6603\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8965 - accuracy: 0.6102 - val_loss: 3.7433 - val_accuracy: 0.6603\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8943 - accuracy: 0.6103 - val_loss: 3.7432 - val_accuracy: 0.6603\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8961 - accuracy: 0.6097 - val_loss: 3.7432 - val_accuracy: 0.6603\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:19.986227\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 9.6196 - accuracy: 0.0431 - val_loss: 9.3522 - val_accuracy: 0.0783\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 41ms/step - loss: 9.0081 - accuracy: 0.1099 - val_loss: 8.5349 - val_accuracy: 0.2370\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 7.9095 - accuracy: 0.2550 - val_loss: 7.1417 - val_accuracy: 0.4365\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.8471 - accuracy: 0.3882 - val_loss: 6.2882 - val_accuracy: 0.5313\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.2013 - accuracy: 0.4664 - val_loss: 5.7568 - val_accuracy: 0.5793\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.7544 - accuracy: 0.5085 - val_loss: 5.3861 - val_accuracy: 0.6045\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.4293 - accuracy: 0.5362 - val_loss: 5.1084 - val_accuracy: 0.6202\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.1702 - accuracy: 0.5529 - val_loss: 4.8817 - val_accuracy: 0.6317\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.9627 - accuracy: 0.5649 - val_loss: 4.6965 - val_accuracy: 0.6418\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.7880 - accuracy: 0.5770 - val_loss: 4.5424 - val_accuracy: 0.6480\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.6479 - accuracy: 0.5833 - val_loss: 4.4135 - val_accuracy: 0.6528\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5230 - accuracy: 0.5889 - val_loss: 4.3027 - val_accuracy: 0.6575\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.4189 - accuracy: 0.5958 - val_loss: 4.2080 - val_accuracy: 0.6607\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3287 - accuracy: 0.6014 - val_loss: 4.1277 - val_accuracy: 0.6633\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2535 - accuracy: 0.6029 - val_loss: 4.0567 - val_accuracy: 0.6658\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1844 - accuracy: 0.6070 - val_loss: 3.9945 - val_accuracy: 0.6678\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1268 - accuracy: 0.6106 - val_loss: 3.9417 - val_accuracy: 0.6690\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0785 - accuracy: 0.6127 - val_loss: 3.8959 - val_accuracy: 0.6707\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0354 - accuracy: 0.6126 - val_loss: 3.8558 - val_accuracy: 0.6724\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9950 - accuracy: 0.6148 - val_loss: 3.8197 - val_accuracy: 0.6746\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:36.849817\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9660 - accuracy: 0.6153 - val_loss: 3.8019 - val_accuracy: 0.6742\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9544 - accuracy: 0.6167 - val_loss: 3.7934 - val_accuracy: 0.6745\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9479 - accuracy: 0.6167 - val_loss: 3.7893 - val_accuracy: 0.6744\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9426 - accuracy: 0.6180 - val_loss: 3.7874 - val_accuracy: 0.6746\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9415 - accuracy: 0.6196 - val_loss: 3.7866 - val_accuracy: 0.6748\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9407 - accuracy: 0.6184 - val_loss: 3.7862 - val_accuracy: 0.6748\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9372 - accuracy: 0.6202 - val_loss: 3.7861 - val_accuracy: 0.6748\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9412 - accuracy: 0.6183 - val_loss: 3.7860 - val_accuracy: 0.6748\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:50.832306\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0530 - accuracy: 0.0513 - val_loss: 4.0005 - val_accuracy: 0.1094\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8471 - accuracy: 0.1295 - val_loss: 3.5480 - val_accuracy: 0.2553\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1478 - accuracy: 0.2579 - val_loss: 2.5922 - val_accuracy: 0.4360\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.5009 - accuracy: 0.3849 - val_loss: 2.0813 - val_accuracy: 0.5332\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.1733 - accuracy: 0.4590 - val_loss: 1.8421 - val_accuracy: 0.5773\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9934 - accuracy: 0.5030 - val_loss: 1.7112 - val_accuracy: 0.5970\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8817 - accuracy: 0.5295 - val_loss: 1.6312 - val_accuracy: 0.6139\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8116 - accuracy: 0.5461 - val_loss: 1.5710 - val_accuracy: 0.6290\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7574 - accuracy: 0.5611 - val_loss: 1.5280 - val_accuracy: 0.6373\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7161 - accuracy: 0.5706 - val_loss: 1.4946 - val_accuracy: 0.6475\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6815 - accuracy: 0.5787 - val_loss: 1.4675 - val_accuracy: 0.6524\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6588 - accuracy: 0.5853 - val_loss: 1.4444 - val_accuracy: 0.6577\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6261 - accuracy: 0.5937 - val_loss: 1.4251 - val_accuracy: 0.6623\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6090 - accuracy: 0.5979 - val_loss: 1.4086 - val_accuracy: 0.6652\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5955 - accuracy: 0.6002 - val_loss: 1.3954 - val_accuracy: 0.6690\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5844 - accuracy: 0.6049 - val_loss: 1.3849 - val_accuracy: 0.6714\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5674 - accuracy: 0.6089 - val_loss: 1.3734 - val_accuracy: 0.6724\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5567 - accuracy: 0.6111 - val_loss: 1.3641 - val_accuracy: 0.6745\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5493 - accuracy: 0.6116 - val_loss: 1.3572 - val_accuracy: 0.6769\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5408 - accuracy: 0.6153 - val_loss: 1.3505 - val_accuracy: 0.6781\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:05.367149\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5362 - accuracy: 0.6150 - val_loss: 1.3476 - val_accuracy: 0.6786\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5348 - accuracy: 0.6153 - val_loss: 1.3460 - val_accuracy: 0.6791\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5302 - accuracy: 0.6173 - val_loss: 1.3452 - val_accuracy: 0.6794\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5278 - accuracy: 0.6194 - val_loss: 1.3449 - val_accuracy: 0.6796\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5330 - accuracy: 0.6168 - val_loss: 1.3447 - val_accuracy: 0.6795\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5303 - accuracy: 0.6169 - val_loss: 1.3447 - val_accuracy: 0.6795\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5282 - accuracy: 0.6164 - val_loss: 1.3447 - val_accuracy: 0.6795\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:10.287837\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0705 - accuracy: 0.0363 - val_loss: 4.0482 - val_accuracy: 0.0673\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.0034 - accuracy: 0.0740 - val_loss: 3.9250 - val_accuracy: 0.0987\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7262 - accuracy: 0.1477 - val_loss: 3.3630 - val_accuracy: 0.2995\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.0293 - accuracy: 0.2776 - val_loss: 2.4851 - val_accuracy: 0.4617\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.4647 - accuracy: 0.3857 - val_loss: 2.0436 - val_accuracy: 0.5394\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.1855 - accuracy: 0.4479 - val_loss: 1.8305 - val_accuracy: 0.5805\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.0316 - accuracy: 0.4873 - val_loss: 1.7101 - val_accuracy: 0.6058\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9298 - accuracy: 0.5131 - val_loss: 1.6288 - val_accuracy: 0.6212\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8575 - accuracy: 0.5308 - val_loss: 1.5699 - val_accuracy: 0.6368\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8097 - accuracy: 0.5433 - val_loss: 1.5272 - val_accuracy: 0.6441\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7682 - accuracy: 0.5547 - val_loss: 1.4940 - val_accuracy: 0.6510\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7306 - accuracy: 0.5649 - val_loss: 1.4638 - val_accuracy: 0.6597\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7038 - accuracy: 0.5698 - val_loss: 1.4411 - val_accuracy: 0.6633\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6780 - accuracy: 0.5773 - val_loss: 1.4214 - val_accuracy: 0.6673\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6550 - accuracy: 0.5833 - val_loss: 1.4035 - val_accuracy: 0.6711\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6410 - accuracy: 0.5871 - val_loss: 1.3898 - val_accuracy: 0.6734\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6297 - accuracy: 0.5910 - val_loss: 1.3788 - val_accuracy: 0.6774\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6174 - accuracy: 0.5944 - val_loss: 1.3691 - val_accuracy: 0.6795\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6066 - accuracy: 0.5967 - val_loss: 1.3598 - val_accuracy: 0.6818\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5955 - accuracy: 0.5972 - val_loss: 1.3515 - val_accuracy: 0.6842\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:08:59.072085\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5865 - accuracy: 0.6013 - val_loss: 1.3472 - val_accuracy: 0.6848\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5838 - accuracy: 0.6010 - val_loss: 1.3453 - val_accuracy: 0.6850\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5860 - accuracy: 0.6002 - val_loss: 1.3446 - val_accuracy: 0.6851\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5813 - accuracy: 0.6017 - val_loss: 1.3442 - val_accuracy: 0.6853\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5802 - accuracy: 0.6021 - val_loss: 1.3440 - val_accuracy: 0.6853\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5838 - accuracy: 0.6013 - val_loss: 1.3439 - val_accuracy: 0.6854\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5828 - accuracy: 0.6032 - val_loss: 1.3439 - val_accuracy: 0.6855\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5839 - accuracy: 0.6021 - val_loss: 1.3439 - val_accuracy: 0.6855\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5816 - accuracy: 0.6008 - val_loss: 1.3439 - val_accuracy: 0.6855\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5816 - accuracy: 0.6029 - val_loss: 1.3439 - val_accuracy: 0.6855\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:32.120948\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0565 - accuracy: 0.0430 - val_loss: 4.0127 - val_accuracy: 0.0721\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9098 - accuracy: 0.0845 - val_loss: 3.7097 - val_accuracy: 0.1433\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.3776 - accuracy: 0.2000 - val_loss: 2.8328 - val_accuracy: 0.3973\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.6712 - accuracy: 0.3429 - val_loss: 2.1943 - val_accuracy: 0.5172\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 2.2824 - accuracy: 0.4264 - val_loss: 1.9040 - val_accuracy: 0.5707\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.0763 - accuracy: 0.4787 - val_loss: 1.7492 - val_accuracy: 0.5972\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9572 - accuracy: 0.5068 - val_loss: 1.6576 - val_accuracy: 0.6172\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8741 - accuracy: 0.5304 - val_loss: 1.5905 - val_accuracy: 0.6316\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8118 - accuracy: 0.5445 - val_loss: 1.5418 - val_accuracy: 0.6409\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7627 - accuracy: 0.5590 - val_loss: 1.5040 - val_accuracy: 0.6477\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7239 - accuracy: 0.5662 - val_loss: 1.4739 - val_accuracy: 0.6548\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6935 - accuracy: 0.5759 - val_loss: 1.4481 - val_accuracy: 0.6618\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6696 - accuracy: 0.5815 - val_loss: 1.4266 - val_accuracy: 0.6660\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6486 - accuracy: 0.5874 - val_loss: 1.4098 - val_accuracy: 0.6677\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6270 - accuracy: 0.5920 - val_loss: 1.3953 - val_accuracy: 0.6720\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6140 - accuracy: 0.5944 - val_loss: 1.3832 - val_accuracy: 0.6742\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6028 - accuracy: 0.5993 - val_loss: 1.3722 - val_accuracy: 0.6772\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5863 - accuracy: 0.6028 - val_loss: 1.3615 - val_accuracy: 0.6790\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5803 - accuracy: 0.6035 - val_loss: 1.3540 - val_accuracy: 0.6814\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5707 - accuracy: 0.6059 - val_loss: 1.3475 - val_accuracy: 0.6817\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.585288\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5617 - accuracy: 0.6090 - val_loss: 1.3435 - val_accuracy: 0.6828\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5653 - accuracy: 0.6086 - val_loss: 1.3420 - val_accuracy: 0.6837\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5641 - accuracy: 0.6077 - val_loss: 1.3413 - val_accuracy: 0.6839\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5582 - accuracy: 0.6096 - val_loss: 1.3409 - val_accuracy: 0.6837\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5587 - accuracy: 0.6091 - val_loss: 1.3407 - val_accuracy: 0.6837\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5595 - accuracy: 0.6083 - val_loss: 1.3407 - val_accuracy: 0.6836\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:43.730320\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0551 - accuracy: 0.0346 - val_loss: 4.0044 - val_accuracy: 0.0738\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8464 - accuracy: 0.1257 - val_loss: 3.5138 - val_accuracy: 0.2445\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.0541 - accuracy: 0.2836 - val_loss: 2.4210 - val_accuracy: 0.4704\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.3787 - accuracy: 0.4117 - val_loss: 1.9643 - val_accuracy: 0.5523\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.0900 - accuracy: 0.4775 - val_loss: 1.7625 - val_accuracy: 0.5920\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.9358 - accuracy: 0.5150 - val_loss: 1.6454 - val_accuracy: 0.6174\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8430 - accuracy: 0.5388 - val_loss: 1.5727 - val_accuracy: 0.6321\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7747 - accuracy: 0.5573 - val_loss: 1.5196 - val_accuracy: 0.6443\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7231 - accuracy: 0.5697 - val_loss: 1.4774 - val_accuracy: 0.6537\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6796 - accuracy: 0.5816 - val_loss: 1.4447 - val_accuracy: 0.6612\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6475 - accuracy: 0.5874 - val_loss: 1.4172 - val_accuracy: 0.6672\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6184 - accuracy: 0.5957 - val_loss: 1.3939 - val_accuracy: 0.6736\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5979 - accuracy: 0.6013 - val_loss: 1.3742 - val_accuracy: 0.6782\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5783 - accuracy: 0.6055 - val_loss: 1.3598 - val_accuracy: 0.6812\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5638 - accuracy: 0.6088 - val_loss: 1.3459 - val_accuracy: 0.6844\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5488 - accuracy: 0.6134 - val_loss: 1.3336 - val_accuracy: 0.6879\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5362 - accuracy: 0.6175 - val_loss: 1.3241 - val_accuracy: 0.6894\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5285 - accuracy: 0.6198 - val_loss: 1.3158 - val_accuracy: 0.6923\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5157 - accuracy: 0.6234 - val_loss: 1.3080 - val_accuracy: 0.6929\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5087 - accuracy: 0.6226 - val_loss: 1.3007 - val_accuracy: 0.6948\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:08.742511\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5014 - accuracy: 0.6267 - val_loss: 1.2974 - val_accuracy: 0.6965\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5022 - accuracy: 0.6242 - val_loss: 1.2958 - val_accuracy: 0.6964\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4963 - accuracy: 0.6273 - val_loss: 1.2950 - val_accuracy: 0.6969\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4984 - accuracy: 0.6253 - val_loss: 1.2947 - val_accuracy: 0.6969\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.4972 - accuracy: 0.6272 - val_loss: 1.2945 - val_accuracy: 0.6969\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5024 - accuracy: 0.6248 - val_loss: 1.2945 - val_accuracy: 0.6969\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5009 - accuracy: 0.6235 - val_loss: 1.2945 - val_accuracy: 0.6969\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:11.495858\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0641 - accuracy: 0.0293 - val_loss: 4.0252 - val_accuracy: 0.0620\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9239 - accuracy: 0.0964 - val_loss: 3.7175 - val_accuracy: 0.2215\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.3177 - accuracy: 0.2319 - val_loss: 2.7256 - val_accuracy: 0.4367\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.5864 - accuracy: 0.3635 - val_loss: 2.1411 - val_accuracy: 0.5291\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.2382 - accuracy: 0.4412 - val_loss: 1.8840 - val_accuracy: 0.5733\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.0503 - accuracy: 0.4879 - val_loss: 1.7460 - val_accuracy: 0.5991\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.9382 - accuracy: 0.5157 - val_loss: 1.6574 - val_accuracy: 0.6162\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8630 - accuracy: 0.5333 - val_loss: 1.5966 - val_accuracy: 0.6281\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8082 - accuracy: 0.5482 - val_loss: 1.5500 - val_accuracy: 0.6392\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.7631 - accuracy: 0.5590 - val_loss: 1.5135 - val_accuracy: 0.6454\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7279 - accuracy: 0.5681 - val_loss: 1.4823 - val_accuracy: 0.6519\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6943 - accuracy: 0.5782 - val_loss: 1.4586 - val_accuracy: 0.6566\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6728 - accuracy: 0.5825 - val_loss: 1.4390 - val_accuracy: 0.6620\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6526 - accuracy: 0.5873 - val_loss: 1.4223 - val_accuracy: 0.6655\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6352 - accuracy: 0.5908 - val_loss: 1.4073 - val_accuracy: 0.6684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6193 - accuracy: 0.5948 - val_loss: 1.3938 - val_accuracy: 0.6728\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6061 - accuracy: 0.5962 - val_loss: 1.3831 - val_accuracy: 0.6742\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5963 - accuracy: 0.6010 - val_loss: 1.3738 - val_accuracy: 0.6764\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5842 - accuracy: 0.6060 - val_loss: 1.3651 - val_accuracy: 0.6785\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5732 - accuracy: 0.6087 - val_loss: 1.3571 - val_accuracy: 0.6807\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:02.951429\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5669 - accuracy: 0.6085 - val_loss: 1.3535 - val_accuracy: 0.6813\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5662 - accuracy: 0.6083 - val_loss: 1.3519 - val_accuracy: 0.6811\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5666 - accuracy: 0.6077 - val_loss: 1.3512 - val_accuracy: 0.6812\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5640 - accuracy: 0.6100 - val_loss: 1.3509 - val_accuracy: 0.6816\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5638 - accuracy: 0.6097 - val_loss: 1.3507 - val_accuracy: 0.6816\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5608 - accuracy: 0.6108 - val_loss: 1.3506 - val_accuracy: 0.6816\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5639 - accuracy: 0.6092 - val_loss: 1.3506 - val_accuracy: 0.6816\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:10.232880\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0132 - accuracy: 0.0665 - val_loss: 3.8827 - val_accuracy: 0.1530\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4845 - accuracy: 0.2312 - val_loss: 2.8650 - val_accuracy: 0.3847\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.5191 - accuracy: 0.3978 - val_loss: 2.0996 - val_accuracy: 0.5204\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.0897 - accuracy: 0.4895 - val_loss: 1.8221 - val_accuracy: 0.5738\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8937 - accuracy: 0.5338 - val_loss: 1.6792 - val_accuracy: 0.6033\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7870 - accuracy: 0.5598 - val_loss: 1.5956 - val_accuracy: 0.6233\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7145 - accuracy: 0.5781 - val_loss: 1.5363 - val_accuracy: 0.6365\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6634 - accuracy: 0.5910 - val_loss: 1.4930 - val_accuracy: 0.6463\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6228 - accuracy: 0.6015 - val_loss: 1.4597 - val_accuracy: 0.6547\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5915 - accuracy: 0.6081 - val_loss: 1.4313 - val_accuracy: 0.6621\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5662 - accuracy: 0.6159 - val_loss: 1.4102 - val_accuracy: 0.6677\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5448 - accuracy: 0.6212 - val_loss: 1.3916 - val_accuracy: 0.6716\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5276 - accuracy: 0.6252 - val_loss: 1.3749 - val_accuracy: 0.6762\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5123 - accuracy: 0.6298 - val_loss: 1.3621 - val_accuracy: 0.6781\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4999 - accuracy: 0.6326 - val_loss: 1.3504 - val_accuracy: 0.6822\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4874 - accuracy: 0.6344 - val_loss: 1.3396 - val_accuracy: 0.6849\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4753 - accuracy: 0.6386 - val_loss: 1.3309 - val_accuracy: 0.6865\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4691 - accuracy: 0.6408 - val_loss: 1.3237 - val_accuracy: 0.6885\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4611 - accuracy: 0.6424 - val_loss: 1.3170 - val_accuracy: 0.6902\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4531 - accuracy: 0.6444 - val_loss: 1.3110 - val_accuracy: 0.6914\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:14.148258\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.4485 - accuracy: 0.6459 - val_loss: 1.3076 - val_accuracy: 0.6917\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.4467 - accuracy: 0.6452 - val_loss: 1.3062 - val_accuracy: 0.6928\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4442 - accuracy: 0.6477 - val_loss: 1.3056 - val_accuracy: 0.6927\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4443 - accuracy: 0.6470 - val_loss: 1.3053 - val_accuracy: 0.6929\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4451 - accuracy: 0.6459 - val_loss: 1.3052 - val_accuracy: 0.6929\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4430 - accuracy: 0.6483 - val_loss: 1.3051 - val_accuracy: 0.6928\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4455 - accuracy: 0.6450 - val_loss: 1.3051 - val_accuracy: 0.6928\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:20.053184\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9934 - accuracy: 0.0706 - val_loss: 3.8461 - val_accuracy: 0.1907\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4457 - accuracy: 0.2465 - val_loss: 2.8711 - val_accuracy: 0.3863\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.5379 - accuracy: 0.3953 - val_loss: 2.1248 - val_accuracy: 0.5186\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.0969 - accuracy: 0.4881 - val_loss: 1.8319 - val_accuracy: 0.5747\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8922 - accuracy: 0.5351 - val_loss: 1.6778 - val_accuracy: 0.6069\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7752 - accuracy: 0.5647 - val_loss: 1.5894 - val_accuracy: 0.6261\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6994 - accuracy: 0.5825 - val_loss: 1.5303 - val_accuracy: 0.6391\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6454 - accuracy: 0.5961 - val_loss: 1.4843 - val_accuracy: 0.6501\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6056 - accuracy: 0.6060 - val_loss: 1.4496 - val_accuracy: 0.6590\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5716 - accuracy: 0.6145 - val_loss: 1.4199 - val_accuracy: 0.6652\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5442 - accuracy: 0.6204 - val_loss: 1.3958 - val_accuracy: 0.6709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5198 - accuracy: 0.6271 - val_loss: 1.3762 - val_accuracy: 0.6768\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5067 - accuracy: 0.6298 - val_loss: 1.3599 - val_accuracy: 0.6813\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4848 - accuracy: 0.6370 - val_loss: 1.3450 - val_accuracy: 0.6835\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4711 - accuracy: 0.6395 - val_loss: 1.3321 - val_accuracy: 0.6897\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4585 - accuracy: 0.6424 - val_loss: 1.3216 - val_accuracy: 0.6910\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4482 - accuracy: 0.6467 - val_loss: 1.3116 - val_accuracy: 0.6938\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4380 - accuracy: 0.6490 - val_loss: 1.3031 - val_accuracy: 0.6956\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4308 - accuracy: 0.6514 - val_loss: 1.2962 - val_accuracy: 0.6976\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4237 - accuracy: 0.6522 - val_loss: 1.2896 - val_accuracy: 0.6987\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:12.885609\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4161 - accuracy: 0.6531 - val_loss: 1.2864 - val_accuracy: 0.6997\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4160 - accuracy: 0.6534 - val_loss: 1.2847 - val_accuracy: 0.7004\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4117 - accuracy: 0.6546 - val_loss: 1.2840 - val_accuracy: 0.7008\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4138 - accuracy: 0.6549 - val_loss: 1.2837 - val_accuracy: 0.7006\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4128 - accuracy: 0.6534 - val_loss: 1.2835 - val_accuracy: 0.7007\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4108 - accuracy: 0.6548 - val_loss: 1.2834 - val_accuracy: 0.7008\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:48.682835\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9531 - accuracy: 0.0904 - val_loss: 3.7111 - val_accuracy: 0.2165\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.1727 - accuracy: 0.2941 - val_loss: 2.5276 - val_accuracy: 0.4565\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.3096 - accuracy: 0.4427 - val_loss: 1.9656 - val_accuracy: 0.5541\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.9752 - accuracy: 0.5162 - val_loss: 1.7462 - val_accuracy: 0.5941\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8176 - accuracy: 0.5529 - val_loss: 1.6210 - val_accuracy: 0.6223\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7139 - accuracy: 0.5784 - val_loss: 1.5428 - val_accuracy: 0.6428\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6450 - accuracy: 0.5952 - val_loss: 1.4875 - val_accuracy: 0.6544\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5886 - accuracy: 0.6099 - val_loss: 1.4420 - val_accuracy: 0.6639\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5527 - accuracy: 0.6179 - val_loss: 1.4090 - val_accuracy: 0.6724\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5153 - accuracy: 0.6285 - val_loss: 1.3813 - val_accuracy: 0.6771\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4868 - accuracy: 0.6354 - val_loss: 1.3558 - val_accuracy: 0.6844\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4611 - accuracy: 0.6427 - val_loss: 1.3352 - val_accuracy: 0.6891\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4425 - accuracy: 0.6460 - val_loss: 1.3180 - val_accuracy: 0.6941\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4236 - accuracy: 0.6505 - val_loss: 1.3021 - val_accuracy: 0.6985\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4115 - accuracy: 0.6536 - val_loss: 1.2893 - val_accuracy: 0.7021\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3964 - accuracy: 0.6576 - val_loss: 1.2783 - val_accuracy: 0.7054\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3851 - accuracy: 0.6614 - val_loss: 1.2686 - val_accuracy: 0.7066\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3741 - accuracy: 0.6664 - val_loss: 1.2600 - val_accuracy: 0.7092\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3674 - accuracy: 0.6653 - val_loss: 1.2525 - val_accuracy: 0.7104\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3605 - accuracy: 0.6664 - val_loss: 1.2459 - val_accuracy: 0.7125\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:15.694009\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3559 - accuracy: 0.6681 - val_loss: 1.2430 - val_accuracy: 0.7130\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.3546 - accuracy: 0.6681 - val_loss: 1.2414 - val_accuracy: 0.7134\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3529 - accuracy: 0.6684 - val_loss: 1.2407 - val_accuracy: 0.7130\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3517 - accuracy: 0.6696 - val_loss: 1.2404 - val_accuracy: 0.7130\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3495 - accuracy: 0.6691 - val_loss: 1.2402 - val_accuracy: 0.7133\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:23.592079\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0245 - accuracy: 0.0562 - val_loss: 3.9125 - val_accuracy: 0.1370\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.5939 - accuracy: 0.2130 - val_loss: 3.0441 - val_accuracy: 0.3795\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.6082 - accuracy: 0.3897 - val_loss: 2.1419 - val_accuracy: 0.5262\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.1033 - accuracy: 0.4841 - val_loss: 1.8325 - val_accuracy: 0.5773\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8977 - accuracy: 0.5333 - val_loss: 1.6833 - val_accuracy: 0.6061\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7802 - accuracy: 0.5604 - val_loss: 1.5938 - val_accuracy: 0.6279\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7090 - accuracy: 0.5806 - val_loss: 1.5333 - val_accuracy: 0.6401\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6535 - accuracy: 0.5920 - val_loss: 1.4873 - val_accuracy: 0.6498\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6115 - accuracy: 0.6029 - val_loss: 1.4551 - val_accuracy: 0.6583\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5770 - accuracy: 0.6121 - val_loss: 1.4259 - val_accuracy: 0.6666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5499 - accuracy: 0.6196 - val_loss: 1.4021 - val_accuracy: 0.6727\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5270 - accuracy: 0.6233 - val_loss: 1.3811 - val_accuracy: 0.6757\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5069 - accuracy: 0.6306 - val_loss: 1.3640 - val_accuracy: 0.6820\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4906 - accuracy: 0.6339 - val_loss: 1.3488 - val_accuracy: 0.6846\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4753 - accuracy: 0.6370 - val_loss: 1.3367 - val_accuracy: 0.6874\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4652 - accuracy: 0.6401 - val_loss: 1.3260 - val_accuracy: 0.6896\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4539 - accuracy: 0.6434 - val_loss: 1.3168 - val_accuracy: 0.6916\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4451 - accuracy: 0.6455 - val_loss: 1.3089 - val_accuracy: 0.6938\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4340 - accuracy: 0.6485 - val_loss: 1.3016 - val_accuracy: 0.6954\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4294 - accuracy: 0.6483 - val_loss: 1.2955 - val_accuracy: 0.6968\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:12.139544\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4199 - accuracy: 0.6521 - val_loss: 1.2922 - val_accuracy: 0.6980\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.4181 - accuracy: 0.6530 - val_loss: 1.2906 - val_accuracy: 0.6981\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4226 - accuracy: 0.6493 - val_loss: 1.2899 - val_accuracy: 0.6983\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4191 - accuracy: 0.6504 - val_loss: 1.2896 - val_accuracy: 0.6984\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4191 - accuracy: 0.6528 - val_loss: 1.2894 - val_accuracy: 0.6984\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4190 - accuracy: 0.6514 - val_loss: 1.2894 - val_accuracy: 0.6984\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4206 - accuracy: 0.6513 - val_loss: 1.2893 - val_accuracy: 0.6984\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4161 - accuracy: 0.6528 - val_loss: 1.2893 - val_accuracy: 0.6984\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:43.990921\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0032 - accuracy: 0.0579 - val_loss: 3.8461 - val_accuracy: 0.1715\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4082 - accuracy: 0.2544 - val_loss: 2.7566 - val_accuracy: 0.4205\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.4360 - accuracy: 0.4195 - val_loss: 2.0290 - val_accuracy: 0.5436\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.0386 - accuracy: 0.5020 - val_loss: 1.7853 - val_accuracy: 0.5908\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8660 - accuracy: 0.5421 - val_loss: 1.6564 - val_accuracy: 0.6148\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7581 - accuracy: 0.5667 - val_loss: 1.5729 - val_accuracy: 0.6327\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6919 - accuracy: 0.5831 - val_loss: 1.5207 - val_accuracy: 0.6436\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6374 - accuracy: 0.5966 - val_loss: 1.4759 - val_accuracy: 0.6540\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.5978 - accuracy: 0.6068 - val_loss: 1.4417 - val_accuracy: 0.6611\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 1.5621 - accuracy: 0.6149 - val_loss: 1.4137 - val_accuracy: 0.6671\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 1.5348 - accuracy: 0.6221 - val_loss: 1.3911 - val_accuracy: 0.6722\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 1.5113 - accuracy: 0.6281 - val_loss: 1.3705 - val_accuracy: 0.6767\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 32s 46ms/step - loss: 1.4934 - accuracy: 0.6320 - val_loss: 1.3549 - val_accuracy: 0.6820\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 1.4756 - accuracy: 0.6378 - val_loss: 1.3394 - val_accuracy: 0.6852\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4580 - accuracy: 0.6415 - val_loss: 1.3263 - val_accuracy: 0.6876\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4473 - accuracy: 0.6443 - val_loss: 1.3162 - val_accuracy: 0.6902\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4378 - accuracy: 0.6477 - val_loss: 1.3073 - val_accuracy: 0.6930\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4290 - accuracy: 0.6494 - val_loss: 1.2997 - val_accuracy: 0.6942\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4196 - accuracy: 0.6516 - val_loss: 1.2918 - val_accuracy: 0.6958\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4172 - accuracy: 0.6520 - val_loss: 1.2855 - val_accuracy: 0.6980\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:39.945831\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4094 - accuracy: 0.6549 - val_loss: 1.2823 - val_accuracy: 0.6982\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4037 - accuracy: 0.6562 - val_loss: 1.2807 - val_accuracy: 0.6985\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4027 - accuracy: 0.6555 - val_loss: 1.2799 - val_accuracy: 0.6987\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4023 - accuracy: 0.6566 - val_loss: 1.2795 - val_accuracy: 0.6989\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4027 - accuracy: 0.6559 - val_loss: 1.2794 - val_accuracy: 0.6989\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4043 - accuracy: 0.6553 - val_loss: 1.2794 - val_accuracy: 0.6990\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4049 - accuracy: 0.6559 - val_loss: 1.2793 - val_accuracy: 0.6990\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4030 - accuracy: 0.6546 - val_loss: 1.2793 - val_accuracy: 0.6990\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4021 - accuracy: 0.6564 - val_loss: 1.2793 - val_accuracy: 0.6990\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:09.060243\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.0660 - accuracy: 0.0368 - val_loss: 4.0354 - val_accuracy: 0.0513\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.9505 - accuracy: 0.0815 - val_loss: 3.7801 - val_accuracy: 0.1855\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.3973 - accuracy: 0.2131 - val_loss: 2.8117 - val_accuracy: 0.4042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 2.6048 - accuracy: 0.3638 - val_loss: 2.1634 - val_accuracy: 0.5184\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.2089 - accuracy: 0.4523 - val_loss: 1.9009 - val_accuracy: 0.5632\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0171 - accuracy: 0.4971 - val_loss: 1.7659 - val_accuracy: 0.5891\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.9015 - accuracy: 0.5256 - val_loss: 1.6829 - val_accuracy: 0.6066\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8237 - accuracy: 0.5465 - val_loss: 1.6257 - val_accuracy: 0.6207\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.7682 - accuracy: 0.5613 - val_loss: 1.5828 - val_accuracy: 0.6295\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7259 - accuracy: 0.5724 - val_loss: 1.5456 - val_accuracy: 0.6387\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6897 - accuracy: 0.5798 - val_loss: 1.5193 - val_accuracy: 0.6455\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.6573 - accuracy: 0.5879 - val_loss: 1.4930 - val_accuracy: 0.6506\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6369 - accuracy: 0.5933 - val_loss: 1.4751 - val_accuracy: 0.6543\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6168 - accuracy: 0.5989 - val_loss: 1.4591 - val_accuracy: 0.6587\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5979 - accuracy: 0.6042 - val_loss: 1.4445 - val_accuracy: 0.6607\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.5848 - accuracy: 0.6084 - val_loss: 1.4331 - val_accuracy: 0.6641\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5745 - accuracy: 0.6104 - val_loss: 1.4221 - val_accuracy: 0.6672\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5621 - accuracy: 0.6125 - val_loss: 1.4133 - val_accuracy: 0.6695\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.5535 - accuracy: 0.6152 - val_loss: 1.4046 - val_accuracy: 0.6720\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.5419 - accuracy: 0.6169 - val_loss: 1.3985 - val_accuracy: 0.6724\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:37.934820\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.5369 - accuracy: 0.6188 - val_loss: 1.3943 - val_accuracy: 0.6744\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.5365 - accuracy: 0.6193 - val_loss: 1.3926 - val_accuracy: 0.6750\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5353 - accuracy: 0.6186 - val_loss: 1.3920 - val_accuracy: 0.6754\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5330 - accuracy: 0.6210 - val_loss: 1.3916 - val_accuracy: 0.6757\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5333 - accuracy: 0.6187 - val_loss: 1.3915 - val_accuracy: 0.6757\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5307 - accuracy: 0.6194 - val_loss: 1.3914 - val_accuracy: 0.6757\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5311 - accuracy: 0.6211 - val_loss: 1.3914 - val_accuracy: 0.6757\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.5305 - accuracy: 0.6216 - val_loss: 1.3913 - val_accuracy: 0.6757\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:49.737886\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0542 - accuracy: 0.0387 - val_loss: 3.9976 - val_accuracy: 0.0724\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8257 - accuracy: 0.1258 - val_loss: 3.4757 - val_accuracy: 0.2766\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.0377 - accuracy: 0.2798 - val_loss: 2.4643 - val_accuracy: 0.4480\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.3980 - accuracy: 0.4025 - val_loss: 2.0379 - val_accuracy: 0.5303\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.1077 - accuracy: 0.4717 - val_loss: 1.8349 - val_accuracy: 0.5693\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.9530 - accuracy: 0.5112 - val_loss: 1.7247 - val_accuracy: 0.5949\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8581 - accuracy: 0.5362 - val_loss: 1.6514 - val_accuracy: 0.6106\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7855 - accuracy: 0.5542 - val_loss: 1.5971 - val_accuracy: 0.6233\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7379 - accuracy: 0.5649 - val_loss: 1.5598 - val_accuracy: 0.6306\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6961 - accuracy: 0.5759 - val_loss: 1.5252 - val_accuracy: 0.6376\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6649 - accuracy: 0.5857 - val_loss: 1.4985 - val_accuracy: 0.6437\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6364 - accuracy: 0.5929 - val_loss: 1.4753 - val_accuracy: 0.6499\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6130 - accuracy: 0.5987 - val_loss: 1.4565 - val_accuracy: 0.6529\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5938 - accuracy: 0.6012 - val_loss: 1.4415 - val_accuracy: 0.6573\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5793 - accuracy: 0.6068 - val_loss: 1.4287 - val_accuracy: 0.6605\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5636 - accuracy: 0.6115 - val_loss: 1.4163 - val_accuracy: 0.6624\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5535 - accuracy: 0.6136 - val_loss: 1.4069 - val_accuracy: 0.6656\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5400 - accuracy: 0.6181 - val_loss: 1.3982 - val_accuracy: 0.6666\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5345 - accuracy: 0.6184 - val_loss: 1.3897 - val_accuracy: 0.6699\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5243 - accuracy: 0.6202 - val_loss: 1.3824 - val_accuracy: 0.6708\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:35.537335\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5155 - accuracy: 0.6243 - val_loss: 1.3792 - val_accuracy: 0.6711\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.5136 - accuracy: 0.6246 - val_loss: 1.3778 - val_accuracy: 0.6719\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5121 - accuracy: 0.6223 - val_loss: 1.3769 - val_accuracy: 0.6718\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5159 - accuracy: 0.6225 - val_loss: 1.3766 - val_accuracy: 0.6721\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5121 - accuracy: 0.6243 - val_loss: 1.3764 - val_accuracy: 0.6720\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5159 - accuracy: 0.6239 - val_loss: 1.3764 - val_accuracy: 0.6721\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5167 - accuracy: 0.6237 - val_loss: 1.3763 - val_accuracy: 0.6721\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5132 - accuracy: 0.6247 - val_loss: 1.3763 - val_accuracy: 0.6721\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5132 - accuracy: 0.6235 - val_loss: 1.3763 - val_accuracy: 0.6721\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5137 - accuracy: 0.6236 - val_loss: 1.3763 - val_accuracy: 0.6721\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:49.587199\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0734 - accuracy: 0.0266 - val_loss: 4.0520 - val_accuracy: 0.0420\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0088 - accuracy: 0.0557 - val_loss: 3.9275 - val_accuracy: 0.1065\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7145 - accuracy: 0.1507 - val_loss: 3.3093 - val_accuracy: 0.3263\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.9480 - accuracy: 0.2983 - val_loss: 2.4130 - val_accuracy: 0.4772\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.3792 - accuracy: 0.4107 - val_loss: 2.0029 - val_accuracy: 0.5480\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.1085 - accuracy: 0.4759 - val_loss: 1.8200 - val_accuracy: 0.5847\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.9699 - accuracy: 0.5103 - val_loss: 1.7199 - val_accuracy: 0.6037\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8772 - accuracy: 0.5335 - val_loss: 1.6526 - val_accuracy: 0.6170\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8146 - accuracy: 0.5501 - val_loss: 1.6035 - val_accuracy: 0.6274\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7677 - accuracy: 0.5610 - val_loss: 1.5669 - val_accuracy: 0.6340\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7328 - accuracy: 0.5701 - val_loss: 1.5370 - val_accuracy: 0.6418\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6983 - accuracy: 0.5786 - val_loss: 1.5115 - val_accuracy: 0.6470\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6783 - accuracy: 0.5834 - val_loss: 1.4918 - val_accuracy: 0.6511\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6569 - accuracy: 0.5908 - val_loss: 1.4760 - val_accuracy: 0.6547\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6339 - accuracy: 0.5950 - val_loss: 1.4602 - val_accuracy: 0.6577\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6212 - accuracy: 0.5984 - val_loss: 1.4479 - val_accuracy: 0.6597\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6093 - accuracy: 0.6019 - val_loss: 1.4365 - val_accuracy: 0.6628\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5985 - accuracy: 0.6041 - val_loss: 1.4274 - val_accuracy: 0.6643\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5911 - accuracy: 0.6063 - val_loss: 1.4197 - val_accuracy: 0.6656\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5804 - accuracy: 0.6093 - val_loss: 1.4122 - val_accuracy: 0.6677\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:36.231818\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 32s 46ms/step - loss: 1.5770 - accuracy: 0.6097 - val_loss: 1.4086 - val_accuracy: 0.6688\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.5720 - accuracy: 0.6115 - val_loss: 1.4070 - val_accuracy: 0.6686\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5686 - accuracy: 0.6112 - val_loss: 1.4061 - val_accuracy: 0.6688\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5691 - accuracy: 0.6113 - val_loss: 1.4058 - val_accuracy: 0.6689\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.5672 - accuracy: 0.6115 - val_loss: 1.4056 - val_accuracy: 0.6689\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.5685 - accuracy: 0.6115 - val_loss: 1.4055 - val_accuracy: 0.6688\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5695 - accuracy: 0.6118 - val_loss: 1.4055 - val_accuracy: 0.6689\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:28.173303\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.0586 - accuracy: 0.0401 - val_loss: 4.0093 - val_accuracy: 0.0776\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 3.8614 - accuracy: 0.1174 - val_loss: 3.5728 - val_accuracy: 0.2307\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 35s 49ms/step - loss: 3.1401 - accuracy: 0.2640 - val_loss: 2.5565 - val_accuracy: 0.4309\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 2.4338 - accuracy: 0.3995 - val_loss: 2.0245 - val_accuracy: 0.5326\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 2.0987 - accuracy: 0.4775 - val_loss: 1.7866 - val_accuracy: 0.5833\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.9244 - accuracy: 0.5216 - val_loss: 1.6716 - val_accuracy: 0.6090\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8255 - accuracy: 0.5467 - val_loss: 1.5914 - val_accuracy: 0.6270\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7551 - accuracy: 0.5630 - val_loss: 1.5384 - val_accuracy: 0.6387\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7026 - accuracy: 0.5804 - val_loss: 1.4946 - val_accuracy: 0.6505\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6649 - accuracy: 0.5873 - val_loss: 1.4660 - val_accuracy: 0.6582\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6271 - accuracy: 0.5980 - val_loss: 1.4363 - val_accuracy: 0.6652\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6039 - accuracy: 0.6042 - val_loss: 1.4142 - val_accuracy: 0.6694\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5825 - accuracy: 0.6098 - val_loss: 1.3961 - val_accuracy: 0.6744\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5654 - accuracy: 0.6154 - val_loss: 1.3802 - val_accuracy: 0.6790\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5453 - accuracy: 0.6178 - val_loss: 1.3675 - val_accuracy: 0.6809\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5318 - accuracy: 0.6239 - val_loss: 1.3555 - val_accuracy: 0.6836\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5212 - accuracy: 0.6241 - val_loss: 1.3454 - val_accuracy: 0.6858\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5085 - accuracy: 0.6298 - val_loss: 1.3368 - val_accuracy: 0.6874\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5015 - accuracy: 0.6296 - val_loss: 1.3294 - val_accuracy: 0.6898\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4941 - accuracy: 0.6306 - val_loss: 1.3226 - val_accuracy: 0.6907\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:49.589689\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4873 - accuracy: 0.6334 - val_loss: 1.3192 - val_accuracy: 0.6914\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.4878 - accuracy: 0.6350 - val_loss: 1.3177 - val_accuracy: 0.6922\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4855 - accuracy: 0.6340 - val_loss: 1.3169 - val_accuracy: 0.6923\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.4857 - accuracy: 0.6326 - val_loss: 1.3166 - val_accuracy: 0.6925\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4829 - accuracy: 0.6340 - val_loss: 1.3164 - val_accuracy: 0.6925\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4862 - accuracy: 0.6342 - val_loss: 1.3164 - val_accuracy: 0.6926\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4852 - accuracy: 0.6347 - val_loss: 1.3164 - val_accuracy: 0.6926\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4840 - accuracy: 0.6330 - val_loss: 1.3163 - val_accuracy: 0.6926\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4832 - accuracy: 0.6362 - val_loss: 1.3163 - val_accuracy: 0.6926\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4847 - accuracy: 0.6350 - val_loss: 1.3163 - val_accuracy: 0.6926\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:49.452072\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0668 - accuracy: 0.0323 - val_loss: 4.0286 - val_accuracy: 0.0557\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9331 - accuracy: 0.0889 - val_loss: 3.7368 - val_accuracy: 0.2123\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.3340 - accuracy: 0.2344 - val_loss: 2.7157 - val_accuracy: 0.4222\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.5448 - accuracy: 0.3767 - val_loss: 2.0804 - val_accuracy: 0.5354\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.1576 - accuracy: 0.4639 - val_loss: 1.8121 - val_accuracy: 0.5836\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.9675 - accuracy: 0.5106 - val_loss: 1.6785 - val_accuracy: 0.6096\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.8559 - accuracy: 0.5362 - val_loss: 1.5918 - val_accuracy: 0.6266\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7822 - accuracy: 0.5581 - val_loss: 1.5364 - val_accuracy: 0.6371\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.7308 - accuracy: 0.5718 - val_loss: 1.4937 - val_accuracy: 0.6478\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6860 - accuracy: 0.5818 - val_loss: 1.4607 - val_accuracy: 0.6549\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6505 - accuracy: 0.5904 - val_loss: 1.4316 - val_accuracy: 0.6618\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.6257 - accuracy: 0.5970 - val_loss: 1.4095 - val_accuracy: 0.6670\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6035 - accuracy: 0.6038 - val_loss: 1.3907 - val_accuracy: 0.6712\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5811 - accuracy: 0.6091 - val_loss: 1.3738 - val_accuracy: 0.6751\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5664 - accuracy: 0.6123 - val_loss: 1.3587 - val_accuracy: 0.6787\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5524 - accuracy: 0.6159 - val_loss: 1.3478 - val_accuracy: 0.6806\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5413 - accuracy: 0.6197 - val_loss: 1.3378 - val_accuracy: 0.6824\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5290 - accuracy: 0.6204 - val_loss: 1.3290 - val_accuracy: 0.6841\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.5210 - accuracy: 0.6242 - val_loss: 1.3209 - val_accuracy: 0.6867\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5129 - accuracy: 0.6263 - val_loss: 1.3144 - val_accuracy: 0.6879\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:40.207345\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.5046 - accuracy: 0.6285 - val_loss: 1.3108 - val_accuracy: 0.6889\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.5015 - accuracy: 0.6302 - val_loss: 1.3090 - val_accuracy: 0.6890\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5018 - accuracy: 0.6291 - val_loss: 1.3082 - val_accuracy: 0.6891\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4992 - accuracy: 0.6290 - val_loss: 1.3079 - val_accuracy: 0.6895\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5007 - accuracy: 0.6289 - val_loss: 1.3077 - val_accuracy: 0.6893\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5005 - accuracy: 0.6293 - val_loss: 1.3077 - val_accuracy: 0.6895\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.5012 - accuracy: 0.6299 - val_loss: 1.3077 - val_accuracy: 0.6895\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': True, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:23.153044\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8241 - accuracy: 0.0458 - val_loss: 3.7788 - val_accuracy: 0.0805\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6202 - accuracy: 0.1567 - val_loss: 3.3075 - val_accuracy: 0.2631\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.6269 - accuracy: 0.3802 - val_loss: 2.0499 - val_accuracy: 0.4698\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7740 - accuracy: 0.5277 - val_loss: 1.6157 - val_accuracy: 0.5568\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.5064 - accuracy: 0.5812 - val_loss: 1.4500 - val_accuracy: 0.5933\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3856 - accuracy: 0.6092 - val_loss: 1.3630 - val_accuracy: 0.6172\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3148 - accuracy: 0.6269 - val_loss: 1.3075 - val_accuracy: 0.6298\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2668 - accuracy: 0.6400 - val_loss: 1.2654 - val_accuracy: 0.6423\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2307 - accuracy: 0.6499 - val_loss: 1.2335 - val_accuracy: 0.6496\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2020 - accuracy: 0.6575 - val_loss: 1.2107 - val_accuracy: 0.6562\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1787 - accuracy: 0.6634 - val_loss: 1.1869 - val_accuracy: 0.6621\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1597 - accuracy: 0.6687 - val_loss: 1.1715 - val_accuracy: 0.6671\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1432 - accuracy: 0.6726 - val_loss: 1.1563 - val_accuracy: 0.6693\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1296 - accuracy: 0.6764 - val_loss: 1.1417 - val_accuracy: 0.6731\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1177 - accuracy: 0.6802 - val_loss: 1.1315 - val_accuracy: 0.6762\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1078 - accuracy: 0.6824 - val_loss: 1.1221 - val_accuracy: 0.6803\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0987 - accuracy: 0.6849 - val_loss: 1.1144 - val_accuracy: 0.6820\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0912 - accuracy: 0.6873 - val_loss: 1.1065 - val_accuracy: 0.6819\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0844 - accuracy: 0.6891 - val_loss: 1.0998 - val_accuracy: 0.6854\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0787 - accuracy: 0.6904 - val_loss: 1.0946 - val_accuracy: 0.6854\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:04.307672\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0740 - accuracy: 0.6920 - val_loss: 1.0918 - val_accuracy: 0.6868\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0719 - accuracy: 0.6923 - val_loss: 1.0903 - val_accuracy: 0.6880\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0707 - accuracy: 0.6926 - val_loss: 1.0897 - val_accuracy: 0.6877\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.0702 - accuracy: 0.6927 - val_loss: 1.0895 - val_accuracy: 0.6875\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0699 - accuracy: 0.6928 - val_loss: 1.0893 - val_accuracy: 0.6876\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:16.518051\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8011 - accuracy: 0.0641 - val_loss: 3.7204 - val_accuracy: 0.0880\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.4285 - accuracy: 0.1587 - val_loss: 2.9282 - val_accuracy: 0.3153\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 2.3140 - accuracy: 0.4246 - val_loss: 1.8721 - val_accuracy: 0.5064\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.6643 - accuracy: 0.5472 - val_loss: 1.5220 - val_accuracy: 0.5823\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4366 - accuracy: 0.5992 - val_loss: 1.3741 - val_accuracy: 0.6164\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3254 - accuracy: 0.6265 - val_loss: 1.2922 - val_accuracy: 0.6368\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2569 - accuracy: 0.6438 - val_loss: 1.2395 - val_accuracy: 0.6522\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2090 - accuracy: 0.6557 - val_loss: 1.1962 - val_accuracy: 0.6606\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1725 - accuracy: 0.6654 - val_loss: 1.1633 - val_accuracy: 0.6715\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1434 - accuracy: 0.6715 - val_loss: 1.1399 - val_accuracy: 0.6749\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1199 - accuracy: 0.6784 - val_loss: 1.1187 - val_accuracy: 0.6838\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1000 - accuracy: 0.6830 - val_loss: 1.1003 - val_accuracy: 0.6888\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0834 - accuracy: 0.6868 - val_loss: 1.0863 - val_accuracy: 0.6938\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0692 - accuracy: 0.6914 - val_loss: 1.0733 - val_accuracy: 0.6969\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0571 - accuracy: 0.6943 - val_loss: 1.0625 - val_accuracy: 0.7002\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0468 - accuracy: 0.6968 - val_loss: 1.0531 - val_accuracy: 0.7020\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0376 - accuracy: 0.6995 - val_loss: 1.0457 - val_accuracy: 0.7029\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0300 - accuracy: 0.7015 - val_loss: 1.0386 - val_accuracy: 0.7046\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0231 - accuracy: 0.7039 - val_loss: 1.0327 - val_accuracy: 0.7068\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0173 - accuracy: 0.7044 - val_loss: 1.0273 - val_accuracy: 0.7072\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.450129\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0128 - accuracy: 0.7069 - val_loss: 1.0245 - val_accuracy: 0.7084\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0105 - accuracy: 0.7072 - val_loss: 1.0229 - val_accuracy: 0.7083\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0094 - accuracy: 0.7074 - val_loss: 1.0223 - val_accuracy: 0.7086\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0088 - accuracy: 0.7076 - val_loss: 1.0220 - val_accuracy: 0.7087\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0086 - accuracy: 0.7077 - val_loss: 1.0219 - val_accuracy: 0.7088\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0085 - accuracy: 0.7077 - val_loss: 1.0219 - val_accuracy: 0.7088\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0084 - accuracy: 0.7077 - val_loss: 1.0219 - val_accuracy: 0.7088\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0084 - accuracy: 0.7076 - val_loss: 1.0218 - val_accuracy: 0.7088\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0084 - accuracy: 0.7076 - val_loss: 1.0218 - val_accuracy: 0.7088\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:06.755017\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.8280 - accuracy: 0.0345 - val_loss: 3.7969 - val_accuracy: 0.0529\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6998 - accuracy: 0.1185 - val_loss: 3.5173 - val_accuracy: 0.1812\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.9669 - accuracy: 0.3038 - val_loss: 2.3225 - val_accuracy: 0.4244\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9392 - accuracy: 0.4931 - val_loss: 1.7061 - val_accuracy: 0.5379\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5675 - accuracy: 0.5680 - val_loss: 1.4820 - val_accuracy: 0.5864\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4116 - accuracy: 0.6051 - val_loss: 1.3726 - val_accuracy: 0.6158\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3256 - accuracy: 0.6268 - val_loss: 1.3047 - val_accuracy: 0.6308\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2679 - accuracy: 0.6408 - val_loss: 1.2578 - val_accuracy: 0.6429\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2259 - accuracy: 0.6529 - val_loss: 1.2200 - val_accuracy: 0.6512\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1930 - accuracy: 0.6604 - val_loss: 1.1927 - val_accuracy: 0.6571\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1663 - accuracy: 0.6679 - val_loss: 1.1678 - val_accuracy: 0.6643\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1444 - accuracy: 0.6732 - val_loss: 1.1493 - val_accuracy: 0.6696\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1260 - accuracy: 0.6786 - val_loss: 1.1316 - val_accuracy: 0.6732\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1104 - accuracy: 0.6817 - val_loss: 1.1178 - val_accuracy: 0.6778\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0971 - accuracy: 0.6850 - val_loss: 1.1056 - val_accuracy: 0.6816\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0857 - accuracy: 0.6876 - val_loss: 1.0951 - val_accuracy: 0.6825\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0758 - accuracy: 0.6911 - val_loss: 1.0861 - val_accuracy: 0.6853\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0671 - accuracy: 0.6928 - val_loss: 1.0782 - val_accuracy: 0.6882\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0597 - accuracy: 0.6947 - val_loss: 1.0714 - val_accuracy: 0.6906\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0531 - accuracy: 0.6964 - val_loss: 1.0656 - val_accuracy: 0.6911\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:10.111184\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0481 - accuracy: 0.6974 - val_loss: 1.0623 - val_accuracy: 0.6930\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.0457 - accuracy: 0.6979 - val_loss: 1.0608 - val_accuracy: 0.6928\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.0445 - accuracy: 0.6985 - val_loss: 1.0601 - val_accuracy: 0.6934\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0439 - accuracy: 0.6987 - val_loss: 1.0598 - val_accuracy: 0.6935\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0436 - accuracy: 0.6987 - val_loss: 1.0596 - val_accuracy: 0.6935\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0435 - accuracy: 0.6987 - val_loss: 1.0596 - val_accuracy: 0.6935\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0434 - accuracy: 0.6987 - val_loss: 1.0596 - val_accuracy: 0.6935\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:20.054454\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.8029 - accuracy: 0.0641 - val_loss: 3.7226 - val_accuracy: 0.1116\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.4025 - accuracy: 0.2005 - val_loss: 2.8320 - val_accuracy: 0.3350\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.2131 - accuracy: 0.4487 - val_loss: 1.8004 - val_accuracy: 0.5176\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6238 - accuracy: 0.5594 - val_loss: 1.4932 - val_accuracy: 0.5864\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4195 - accuracy: 0.6055 - val_loss: 1.3571 - val_accuracy: 0.6188\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3120 - accuracy: 0.6307 - val_loss: 1.2719 - val_accuracy: 0.6423\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2442 - accuracy: 0.6488 - val_loss: 1.2182 - val_accuracy: 0.6562\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1959 - accuracy: 0.6616 - val_loss: 1.1753 - val_accuracy: 0.6660\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1585 - accuracy: 0.6704 - val_loss: 1.1426 - val_accuracy: 0.6750\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1287 - accuracy: 0.6775 - val_loss: 1.1160 - val_accuracy: 0.6785\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1041 - accuracy: 0.6842 - val_loss: 1.0956 - val_accuracy: 0.6845\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0834 - accuracy: 0.6896 - val_loss: 1.0753 - val_accuracy: 0.6907\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0663 - accuracy: 0.6939 - val_loss: 1.0607 - val_accuracy: 0.6937\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0515 - accuracy: 0.6980 - val_loss: 1.0465 - val_accuracy: 0.6976\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0387 - accuracy: 0.7012 - val_loss: 1.0356 - val_accuracy: 0.6985\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0276 - accuracy: 0.7042 - val_loss: 1.0260 - val_accuracy: 0.7010\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0182 - accuracy: 0.7064 - val_loss: 1.0156 - val_accuracy: 0.7051\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0098 - accuracy: 0.7089 - val_loss: 1.0082 - val_accuracy: 0.7060\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0025 - accuracy: 0.7110 - val_loss: 1.0022 - val_accuracy: 0.7080\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9962 - accuracy: 0.7121 - val_loss: 0.9960 - val_accuracy: 0.7098\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:13.846586\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 0.9914 - accuracy: 0.7137 - val_loss: 0.9931 - val_accuracy: 0.7113\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 0.9889 - accuracy: 0.7145 - val_loss: 0.9918 - val_accuracy: 0.7121\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9877 - accuracy: 0.7147 - val_loss: 0.9910 - val_accuracy: 0.7118\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9872 - accuracy: 0.7150 - val_loss: 0.9907 - val_accuracy: 0.7121\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 0.9869 - accuracy: 0.7150 - val_loss: 0.9906 - val_accuracy: 0.7120\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:21.692631\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8382 - accuracy: 0.0213 - val_loss: 3.8237 - val_accuracy: 0.0258\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7873 - accuracy: 0.0550 - val_loss: 3.7270 - val_accuracy: 0.0992\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.5227 - accuracy: 0.1955 - val_loss: 3.1689 - val_accuracy: 0.3165\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.5945 - accuracy: 0.3973 - val_loss: 2.1030 - val_accuracy: 0.4723\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.8580 - accuracy: 0.5135 - val_loss: 1.6734 - val_accuracy: 0.5485\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5846 - accuracy: 0.5677 - val_loss: 1.4988 - val_accuracy: 0.5900\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4570 - accuracy: 0.5947 - val_loss: 1.4062 - val_accuracy: 0.6064\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3804 - accuracy: 0.6127 - val_loss: 1.3427 - val_accuracy: 0.6206\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.3277 - accuracy: 0.6266 - val_loss: 1.2987 - val_accuracy: 0.6319\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2884 - accuracy: 0.6371 - val_loss: 1.2638 - val_accuracy: 0.6403\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2576 - accuracy: 0.6451 - val_loss: 1.2371 - val_accuracy: 0.6476\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2333 - accuracy: 0.6516 - val_loss: 1.2145 - val_accuracy: 0.6522\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.2130 - accuracy: 0.6564 - val_loss: 1.1961 - val_accuracy: 0.6566\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1962 - accuracy: 0.6611 - val_loss: 1.1813 - val_accuracy: 0.6605\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1819 - accuracy: 0.6640 - val_loss: 1.1683 - val_accuracy: 0.6639\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.1696 - accuracy: 0.6677 - val_loss: 1.1573 - val_accuracy: 0.6656\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1592 - accuracy: 0.6703 - val_loss: 1.1478 - val_accuracy: 0.6671\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1501 - accuracy: 0.6727 - val_loss: 1.1393 - val_accuracy: 0.6703\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1422 - accuracy: 0.6746 - val_loss: 1.1319 - val_accuracy: 0.6719\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 1.1354 - accuracy: 0.6759 - val_loss: 1.1259 - val_accuracy: 0.6734\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:10.230761\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1302 - accuracy: 0.6772 - val_loss: 1.1226 - val_accuracy: 0.6740\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1277 - accuracy: 0.6782 - val_loss: 1.1209 - val_accuracy: 0.6749\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1264 - accuracy: 0.6786 - val_loss: 1.1202 - val_accuracy: 0.6751\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1259 - accuracy: 0.6787 - val_loss: 1.1199 - val_accuracy: 0.6752\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1256 - accuracy: 0.6788 - val_loss: 1.1197 - val_accuracy: 0.6752\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1254 - accuracy: 0.6789 - val_loss: 1.1197 - val_accuracy: 0.6753\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1254 - accuracy: 0.6789 - val_loss: 1.1197 - val_accuracy: 0.6753\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1254 - accuracy: 0.6789 - val_loss: 1.1197 - val_accuracy: 0.6753\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1254 - accuracy: 0.6789 - val_loss: 1.1197 - val_accuracy: 0.6753\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:13.272388\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7352 - accuracy: 0.0751 - val_loss: 3.5186 - val_accuracy: 0.1929\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.9057 - accuracy: 0.3346 - val_loss: 2.1872 - val_accuracy: 0.4708\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8257 - accuracy: 0.5305 - val_loss: 1.5828 - val_accuracy: 0.5735\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4869 - accuracy: 0.5912 - val_loss: 1.3960 - val_accuracy: 0.6117\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3488 - accuracy: 0.6229 - val_loss: 1.2937 - val_accuracy: 0.6383\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2668 - accuracy: 0.6426 - val_loss: 1.2336 - val_accuracy: 0.6497\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2117 - accuracy: 0.6571 - val_loss: 1.1885 - val_accuracy: 0.6606\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1698 - accuracy: 0.6681 - val_loss: 1.1510 - val_accuracy: 0.6709\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1371 - accuracy: 0.6764 - val_loss: 1.1225 - val_accuracy: 0.6771\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1101 - accuracy: 0.6836 - val_loss: 1.1000 - val_accuracy: 0.6826\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0878 - accuracy: 0.6890 - val_loss: 1.0790 - val_accuracy: 0.6880\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0686 - accuracy: 0.6945 - val_loss: 1.0625 - val_accuracy: 0.6935\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0524 - accuracy: 0.6987 - val_loss: 1.0475 - val_accuracy: 0.6965\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0387 - accuracy: 0.7022 - val_loss: 1.0353 - val_accuracy: 0.7005\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0265 - accuracy: 0.7057 - val_loss: 1.0250 - val_accuracy: 0.7026\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0162 - accuracy: 0.7079 - val_loss: 1.0153 - val_accuracy: 0.7052\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0072 - accuracy: 0.7105 - val_loss: 1.0076 - val_accuracy: 0.7058\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9993 - accuracy: 0.7125 - val_loss: 1.0005 - val_accuracy: 0.7086\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9925 - accuracy: 0.7147 - val_loss: 0.9945 - val_accuracy: 0.7097\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9864 - accuracy: 0.7167 - val_loss: 0.9887 - val_accuracy: 0.7109\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:10.802264\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9818 - accuracy: 0.7177 - val_loss: 0.9859 - val_accuracy: 0.7118\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9796 - accuracy: 0.7181 - val_loss: 0.9844 - val_accuracy: 0.7113\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9784 - accuracy: 0.7186 - val_loss: 0.9838 - val_accuracy: 0.7114\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9779 - accuracy: 0.7189 - val_loss: 0.9835 - val_accuracy: 0.7116\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:50.007276\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7486 - accuracy: 0.0782 - val_loss: 3.5728 - val_accuracy: 0.1782\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.0532 - accuracy: 0.3072 - val_loss: 2.3984 - val_accuracy: 0.4207\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9537 - accuracy: 0.5056 - val_loss: 1.6635 - val_accuracy: 0.5526\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5385 - accuracy: 0.5834 - val_loss: 1.4430 - val_accuracy: 0.5933\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3874 - accuracy: 0.6159 - val_loss: 1.3397 - val_accuracy: 0.6166\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3040 - accuracy: 0.6346 - val_loss: 1.2749 - val_accuracy: 0.6332\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2483 - accuracy: 0.6478 - val_loss: 1.2282 - val_accuracy: 0.6453\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2062 - accuracy: 0.6591 - val_loss: 1.1913 - val_accuracy: 0.6561\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1733 - accuracy: 0.6679 - val_loss: 1.1617 - val_accuracy: 0.6651\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1460 - accuracy: 0.6748 - val_loss: 1.1389 - val_accuracy: 0.6719\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1235 - accuracy: 0.6806 - val_loss: 1.1185 - val_accuracy: 0.6756\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1043 - accuracy: 0.6845 - val_loss: 1.1012 - val_accuracy: 0.6813\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0880 - accuracy: 0.6890 - val_loss: 1.0861 - val_accuracy: 0.6865\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0738 - accuracy: 0.6920 - val_loss: 1.0744 - val_accuracy: 0.6898\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0617 - accuracy: 0.6951 - val_loss: 1.0625 - val_accuracy: 0.6922\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0509 - accuracy: 0.6982 - val_loss: 1.0536 - val_accuracy: 0.6959\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0416 - accuracy: 0.7004 - val_loss: 1.0455 - val_accuracy: 0.6974\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0336 - accuracy: 0.7021 - val_loss: 1.0378 - val_accuracy: 0.6980\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0264 - accuracy: 0.7043 - val_loss: 1.0311 - val_accuracy: 0.7015\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0202 - accuracy: 0.7058 - val_loss: 1.0255 - val_accuracy: 0.7024\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:09.366190\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0154 - accuracy: 0.7076 - val_loss: 1.0227 - val_accuracy: 0.7036\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0130 - accuracy: 0.7081 - val_loss: 1.0213 - val_accuracy: 0.7035\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0118 - accuracy: 0.7085 - val_loss: 1.0206 - val_accuracy: 0.7039\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0113 - accuracy: 0.7084 - val_loss: 1.0203 - val_accuracy: 0.7038\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0110 - accuracy: 0.7085 - val_loss: 1.0202 - val_accuracy: 0.7038\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0109 - accuracy: 0.7085 - val_loss: 1.0201 - val_accuracy: 0.7038\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:44.481849\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7485 - accuracy: 0.1080 - val_loss: 3.5861 - val_accuracy: 0.1761\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1159 - accuracy: 0.2850 - val_loss: 2.4758 - val_accuracy: 0.4082\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.9862 - accuracy: 0.4964 - val_loss: 1.6660 - val_accuracy: 0.5547\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5245 - accuracy: 0.5828 - val_loss: 1.4277 - val_accuracy: 0.6049\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3624 - accuracy: 0.6191 - val_loss: 1.3173 - val_accuracy: 0.6346\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2756 - accuracy: 0.6410 - val_loss: 1.2502 - val_accuracy: 0.6504\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2191 - accuracy: 0.6550 - val_loss: 1.2040 - val_accuracy: 0.6625\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1774 - accuracy: 0.6662 - val_loss: 1.1680 - val_accuracy: 0.6709\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1448 - accuracy: 0.6748 - val_loss: 1.1414 - val_accuracy: 0.6766\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1183 - accuracy: 0.6810 - val_loss: 1.1155 - val_accuracy: 0.6841\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0960 - accuracy: 0.6863 - val_loss: 1.0953 - val_accuracy: 0.6902\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0772 - accuracy: 0.6913 - val_loss: 1.0785 - val_accuracy: 0.6938\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0615 - accuracy: 0.6960 - val_loss: 1.0640 - val_accuracy: 0.6967\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0477 - accuracy: 0.6992 - val_loss: 1.0513 - val_accuracy: 0.7018\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0359 - accuracy: 0.7019 - val_loss: 1.0410 - val_accuracy: 0.7032\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0256 - accuracy: 0.7050 - val_loss: 1.0314 - val_accuracy: 0.7060\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0168 - accuracy: 0.7068 - val_loss: 1.0233 - val_accuracy: 0.7095\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0090 - accuracy: 0.7086 - val_loss: 1.0166 - val_accuracy: 0.7091\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.0023 - accuracy: 0.7104 - val_loss: 1.0103 - val_accuracy: 0.7124\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9962 - accuracy: 0.7120 - val_loss: 1.0048 - val_accuracy: 0.7128\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:09.954826\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9917 - accuracy: 0.7132 - val_loss: 1.0017 - val_accuracy: 0.7122\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9894 - accuracy: 0.7138 - val_loss: 1.0004 - val_accuracy: 0.7129\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9882 - accuracy: 0.7143 - val_loss: 0.9997 - val_accuracy: 0.7133\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9877 - accuracy: 0.7142 - val_loss: 0.9994 - val_accuracy: 0.7133\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9874 - accuracy: 0.7142 - val_loss: 0.9993 - val_accuracy: 0.7134\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9873 - accuracy: 0.7144 - val_loss: 0.9993 - val_accuracy: 0.7134\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 0.9873 - accuracy: 0.7144 - val_loss: 0.9992 - val_accuracy: 0.7134\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9873 - accuracy: 0.7144 - val_loss: 0.9992 - val_accuracy: 0.7134\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9873 - accuracy: 0.7144 - val_loss: 0.9992 - val_accuracy: 0.7134\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:04:07.143104\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7819 - accuracy: 0.0819 - val_loss: 3.6704 - val_accuracy: 0.1448\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.3110 - accuracy: 0.2637 - val_loss: 2.7513 - val_accuracy: 0.3833\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.1776 - accuracy: 0.4756 - val_loss: 1.7836 - val_accuracy: 0.5435\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6024 - accuracy: 0.5736 - val_loss: 1.4924 - val_accuracy: 0.5960\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4075 - accuracy: 0.6121 - val_loss: 1.3623 - val_accuracy: 0.6264\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3076 - accuracy: 0.6342 - val_loss: 1.2920 - val_accuracy: 0.6438\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2449 - accuracy: 0.6490 - val_loss: 1.2384 - val_accuracy: 0.6576\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2004 - accuracy: 0.6605 - val_loss: 1.2026 - val_accuracy: 0.6645\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1658 - accuracy: 0.6684 - val_loss: 1.1729 - val_accuracy: 0.6705\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1386 - accuracy: 0.6763 - val_loss: 1.1489 - val_accuracy: 0.6782\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1159 - accuracy: 0.6823 - val_loss: 1.1301 - val_accuracy: 0.6844\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0970 - accuracy: 0.6860 - val_loss: 1.1130 - val_accuracy: 0.6870\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0810 - accuracy: 0.6908 - val_loss: 1.0995 - val_accuracy: 0.6911\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0672 - accuracy: 0.6942 - val_loss: 1.0872 - val_accuracy: 0.6930\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0554 - accuracy: 0.6965 - val_loss: 1.0765 - val_accuracy: 0.6956\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0451 - accuracy: 0.6989 - val_loss: 1.0670 - val_accuracy: 0.6990\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0363 - accuracy: 0.7017 - val_loss: 1.0598 - val_accuracy: 0.7008\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0285 - accuracy: 0.7036 - val_loss: 1.0524 - val_accuracy: 0.7023\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0218 - accuracy: 0.7047 - val_loss: 1.0461 - val_accuracy: 0.7040\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0158 - accuracy: 0.7064 - val_loss: 1.0411 - val_accuracy: 0.7063\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:07.781467\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0113 - accuracy: 0.7079 - val_loss: 1.0386 - val_accuracy: 0.7055\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0090 - accuracy: 0.7080 - val_loss: 1.0371 - val_accuracy: 0.7069\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0079 - accuracy: 0.7085 - val_loss: 1.0365 - val_accuracy: 0.7067\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0074 - accuracy: 0.7085 - val_loss: 1.0362 - val_accuracy: 0.7070\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0071 - accuracy: 0.7086 - val_loss: 1.0361 - val_accuracy: 0.7071\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0070 - accuracy: 0.7087 - val_loss: 1.0360 - val_accuracy: 0.7070\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0070 - accuracy: 0.7087 - val_loss: 1.0360 - val_accuracy: 0.7070\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0069 - accuracy: 0.7087 - val_loss: 1.0360 - val_accuracy: 0.7070\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:39.459341\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.7164 - accuracy: 0.1006 - val_loss: 3.4789 - val_accuracy: 0.2041\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.8366 - accuracy: 0.3433 - val_loss: 2.1558 - val_accuracy: 0.4688\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8043 - accuracy: 0.5272 - val_loss: 1.5899 - val_accuracy: 0.5700\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4859 - accuracy: 0.5893 - val_loss: 1.4078 - val_accuracy: 0.6129\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3565 - accuracy: 0.6185 - val_loss: 1.3123 - val_accuracy: 0.6361\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2784 - accuracy: 0.6387 - val_loss: 1.2510 - val_accuracy: 0.6494\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2252 - accuracy: 0.6521 - val_loss: 1.2039 - val_accuracy: 0.6604\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1847 - accuracy: 0.6634 - val_loss: 1.1695 - val_accuracy: 0.6700\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1526 - accuracy: 0.6720 - val_loss: 1.1425 - val_accuracy: 0.6781\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.1262 - accuracy: 0.6785 - val_loss: 1.1185 - val_accuracy: 0.6836\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.1042 - accuracy: 0.6847 - val_loss: 1.0982 - val_accuracy: 0.6871\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0854 - accuracy: 0.6898 - val_loss: 1.0803 - val_accuracy: 0.6919\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0695 - accuracy: 0.6938 - val_loss: 1.0654 - val_accuracy: 0.6945\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0555 - accuracy: 0.6973 - val_loss: 1.0530 - val_accuracy: 0.6985\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0438 - accuracy: 0.7002 - val_loss: 1.0424 - val_accuracy: 0.7003\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0333 - accuracy: 0.7034 - val_loss: 1.0328 - val_accuracy: 0.7035\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0244 - accuracy: 0.7051 - val_loss: 1.0245 - val_accuracy: 0.7065\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0165 - accuracy: 0.7072 - val_loss: 1.0171 - val_accuracy: 0.7077\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0096 - accuracy: 0.7089 - val_loss: 1.0114 - val_accuracy: 0.7093\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.0037 - accuracy: 0.7103 - val_loss: 1.0052 - val_accuracy: 0.7112\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:09.463673\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9989 - accuracy: 0.7120 - val_loss: 1.0024 - val_accuracy: 0.7124\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9967 - accuracy: 0.7123 - val_loss: 1.0012 - val_accuracy: 0.7122\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9955 - accuracy: 0.7126 - val_loss: 1.0005 - val_accuracy: 0.7120\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 0.9950 - accuracy: 0.7126 - val_loss: 1.0002 - val_accuracy: 0.7121\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:49.830646\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8315 - accuracy: 0.0552 - val_loss: 3.7945 - val_accuracy: 0.0898\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6613 - accuracy: 0.1280 - val_loss: 3.3992 - val_accuracy: 0.1905\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 2.7273 - accuracy: 0.3513 - val_loss: 2.1088 - val_accuracy: 0.4571\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8012 - accuracy: 0.5199 - val_loss: 1.6379 - val_accuracy: 0.5524\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5161 - accuracy: 0.5815 - val_loss: 1.4698 - val_accuracy: 0.5960\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3909 - accuracy: 0.6128 - val_loss: 1.3798 - val_accuracy: 0.6179\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3174 - accuracy: 0.6303 - val_loss: 1.3178 - val_accuracy: 0.6336\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2669 - accuracy: 0.6429 - val_loss: 1.2762 - val_accuracy: 0.6454\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2288 - accuracy: 0.6532 - val_loss: 1.2419 - val_accuracy: 0.6505\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1987 - accuracy: 0.6610 - val_loss: 1.2155 - val_accuracy: 0.6594\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1745 - accuracy: 0.6684 - val_loss: 1.1919 - val_accuracy: 0.6649\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1543 - accuracy: 0.6736 - val_loss: 1.1750 - val_accuracy: 0.6669\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1371 - accuracy: 0.6779 - val_loss: 1.1589 - val_accuracy: 0.6723\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1226 - accuracy: 0.6807 - val_loss: 1.1457 - val_accuracy: 0.6761\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1102 - accuracy: 0.6851 - val_loss: 1.1354 - val_accuracy: 0.6771\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0997 - accuracy: 0.6871 - val_loss: 1.1248 - val_accuracy: 0.6818\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0904 - accuracy: 0.6894 - val_loss: 1.1170 - val_accuracy: 0.6831\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0823 - accuracy: 0.6914 - val_loss: 1.1093 - val_accuracy: 0.6858\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0753 - accuracy: 0.6935 - val_loss: 1.1019 - val_accuracy: 0.6871\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0692 - accuracy: 0.6949 - val_loss: 1.0964 - val_accuracy: 0.6897\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:28.532466\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0645 - accuracy: 0.6962 - val_loss: 1.0935 - val_accuracy: 0.6902\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0621 - accuracy: 0.6972 - val_loss: 1.0922 - val_accuracy: 0.6904\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0609 - accuracy: 0.6973 - val_loss: 1.0915 - val_accuracy: 0.6902\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.0604 - accuracy: 0.6975 - val_loss: 1.0912 - val_accuracy: 0.6904\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0601 - accuracy: 0.6976 - val_loss: 1.0911 - val_accuracy: 0.6906\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0600 - accuracy: 0.6976 - val_loss: 1.0910 - val_accuracy: 0.6906\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0600 - accuracy: 0.6977 - val_loss: 1.0910 - val_accuracy: 0.6906\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 1.0599 - accuracy: 0.6977 - val_loss: 1.0910 - val_accuracy: 0.6906\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0599 - accuracy: 0.6977 - val_loss: 1.0910 - val_accuracy: 0.6906\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:16.240501\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7990 - accuracy: 0.0480 - val_loss: 3.7105 - val_accuracy: 0.1098\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.3402 - accuracy: 0.2318 - val_loss: 2.7183 - val_accuracy: 0.3578\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.1468 - accuracy: 0.4583 - val_loss: 1.7972 - val_accuracy: 0.5224\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6311 - accuracy: 0.5580 - val_loss: 1.5361 - val_accuracy: 0.5795\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4510 - accuracy: 0.5981 - val_loss: 1.4098 - val_accuracy: 0.6068\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3539 - accuracy: 0.6209 - val_loss: 1.3366 - val_accuracy: 0.6223\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2931 - accuracy: 0.6360 - val_loss: 1.2884 - val_accuracy: 0.6345\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2492 - accuracy: 0.6485 - val_loss: 1.2494 - val_accuracy: 0.6448\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2156 - accuracy: 0.6567 - val_loss: 1.2236 - val_accuracy: 0.6507\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1884 - accuracy: 0.6639 - val_loss: 1.1988 - val_accuracy: 0.6564\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1659 - accuracy: 0.6693 - val_loss: 1.1785 - val_accuracy: 0.6631\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1471 - accuracy: 0.6742 - val_loss: 1.1605 - val_accuracy: 0.6680\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1309 - accuracy: 0.6781 - val_loss: 1.1466 - val_accuracy: 0.6721\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1171 - accuracy: 0.6809 - val_loss: 1.1348 - val_accuracy: 0.6746\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1053 - accuracy: 0.6842 - val_loss: 1.1235 - val_accuracy: 0.6782\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0948 - accuracy: 0.6873 - val_loss: 1.1137 - val_accuracy: 0.6777\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0858 - accuracy: 0.6898 - val_loss: 1.1054 - val_accuracy: 0.6815\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0780 - accuracy: 0.6916 - val_loss: 1.0983 - val_accuracy: 0.6830\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0711 - accuracy: 0.6935 - val_loss: 1.0920 - val_accuracy: 0.6839\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0649 - accuracy: 0.6945 - val_loss: 1.0862 - val_accuracy: 0.6855\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:28.823126\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0602 - accuracy: 0.6962 - val_loss: 1.0835 - val_accuracy: 0.6865\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0580 - accuracy: 0.6972 - val_loss: 1.0820 - val_accuracy: 0.6863\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0568 - accuracy: 0.6973 - val_loss: 1.0814 - val_accuracy: 0.6865\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0562 - accuracy: 0.6975 - val_loss: 1.0811 - val_accuracy: 0.6867\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0560 - accuracy: 0.6978 - val_loss: 1.0810 - val_accuracy: 0.6867\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0559 - accuracy: 0.6977 - val_loss: 1.0809 - val_accuracy: 0.6867\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0558 - accuracy: 0.6977 - val_loss: 1.0809 - val_accuracy: 0.6868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0558 - accuracy: 0.6977 - val_loss: 1.0809 - val_accuracy: 0.6868\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0558 - accuracy: 0.6977 - val_loss: 1.0809 - val_accuracy: 0.6868\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0558 - accuracy: 0.6977 - val_loss: 1.0809 - val_accuracy: 0.6868\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:43.901193\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8204 - accuracy: 0.0354 - val_loss: 3.7702 - val_accuracy: 0.0671\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5731 - accuracy: 0.1586 - val_loss: 3.1980 - val_accuracy: 0.2918\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.5444 - accuracy: 0.3976 - val_loss: 2.0161 - val_accuracy: 0.4794\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.7796 - accuracy: 0.5275 - val_loss: 1.6053 - val_accuracy: 0.5596\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5138 - accuracy: 0.5837 - val_loss: 1.4320 - val_accuracy: 0.6021\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3846 - accuracy: 0.6152 - val_loss: 1.3379 - val_accuracy: 0.6251\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3081 - accuracy: 0.6330 - val_loss: 1.2762 - val_accuracy: 0.6397\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2557 - accuracy: 0.6468 - val_loss: 1.2327 - val_accuracy: 0.6508\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2166 - accuracy: 0.6560 - val_loss: 1.1980 - val_accuracy: 0.6586\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1860 - accuracy: 0.6642 - val_loss: 1.1717 - val_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1610 - accuracy: 0.6710 - val_loss: 1.1493 - val_accuracy: 0.6708\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1404 - accuracy: 0.6764 - val_loss: 1.1311 - val_accuracy: 0.6762\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1229 - accuracy: 0.6814 - val_loss: 1.1152 - val_accuracy: 0.6817\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1081 - accuracy: 0.6845 - val_loss: 1.1021 - val_accuracy: 0.6831\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0955 - accuracy: 0.6874 - val_loss: 1.0912 - val_accuracy: 0.6865\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0844 - accuracy: 0.6912 - val_loss: 1.0812 - val_accuracy: 0.6891\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0751 - accuracy: 0.6930 - val_loss: 1.0730 - val_accuracy: 0.6912\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0670 - accuracy: 0.6949 - val_loss: 1.0652 - val_accuracy: 0.6928\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0597 - accuracy: 0.6968 - val_loss: 1.0592 - val_accuracy: 0.6938\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0536 - accuracy: 0.6983 - val_loss: 1.0532 - val_accuracy: 0.6948\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:27.099725\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0488 - accuracy: 0.6996 - val_loss: 1.0503 - val_accuracy: 0.6965\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0464 - accuracy: 0.7002 - val_loss: 1.0490 - val_accuracy: 0.6968\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0452 - accuracy: 0.7004 - val_loss: 1.0483 - val_accuracy: 0.6969\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0447 - accuracy: 0.7004 - val_loss: 1.0480 - val_accuracy: 0.6968\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0444 - accuracy: 0.7007 - val_loss: 1.0478 - val_accuracy: 0.6968\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0443 - accuracy: 0.7006 - val_loss: 1.0478 - val_accuracy: 0.6968\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:50.311534\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8242 - accuracy: 0.0403 - val_loss: 3.7888 - val_accuracy: 0.0547\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6708 - accuracy: 0.1025 - val_loss: 3.4260 - val_accuracy: 0.2169\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 2.7686 - accuracy: 0.3591 - val_loss: 2.0927 - val_accuracy: 0.4682\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8104 - accuracy: 0.5227 - val_loss: 1.5988 - val_accuracy: 0.5628\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5185 - accuracy: 0.5822 - val_loss: 1.4254 - val_accuracy: 0.6037\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3956 - accuracy: 0.6105 - val_loss: 1.3384 - val_accuracy: 0.6223\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3258 - accuracy: 0.6290 - val_loss: 1.2833 - val_accuracy: 0.6380\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2780 - accuracy: 0.6405 - val_loss: 1.2425 - val_accuracy: 0.6494\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2422 - accuracy: 0.6504 - val_loss: 1.2117 - val_accuracy: 0.6568\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2135 - accuracy: 0.6577 - val_loss: 1.1872 - val_accuracy: 0.6635\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1901 - accuracy: 0.6640 - val_loss: 1.1670 - val_accuracy: 0.6683\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1706 - accuracy: 0.6692 - val_loss: 1.1516 - val_accuracy: 0.6704\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1541 - accuracy: 0.6724 - val_loss: 1.1343 - val_accuracy: 0.6773\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1403 - accuracy: 0.6760 - val_loss: 1.1216 - val_accuracy: 0.6800\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1283 - accuracy: 0.6799 - val_loss: 1.1102 - val_accuracy: 0.6825\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1177 - accuracy: 0.6825 - val_loss: 1.1010 - val_accuracy: 0.6855\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1087 - accuracy: 0.6853 - val_loss: 1.0933 - val_accuracy: 0.6865\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1008 - accuracy: 0.6870 - val_loss: 1.0861 - val_accuracy: 0.6878\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0939 - accuracy: 0.6894 - val_loss: 1.0797 - val_accuracy: 0.6898\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0878 - accuracy: 0.6908 - val_loss: 1.0748 - val_accuracy: 0.6900\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:28.910195\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.0832 - accuracy: 0.6915 - val_loss: 1.0714 - val_accuracy: 0.6922\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0808 - accuracy: 0.6926 - val_loss: 1.0701 - val_accuracy: 0.6918\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0797 - accuracy: 0.6929 - val_loss: 1.0694 - val_accuracy: 0.6921\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0791 - accuracy: 0.6931 - val_loss: 1.0690 - val_accuracy: 0.6922\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:01:53.601294\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7878 - accuracy: 0.0535 - val_loss: 3.6752 - val_accuracy: 0.1113\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.2408 - accuracy: 0.2537 - val_loss: 2.5648 - val_accuracy: 0.3887\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.0471 - accuracy: 0.4757 - val_loss: 1.7166 - val_accuracy: 0.5462\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5731 - accuracy: 0.5722 - val_loss: 1.4659 - val_accuracy: 0.6004\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.4002 - accuracy: 0.6126 - val_loss: 1.3461 - val_accuracy: 0.6267\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3079 - accuracy: 0.6343 - val_loss: 1.2787 - val_accuracy: 0.6449\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2484 - accuracy: 0.6495 - val_loss: 1.2312 - val_accuracy: 0.6565\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2053 - accuracy: 0.6591 - val_loss: 1.1993 - val_accuracy: 0.6636\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1720 - accuracy: 0.6679 - val_loss: 1.1690 - val_accuracy: 0.6715\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1452 - accuracy: 0.6752 - val_loss: 1.1430 - val_accuracy: 0.6796\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1226 - accuracy: 0.6812 - val_loss: 1.1220 - val_accuracy: 0.6853\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.1037 - accuracy: 0.6860 - val_loss: 1.1064 - val_accuracy: 0.6894\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0877 - accuracy: 0.6900 - val_loss: 1.0909 - val_accuracy: 0.6925\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0741 - accuracy: 0.6933 - val_loss: 1.0793 - val_accuracy: 0.6968\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0622 - accuracy: 0.6965 - val_loss: 1.0691 - val_accuracy: 0.6983\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0520 - accuracy: 0.6991 - val_loss: 1.0588 - val_accuracy: 0.7020\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0430 - accuracy: 0.7018 - val_loss: 1.0506 - val_accuracy: 0.7049\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0351 - accuracy: 0.7038 - val_loss: 1.0440 - val_accuracy: 0.7066\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0284 - accuracy: 0.7053 - val_loss: 1.0376 - val_accuracy: 0.7076\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0223 - accuracy: 0.7070 - val_loss: 1.0321 - val_accuracy: 0.7083\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:26.294960\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0177 - accuracy: 0.7084 - val_loss: 1.0291 - val_accuracy: 0.7098\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0154 - accuracy: 0.7089 - val_loss: 1.0277 - val_accuracy: 0.7099\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0142 - accuracy: 0.7092 - val_loss: 1.0272 - val_accuracy: 0.7103\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0137 - accuracy: 0.7095 - val_loss: 1.0269 - val_accuracy: 0.7102\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0134 - accuracy: 0.7097 - val_loss: 1.0267 - val_accuracy: 0.7102\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.0133 - accuracy: 0.7095 - val_loss: 1.0267 - val_accuracy: 0.7102\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': None, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:49.787992\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 9.6268 - accuracy: 0.0467 - val_loss: 9.3388 - val_accuracy: 0.1022\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 8.8708 - accuracy: 0.1907 - val_loss: 8.1773 - val_accuracy: 0.3147\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 7.3454 - accuracy: 0.4293 - val_loss: 6.7237 - val_accuracy: 0.5064\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.3514 - accuracy: 0.5506 - val_loss: 6.0699 - val_accuracy: 0.5751\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.8219 - accuracy: 0.5961 - val_loss: 5.6300 - val_accuracy: 0.6054\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.4384 - accuracy: 0.6191 - val_loss: 5.3026 - val_accuracy: 0.6221\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.1396 - accuracy: 0.6342 - val_loss: 5.0385 - val_accuracy: 0.6348\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.8956 - accuracy: 0.6447 - val_loss: 4.8176 - val_accuracy: 0.6427\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.6914 - accuracy: 0.6537 - val_loss: 4.6284 - val_accuracy: 0.6537\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.5194 - accuracy: 0.6612 - val_loss: 4.4707 - val_accuracy: 0.6589\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3728 - accuracy: 0.6673 - val_loss: 4.3361 - val_accuracy: 0.6656\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2473 - accuracy: 0.6727 - val_loss: 4.2201 - val_accuracy: 0.6687\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1391 - accuracy: 0.6770 - val_loss: 4.1209 - val_accuracy: 0.6710\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0455 - accuracy: 0.6801 - val_loss: 4.0343 - val_accuracy: 0.6749\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9641 - accuracy: 0.6831 - val_loss: 3.9576 - val_accuracy: 0.6780\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8933 - accuracy: 0.6860 - val_loss: 3.8928 - val_accuracy: 0.6809\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8316 - accuracy: 0.6888 - val_loss: 3.8355 - val_accuracy: 0.6825\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7776 - accuracy: 0.6907 - val_loss: 3.7854 - val_accuracy: 0.6838\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.7302 - accuracy: 0.6923 - val_loss: 3.7405 - val_accuracy: 0.6854\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6886 - accuracy: 0.6938 - val_loss: 3.7020 - val_accuracy: 0.6862\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:06.204324\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6592 - accuracy: 0.6948 - val_loss: 3.6825 - val_accuracy: 0.6877\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6447 - accuracy: 0.6954 - val_loss: 3.6731 - val_accuracy: 0.6883\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6376 - accuracy: 0.6958 - val_loss: 3.6686 - val_accuracy: 0.6877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6343 - accuracy: 0.6959 - val_loss: 3.6665 - val_accuracy: 0.6881\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6327 - accuracy: 0.6959 - val_loss: 3.6656 - val_accuracy: 0.6882\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:17.786533\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 9.6329 - accuracy: 0.0437 - val_loss: 9.3714 - val_accuracy: 0.0646\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 9.0381 - accuracy: 0.1165 - val_loss: 8.6004 - val_accuracy: 0.1945\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 7.8520 - accuracy: 0.3284 - val_loss: 7.0401 - val_accuracy: 0.4535\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 6.5476 - accuracy: 0.5093 - val_loss: 6.1197 - val_accuracy: 0.5574\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.8750 - accuracy: 0.5765 - val_loss: 5.6031 - val_accuracy: 0.6035\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.4469 - accuracy: 0.6076 - val_loss: 5.2455 - val_accuracy: 0.6220\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 5.1319 - accuracy: 0.6259 - val_loss: 4.9686 - val_accuracy: 0.6423\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.8811 - accuracy: 0.6381 - val_loss: 4.7429 - val_accuracy: 0.6508\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.6747 - accuracy: 0.6479 - val_loss: 4.5580 - val_accuracy: 0.6571\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.5023 - accuracy: 0.6549 - val_loss: 4.4008 - val_accuracy: 0.6641\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.3565 - accuracy: 0.6619 - val_loss: 4.2667 - val_accuracy: 0.6688\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 4.2318 - accuracy: 0.6667 - val_loss: 4.1520 - val_accuracy: 0.6725\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1247 - accuracy: 0.6710 - val_loss: 4.0540 - val_accuracy: 0.6759\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0323 - accuracy: 0.6748 - val_loss: 3.9679 - val_accuracy: 0.6794\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.9522 - accuracy: 0.6768 - val_loss: 3.8941 - val_accuracy: 0.6811\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8825 - accuracy: 0.6795 - val_loss: 3.8295 - val_accuracy: 0.6842\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8217 - accuracy: 0.6819 - val_loss: 3.7744 - val_accuracy: 0.6862\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7686 - accuracy: 0.6835 - val_loss: 3.7246 - val_accuracy: 0.6873\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7219 - accuracy: 0.6851 - val_loss: 3.6808 - val_accuracy: 0.6886\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6810 - accuracy: 0.6862 - val_loss: 3.6427 - val_accuracy: 0.6895\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:03.937047\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.6520 - accuracy: 0.6875 - val_loss: 3.6238 - val_accuracy: 0.6899\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6377 - accuracy: 0.6880 - val_loss: 3.6148 - val_accuracy: 0.6912\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6308 - accuracy: 0.6884 - val_loss: 3.6103 - val_accuracy: 0.6911\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6275 - accuracy: 0.6887 - val_loss: 3.6082 - val_accuracy: 0.6910\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6260 - accuracy: 0.6888 - val_loss: 3.6073 - val_accuracy: 0.6911\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:18.337349\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 9.6125 - accuracy: 0.0554 - val_loss: 9.3201 - val_accuracy: 0.0946\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 8.8384 - accuracy: 0.1929 - val_loss: 8.1383 - val_accuracy: 0.3495\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 7.3356 - accuracy: 0.4409 - val_loss: 6.7285 - val_accuracy: 0.5033\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.3689 - accuracy: 0.5436 - val_loss: 6.0771 - val_accuracy: 0.5693\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.8358 - accuracy: 0.5908 - val_loss: 5.6337 - val_accuracy: 0.5977\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4474 - accuracy: 0.6154 - val_loss: 5.2915 - val_accuracy: 0.6219\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.1450 - accuracy: 0.6315 - val_loss: 5.0236 - val_accuracy: 0.6363\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9005 - accuracy: 0.6445 - val_loss: 4.8028 - val_accuracy: 0.6464\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.6982 - accuracy: 0.6535 - val_loss: 4.6175 - val_accuracy: 0.6559\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5283 - accuracy: 0.6614 - val_loss: 4.4637 - val_accuracy: 0.6603\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3840 - accuracy: 0.6668 - val_loss: 4.3312 - val_accuracy: 0.6645\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2609 - accuracy: 0.6717 - val_loss: 4.2190 - val_accuracy: 0.6696\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1555 - accuracy: 0.6758 - val_loss: 4.1191 - val_accuracy: 0.6763\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0643 - accuracy: 0.6787 - val_loss: 4.0353 - val_accuracy: 0.6770\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9854 - accuracy: 0.6826 - val_loss: 3.9619 - val_accuracy: 0.6804\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9168 - accuracy: 0.6840 - val_loss: 3.8984 - val_accuracy: 0.6814\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8570 - accuracy: 0.6862 - val_loss: 3.8425 - val_accuracy: 0.6847\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8046 - accuracy: 0.6882 - val_loss: 3.7942 - val_accuracy: 0.6843\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7589 - accuracy: 0.6899 - val_loss: 3.7511 - val_accuracy: 0.6877\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7184 - accuracy: 0.6914 - val_loss: 3.7134 - val_accuracy: 0.6879\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:12.144214\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6899 - accuracy: 0.6921 - val_loss: 3.6946 - val_accuracy: 0.6897\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.6760 - accuracy: 0.6930 - val_loss: 3.6856 - val_accuracy: 0.6899\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6692 - accuracy: 0.6932 - val_loss: 3.6812 - val_accuracy: 0.6903\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6659 - accuracy: 0.6931 - val_loss: 3.6792 - val_accuracy: 0.6904\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6644 - accuracy: 0.6930 - val_loss: 3.6783 - val_accuracy: 0.6904\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6637 - accuracy: 0.6933 - val_loss: 3.6779 - val_accuracy: 0.6905\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6635 - accuracy: 0.6933 - val_loss: 3.6778 - val_accuracy: 0.6904\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.6634 - accuracy: 0.6933 - val_loss: 3.6777 - val_accuracy: 0.6904\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 38ms/step - loss: 3.6633 - accuracy: 0.6933 - val_loss: 3.6777 - val_accuracy: 0.6904\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:07.202488\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 9.5945 - accuracy: 0.0736 - val_loss: 9.2824 - val_accuracy: 0.1323\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 8.7577 - accuracy: 0.2284 - val_loss: 8.0202 - val_accuracy: 0.3488\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 7.2386 - accuracy: 0.4502 - val_loss: 6.6742 - val_accuracy: 0.5147\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 6.3317 - accuracy: 0.5508 - val_loss: 6.0576 - val_accuracy: 0.5754\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.8332 - accuracy: 0.5937 - val_loss: 5.6360 - val_accuracy: 0.6074\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.4716 - accuracy: 0.6178 - val_loss: 5.3275 - val_accuracy: 0.6238\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.1936 - accuracy: 0.6340 - val_loss: 5.0815 - val_accuracy: 0.6373\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.9701 - accuracy: 0.6461 - val_loss: 4.8823 - val_accuracy: 0.6469\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.7863 - accuracy: 0.6539 - val_loss: 4.7109 - val_accuracy: 0.6551\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.6324 - accuracy: 0.6614 - val_loss: 4.5734 - val_accuracy: 0.6605\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.5019 - accuracy: 0.6664 - val_loss: 4.4534 - val_accuracy: 0.6644\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.3908 - accuracy: 0.6714 - val_loss: 4.3519 - val_accuracy: 0.6680\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2957 - accuracy: 0.6758 - val_loss: 4.2626 - val_accuracy: 0.6719\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2140 - accuracy: 0.6782 - val_loss: 4.1873 - val_accuracy: 0.6754\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1432 - accuracy: 0.6811 - val_loss: 4.1219 - val_accuracy: 0.6778\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0819 - accuracy: 0.6835 - val_loss: 4.0645 - val_accuracy: 0.6803\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0285 - accuracy: 0.6862 - val_loss: 4.0146 - val_accuracy: 0.6826\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9820 - accuracy: 0.6869 - val_loss: 3.9714 - val_accuracy: 0.6844\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9413 - accuracy: 0.6885 - val_loss: 3.9340 - val_accuracy: 0.6848\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9055 - accuracy: 0.6900 - val_loss: 3.9005 - val_accuracy: 0.6873\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:09.681483\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8802 - accuracy: 0.6912 - val_loss: 3.8838 - val_accuracy: 0.6870\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8677 - accuracy: 0.6915 - val_loss: 3.8757 - val_accuracy: 0.6874\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8617 - accuracy: 0.6921 - val_loss: 3.8718 - val_accuracy: 0.6875\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.8587 - accuracy: 0.6921 - val_loss: 3.8701 - val_accuracy: 0.6875\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8574 - accuracy: 0.6921 - val_loss: 3.8693 - val_accuracy: 0.6875\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8568 - accuracy: 0.6922 - val_loss: 3.8689 - val_accuracy: 0.6875\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:48.590051\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 9.6352 - accuracy: 0.0482 - val_loss: 9.3706 - val_accuracy: 0.0868\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 9.0206 - accuracy: 0.1451 - val_loss: 8.5415 - val_accuracy: 0.2307\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 7.7119 - accuracy: 0.3570 - val_loss: 6.9423 - val_accuracy: 0.4679\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 6.4811 - accuracy: 0.5193 - val_loss: 6.1304 - val_accuracy: 0.5577\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.8695 - accuracy: 0.5816 - val_loss: 5.6484 - val_accuracy: 0.5986\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.4682 - accuracy: 0.6102 - val_loss: 5.3047 - val_accuracy: 0.6195\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 5.1693 - accuracy: 0.6263 - val_loss: 5.0428 - val_accuracy: 0.6325\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.9302 - accuracy: 0.6377 - val_loss: 4.8279 - val_accuracy: 0.6426\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.7339 - accuracy: 0.6461 - val_loss: 4.6520 - val_accuracy: 0.6473\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.5691 - accuracy: 0.6521 - val_loss: 4.4985 - val_accuracy: 0.6529\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.4290 - accuracy: 0.6565 - val_loss: 4.3708 - val_accuracy: 0.6589\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.3092 - accuracy: 0.6604 - val_loss: 4.2589 - val_accuracy: 0.6633\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.2066 - accuracy: 0.6645 - val_loss: 4.1648 - val_accuracy: 0.6665\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.1178 - accuracy: 0.6673 - val_loss: 4.0822 - val_accuracy: 0.6675\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0410 - accuracy: 0.6693 - val_loss: 4.0099 - val_accuracy: 0.6709\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9740 - accuracy: 0.6717 - val_loss: 3.9490 - val_accuracy: 0.6708\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9158 - accuracy: 0.6732 - val_loss: 3.8937 - val_accuracy: 0.6747\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8647 - accuracy: 0.6750 - val_loss: 3.8466 - val_accuracy: 0.6747\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8201 - accuracy: 0.6763 - val_loss: 3.8043 - val_accuracy: 0.6774\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7805 - accuracy: 0.6773 - val_loss: 3.7680 - val_accuracy: 0.6779\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:11.698033\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7527 - accuracy: 0.6787 - val_loss: 3.7496 - val_accuracy: 0.6798\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7390 - accuracy: 0.6790 - val_loss: 3.7408 - val_accuracy: 0.6795\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7323 - accuracy: 0.6792 - val_loss: 3.7366 - val_accuracy: 0.6792\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.7291 - accuracy: 0.6794 - val_loss: 3.7346 - val_accuracy: 0.6796\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:01:50.626958\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 9.5832 - accuracy: 0.0917 - val_loss: 9.2240 - val_accuracy: 0.1905\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.5478 - accuracy: 0.3180 - val_loss: 7.6780 - val_accuracy: 0.4320\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.0020 - accuracy: 0.5040 - val_loss: 6.5177 - val_accuracy: 0.5595\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.2269 - accuracy: 0.5845 - val_loss: 5.9726 - val_accuracy: 0.6044\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7733 - accuracy: 0.6153 - val_loss: 5.5842 - val_accuracy: 0.6267\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4327 - accuracy: 0.6345 - val_loss: 5.2852 - val_accuracy: 0.6419\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1669 - accuracy: 0.6466 - val_loss: 5.0502 - val_accuracy: 0.6529\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.9515 - accuracy: 0.6558 - val_loss: 4.8560 - val_accuracy: 0.6613\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7728 - accuracy: 0.6623 - val_loss: 4.6948 - val_accuracy: 0.6659\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.6228 - accuracy: 0.6687 - val_loss: 4.5593 - val_accuracy: 0.6737\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4962 - accuracy: 0.6738 - val_loss: 4.4436 - val_accuracy: 0.6780\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3882 - accuracy: 0.6777 - val_loss: 4.3435 - val_accuracy: 0.6791\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2956 - accuracy: 0.6816 - val_loss: 4.2583 - val_accuracy: 0.6836\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2159 - accuracy: 0.6846 - val_loss: 4.1856 - val_accuracy: 0.6869\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1472 - accuracy: 0.6877 - val_loss: 4.1220 - val_accuracy: 0.6876\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0877 - accuracy: 0.6894 - val_loss: 4.0668 - val_accuracy: 0.6891\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0359 - accuracy: 0.6916 - val_loss: 4.0187 - val_accuracy: 0.6905\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 3.9908 - accuracy: 0.6933 - val_loss: 3.9770 - val_accuracy: 0.6929\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9514 - accuracy: 0.6945 - val_loss: 3.9408 - val_accuracy: 0.6930\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9168 - accuracy: 0.6965 - val_loss: 3.9084 - val_accuracy: 0.6962\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:27.931006\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.8922 - accuracy: 0.6972 - val_loss: 3.8924 - val_accuracy: 0.6959\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8802 - accuracy: 0.6975 - val_loss: 3.8847 - val_accuracy: 0.6962\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8744 - accuracy: 0.6977 - val_loss: 3.8810 - val_accuracy: 0.6965\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8716 - accuracy: 0.6979 - val_loss: 3.8793 - val_accuracy: 0.6963\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8703 - accuracy: 0.6980 - val_loss: 3.8785 - val_accuracy: 0.6964\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8698 - accuracy: 0.6980 - val_loss: 3.8782 - val_accuracy: 0.6962\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:52.902457\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 9.5247 - accuracy: 0.0976 - val_loss: 9.0791 - val_accuracy: 0.2002\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.2552 - accuracy: 0.3485 - val_loss: 7.3894 - val_accuracy: 0.4649\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.8413 - accuracy: 0.5332 - val_loss: 6.4493 - val_accuracy: 0.5737\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.1750 - accuracy: 0.5943 - val_loss: 5.9517 - val_accuracy: 0.6116\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7446 - accuracy: 0.6218 - val_loss: 5.5697 - val_accuracy: 0.6329\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4066 - accuracy: 0.6388 - val_loss: 5.2746 - val_accuracy: 0.6447\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1375 - accuracy: 0.6508 - val_loss: 5.0331 - val_accuracy: 0.6547\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.9160 - accuracy: 0.6597 - val_loss: 4.8319 - val_accuracy: 0.6629\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7311 - accuracy: 0.6670 - val_loss: 4.6620 - val_accuracy: 0.6691\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5754 - accuracy: 0.6728 - val_loss: 4.5199 - val_accuracy: 0.6729\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4425 - accuracy: 0.6761 - val_loss: 4.3975 - val_accuracy: 0.6780\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3289 - accuracy: 0.6812 - val_loss: 4.2935 - val_accuracy: 0.6818\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2314 - accuracy: 0.6841 - val_loss: 4.2030 - val_accuracy: 0.6840\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1472 - accuracy: 0.6869 - val_loss: 4.1256 - val_accuracy: 0.6868\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0743 - accuracy: 0.6895 - val_loss: 4.0574 - val_accuracy: 0.6894\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0110 - accuracy: 0.6921 - val_loss: 3.9985 - val_accuracy: 0.6912\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9561 - accuracy: 0.6935 - val_loss: 3.9481 - val_accuracy: 0.6921\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9080 - accuracy: 0.6955 - val_loss: 3.9022 - val_accuracy: 0.6948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8659 - accuracy: 0.6967 - val_loss: 3.8636 - val_accuracy: 0.6963\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8290 - accuracy: 0.6980 - val_loss: 3.8289 - val_accuracy: 0.6971\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:26.056244\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8029 - accuracy: 0.6991 - val_loss: 3.8118 - val_accuracy: 0.6974\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7901 - accuracy: 0.6995 - val_loss: 3.8035 - val_accuracy: 0.6981\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7839 - accuracy: 0.6998 - val_loss: 3.7995 - val_accuracy: 0.6976\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7810 - accuracy: 0.7000 - val_loss: 3.7977 - val_accuracy: 0.6980\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7796 - accuracy: 0.6999 - val_loss: 3.7969 - val_accuracy: 0.6980\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:20.979274\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 9.5891 - accuracy: 0.0559 - val_loss: 9.2318 - val_accuracy: 0.1418\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 8.6136 - accuracy: 0.2659 - val_loss: 7.8208 - val_accuracy: 0.3896\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 7.1140 - accuracy: 0.4866 - val_loss: 6.5873 - val_accuracy: 0.5496\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.2648 - accuracy: 0.5773 - val_loss: 5.9984 - val_accuracy: 0.5947\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.7804 - accuracy: 0.6153 - val_loss: 5.5863 - val_accuracy: 0.6234\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4211 - accuracy: 0.6352 - val_loss: 5.2759 - val_accuracy: 0.6431\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1438 - accuracy: 0.6492 - val_loss: 5.0292 - val_accuracy: 0.6525\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.9196 - accuracy: 0.6587 - val_loss: 4.8263 - val_accuracy: 0.6592\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7344 - accuracy: 0.6668 - val_loss: 4.6601 - val_accuracy: 0.6658\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5796 - accuracy: 0.6726 - val_loss: 4.5168 - val_accuracy: 0.6715\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4486 - accuracy: 0.6773 - val_loss: 4.3973 - val_accuracy: 0.6750\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3373 - accuracy: 0.6819 - val_loss: 4.2955 - val_accuracy: 0.6779\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2420 - accuracy: 0.6854 - val_loss: 4.2088 - val_accuracy: 0.6797\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1602 - accuracy: 0.6880 - val_loss: 4.1331 - val_accuracy: 0.6811\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0897 - accuracy: 0.6910 - val_loss: 4.0671 - val_accuracy: 0.6841\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0284 - accuracy: 0.6931 - val_loss: 4.0112 - val_accuracy: 0.6868\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9753 - accuracy: 0.6949 - val_loss: 3.9611 - val_accuracy: 0.6885\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9288 - accuracy: 0.6966 - val_loss: 3.9182 - val_accuracy: 0.6903\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8886 - accuracy: 0.6980 - val_loss: 3.8815 - val_accuracy: 0.6889\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8532 - accuracy: 0.6997 - val_loss: 3.8476 - val_accuracy: 0.6917\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:25.545548\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8281 - accuracy: 0.7001 - val_loss: 3.8312 - val_accuracy: 0.6926\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8158 - accuracy: 0.7009 - val_loss: 3.8232 - val_accuracy: 0.6926\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8099 - accuracy: 0.7012 - val_loss: 3.8194 - val_accuracy: 0.6927\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8071 - accuracy: 0.7013 - val_loss: 3.8177 - val_accuracy: 0.6929\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8058 - accuracy: 0.7013 - val_loss: 3.8169 - val_accuracy: 0.6930\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8052 - accuracy: 0.7014 - val_loss: 3.8166 - val_accuracy: 0.6929\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8050 - accuracy: 0.7013 - val_loss: 3.8165 - val_accuracy: 0.6929\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8049 - accuracy: 0.7014 - val_loss: 3.8164 - val_accuracy: 0.6929\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:48.001926\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 9.5456 - accuracy: 0.1014 - val_loss: 9.1384 - val_accuracy: 0.2161\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 40ms/step - loss: 8.3901 - accuracy: 0.3296 - val_loss: 7.5069 - val_accuracy: 0.4466\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.9137 - accuracy: 0.5181 - val_loss: 6.4645 - val_accuracy: 0.5688\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 6.1922 - accuracy: 0.5901 - val_loss: 5.9381 - val_accuracy: 0.6105\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7436 - accuracy: 0.6200 - val_loss: 5.5461 - val_accuracy: 0.6341\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.3982 - accuracy: 0.6393 - val_loss: 5.2453 - val_accuracy: 0.6480\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1272 - accuracy: 0.6519 - val_loss: 5.0038 - val_accuracy: 0.6607\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.9057 - accuracy: 0.6620 - val_loss: 4.8035 - val_accuracy: 0.6684\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7216 - accuracy: 0.6697 - val_loss: 4.6387 - val_accuracy: 0.6742\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.5670 - accuracy: 0.6753 - val_loss: 4.4952 - val_accuracy: 0.6809\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4360 - accuracy: 0.6808 - val_loss: 4.3747 - val_accuracy: 0.6855\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3240 - accuracy: 0.6846 - val_loss: 4.2721 - val_accuracy: 0.6887\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.2282 - accuracy: 0.6879 - val_loss: 4.1828 - val_accuracy: 0.6941\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1455 - accuracy: 0.6908 - val_loss: 4.1079 - val_accuracy: 0.6961\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0740 - accuracy: 0.6941 - val_loss: 4.0416 - val_accuracy: 0.6975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0121 - accuracy: 0.6955 - val_loss: 3.9839 - val_accuracy: 0.7000\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9582 - accuracy: 0.6978 - val_loss: 3.9343 - val_accuracy: 0.7016\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9112 - accuracy: 0.6995 - val_loss: 3.8910 - val_accuracy: 0.7027\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8701 - accuracy: 0.7004 - val_loss: 3.8527 - val_accuracy: 0.7039\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8341 - accuracy: 0.7019 - val_loss: 3.8194 - val_accuracy: 0.7055\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:26.583523\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8085 - accuracy: 0.7031 - val_loss: 3.8025 - val_accuracy: 0.7067\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7961 - accuracy: 0.7032 - val_loss: 3.7947 - val_accuracy: 0.7067\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7900 - accuracy: 0.7038 - val_loss: 3.7908 - val_accuracy: 0.7070\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7871 - accuracy: 0.7037 - val_loss: 3.7890 - val_accuracy: 0.7071\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7858 - accuracy: 0.7038 - val_loss: 3.7882 - val_accuracy: 0.7071\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7852 - accuracy: 0.7039 - val_loss: 3.7879 - val_accuracy: 0.7072\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7850 - accuracy: 0.7040 - val_loss: 3.7878 - val_accuracy: 0.7072\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7849 - accuracy: 0.7039 - val_loss: 3.7877 - val_accuracy: 0.7072\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7849 - accuracy: 0.7040 - val_loss: 3.7877 - val_accuracy: 0.7073\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7849 - accuracy: 0.7040 - val_loss: 3.7877 - val_accuracy: 0.7073\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7849 - accuracy: 0.7040 - val_loss: 3.7877 - val_accuracy: 0.7073\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.7849 - accuracy: 0.7040 - val_loss: 3.7877 - val_accuracy: 0.7073\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:43.065293\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 9.5413 - accuracy: 0.0908 - val_loss: 9.0857 - val_accuracy: 0.2058\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 8.2415 - accuracy: 0.3558 - val_loss: 7.3739 - val_accuracy: 0.4729\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 6.8517 - accuracy: 0.5330 - val_loss: 6.4832 - val_accuracy: 0.5651\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.2140 - accuracy: 0.5893 - val_loss: 5.9962 - val_accuracy: 0.6012\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.7861 - accuracy: 0.6167 - val_loss: 5.6143 - val_accuracy: 0.6215\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.4471 - accuracy: 0.6345 - val_loss: 5.3169 - val_accuracy: 0.6383\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 5.1779 - accuracy: 0.6457 - val_loss: 5.0725 - val_accuracy: 0.6488\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.9568 - accuracy: 0.6551 - val_loss: 4.8730 - val_accuracy: 0.6561\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.7730 - accuracy: 0.6622 - val_loss: 4.7065 - val_accuracy: 0.6633\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.6185 - accuracy: 0.6689 - val_loss: 4.5677 - val_accuracy: 0.6669\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.4871 - accuracy: 0.6737 - val_loss: 4.4458 - val_accuracy: 0.6730\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.3752 - accuracy: 0.6776 - val_loss: 4.3420 - val_accuracy: 0.6758\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.2791 - accuracy: 0.6816 - val_loss: 4.2544 - val_accuracy: 0.6789\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.1962 - accuracy: 0.6849 - val_loss: 4.1765 - val_accuracy: 0.6824\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.1247 - accuracy: 0.6874 - val_loss: 4.1104 - val_accuracy: 0.6845\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0626 - accuracy: 0.6892 - val_loss: 4.0528 - val_accuracy: 0.6860\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0082 - accuracy: 0.6918 - val_loss: 4.0033 - val_accuracy: 0.6883\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9611 - accuracy: 0.6938 - val_loss: 3.9590 - val_accuracy: 0.6901\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9198 - accuracy: 0.6952 - val_loss: 3.9205 - val_accuracy: 0.6913\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8835 - accuracy: 0.6964 - val_loss: 3.8868 - val_accuracy: 0.6927\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:32.747869\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8578 - accuracy: 0.6973 - val_loss: 3.8700 - val_accuracy: 0.6930\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8453 - accuracy: 0.6983 - val_loss: 3.8620 - val_accuracy: 0.6931\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8392 - accuracy: 0.6984 - val_loss: 3.8582 - val_accuracy: 0.6934\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8363 - accuracy: 0.6986 - val_loss: 3.8564 - val_accuracy: 0.6932\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8349 - accuracy: 0.6987 - val_loss: 3.8556 - val_accuracy: 0.6934\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.8343 - accuracy: 0.6988 - val_loss: 3.8553 - val_accuracy: 0.6934\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:50.451779\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 9.6351 - accuracy: 0.0319 - val_loss: 9.3743 - val_accuracy: 0.0578\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 9.0323 - accuracy: 0.1185 - val_loss: 8.5677 - val_accuracy: 0.1956\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 7.7130 - accuracy: 0.3572 - val_loss: 6.9175 - val_accuracy: 0.4777\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.4561 - accuracy: 0.5236 - val_loss: 6.1073 - val_accuracy: 0.5615\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.8535 - accuracy: 0.5818 - val_loss: 5.6390 - val_accuracy: 0.5981\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.4600 - accuracy: 0.6103 - val_loss: 5.3043 - val_accuracy: 0.6196\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.1668 - accuracy: 0.6264 - val_loss: 5.0454 - val_accuracy: 0.6339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.9338 - accuracy: 0.6364 - val_loss: 4.8416 - val_accuracy: 0.6375\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.7424 - accuracy: 0.6469 - val_loss: 4.6667 - val_accuracy: 0.6474\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5824 - accuracy: 0.6536 - val_loss: 4.5218 - val_accuracy: 0.6533\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.4476 - accuracy: 0.6593 - val_loss: 4.3989 - val_accuracy: 0.6561\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3328 - accuracy: 0.6637 - val_loss: 4.2912 - val_accuracy: 0.6612\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2342 - accuracy: 0.6672 - val_loss: 4.2012 - val_accuracy: 0.6641\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1496 - accuracy: 0.6705 - val_loss: 4.1233 - val_accuracy: 0.6680\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0766 - accuracy: 0.6733 - val_loss: 4.0574 - val_accuracy: 0.6665\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0133 - accuracy: 0.6756 - val_loss: 3.9976 - val_accuracy: 0.6707\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9585 - accuracy: 0.6777 - val_loss: 3.9461 - val_accuracy: 0.6727\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9105 - accuracy: 0.6795 - val_loss: 3.9022 - val_accuracy: 0.6745\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.8685 - accuracy: 0.6813 - val_loss: 3.8630 - val_accuracy: 0.6749\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8319 - accuracy: 0.6828 - val_loss: 3.8282 - val_accuracy: 0.6774\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:43.597862\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.8058 - accuracy: 0.6841 - val_loss: 3.8112 - val_accuracy: 0.6779\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7930 - accuracy: 0.6841 - val_loss: 3.8031 - val_accuracy: 0.6782\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7868 - accuracy: 0.6845 - val_loss: 3.7992 - val_accuracy: 0.6786\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.7839 - accuracy: 0.6845 - val_loss: 3.7973 - val_accuracy: 0.6786\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7825 - accuracy: 0.6846 - val_loss: 3.7965 - val_accuracy: 0.6785\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7819 - accuracy: 0.6846 - val_loss: 3.7962 - val_accuracy: 0.6785\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:56.234603\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 9.6184 - accuracy: 0.0621 - val_loss: 9.3187 - val_accuracy: 0.1127\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.8032 - accuracy: 0.2124 - val_loss: 8.0860 - val_accuracy: 0.3117\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 7.3215 - accuracy: 0.4268 - val_loss: 6.7428 - val_accuracy: 0.5067\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.3812 - accuracy: 0.5480 - val_loss: 6.1062 - val_accuracy: 0.5715\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.8601 - accuracy: 0.5923 - val_loss: 5.6591 - val_accuracy: 0.6095\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.4880 - accuracy: 0.6170 - val_loss: 5.3414 - val_accuracy: 0.6223\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 5.2037 - accuracy: 0.6310 - val_loss: 5.0879 - val_accuracy: 0.6364\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.9735 - accuracy: 0.6416 - val_loss: 4.8786 - val_accuracy: 0.6463\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.7833 - accuracy: 0.6492 - val_loss: 4.7062 - val_accuracy: 0.6542\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.6237 - accuracy: 0.6563 - val_loss: 4.5608 - val_accuracy: 0.6582\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.4892 - accuracy: 0.6617 - val_loss: 4.4376 - val_accuracy: 0.6634\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3737 - accuracy: 0.6659 - val_loss: 4.3333 - val_accuracy: 0.6672\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2750 - accuracy: 0.6689 - val_loss: 4.2400 - val_accuracy: 0.6714\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1898 - accuracy: 0.6725 - val_loss: 4.1606 - val_accuracy: 0.6753\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1161 - accuracy: 0.6751 - val_loss: 4.0923 - val_accuracy: 0.6777\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0521 - accuracy: 0.6779 - val_loss: 4.0327 - val_accuracy: 0.6786\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9964 - accuracy: 0.6796 - val_loss: 3.9805 - val_accuracy: 0.6819\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9478 - accuracy: 0.6807 - val_loss: 3.9353 - val_accuracy: 0.6824\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9050 - accuracy: 0.6823 - val_loss: 3.8963 - val_accuracy: 0.6844\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8676 - accuracy: 0.6837 - val_loss: 3.8607 - val_accuracy: 0.6859\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:41.971381\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 3.8412 - accuracy: 0.6848 - val_loss: 3.8438 - val_accuracy: 0.6863\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.8282 - accuracy: 0.6858 - val_loss: 3.8351 - val_accuracy: 0.6872\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.8218 - accuracy: 0.6859 - val_loss: 3.8312 - val_accuracy: 0.6868\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8188 - accuracy: 0.6863 - val_loss: 3.8293 - val_accuracy: 0.6872\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8174 - accuracy: 0.6863 - val_loss: 3.8285 - val_accuracy: 0.6873\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8168 - accuracy: 0.6862 - val_loss: 3.8281 - val_accuracy: 0.6873\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8165 - accuracy: 0.6862 - val_loss: 3.8280 - val_accuracy: 0.6873\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8164 - accuracy: 0.6862 - val_loss: 3.8280 - val_accuracy: 0.6873\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8164 - accuracy: 0.6862 - val_loss: 3.8279 - val_accuracy: 0.6873\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8164 - accuracy: 0.6862 - val_loss: 3.8279 - val_accuracy: 0.6873\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:53.200031\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 9.6412 - accuracy: 0.0345 - val_loss: 9.3901 - val_accuracy: 0.0690\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 9.0965 - accuracy: 0.1214 - val_loss: 8.7327 - val_accuracy: 0.1814\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 8.0318 - accuracy: 0.3068 - val_loss: 7.1903 - val_accuracy: 0.4414\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.5937 - accuracy: 0.5091 - val_loss: 6.1595 - val_accuracy: 0.5477\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 5.8758 - accuracy: 0.5763 - val_loss: 5.6346 - val_accuracy: 0.5887\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.4454 - accuracy: 0.6065 - val_loss: 5.2768 - val_accuracy: 0.6145\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.1303 - accuracy: 0.6245 - val_loss: 4.9971 - val_accuracy: 0.6302\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.8805 - accuracy: 0.6383 - val_loss: 4.7748 - val_accuracy: 0.6412\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.6757 - accuracy: 0.6473 - val_loss: 4.5884 - val_accuracy: 0.6511\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5050 - accuracy: 0.6555 - val_loss: 4.4316 - val_accuracy: 0.6578\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3604 - accuracy: 0.6604 - val_loss: 4.2992 - val_accuracy: 0.6639\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.2381 - accuracy: 0.6662 - val_loss: 4.1853 - val_accuracy: 0.6690\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.1333 - accuracy: 0.6699 - val_loss: 4.0909 - val_accuracy: 0.6726\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0434 - accuracy: 0.6732 - val_loss: 4.0066 - val_accuracy: 0.6765\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9653 - accuracy: 0.6767 - val_loss: 3.9347 - val_accuracy: 0.6784\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.8980 - accuracy: 0.6785 - val_loss: 3.8719 - val_accuracy: 0.6822\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.8391 - accuracy: 0.6817 - val_loss: 3.8171 - val_accuracy: 0.6834\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7878 - accuracy: 0.6835 - val_loss: 3.7693 - val_accuracy: 0.6853\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7429 - accuracy: 0.6847 - val_loss: 3.7283 - val_accuracy: 0.6862\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.7036 - accuracy: 0.6855 - val_loss: 3.6913 - val_accuracy: 0.6892\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:46.040438\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.6758 - accuracy: 0.6869 - val_loss: 3.6731 - val_accuracy: 0.6889\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.6622 - accuracy: 0.6875 - val_loss: 3.6641 - val_accuracy: 0.6893\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.6555 - accuracy: 0.6876 - val_loss: 3.6599 - val_accuracy: 0.6899\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6524 - accuracy: 0.6879 - val_loss: 3.6580 - val_accuracy: 0.6898\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.6509 - accuracy: 0.6879 - val_loss: 3.6571 - val_accuracy: 0.6898\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.6503 - accuracy: 0.6881 - val_loss: 3.6567 - val_accuracy: 0.6898\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:58.728155\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 9.6439 - accuracy: 0.0353 - val_loss: 9.3891 - val_accuracy: 0.0685\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 9.0793 - accuracy: 0.1098 - val_loss: 8.6866 - val_accuracy: 0.1871\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 7.9665 - accuracy: 0.3114 - val_loss: 7.1401 - val_accuracy: 0.4289\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 6.5739 - accuracy: 0.5051 - val_loss: 6.1513 - val_accuracy: 0.5540\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 5.8788 - accuracy: 0.5777 - val_loss: 5.6540 - val_accuracy: 0.5892\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 5.4638 - accuracy: 0.6092 - val_loss: 5.3041 - val_accuracy: 0.6147\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 5.1608 - accuracy: 0.6256 - val_loss: 5.0377 - val_accuracy: 0.6297\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.9215 - accuracy: 0.6379 - val_loss: 4.8240 - val_accuracy: 0.6379\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.7255 - accuracy: 0.6459 - val_loss: 4.6468 - val_accuracy: 0.6446\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.5618 - accuracy: 0.6533 - val_loss: 4.4977 - val_accuracy: 0.6513\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.4246 - accuracy: 0.6589 - val_loss: 4.3718 - val_accuracy: 0.6594\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.3076 - accuracy: 0.6627 - val_loss: 4.2651 - val_accuracy: 0.6620\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.2074 - accuracy: 0.6664 - val_loss: 4.1728 - val_accuracy: 0.6633\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.1214 - accuracy: 0.6699 - val_loss: 4.0929 - val_accuracy: 0.6673\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.0469 - accuracy: 0.6729 - val_loss: 4.0239 - val_accuracy: 0.6699\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.9822 - accuracy: 0.6746 - val_loss: 3.9640 - val_accuracy: 0.6704\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.9262 - accuracy: 0.6769 - val_loss: 3.9113 - val_accuracy: 0.6738\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.8772 - accuracy: 0.6787 - val_loss: 3.8665 - val_accuracy: 0.6745\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.8343 - accuracy: 0.6802 - val_loss: 3.8278 - val_accuracy: 0.6749\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.7968 - accuracy: 0.6813 - val_loss: 3.7913 - val_accuracy: 0.6781\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:58.656623\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.7701 - accuracy: 0.6830 - val_loss: 3.7738 - val_accuracy: 0.6784\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.7570 - accuracy: 0.6832 - val_loss: 3.7652 - val_accuracy: 0.6785\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.7507 - accuracy: 0.6837 - val_loss: 3.7613 - val_accuracy: 0.6787\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.7477 - accuracy: 0.6836 - val_loss: 3.7594 - val_accuracy: 0.6787\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.7463 - accuracy: 0.6835 - val_loss: 3.7586 - val_accuracy: 0.6788\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 29s 42ms/step - loss: 3.7457 - accuracy: 0.6836 - val_loss: 3.7583 - val_accuracy: 0.6789\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.7454 - accuracy: 0.6835 - val_loss: 3.7581 - val_accuracy: 0.6789\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.7453 - accuracy: 0.6835 - val_loss: 3.7581 - val_accuracy: 0.6789\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 3.7453 - accuracy: 0.6835 - val_loss: 3.7581 - val_accuracy: 0.6789\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:25.958563\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 9.6248 - accuracy: 0.0646 - val_loss: 9.3331 - val_accuracy: 0.1278\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 8.8273 - accuracy: 0.2191 - val_loss: 8.0823 - val_accuracy: 0.3391\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 7.2493 - accuracy: 0.4506 - val_loss: 6.6417 - val_accuracy: 0.5283\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 6.3137 - accuracy: 0.5604 - val_loss: 6.0388 - val_accuracy: 0.5852\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.8309 - accuracy: 0.5986 - val_loss: 5.6383 - val_accuracy: 0.6121\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.4847 - accuracy: 0.6198 - val_loss: 5.3406 - val_accuracy: 0.6281\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.2191 - accuracy: 0.6328 - val_loss: 5.1053 - val_accuracy: 0.6388\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 5.0056 - accuracy: 0.6431 - val_loss: 4.9143 - val_accuracy: 0.6453\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.8295 - accuracy: 0.6501 - val_loss: 4.7539 - val_accuracy: 0.6524\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.6813 - accuracy: 0.6563 - val_loss: 4.6189 - val_accuracy: 0.6572\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.5563 - accuracy: 0.6608 - val_loss: 4.5043 - val_accuracy: 0.6608\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.4496 - accuracy: 0.6645 - val_loss: 4.4069 - val_accuracy: 0.6649\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.3581 - accuracy: 0.6672 - val_loss: 4.3209 - val_accuracy: 0.6691\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2791 - accuracy: 0.6700 - val_loss: 4.2489 - val_accuracy: 0.6702\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.2109 - accuracy: 0.6720 - val_loss: 4.1850 - val_accuracy: 0.6725\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1517 - accuracy: 0.6745 - val_loss: 4.1312 - val_accuracy: 0.6734\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.1001 - accuracy: 0.6757 - val_loss: 4.0833 - val_accuracy: 0.6747\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0552 - accuracy: 0.6769 - val_loss: 4.0411 - val_accuracy: 0.6765\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 4.0158 - accuracy: 0.6787 - val_loss: 4.0046 - val_accuracy: 0.6771\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9812 - accuracy: 0.6800 - val_loss: 3.9727 - val_accuracy: 0.6771\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:39.948036\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9566 - accuracy: 0.6814 - val_loss: 3.9564 - val_accuracy: 0.6781\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9446 - accuracy: 0.6816 - val_loss: 3.9485 - val_accuracy: 0.6787\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9387 - accuracy: 0.6820 - val_loss: 3.9449 - val_accuracy: 0.6786\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9359 - accuracy: 0.6822 - val_loss: 3.9431 - val_accuracy: 0.6786\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.9346 - accuracy: 0.6824 - val_loss: 3.9424 - val_accuracy: 0.6787\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L1 object at 0x0000020084609940>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:24.944841\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0637 - accuracy: 0.0461 - val_loss: 4.0308 - val_accuracy: 0.0785\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.9362 - accuracy: 0.1264 - val_loss: 3.7586 - val_accuracy: 0.1928\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.2346 - accuracy: 0.3166 - val_loss: 2.6145 - val_accuracy: 0.4215\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.2348 - accuracy: 0.4811 - val_loss: 2.0009 - val_accuracy: 0.5241\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8596 - accuracy: 0.5558 - val_loss: 1.7743 - val_accuracy: 0.5757\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6978 - accuracy: 0.5930 - val_loss: 1.6643 - val_accuracy: 0.6019\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6081 - accuracy: 0.6136 - val_loss: 1.5943 - val_accuracy: 0.6184\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5490 - accuracy: 0.6286 - val_loss: 1.5468 - val_accuracy: 0.6304\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5063 - accuracy: 0.6396 - val_loss: 1.5118 - val_accuracy: 0.6407\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4738 - accuracy: 0.6479 - val_loss: 1.4825 - val_accuracy: 0.6475\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4474 - accuracy: 0.6534 - val_loss: 1.4601 - val_accuracy: 0.6524\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4261 - accuracy: 0.6598 - val_loss: 1.4412 - val_accuracy: 0.6587\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4085 - accuracy: 0.6644 - val_loss: 1.4252 - val_accuracy: 0.6608\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3933 - accuracy: 0.6676 - val_loss: 1.4117 - val_accuracy: 0.6651\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3804 - accuracy: 0.6714 - val_loss: 1.4007 - val_accuracy: 0.6661\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3695 - accuracy: 0.6739 - val_loss: 1.3902 - val_accuracy: 0.6692\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3600 - accuracy: 0.6761 - val_loss: 1.3825 - val_accuracy: 0.6711\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3517 - accuracy: 0.6779 - val_loss: 1.3751 - val_accuracy: 0.6726\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3446 - accuracy: 0.6795 - val_loss: 1.3682 - val_accuracy: 0.6754\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3383 - accuracy: 0.6814 - val_loss: 1.3627 - val_accuracy: 0.6759\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:10.259132\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3336 - accuracy: 0.6826 - val_loss: 1.3595 - val_accuracy: 0.6769\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3311 - accuracy: 0.6833 - val_loss: 1.3582 - val_accuracy: 0.6772\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3299 - accuracy: 0.6832 - val_loss: 1.3576 - val_accuracy: 0.6776\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3293 - accuracy: 0.6834 - val_loss: 1.3573 - val_accuracy: 0.6775\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3291 - accuracy: 0.6836 - val_loss: 1.3571 - val_accuracy: 0.6776\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3289 - accuracy: 0.6837 - val_loss: 1.3571 - val_accuracy: 0.6776\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:02:44.471373\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0610 - accuracy: 0.0397 - val_loss: 4.0227 - val_accuracy: 0.0529\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9102 - accuracy: 0.1027 - val_loss: 3.6943 - val_accuracy: 0.1860\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1289 - accuracy: 0.3223 - val_loss: 2.5115 - val_accuracy: 0.4367\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.1709 - accuracy: 0.4950 - val_loss: 1.9344 - val_accuracy: 0.5375\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8233 - accuracy: 0.5638 - val_loss: 1.7280 - val_accuracy: 0.5813\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6767 - accuracy: 0.5973 - val_loss: 1.6273 - val_accuracy: 0.6062\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5951 - accuracy: 0.6169 - val_loss: 1.5617 - val_accuracy: 0.6216\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5396 - accuracy: 0.6305 - val_loss: 1.5154 - val_accuracy: 0.6324\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4993 - accuracy: 0.6412 - val_loss: 1.4785 - val_accuracy: 0.6439\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4678 - accuracy: 0.6495 - val_loss: 1.4496 - val_accuracy: 0.6531\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4421 - accuracy: 0.6561 - val_loss: 1.4267 - val_accuracy: 0.6558\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4206 - accuracy: 0.6614 - val_loss: 1.4094 - val_accuracy: 0.6595\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4029 - accuracy: 0.6659 - val_loss: 1.3913 - val_accuracy: 0.6647\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3875 - accuracy: 0.6700 - val_loss: 1.3774 - val_accuracy: 0.6684\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3743 - accuracy: 0.6739 - val_loss: 1.3665 - val_accuracy: 0.6717\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3628 - accuracy: 0.6762 - val_loss: 1.3553 - val_accuracy: 0.6743\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3531 - accuracy: 0.6780 - val_loss: 1.3461 - val_accuracy: 0.6765\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3445 - accuracy: 0.6807 - val_loss: 1.3383 - val_accuracy: 0.6786\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3369 - accuracy: 0.6821 - val_loss: 1.3318 - val_accuracy: 0.6811\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3303 - accuracy: 0.6834 - val_loss: 1.3254 - val_accuracy: 0.6818\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:08.221896\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3253 - accuracy: 0.6851 - val_loss: 1.3226 - val_accuracy: 0.6824\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3228 - accuracy: 0.6857 - val_loss: 1.3209 - val_accuracy: 0.6825\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3216 - accuracy: 0.6859 - val_loss: 1.3200 - val_accuracy: 0.6827\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3210 - accuracy: 0.6863 - val_loss: 1.3196 - val_accuracy: 0.6834\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3207 - accuracy: 0.6863 - val_loss: 1.3195 - val_accuracy: 0.6834\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3206 - accuracy: 0.6862 - val_loss: 1.3194 - val_accuracy: 0.6834\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3205 - accuracy: 0.6862 - val_loss: 1.3194 - val_accuracy: 0.6835\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3205 - accuracy: 0.6862 - val_loss: 1.3194 - val_accuracy: 0.6835\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3205 - accuracy: 0.6862 - val_loss: 1.3194 - val_accuracy: 0.6835\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3205 - accuracy: 0.6862 - val_loss: 1.3194 - val_accuracy: 0.6835\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:34.334842\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 4.0545 - accuracy: 0.0549 - val_loss: 4.0045 - val_accuracy: 0.0808\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.8485 - accuracy: 0.1318 - val_loss: 3.5539 - val_accuracy: 0.2304\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.9544 - accuracy: 0.3542 - val_loss: 2.3991 - val_accuracy: 0.4520\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.1044 - accuracy: 0.5110 - val_loss: 1.9083 - val_accuracy: 0.5544\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7967 - accuracy: 0.5760 - val_loss: 1.7172 - val_accuracy: 0.5920\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6586 - accuracy: 0.6073 - val_loss: 1.6145 - val_accuracy: 0.6174\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5787 - accuracy: 0.6270 - val_loss: 1.5555 - val_accuracy: 0.6293\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5243 - accuracy: 0.6392 - val_loss: 1.5092 - val_accuracy: 0.6418\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4844 - accuracy: 0.6486 - val_loss: 1.4744 - val_accuracy: 0.6504\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4529 - accuracy: 0.6558 - val_loss: 1.4466 - val_accuracy: 0.6580\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4272 - accuracy: 0.6626 - val_loss: 1.4259 - val_accuracy: 0.6623\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4065 - accuracy: 0.6679 - val_loss: 1.4069 - val_accuracy: 0.6668\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3888 - accuracy: 0.6719 - val_loss: 1.3910 - val_accuracy: 0.6707\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3737 - accuracy: 0.6755 - val_loss: 1.3767 - val_accuracy: 0.6742\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3607 - accuracy: 0.6789 - val_loss: 1.3673 - val_accuracy: 0.6766\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3497 - accuracy: 0.6814 - val_loss: 1.3551 - val_accuracy: 0.6793\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3400 - accuracy: 0.6837 - val_loss: 1.3467 - val_accuracy: 0.6816\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3316 - accuracy: 0.6856 - val_loss: 1.3394 - val_accuracy: 0.6833\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3243 - accuracy: 0.6874 - val_loss: 1.3336 - val_accuracy: 0.6840\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3180 - accuracy: 0.6888 - val_loss: 1.3271 - val_accuracy: 0.6853\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:07.040237\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3131 - accuracy: 0.6906 - val_loss: 1.3239 - val_accuracy: 0.6861\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3107 - accuracy: 0.6912 - val_loss: 1.3225 - val_accuracy: 0.6871\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3095 - accuracy: 0.6912 - val_loss: 1.3218 - val_accuracy: 0.6873\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3090 - accuracy: 0.6914 - val_loss: 1.3215 - val_accuracy: 0.6874\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3087 - accuracy: 0.6916 - val_loss: 1.3214 - val_accuracy: 0.6874\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3086 - accuracy: 0.6916 - val_loss: 1.3213 - val_accuracy: 0.6874\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3085 - accuracy: 0.6917 - val_loss: 1.3213 - val_accuracy: 0.6874\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3085 - accuracy: 0.6917 - val_loss: 1.3213 - val_accuracy: 0.6874\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3085 - accuracy: 0.6917 - val_loss: 1.3213 - val_accuracy: 0.6874\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:06.641343\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0663 - accuracy: 0.0358 - val_loss: 4.0354 - val_accuracy: 0.0694\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9457 - accuracy: 0.1052 - val_loss: 3.7761 - val_accuracy: 0.1539\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.2698 - accuracy: 0.2845 - val_loss: 2.6469 - val_accuracy: 0.4186\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.2395 - accuracy: 0.4885 - val_loss: 1.9758 - val_accuracy: 0.5388\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.8414 - accuracy: 0.5645 - val_loss: 1.7456 - val_accuracy: 0.5817\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6848 - accuracy: 0.5972 - val_loss: 1.6400 - val_accuracy: 0.6047\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6017 - accuracy: 0.6160 - val_loss: 1.5744 - val_accuracy: 0.6200\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5469 - accuracy: 0.6288 - val_loss: 1.5295 - val_accuracy: 0.6322\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5072 - accuracy: 0.6384 - val_loss: 1.4947 - val_accuracy: 0.6398\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4755 - accuracy: 0.6455 - val_loss: 1.4679 - val_accuracy: 0.6477\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4507 - accuracy: 0.6525 - val_loss: 1.4446 - val_accuracy: 0.6533\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4299 - accuracy: 0.6574 - val_loss: 1.4283 - val_accuracy: 0.6564\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4124 - accuracy: 0.6617 - val_loss: 1.4127 - val_accuracy: 0.6609\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3974 - accuracy: 0.6658 - val_loss: 1.3991 - val_accuracy: 0.6645\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3845 - accuracy: 0.6695 - val_loss: 1.3869 - val_accuracy: 0.6673\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3734 - accuracy: 0.6723 - val_loss: 1.3766 - val_accuracy: 0.6702\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3639 - accuracy: 0.6746 - val_loss: 1.3681 - val_accuracy: 0.6719\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3554 - accuracy: 0.6762 - val_loss: 1.3600 - val_accuracy: 0.6738\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3482 - accuracy: 0.6786 - val_loss: 1.3536 - val_accuracy: 0.6740\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3416 - accuracy: 0.6802 - val_loss: 1.3468 - val_accuracy: 0.6766\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:08.054343\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3368 - accuracy: 0.6811 - val_loss: 1.3441 - val_accuracy: 0.6779\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3343 - accuracy: 0.6818 - val_loss: 1.3426 - val_accuracy: 0.6779\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3330 - accuracy: 0.6820 - val_loss: 1.3419 - val_accuracy: 0.6780\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3324 - accuracy: 0.6822 - val_loss: 1.3416 - val_accuracy: 0.6784\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3322 - accuracy: 0.6823 - val_loss: 1.3415 - val_accuracy: 0.6783\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3320 - accuracy: 0.6823 - val_loss: 1.3415 - val_accuracy: 0.6783\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3320 - accuracy: 0.6824 - val_loss: 1.3414 - val_accuracy: 0.6782\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:03:12.225047\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 4.0623 - accuracy: 0.0372 - val_loss: 4.0248 - val_accuracy: 0.0667\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.9106 - accuracy: 0.1253 - val_loss: 3.7021 - val_accuracy: 0.2025\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 3.1398 - accuracy: 0.3177 - val_loss: 2.5148 - val_accuracy: 0.4424\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 2.1520 - accuracy: 0.5043 - val_loss: 1.9120 - val_accuracy: 0.5466\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.7902 - accuracy: 0.5742 - val_loss: 1.6992 - val_accuracy: 0.5939\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.6401 - accuracy: 0.6080 - val_loss: 1.5941 - val_accuracy: 0.6180\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.5547 - accuracy: 0.6274 - val_loss: 1.5285 - val_accuracy: 0.6323\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4969 - accuracy: 0.6412 - val_loss: 1.4785 - val_accuracy: 0.6469\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4538 - accuracy: 0.6518 - val_loss: 1.4416 - val_accuracy: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.4208 - accuracy: 0.6605 - val_loss: 1.4127 - val_accuracy: 0.6627\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3940 - accuracy: 0.6670 - val_loss: 1.3908 - val_accuracy: 0.6685\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3722 - accuracy: 0.6724 - val_loss: 1.3704 - val_accuracy: 0.6753\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3536 - accuracy: 0.6772 - val_loss: 1.3551 - val_accuracy: 0.6786\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3381 - accuracy: 0.6810 - val_loss: 1.3404 - val_accuracy: 0.6827\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3247 - accuracy: 0.6849 - val_loss: 1.3282 - val_accuracy: 0.6848\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3134 - accuracy: 0.6878 - val_loss: 1.3175 - val_accuracy: 0.6879\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.3035 - accuracy: 0.6900 - val_loss: 1.3089 - val_accuracy: 0.6906\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2948 - accuracy: 0.6925 - val_loss: 1.3009 - val_accuracy: 0.6918\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2872 - accuracy: 0.6941 - val_loss: 1.2939 - val_accuracy: 0.6948\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2806 - accuracy: 0.6956 - val_loss: 1.2883 - val_accuracy: 0.6946\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:09:07.459248\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2756 - accuracy: 0.6968 - val_loss: 1.2850 - val_accuracy: 0.6954\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2731 - accuracy: 0.6979 - val_loss: 1.2835 - val_accuracy: 0.6961\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2719 - accuracy: 0.6982 - val_loss: 1.2828 - val_accuracy: 0.6965\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2713 - accuracy: 0.6981 - val_loss: 1.2825 - val_accuracy: 0.6968\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2710 - accuracy: 0.6984 - val_loss: 1.2823 - val_accuracy: 0.6968\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2709 - accuracy: 0.6984 - val_loss: 1.2823 - val_accuracy: 0.6968\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2708 - accuracy: 0.6984 - val_loss: 1.2823 - val_accuracy: 0.6968\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2708 - accuracy: 0.6984 - val_loss: 1.2823 - val_accuracy: 0.6968\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 27s 39ms/step - loss: 1.2708 - accuracy: 0.6984 - val_loss: 1.2823 - val_accuracy: 0.6968\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2708 - accuracy: 0.6984 - val_loss: 1.2823 - val_accuracy: 0.6968\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'relu'}\n",
      " Training time for the model is, 0:04:34.491647\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9870 - accuracy: 0.0650 - val_loss: 3.8180 - val_accuracy: 0.1499\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 3.2665 - accuracy: 0.3144 - val_loss: 2.5601 - val_accuracy: 0.4351\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.1378 - accuracy: 0.5105 - val_loss: 1.8663 - val_accuracy: 0.5617\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7617 - accuracy: 0.5792 - val_loss: 1.6682 - val_accuracy: 0.6025\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6203 - accuracy: 0.6120 - val_loss: 1.5664 - val_accuracy: 0.6255\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5381 - accuracy: 0.6331 - val_loss: 1.5041 - val_accuracy: 0.6396\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4823 - accuracy: 0.6471 - val_loss: 1.4569 - val_accuracy: 0.6547\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4404 - accuracy: 0.6581 - val_loss: 1.4245 - val_accuracy: 0.6614\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4073 - accuracy: 0.6669 - val_loss: 1.3968 - val_accuracy: 0.6674\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3803 - accuracy: 0.6744 - val_loss: 1.3717 - val_accuracy: 0.6750\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3573 - accuracy: 0.6810 - val_loss: 1.3521 - val_accuracy: 0.6797\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3379 - accuracy: 0.6848 - val_loss: 1.3368 - val_accuracy: 0.6823\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3215 - accuracy: 0.6899 - val_loss: 1.3207 - val_accuracy: 0.6888\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3074 - accuracy: 0.6928 - val_loss: 1.3086 - val_accuracy: 0.6906\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2949 - accuracy: 0.6959 - val_loss: 1.2972 - val_accuracy: 0.6945\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2844 - accuracy: 0.6989 - val_loss: 1.2879 - val_accuracy: 0.6963\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2748 - accuracy: 0.7019 - val_loss: 1.2804 - val_accuracy: 0.6986\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2667 - accuracy: 0.7039 - val_loss: 1.2731 - val_accuracy: 0.7003\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2597 - accuracy: 0.7055 - val_loss: 1.2665 - val_accuracy: 0.7012\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2532 - accuracy: 0.7080 - val_loss: 1.2611 - val_accuracy: 0.7032\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:15.620139\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2485 - accuracy: 0.7091 - val_loss: 1.2580 - val_accuracy: 0.7040\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2461 - accuracy: 0.7094 - val_loss: 1.2566 - val_accuracy: 0.7040\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2449 - accuracy: 0.7097 - val_loss: 1.2560 - val_accuracy: 0.7037\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2443 - accuracy: 0.7097 - val_loss: 1.2557 - val_accuracy: 0.7039\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:01:51.101212\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0135 - accuracy: 0.0748 - val_loss: 3.8872 - val_accuracy: 0.1593\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4705 - accuracy: 0.2868 - val_loss: 2.8379 - val_accuracy: 0.3938\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.3230 - accuracy: 0.4829 - val_loss: 1.9647 - val_accuracy: 0.5475\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.8128 - accuracy: 0.5756 - val_loss: 1.6938 - val_accuracy: 0.6026\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6324 - accuracy: 0.6134 - val_loss: 1.5732 - val_accuracy: 0.6274\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5406 - accuracy: 0.6346 - val_loss: 1.5067 - val_accuracy: 0.6424\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4827 - accuracy: 0.6481 - val_loss: 1.4575 - val_accuracy: 0.6545\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4412 - accuracy: 0.6591 - val_loss: 1.4214 - val_accuracy: 0.6636\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4093 - accuracy: 0.6667 - val_loss: 1.3941 - val_accuracy: 0.6687\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3837 - accuracy: 0.6725 - val_loss: 1.3715 - val_accuracy: 0.6752\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3624 - accuracy: 0.6783 - val_loss: 1.3522 - val_accuracy: 0.6789\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3446 - accuracy: 0.6824 - val_loss: 1.3351 - val_accuracy: 0.6838\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3295 - accuracy: 0.6857 - val_loss: 1.3214 - val_accuracy: 0.6882\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3162 - accuracy: 0.6891 - val_loss: 1.3107 - val_accuracy: 0.6875\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3050 - accuracy: 0.6918 - val_loss: 1.2998 - val_accuracy: 0.6922\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2952 - accuracy: 0.6944 - val_loss: 1.2911 - val_accuracy: 0.6933\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2867 - accuracy: 0.6964 - val_loss: 1.2826 - val_accuracy: 0.6961\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2792 - accuracy: 0.6985 - val_loss: 1.2763 - val_accuracy: 0.6985\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2727 - accuracy: 0.7002 - val_loss: 1.2699 - val_accuracy: 0.7002\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2669 - accuracy: 0.7010 - val_loss: 1.2645 - val_accuracy: 0.7009\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:16.091200\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2623 - accuracy: 0.7026 - val_loss: 1.2618 - val_accuracy: 0.7016\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2602 - accuracy: 0.7033 - val_loss: 1.2606 - val_accuracy: 0.7012\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2591 - accuracy: 0.7034 - val_loss: 1.2600 - val_accuracy: 0.7023\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2585 - accuracy: 0.7038 - val_loss: 1.2597 - val_accuracy: 0.7022\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2583 - accuracy: 0.7039 - val_loss: 1.2596 - val_accuracy: 0.7022\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2582 - accuracy: 0.7039 - val_loss: 1.2595 - val_accuracy: 0.7023\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:46.970224\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0067 - accuracy: 0.0770 - val_loss: 3.8660 - val_accuracy: 0.1450\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.4036 - accuracy: 0.2785 - val_loss: 2.7531 - val_accuracy: 0.4020\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.2361 - accuracy: 0.4951 - val_loss: 1.9282 - val_accuracy: 0.5522\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7706 - accuracy: 0.5830 - val_loss: 1.6920 - val_accuracy: 0.5987\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.6070 - accuracy: 0.6186 - val_loss: 1.5768 - val_accuracy: 0.6274\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5197 - accuracy: 0.6387 - val_loss: 1.5098 - val_accuracy: 0.6434\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4628 - accuracy: 0.6535 - val_loss: 1.4635 - val_accuracy: 0.6530\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4213 - accuracy: 0.6638 - val_loss: 1.4282 - val_accuracy: 0.6629\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3884 - accuracy: 0.6729 - val_loss: 1.3982 - val_accuracy: 0.6716\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3618 - accuracy: 0.6783 - val_loss: 1.3749 - val_accuracy: 0.6766\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3397 - accuracy: 0.6850 - val_loss: 1.3545 - val_accuracy: 0.6817\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3208 - accuracy: 0.6895 - val_loss: 1.3384 - val_accuracy: 0.6860\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3047 - accuracy: 0.6922 - val_loss: 1.3233 - val_accuracy: 0.6895\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2911 - accuracy: 0.6967 - val_loss: 1.3103 - val_accuracy: 0.6938\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2791 - accuracy: 0.6992 - val_loss: 1.2998 - val_accuracy: 0.6966\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2688 - accuracy: 0.7019 - val_loss: 1.2900 - val_accuracy: 0.6990\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2598 - accuracy: 0.7044 - val_loss: 1.2817 - val_accuracy: 0.7003\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2518 - accuracy: 0.7066 - val_loss: 1.2747 - val_accuracy: 0.7020\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2450 - accuracy: 0.7074 - val_loss: 1.2684 - val_accuracy: 0.7040\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2389 - accuracy: 0.7092 - val_loss: 1.2624 - val_accuracy: 0.7059\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:17.966064\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2343 - accuracy: 0.7104 - val_loss: 1.2599 - val_accuracy: 0.7061\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2319 - accuracy: 0.7112 - val_loss: 1.2585 - val_accuracy: 0.7058\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2308 - accuracy: 0.7115 - val_loss: 1.2578 - val_accuracy: 0.7060\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2302 - accuracy: 0.7114 - val_loss: 1.2575 - val_accuracy: 0.7062\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2300 - accuracy: 0.7116 - val_loss: 1.2574 - val_accuracy: 0.7063\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 1.2298 - accuracy: 0.7116 - val_loss: 1.2573 - val_accuracy: 0.7064\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 1.2298 - accuracy: 0.7116 - val_loss: 1.2573 - val_accuracy: 0.7064\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.2298 - accuracy: 0.7116 - val_loss: 1.2573 - val_accuracy: 0.7064\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 31s 45ms/step - loss: 1.2298 - accuracy: 0.7116 - val_loss: 1.2573 - val_accuracy: 0.7064\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2298 - accuracy: 0.7116 - val_loss: 1.2573 - val_accuracy: 0.7064\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2298 - accuracy: 0.7116 - val_loss: 1.2573 - val_accuracy: 0.7064\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:05:20.718572\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 4.0259 - accuracy: 0.0588 - val_loss: 3.9218 - val_accuracy: 0.1293\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.5952 - accuracy: 0.2533 - val_loss: 3.0717 - val_accuracy: 0.3699\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 2.4465 - accuracy: 0.4680 - val_loss: 2.0113 - val_accuracy: 0.5349\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.8184 - accuracy: 0.5770 - val_loss: 1.7047 - val_accuracy: 0.5924\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.6179 - accuracy: 0.6176 - val_loss: 1.5703 - val_accuracy: 0.6192\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5173 - accuracy: 0.6416 - val_loss: 1.4939 - val_accuracy: 0.6401\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4538 - accuracy: 0.6565 - val_loss: 1.4425 - val_accuracy: 0.6521\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4079 - accuracy: 0.6678 - val_loss: 1.4029 - val_accuracy: 0.6630\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3723 - accuracy: 0.6763 - val_loss: 1.3710 - val_accuracy: 0.6719\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3433 - accuracy: 0.6833 - val_loss: 1.3457 - val_accuracy: 0.6764\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3193 - accuracy: 0.6893 - val_loss: 1.3247 - val_accuracy: 0.6820\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2990 - accuracy: 0.6944 - val_loss: 1.3050 - val_accuracy: 0.6872\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2818 - accuracy: 0.6983 - val_loss: 1.2895 - val_accuracy: 0.6907\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2670 - accuracy: 0.7017 - val_loss: 1.2762 - val_accuracy: 0.6945\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2543 - accuracy: 0.7049 - val_loss: 1.2652 - val_accuracy: 0.6978\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2433 - accuracy: 0.7078 - val_loss: 1.2545 - val_accuracy: 0.6992\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2335 - accuracy: 0.7102 - val_loss: 1.2461 - val_accuracy: 0.7019\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2252 - accuracy: 0.7123 - val_loss: 1.2384 - val_accuracy: 0.7039\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2179 - accuracy: 0.7137 - val_loss: 1.2320 - val_accuracy: 0.7065\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2114 - accuracy: 0.7157 - val_loss: 1.2262 - val_accuracy: 0.7070\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:19.003994\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 1.2065 - accuracy: 0.7172 - val_loss: 1.2229 - val_accuracy: 0.7084\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2041 - accuracy: 0.7176 - val_loss: 1.2216 - val_accuracy: 0.7091\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2028 - accuracy: 0.7182 - val_loss: 1.2209 - val_accuracy: 0.7090\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2023 - accuracy: 0.7183 - val_loss: 1.2206 - val_accuracy: 0.7090\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2020 - accuracy: 0.7186 - val_loss: 1.2205 - val_accuracy: 0.7090\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:02:23.987829\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.9908 - accuracy: 0.0825 - val_loss: 3.8228 - val_accuracy: 0.1769\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 3.3427 - accuracy: 0.3016 - val_loss: 2.6983 - val_accuracy: 0.4282\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.2099 - accuracy: 0.5123 - val_loss: 1.8891 - val_accuracy: 0.5639\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.7534 - accuracy: 0.5906 - val_loss: 1.6514 - val_accuracy: 0.6085\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.5956 - accuracy: 0.6228 - val_loss: 1.5457 - val_accuracy: 0.6330\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.5090 - accuracy: 0.6431 - val_loss: 1.4747 - val_accuracy: 0.6513\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4508 - accuracy: 0.6568 - val_loss: 1.4274 - val_accuracy: 0.6624\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.4073 - accuracy: 0.6679 - val_loss: 1.3891 - val_accuracy: 0.6715\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3726 - accuracy: 0.6754 - val_loss: 1.3583 - val_accuracy: 0.6773\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.3440 - accuracy: 0.6822 - val_loss: 1.3333 - val_accuracy: 0.6847\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3203 - accuracy: 0.6889 - val_loss: 1.3123 - val_accuracy: 0.6903\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.3002 - accuracy: 0.6935 - val_loss: 1.2935 - val_accuracy: 0.6945\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2831 - accuracy: 0.6987 - val_loss: 1.2783 - val_accuracy: 0.6977\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2684 - accuracy: 0.7021 - val_loss: 1.2667 - val_accuracy: 0.7007\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2557 - accuracy: 0.7050 - val_loss: 1.2543 - val_accuracy: 0.7030\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2448 - accuracy: 0.7084 - val_loss: 1.2445 - val_accuracy: 0.7060\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2353 - accuracy: 0.7105 - val_loss: 1.2356 - val_accuracy: 0.7092\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2271 - accuracy: 0.7126 - val_loss: 1.2280 - val_accuracy: 0.7102\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2199 - accuracy: 0.7142 - val_loss: 1.2213 - val_accuracy: 0.7125\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2135 - accuracy: 0.7162 - val_loss: 1.2157 - val_accuracy: 0.7141\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:09:17.735559\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 1.2087 - accuracy: 0.7173 - val_loss: 1.2126 - val_accuracy: 0.7148\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 1.2062 - accuracy: 0.7177 - val_loss: 1.2112 - val_accuracy: 0.7148\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2051 - accuracy: 0.7183 - val_loss: 1.2105 - val_accuracy: 0.7150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2045 - accuracy: 0.7185 - val_loss: 1.2102 - val_accuracy: 0.7151\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2042 - accuracy: 0.7184 - val_loss: 1.2101 - val_accuracy: 0.7153\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2041 - accuracy: 0.7184 - val_loss: 1.2100 - val_accuracy: 0.7153\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 1.2041 - accuracy: 0.7184 - val_loss: 1.2100 - val_accuracy: 0.7153\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 28s 39ms/step - loss: 1.2040 - accuracy: 0.7183 - val_loss: 1.2100 - val_accuracy: 0.7153\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'elu'}\n",
      " Training time for the model is, 0:03:49.496553\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 4.0435 - accuracy: 0.0428 - val_loss: 3.9720 - val_accuracy: 0.0984\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 3.6852 - accuracy: 0.2021 - val_loss: 3.1495 - val_accuracy: 0.3269\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 2.5173 - accuracy: 0.4372 - val_loss: 2.0973 - val_accuracy: 0.5078\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.9122 - accuracy: 0.5456 - val_loss: 1.7824 - val_accuracy: 0.5760\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.7077 - accuracy: 0.5908 - val_loss: 1.6437 - val_accuracy: 0.6059\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6030 - accuracy: 0.6164 - val_loss: 1.5656 - val_accuracy: 0.6270\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.5387 - accuracy: 0.6317 - val_loss: 1.5125 - val_accuracy: 0.6356\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4936 - accuracy: 0.6421 - val_loss: 1.4755 - val_accuracy: 0.6452\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4592 - accuracy: 0.6512 - val_loss: 1.4460 - val_accuracy: 0.6557\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4314 - accuracy: 0.6585 - val_loss: 1.4206 - val_accuracy: 0.6631\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4081 - accuracy: 0.6648 - val_loss: 1.4024 - val_accuracy: 0.6658\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3887 - accuracy: 0.6698 - val_loss: 1.3831 - val_accuracy: 0.6703\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3726 - accuracy: 0.6736 - val_loss: 1.3689 - val_accuracy: 0.6750\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3584 - accuracy: 0.6777 - val_loss: 1.3551 - val_accuracy: 0.6793\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3463 - accuracy: 0.6806 - val_loss: 1.3443 - val_accuracy: 0.6823\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3356 - accuracy: 0.6828 - val_loss: 1.3351 - val_accuracy: 0.6824\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3264 - accuracy: 0.6850 - val_loss: 1.3267 - val_accuracy: 0.6844\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3184 - accuracy: 0.6870 - val_loss: 1.3189 - val_accuracy: 0.6873\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3112 - accuracy: 0.6890 - val_loss: 1.3124 - val_accuracy: 0.6883\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3050 - accuracy: 0.6906 - val_loss: 1.3071 - val_accuracy: 0.6887\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:46.661413\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 32s 46ms/step - loss: 1.3004 - accuracy: 0.6919 - val_loss: 1.3039 - val_accuracy: 0.6910\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 32s 46ms/step - loss: 1.2979 - accuracy: 0.6924 - val_loss: 1.3024 - val_accuracy: 0.6914\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2968 - accuracy: 0.6929 - val_loss: 1.3018 - val_accuracy: 0.6914\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2962 - accuracy: 0.6931 - val_loss: 1.3015 - val_accuracy: 0.6916\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2959 - accuracy: 0.6929 - val_loss: 1.3013 - val_accuracy: 0.6917\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2958 - accuracy: 0.6931 - val_loss: 1.3013 - val_accuracy: 0.6916\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2958 - accuracy: 0.6930 - val_loss: 1.3013 - val_accuracy: 0.6916\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2957 - accuracy: 0.6930 - val_loss: 1.3013 - val_accuracy: 0.6916\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:01.382691\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 32s 46ms/step - loss: 4.0603 - accuracy: 0.0496 - val_loss: 4.0219 - val_accuracy: 0.0637\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 32s 46ms/step - loss: 3.8813 - accuracy: 0.1143 - val_loss: 3.5977 - val_accuracy: 0.2249\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 28s 40ms/step - loss: 2.9254 - accuracy: 0.3661 - val_loss: 2.2993 - val_accuracy: 0.4756\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 2.0207 - accuracy: 0.5292 - val_loss: 1.8428 - val_accuracy: 0.5587\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.7411 - accuracy: 0.5866 - val_loss: 1.6755 - val_accuracy: 0.5979\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.6207 - accuracy: 0.6133 - val_loss: 1.5865 - val_accuracy: 0.6220\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.5506 - accuracy: 0.6303 - val_loss: 1.5294 - val_accuracy: 0.6356\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.5029 - accuracy: 0.6427 - val_loss: 1.4874 - val_accuracy: 0.6482\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.4663 - accuracy: 0.6516 - val_loss: 1.4568 - val_accuracy: 0.6552\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4372 - accuracy: 0.6585 - val_loss: 1.4316 - val_accuracy: 0.6613\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4133 - accuracy: 0.6647 - val_loss: 1.4099 - val_accuracy: 0.6695\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3932 - accuracy: 0.6700 - val_loss: 1.3918 - val_accuracy: 0.6706\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3762 - accuracy: 0.6744 - val_loss: 1.3768 - val_accuracy: 0.6757\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3615 - accuracy: 0.6777 - val_loss: 1.3638 - val_accuracy: 0.6777\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3491 - accuracy: 0.6804 - val_loss: 1.3517 - val_accuracy: 0.6819\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3380 - accuracy: 0.6832 - val_loss: 1.3409 - val_accuracy: 0.6840\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3285 - accuracy: 0.6856 - val_loss: 1.3328 - val_accuracy: 0.6862\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3201 - accuracy: 0.6884 - val_loss: 1.3247 - val_accuracy: 0.6881\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3128 - accuracy: 0.6896 - val_loss: 1.3185 - val_accuracy: 0.6898\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3063 - accuracy: 0.6912 - val_loss: 1.3124 - val_accuracy: 0.6899\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:52.406783\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.3014 - accuracy: 0.6929 - val_loss: 1.3091 - val_accuracy: 0.6903\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 31s 45ms/step - loss: 1.2990 - accuracy: 0.6936 - val_loss: 1.3075 - val_accuracy: 0.6906\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 1.2978 - accuracy: 0.6936 - val_loss: 1.3067 - val_accuracy: 0.6912\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2972 - accuracy: 0.6937 - val_loss: 1.3064 - val_accuracy: 0.6913\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2969 - accuracy: 0.6938 - val_loss: 1.3063 - val_accuracy: 0.6915\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2968 - accuracy: 0.6938 - val_loss: 1.3062 - val_accuracy: 0.6915\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2967 - accuracy: 0.6938 - val_loss: 1.3062 - val_accuracy: 0.6915\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2967 - accuracy: 0.6938 - val_loss: 1.3062 - val_accuracy: 0.6915\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2967 - accuracy: 0.6938 - val_loss: 1.3062 - val_accuracy: 0.6915\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:28.286516\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 4.0390 - accuracy: 0.0343 - val_loss: 3.9494 - val_accuracy: 0.0772\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 3.5943 - accuracy: 0.1956 - val_loss: 3.0007 - val_accuracy: 0.3506\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 2.4103 - accuracy: 0.4533 - val_loss: 2.0531 - val_accuracy: 0.5155\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.8759 - accuracy: 0.5555 - val_loss: 1.7772 - val_accuracy: 0.5785\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.6919 - accuracy: 0.5968 - val_loss: 1.6490 - val_accuracy: 0.6084\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.5939 - accuracy: 0.6192 - val_loss: 1.5735 - val_accuracy: 0.6258\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.5308 - accuracy: 0.6334 - val_loss: 1.5205 - val_accuracy: 0.6383\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.4855 - accuracy: 0.6450 - val_loss: 1.4813 - val_accuracy: 0.6479\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4503 - accuracy: 0.6533 - val_loss: 1.4484 - val_accuracy: 0.6547\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.4226 - accuracy: 0.6597 - val_loss: 1.4251 - val_accuracy: 0.6615\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3994 - accuracy: 0.6653 - val_loss: 1.4027 - val_accuracy: 0.6656\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.3800 - accuracy: 0.6702 - val_loss: 1.3855 - val_accuracy: 0.6708\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3632 - accuracy: 0.6751 - val_loss: 1.3709 - val_accuracy: 0.6732\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3493 - accuracy: 0.6784 - val_loss: 1.3570 - val_accuracy: 0.6762\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3369 - accuracy: 0.6823 - val_loss: 1.3459 - val_accuracy: 0.6796\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3261 - accuracy: 0.6847 - val_loss: 1.3356 - val_accuracy: 0.6827\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.3169 - accuracy: 0.6866 - val_loss: 1.3279 - val_accuracy: 0.6850\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3088 - accuracy: 0.6893 - val_loss: 1.3198 - val_accuracy: 0.6855\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3016 - accuracy: 0.6909 - val_loss: 1.3134 - val_accuracy: 0.6867\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2952 - accuracy: 0.6922 - val_loss: 1.3079 - val_accuracy: 0.6887\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:51.890882\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.2904 - accuracy: 0.6941 - val_loss: 1.3047 - val_accuracy: 0.6892\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 33s 46ms/step - loss: 1.2880 - accuracy: 0.6944 - val_loss: 1.3032 - val_accuracy: 0.6896\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 1.2868 - accuracy: 0.6946 - val_loss: 1.3026 - val_accuracy: 0.6896\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 31s 43ms/step - loss: 1.2862 - accuracy: 0.6951 - val_loss: 1.3023 - val_accuracy: 0.6897\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 32s 46ms/step - loss: 1.2859 - accuracy: 0.6951 - val_loss: 1.3021 - val_accuracy: 0.6898\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2858 - accuracy: 0.6950 - val_loss: 1.3021 - val_accuracy: 0.6897\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2857 - accuracy: 0.6951 - val_loss: 1.3021 - val_accuracy: 0.6897\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2857 - accuracy: 0.6951 - val_loss: 1.3020 - val_accuracy: 0.6897\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:04:05.345584\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 4.0514 - accuracy: 0.0444 - val_loss: 3.9966 - val_accuracy: 0.0928\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.7910 - accuracy: 0.1622 - val_loss: 3.3965 - val_accuracy: 0.2735\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 2.7186 - accuracy: 0.3970 - val_loss: 2.1726 - val_accuracy: 0.4985\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.9390 - accuracy: 0.5426 - val_loss: 1.7820 - val_accuracy: 0.5770\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.6940 - accuracy: 0.5952 - val_loss: 1.6314 - val_accuracy: 0.6094\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.5808 - accuracy: 0.6217 - val_loss: 1.5500 - val_accuracy: 0.6301\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.5131 - accuracy: 0.6381 - val_loss: 1.4960 - val_accuracy: 0.6440\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4655 - accuracy: 0.6492 - val_loss: 1.4550 - val_accuracy: 0.6533\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.4284 - accuracy: 0.6590 - val_loss: 1.4223 - val_accuracy: 0.6603\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3987 - accuracy: 0.6666 - val_loss: 1.3962 - val_accuracy: 0.6670\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705/705 [==============================] - 30s 42ms/step - loss: 1.3745 - accuracy: 0.6735 - val_loss: 1.3739 - val_accuracy: 0.6743\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3540 - accuracy: 0.6792 - val_loss: 1.3560 - val_accuracy: 0.6780\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3366 - accuracy: 0.6835 - val_loss: 1.3404 - val_accuracy: 0.6814\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3216 - accuracy: 0.6878 - val_loss: 1.3265 - val_accuracy: 0.6841\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3087 - accuracy: 0.6903 - val_loss: 1.3147 - val_accuracy: 0.6875\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2975 - accuracy: 0.6940 - val_loss: 1.3038 - val_accuracy: 0.6906\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2878 - accuracy: 0.6961 - val_loss: 1.2949 - val_accuracy: 0.6934\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2792 - accuracy: 0.6983 - val_loss: 1.2871 - val_accuracy: 0.6952\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2718 - accuracy: 0.7005 - val_loss: 1.2804 - val_accuracy: 0.6970\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2652 - accuracy: 0.7018 - val_loss: 1.2749 - val_accuracy: 0.6988\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:09:50.978460\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2603 - accuracy: 0.7032 - val_loss: 1.2715 - val_accuracy: 0.6995\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.2577 - accuracy: 0.7038 - val_loss: 1.2698 - val_accuracy: 0.6994\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2565 - accuracy: 0.7040 - val_loss: 1.2691 - val_accuracy: 0.6996\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2559 - accuracy: 0.7046 - val_loss: 1.2688 - val_accuracy: 0.6996\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2556 - accuracy: 0.7046 - val_loss: 1.2686 - val_accuracy: 0.6996\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2555 - accuracy: 0.7046 - val_loss: 1.2686 - val_accuracy: 0.6996\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:02:58.705842\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 4.0665 - accuracy: 0.0530 - val_loss: 4.0307 - val_accuracy: 0.0835\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 3.9307 - accuracy: 0.1202 - val_loss: 3.7440 - val_accuracy: 0.1801\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 3.1978 - accuracy: 0.3059 - val_loss: 2.5521 - val_accuracy: 0.4247\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 2.1727 - accuracy: 0.4961 - val_loss: 1.9124 - val_accuracy: 0.5459\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 30s 43ms/step - loss: 1.7928 - accuracy: 0.5731 - val_loss: 1.6952 - val_accuracy: 0.5943\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 1.6372 - accuracy: 0.6102 - val_loss: 1.5871 - val_accuracy: 0.6206\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 33s 47ms/step - loss: 1.5504 - accuracy: 0.6304 - val_loss: 1.5186 - val_accuracy: 0.6369\n",
      "Epoch 8/20\n",
      "705/705 [==============================] - 32s 45ms/step - loss: 1.4919 - accuracy: 0.6455 - val_loss: 1.4715 - val_accuracy: 0.6498\n",
      "Epoch 9/20\n",
      "705/705 [==============================] - 31s 44ms/step - loss: 1.4486 - accuracy: 0.6563 - val_loss: 1.4339 - val_accuracy: 0.6594\n",
      "Epoch 10/20\n",
      "705/705 [==============================] - 33s 47ms/step - loss: 1.4145 - accuracy: 0.6647 - val_loss: 1.4041 - val_accuracy: 0.6688\n",
      "Epoch 11/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.3869 - accuracy: 0.6719 - val_loss: 1.3787 - val_accuracy: 0.6747\n",
      "Epoch 12/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.3636 - accuracy: 0.6777 - val_loss: 1.3594 - val_accuracy: 0.6786\n",
      "Epoch 13/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.3444 - accuracy: 0.6831 - val_loss: 1.3416 - val_accuracy: 0.6819\n",
      "Epoch 14/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.3281 - accuracy: 0.6873 - val_loss: 1.3266 - val_accuracy: 0.6882\n",
      "Epoch 15/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.3138 - accuracy: 0.6909 - val_loss: 1.3150 - val_accuracy: 0.6894\n",
      "Epoch 16/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.3017 - accuracy: 0.6941 - val_loss: 1.3024 - val_accuracy: 0.6918\n",
      "Epoch 17/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2910 - accuracy: 0.6968 - val_loss: 1.2938 - val_accuracy: 0.6954\n",
      "Epoch 18/20\n",
      "705/705 [==============================] - 30s 42ms/step - loss: 1.2819 - accuracy: 0.6992 - val_loss: 1.2854 - val_accuracy: 0.6950\n",
      "Epoch 19/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2740 - accuracy: 0.7011 - val_loss: 1.2779 - val_accuracy: 0.6986\n",
      "Epoch 20/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2670 - accuracy: 0.7030 - val_loss: 1.2715 - val_accuracy: 0.6993\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:10:07.014793\n",
      "Epoch 1/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2616 - accuracy: 0.7039 - val_loss: 1.2681 - val_accuracy: 0.7006\n",
      "Epoch 2/20\n",
      "705/705 [==============================] - 29s 41ms/step - loss: 1.2589 - accuracy: 0.7050 - val_loss: 1.2665 - val_accuracy: 0.7004\n",
      "Epoch 3/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2576 - accuracy: 0.7055 - val_loss: 1.2657 - val_accuracy: 0.7006\n",
      "Epoch 4/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2570 - accuracy: 0.7054 - val_loss: 1.2654 - val_accuracy: 0.7007\n",
      "Epoch 5/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2567 - accuracy: 0.7056 - val_loss: 1.2652 - val_accuracy: 0.7006\n",
      "Epoch 6/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2566 - accuracy: 0.7056 - val_loss: 1.2652 - val_accuracy: 0.7007\n",
      "Epoch 7/20\n",
      "705/705 [==============================] - 29s 42ms/step - loss: 1.2565 - accuracy: 0.7056 - val_loss: 1.2652 - val_accuracy: 0.7007\n",
      " Hyperparameter combinations for training, {'optimizer': 'adagrad', 'batchNorm': False, 'dropOut': False, 'reg': <tensorflow.python.keras.regularizers.L2 object at 0x00000200846D6C70>, 'activation': 'leaky_relu'}\n",
      " Training time for the model is, 0:03:25.722837\n"
     ]
    }
   ],
   "source": [
    "# initializing the basis for the best combination\n",
    "best_cnn_model = None \n",
    "best_cnn_acc = 0.0            # best accuracy\n",
    "\n",
    "for params in itertools.product(*hyperparams.values()): # performing a grid search\n",
    "    param_dict = dict(zip(hyperparams.keys(), params))  # producing a combo of all possible hyperparams\n",
    "    accuracies = []\n",
    "    for train_index, val_index in kf.split(ds_train_images):\n",
    "        # Split data into training and validation sets\n",
    "\n",
    "        new_train_ds, new_train_labels = ds_train_images[train_index], ds_train_labels[train_index]\n",
    "        new_val_ds, new_val_labels = ds_train_images[val_index], ds_train_labels[val_index]\n",
    "        model = cnn_model(**param_dict) # double asterix to unpack key-value pairs in dictionary\n",
    "        \n",
    "        for scheduler in schedulers:\n",
    "            # define the learning rate schedulers\n",
    "            lr_scheduler = LearningRateScheduler(scheduler)\n",
    "            # train the model\n",
    "            start_time = datetime.datetime.now()            # start the timer\n",
    "            # history = model.fit(train_ds.batch(128),\n",
    "            history = model.fit(new_train_ds, new_train_labels, batch_size=128,\n",
    "                                     epochs=20,\n",
    "                                     validation_data=(new_val_ds, new_val_labels),\n",
    "                                     callbacks=[lr_scheduler, early_stopping])\n",
    "            accuracies.append(history.history['val_accuracy'][-1])\n",
    "            end_time = datetime.datetime.now()             # end timer\n",
    "            total_time = end_time - start_time\n",
    "            print(f' Hyperparameter combinations for training, {param_dict}')\n",
    "            print(f' Training time for the model is, {total_time}')\n",
    "            \n",
    "            \n",
    "    avg_acc = np.mean(accuracies)\n",
    "    \n",
    "    # To ascertain if current set of hyperparameters are best\n",
    "    if avg_acc > best_cnn_acc:\n",
    "        best_cnn_acc = avg_acc\n",
    "        best_cnn_model = cnn_model(**param_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39f02797",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn_model.save(\"best_cnn_model.h5\")\n",
    "saved_cnn_model = keras.models.load_model(\"best_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26868d",
   "metadata": {},
   "source": [
    "### CNN Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48face46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588/588 - 2s - loss: 0.4393 - accuracy: 0.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4393307864665985, 0.8778723478317261]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cnn_model.evaluate(ds_test_images, ds_test_labels, verbose=2) # evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "236b3bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "882/882 [==============================] - 36s 41ms/step - loss: 1.1171 - accuracy: 0.7020 - val_loss: 0.6196 - val_accuracy: 0.8341\n",
      "Epoch 2/20\n",
      "882/882 [==============================] - 37s 42ms/step - loss: 0.6585 - accuracy: 0.8180 - val_loss: 0.5304 - val_accuracy: 0.8531\n",
      "Epoch 3/20\n",
      "882/882 [==============================] - 36s 40ms/step - loss: 0.5861 - accuracy: 0.8345 - val_loss: 0.5072 - val_accuracy: 0.8514\n",
      "Epoch 4/20\n",
      "882/882 [==============================] - 36s 40ms/step - loss: 0.5508 - accuracy: 0.8425 - val_loss: 0.4642 - val_accuracy: 0.8711\n",
      "Epoch 5/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.5262 - accuracy: 0.8507 - val_loss: 0.4440 - val_accuracy: 0.8742\n",
      "Epoch 6/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.5089 - accuracy: 0.8538 - val_loss: 0.4314 - val_accuracy: 0.8743\n",
      "Epoch 7/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4933 - accuracy: 0.8597 - val_loss: 0.4141 - val_accuracy: 0.8843\n",
      "Epoch 8/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4825 - accuracy: 0.8619 - val_loss: 0.4124 - val_accuracy: 0.8836\n",
      "Epoch 9/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4741 - accuracy: 0.8661 - val_loss: 0.4042 - val_accuracy: 0.8869\n",
      "Epoch 10/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4629 - accuracy: 0.8686 - val_loss: 0.3868 - val_accuracy: 0.8918\n",
      "Epoch 11/20\n",
      "882/882 [==============================] - 36s 40ms/step - loss: 0.4558 - accuracy: 0.8697 - val_loss: 0.3872 - val_accuracy: 0.8934\n",
      "Epoch 12/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4501 - accuracy: 0.8728 - val_loss: 0.3817 - val_accuracy: 0.8942\n",
      "Epoch 13/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4453 - accuracy: 0.8728 - val_loss: 0.3757 - val_accuracy: 0.8948\n",
      "Epoch 14/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4384 - accuracy: 0.8758 - val_loss: 0.3737 - val_accuracy: 0.8967\n",
      "Epoch 15/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4355 - accuracy: 0.8756 - val_loss: 0.3606 - val_accuracy: 0.9006\n",
      "Epoch 16/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4306 - accuracy: 0.8778 - val_loss: 0.3636 - val_accuracy: 0.8994\n",
      "Epoch 17/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4273 - accuracy: 0.8789 - val_loss: 0.3620 - val_accuracy: 0.8983\n",
      "Epoch 18/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4257 - accuracy: 0.8792 - val_loss: 0.3568 - val_accuracy: 0.9008\n",
      "Epoch 19/20\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.4219 - accuracy: 0.8800 - val_loss: 0.3538 - val_accuracy: 0.9027\n",
      "Epoch 20/20\n",
      "882/882 [==============================] - 36s 40ms/step - loss: 0.4191 - accuracy: 0.8809 - val_loss: 0.3491 - val_accuracy: 0.9033\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = best_cnn_model.fit(ds_train_images, ds_train_labels, batch_size=128,\n",
    "                             epochs=20,\n",
    "                             validation_data=(new_val_ds, new_val_labels))\n",
    "\n",
    "\n",
    "# plot the loss and accuracy graphs\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss function graph respect to the iteration/epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy graph respect to the iteration/epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f5f649d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_result = best_cnn_model.predict(ds_test_images)\n",
    "\n",
    "cnn_result_val = [max(row) for row in result]\n",
    "cnn_result_val = np.array(cnn_result_val)\n",
    "\n",
    "# Getting indices of N = 6 maximum values\n",
    "six_best = np.argsort(cnn_result_val)[::-1][:6]\n",
    "\n",
    "# Getting N maximum values\n",
    "# resultValue[six_best]\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "for img, label, value, ax in zip(ds_test_images[six_best], ds_test_labels[six_best], cnn_result_val[six_best], axes):\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(str(label) + \"\\nscore:\" + str(value))\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "508eafe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[195   0   0 ...   0   0   0]\n",
      " [  0 290   1 ...   0   0   0]\n",
      " [  0   0 354 ...   0   0   0]\n",
      " ...\n",
      " [  0   1   0 ... 232   0   0]\n",
      " [  0   0   0 ...   0 378   3]\n",
      " [  0   0   0 ...   0   4 368]]\n",
      "\n",
      "Precision: 0.880\n",
      "Recall: 0.878\n",
      "F1 Score: 0.876\n"
     ]
    }
   ],
   "source": [
    "# get the predicted labels\n",
    "y_pred_labels = np.argmax(cnn_result, axis=1)\n",
    "\n",
    "# calculate the confusion matrix\n",
    "conf_mat = confusion_matrix(ds_test_labels, y_pred_labels)\n",
    "\n",
    "# calculate the precision, recall, and F1 score\n",
    "precision = precision_score(ds_test_labels, y_pred_labels, average='weighted')\n",
    "recall = recall_score(ds_test_labels, y_pred_labels, average='weighted')\n",
    "f1 = f1_score(ds_test_labels, y_pred_labels, average='weighted')\n",
    "\n",
    "# print the confusion matrix and the metrics\n",
    "print(f\"Confusion matrix:\\n{conf_mat}\\n\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1 Score: {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
